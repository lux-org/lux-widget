{"version":3,"sources":["webpack://luxwidget/./node_modules/array-flat-polyfill/index.mjs","webpack://luxwidget/./node_modules/clone/clone.js","webpack://luxwidget/./node_modules/fast-deep-equal/index.js","webpack://luxwidget/./node_modules/fast-json-stable-stringify/index.js","webpack://luxwidget/./node_modules/vega-event-selector/build/vega-event-selector.module.js","webpack://luxwidget/./node_modules/vega-lite/build/src/aggregate.js","webpack://luxwidget/./node_modules/vega-lite/build/src/axis.js","webpack://luxwidget/./node_modules/vega-lite/build/src/bin.js","webpack://luxwidget/./node_modules/vega-lite/build/src/channel.js","webpack://luxwidget/./node_modules/vega-lite/build/src/channeldef.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/axis/assemble.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/axis/component.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/axis/config.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/axis/encode.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/axis/parse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/axis/properties.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/buildmodel.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/common.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/compile.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/concat.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/aggregate.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/assemble.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/bin.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/calculate.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/dataflow.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/density.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/expressions.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/facet.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/filter.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/filterinvalid.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/flatten.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/fold.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/formatparse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/geojson.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/geopoint.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/graticule.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/identifier.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/impute.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/index.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/joinaggregate.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/joinaggregatefacet.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/loess.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/lookup.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/optimize.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/optimizer.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/optimizers.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/parse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/pivot.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/quantile.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/regression.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/sample.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/sequence.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/source.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/stack.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/subtree.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/timeunit.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/data/window.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/facet.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/format.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/guide.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/header/assemble.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/header/common.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/header/component.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/header/parse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/layer.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/layoutsize/assemble.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/layoutsize/component.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/layoutsize/init.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/layoutsize/parse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/legend/assemble.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/legend/component.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/legend/encode.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/legend/parse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/legend/properties.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/arc.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/area.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/bar.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/aria.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/base.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/color.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/conditional.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/defined.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/index.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/nonposition.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/offset.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/position-align.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/position-point.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/position-range.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/position-rect.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/text.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/tooltip.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/valueref.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/encode/zindex.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/geoshape.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/image.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/init.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/line.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/mark.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/point.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/rect.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/rule.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/text.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/mark/tick.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/model.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/predicate.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/projection/assemble.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/projection/component.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/projection/parse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/resolve.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/scale/assemble.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/scale/component.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/scale/domain.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/scale/parse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/scale/properties.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/scale/range.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/scale/type.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/assemble.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/index.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/interval.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/multi.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/parse.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/single.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/clear.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/inputs.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/legends.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/nearest.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/project.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/scales.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/toggle.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/transforms.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/translate.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/selection/transforms/zoom.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/signal.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/split.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compile/unit.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compositemark/base.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compositemark/boxplot.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compositemark/common.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compositemark/errorband.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compositemark/errorbar.js","webpack://luxwidget/./node_modules/vega-lite/build/src/compositemark/index.js","webpack://luxwidget/./node_modules/vega-lite/build/src/config.js","webpack://luxwidget/./node_modules/vega-lite/build/src/data.js","webpack://luxwidget/./node_modules/vega-lite/build/src/datetime.js","webpack://luxwidget/./node_modules/vega-lite/build/src/encoding.js","webpack://luxwidget/./node_modules/vega-lite/build/src/expr.js","webpack://luxwidget/./node_modules/vega-lite/build/src/guide.js","webpack://luxwidget/./node_modules/vega-lite/build/src/header.js","webpack://luxwidget/./node_modules/vega-lite/build/src/index.js","webpack://luxwidget/./node_modules/vega-lite/build/src/legend.js","webpack://luxwidget/./node_modules/vega-lite/build/src/log/index.js","webpack://luxwidget/./node_modules/vega-lite/build/src/log/message.js","webpack://luxwidget/./node_modules/vega-lite/build/src/logical.js","webpack://luxwidget/./node_modules/vega-lite/build/src/mark.js","webpack://luxwidget/./node_modules/vega-lite/build/src/normalize/core.js","webpack://luxwidget/./node_modules/vega-lite/build/src/normalize/index.js","webpack://luxwidget/./node_modules/vega-lite/build/src/normalize/pathoverlay.js","webpack://luxwidget/./node_modules/vega-lite/build/src/normalize/rangestep.js","webpack://luxwidget/./node_modules/vega-lite/build/src/normalize/repeater.js","webpack://luxwidget/./node_modules/vega-lite/build/src/normalize/ruleforrangedline.js","webpack://luxwidget/./node_modules/vega-lite/build/src/parameter.js","webpack://luxwidget/./node_modules/vega-lite/build/src/predicate.js","webpack://luxwidget/./node_modules/vega-lite/build/src/projection.js","webpack://luxwidget/./node_modules/vega-lite/build/src/scale.js","webpack://luxwidget/./node_modules/vega-lite/build/src/selection.js","webpack://luxwidget/./node_modules/vega-lite/build/src/sort.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/base.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/concat.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/facet.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/index.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/layer.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/map.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/repeat.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/toplevel.js","webpack://luxwidget/./node_modules/vega-lite/build/src/spec/unit.js","webpack://luxwidget/./node_modules/vega-lite/build/src/stack.js","webpack://luxwidget/./node_modules/vega-lite/build/src/timeunit.js","webpack://luxwidget/./node_modules/vega-lite/build/src/title.js","webpack://luxwidget/./node_modules/vega-lite/build/src/transform.js","webpack://luxwidget/./node_modules/vega-lite/build/src/type.js","webpack://luxwidget/./node_modules/vega-lite/build/src/util.js","webpack://luxwidget/./node_modules/vega-lite/build/src/vega.schema.js","webpack://luxwidget/./node_modules/vega-lite/node_modules/vega-expression/build/vega-expression.module.js"],"names":[],"mappings":";;;;;;;;;;AAAA,oEAAoE,mCAAmC,iDAAiD,wDAAwD,kEAAkE,sCAAsC,aAAa,4EAA4E,kCAAkC,wDAAwD,aAAa;;;;;;;;;;;ACAxf;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,oBAAoB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,6BAA6B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;;AAED,IAAI,KAA0B;AAC9B;AACA;;;;;;;;;;;;AChQa;;AAEb;;;;AAIA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,sBAAsB,WAAW;AACjC;AACA;AACA;;;;AAIA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,oBAAoB,WAAW;AAC/B;;AAEA,oBAAoB,WAAW;AAC/B;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;AC7Ca;;AAEb;AACA;AACA,4CAA4C;AAC5C;;AAEA;AACA;AACA;AACA,4BAA4B;AAC5B,4BAA4B;AAC5B;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B,KAAK;AACL;;;;;;;;;;;;;;;;AC1DA;AACA;AACA;AACA,iBAAiB;AACjB,iBAAiB;AACjB;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,QAAQ,OAAO;AACf;AACA,0CAA0C,qDAAqD;AAC/F;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;;AAEb;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA,kBAAkB;;AAElB,oCAAoC;;AAEpC;;AAEA;AACA;AACA;AACA,GAAG;;;AAGH;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;;;AAGH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;;AAGH;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEqC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxNO;AACJ;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO,sBAAsB,2CAAI;AAC1B;AACP,WAAW,mDAAQ;AACnB;AACO;AACA;AACP,WAAW,mDAAQ,eAAe,+CAAQ;AAC1C;AACO;AACP,WAAW,mDAAQ,eAAe,+CAAQ;AAC1C;AACA;AACO;AACP;AACA;AACA;AACO;AACA,+BAA+B,gDAAK;AAC3C,qC;;;;;;;;;;;;;;;;;;;;;;;ACxD8B;AACvB;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,kCAAkC,sCAAsC;AAC7H;AACP;AACA;AACA;AACO,wBAAwB,2CAAI;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,2CAAI;AAChC,gC;;;;;;;;;;;;;;;;;;;;;;;;ACnRgD;AACwF;AAC5F;AACI;AAChD;AACA;AACA;AACO;AACP,QAAQ,oDAAS;AACjB,cAAc,yDAAY;AAC1B;AACA;AACA,QAAQ,2CAAI;AACZ,mDAAmD,8CAAO,KAAK,EAAE,GAAG,8CAAO,SAAS,KAAK,8CAAO,KAAK,EAAE,GAAG,OAAO;AACjH;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP,WAAW,mDAAQ;AACnB;AACO;AACP;AACA;AACO;AACP;AACA,aAAa,yCAAG;AAChB,aAAa,4CAAM;AACnB,aAAa,0CAAI;AACjB,aAAa,2CAAK;AAClB,aAAa,0CAAI;AACjB,aAAa,4CAAM;AACnB,aAAa,iDAAW;AACxB,aAAa,6CAAO;AACpB,aAAa,iDAAW;AACxB,aAAa,mDAAa;AAC1B;AACA;AACA,aAAa,2CAAK;AAClB,qBAAqB;AACrB,aAAa,gDAAU;AACvB,qBAAqB;AACrB;AACA;AACA;AACA;AACA,+B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxDA;AACA;AACA;AACA;AACA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC8B;AAC9B;AACO;AACA;AACA;AACP;AACO;AACA;AACA;AACA;AACP;AACO;AACA;AACA;AACA;AACP;AACO;AACA;AACA;AACA;AACP;AACO;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACP;AACO;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO,6BAA6B,2CAAI;AACxC,qFAAqF,wF;AACrF;AACA;AACA;AACA;AACA;AACA,uFAAuF;AAChF;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,2CAAI;AAClC,oDAAoD;AAC7C,iBAAiB,2CAAI;AAC5B,OAAO,uCAAuC;AAC9C,OAAO,iCAAiC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,2CAAI;AAChC,iCAAiC,2CAAI;AACrC;AACP;AACA;AACO;AACP;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,2CAAI;AACjC;AACA,OAAO;AACP;AACA,kLAAkL;AAClL;AACA;AACO,6BAA6B,2CAAI;AACjC;AACP;AACA;AACA;AACO,gCAAgC,2CAAI;AACpC;AACP;AACA;AACO;AACP;AACA;AACA;AACO,sCAAsC,2CAAI;AAC1C;AACP;AACA;AACA;AACA,O;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAC3B,mCAAmC,2CAAI;AACvC;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE;AACxE;AACO,uBAAuB,2CAAI;AAC3B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,eAAe;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA,oBAAoB;AACpB;AACA,oBAAoB;AACpB;AACA,oBAAoB;AACpB;AACA,oBAAoB;AACpB;AACA,oBAAoB;AACpB;AACA;AACA,oBAAoB;AACpB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClcA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACmE;AAC0B;AACvB;AACsR;AAC3S;AACK;AACE;AACrB;AACN;AACY;AACM;AACN;AACM;AAC2D;AACvD;AAC8F;AACrG;AACrC;AACP;AACA;AACO;AACP,qBAAqB,mDAAQ;AAC7B;AACO;AACP,WAAW,kCAAkC;AAC7C,qEAAqE,eAAe,WAAW,KAAK,YAAY,MAAM,KAAK,kBAAkB,YAAY,KAAK,KAAK,QAAQ;AAC3K;AACO;AACP;AACA;AACO,kBAAkB,yEAAyE;AAClG;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B;AACA;AACA,uBAAuB,8DAAa;AACpC;AACA;AACA,uBAAuB,sDAAe,cAAc,8DAAa;AACjE;AACA;AACA,iBAAiB,+CAAS;AAC1B,mBAAmB,sDAAe;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,+CAAS;AACjB,0BAA0B,uDAAuD;AACjF;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA,2BAA2B,kDAAO;AAClC;AACO;AACP;AACA,2BAA2B,kDAAO;AAClC;AACO;AACP;AACA,2BAA2B,kDAAO;AAClC;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP,6BAA6B,mDAAQ;AACrC;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA,WAAW,4CAAI;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACO,mCAAmC;AAC1C;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,gBAAgB,qDAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2BAA2B;AAClD,oBAAoB,+CAAS;AAC7B,yBAAyB,iDAAW;AACpC;AACA;AACA;AACA,wBAAwB,uDAAW;AACnC,2CAA2C,MAAM;AACjD,0CAA0C,iBAAiB;AAC3D;AACA,6BAA6B,uDAAW;AACxC,2CAA2C,MAAM;AACjD,0CAA0C,iBAAiB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,4DAAgB;AACzC,gCAAgC,gDAAQ;AACxC;AACA;AACA;AACA;AACA,+BAA+B,GAAG,GAAG,MAAM;AAC3C;AACA;AACA;AACA,mBAAmB,MAAM,GAAG,OAAO;AACnC;AACA;AACA,mBAAmB,OAAO,GAAG,MAAM;AACnC;AACA;AACA,eAAe,2DAAmB;AAClC;AACA;AACA;AACA,eAAe,2DAAmB;AAClC;AACA;AACA;AACA,eAAe,0DAAkB;AACjC;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,0DAA4B;AAChD;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA,WAAW,kCAAkC;AAC7C;AACA;AACA;AACA,aAAa,+CAAS;AACtB,kBAAkB,MAAM;AACxB;AACA;AACA,2BAA2B,6DAAiB;AAC5C;AACA,sBAAsB,MAAM,IAAI,4DAAgB,iBAAiB;AACjE;AACA;AACA;AACA,YAAY,uDAAW;AACvB,sBAAsB,MAAM,WAAW,iBAAiB;AACxD;AACA,iBAAiB,uDAAW;AAC5B,sBAAsB,MAAM,WAAW,iBAAiB;AACxD;AACA;AACA,sBAAsB,iDAAS,YAAY,MAAM,MAAM;AACvD;AACA;AACA;AACA;AACO;AACP,WAAW,kCAAkC;AAC7C,QAAQ,uDAAW;AACnB,kBAAkB,MAAM,cAAc,iBAAiB;AACvD;AACA,aAAa,uDAAW;AACxB,kBAAkB,MAAM,cAAc,iBAAiB;AACvD;AACA,2BAA2B,6DAAiB;AAC5C,kOAAkO,+CAAS;AAC3O;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO,yCAAyC,wCAAwC;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAe;AAC9B;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,6DAAe;AAC5B;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA,eAAe,qBAAqB;AACpC,gBAAgB;AAChB;AACA;AACA;AACA,eAAe,qBAAqB;AACpC,gBAAgB;AAChB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,kDAAO;AAC/C;AACA;AACA,WAAW,2BAA2B;AACtC;AACA;AACA;AACA,8BAA8B,uDAAW,gBAAgB,uDAAW;AACpE;AACA;AACA;AACA,gBAAgB,yDAAoB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,6DAA6D;AACpE,QAAQ,mDAAQ,gBAAgB,mDAAQ,gBAAgB,oDAAS;AACjE,8BAA8B,mDAAQ,0BAA0B,mDAAQ;AACxE,QAAQ,sCAAQ,CAAC,6DAA+B;AAChD,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,gB;AAC7C;AACA,wFAAwF;AACxF;AACA;AACA;AACO;AACP;AACA,eAAe,qBAAqB;AACpC,YAAY,mEAAkB;AAC9B,YAAY,sCAAQ,CAAC,oEAAsC;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,6DAAe;AACjC;AACA;AACA;AACA,uCAAuC,qBAAqB;AAC5D,gBAAgB,mEAAkB;AAClC,gBAAgB,sCAAQ,CAAC,oEAAsC;AAC/D,yEAAyE,QAAQ,wBAAwB;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,mDAAQ,2BAA2B,mDAAQ,sBAAsB,qDAAU;AACtF,yCAAyC,cAAc,OAAO;AAC9D;AACO,oCAAoC,wBAAwB,KAAK;AACxE,WAAW,kCAAkC;AAC7C,qCAAqC;AACrC;AACA,wCAAwC,yDAAa,gBAAgB,uDAAW,gBAAgB,uDAAW;AAC3G,QAAQ,sCAAQ,CAAC,0DAA4B;AAC7C;AACA;AACA;AACA;AACA,4BAA4B,6DAAiB;AAC7C;AACA;AACA,4BAA4B,MAAM;AAClC;AACA;AACA,QAAQ,+CAAS;AACjB;AACA;AACA,QAAQ,8CAAQ,UAAU,gDAAM;AAChC,QAAQ,sCAAQ,CAAC,yEAA2C;AAC5D;AACA;AACA;AACA,eAAe,OAAO;AACtB,yBAAyB,mDAAW;AACpC;AACA;AACA;AACA;AACA;AACA,gBAAgB,iEAAqB;AACrC,gBAAgB,sCAAQ,CAAC,2EAA6C;AACtE;AACA;AACA;AACA;AACA,cAAc,iEAAuB;AACrC;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAsB;AACrC;AACA,YAAY,sCAAQ;AACpB;AACA;AACA,wCAAwC,mDAAQ;AAChD,eAAe,OAAO;AACtB,YAAY,uDAAe;AAC3B,iDAAiD,cAAc,QAAQ,iBAAiB,EAAE;AAC1F;AACA;AACA,sCAAsC,uDAAe;AACrD,iDAAiD,cAAc,QAAQ,qCAAqC,EAAE;AAC9G;AACA;AACA,QAAQ,6DAAe;AACvB,eAAe,SAAS;AACxB,eAAe,SAAS;AACxB;AACA,iDAAiD,cAAc,uCAAuC,UAAU,uFAAuF,GAAG;AAC1M;AACA;AACA;AACA;AACO;AACP,QAAQ,oDAAS;AACjB,gBAAgB,UAAU,iDAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,SAAS,UAAU,iDAAW,WAAW;AACtF;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACb;AACP;AACA;AACA;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA;AACA,aAAa,yCAAG;AAChB,aAAa,4CAAM;AACnB,aAAa,2CAAK;AAClB;AACA;AACA;AACA,6BAA6B,sEAAwC;AACrE;AACA;AACA;AACA,aAAa,uCAAC;AACd,aAAa,uCAAC;AACd,aAAa,2CAAK;AAClB,aAAa,0CAAI;AACjB,aAAa,4CAAM;AACnB,aAAa,0CAAI;AACjB,aAAa,4CAAM;AACnB,aAAa,yCAAG;AAChB,aAAa,6CAAO;AACpB,aAAa,0CAAI;AACjB,aAAa,yCAAG;AAChB,aAAa,2CAAK;AAClB,aAAa,2CAAK;AAClB,aAAa,4CAAM;AACnB,aAAa,iDAAW;AACxB;AACA,aAAa,+CAAS;AACtB,aAAa,gDAAU;AACvB,aAAa,8CAAQ;AACrB,aAAa,+CAAS;AACtB,yBAAyB,gDAAY;AACrC;AACA;AACA,wCAAwC,QAAQ,sDAAsD,cAAc;AACpH;AACA;AACA;AACA,aAAa,6CAAO;AACpB,aAAa,iDAAW;AACxB,aAAa,mDAAa;AAC1B,aAAa,iDAAW;AACxB,aAAa,0CAAI;AACjB,aAAa,4CAAM;AACnB,aAAa,6CAAO;AACpB,aAAa,wCAAE;AACf,aAAa,wCAAE;AACf;AACA;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA;AACA,aAAa,gDAAU;AACvB,iBAAiB,gDAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,2CAAK;AAClB,iBAAiB,gDAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,2CAAK;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,aAAa;AACxB;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,uDAAuD;AACrF;AACA,oCAAoC,6DAAiB;AACrD;AACA;AACA,QAAQ,gDAAS;AACjB;AACA;AACA,aAAa,0DAAW;AACxB;AACA;AACA,aAAa,qDAAU;AACvB;AACA,eAAe,yDAAc;AAC7B;AACA,aAAa,mDAAQ,OAAO,mDAAQ;AACpC;AACA,+BAA+B,kBAAkB;AACjD,gBAAgB,iEAAqB;AACrC;AACA,qBAAqB,mDAAQ,sBAAsB,mDAAQ;AAC3D,2BAA2B,yDAAc,EAAE,YAAY;AACvD;AACA;AACA;AACA;AACA;AACA,4CAA4C,KAAK;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACO;AACP,SAAS,+CAAS;AAClB;AACA;AACA;AACA;AACA;AACA,WAAW,wDAAc,aAAa,gDAAQ;AAC9C;AACA,sC;;;;;;;;;;;;;;;;;;;;;;;;;;ACtrBA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC2C;AACsE;AACzD;AACR;AACX;AAC6B;AAClB;AACK;AACX;AAC1C;AACA;AACA;AACA;AACA,QAAQ,kDAAO,YAAY,8CAAM;AACjC,qCAAqC,yDAAY;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qDAAqD,gBAAgB;AAC5E;AACA,oCAAoC,mDAAmD;AACvF;AACA;AACA;AACA;AACA,yBAAyB,qDAAkB;AAC3C;AACA;AACA;AACA;AACA;AACA,iBAAiB,6DAAsB;AACvC;AACA,mBAAmB,YAAY;AAC/B,+BAA+B,gDAAK;AACpC,8BAA8B,8DAA2B;AACzD;AACA,uBAAuB,eAAe;AACtC;AACA;AACA;AACA;AACA,+BAA+B,OAAO;AACtC,8CAA8C,OAAO,sDAAU,cAAc;AAC7E,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,OAAO;AACtC,kCAAkC,sDAAU,aAAa,KAAK,iEAAwB,oBAAoB;AAC1G,qBAAqB;AACrB,oCAAoC,iEAAwB;AAC5D;AACA;AACA;AACA;AACA,iBAAiB,yDAAW;AAC5B,8BAA8B,8DAA2B;AACzD;AACA,uBAAuB,eAAe;AACtC;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,OAAO;AAC1B,0CAA0C,WAAW,OAAO,KAAK;AACjE,gBAAgB,8CAAO;AACvB;AACA;AACA;AACA,4CAA4C;AAC5C,oBAAoB,UAAU;AAC9B;AACA;AACA,8DAA8D,sDAAe;AAC7E,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6IAA6I,yDAAW;AACxJ,uBAAuB,iDAAU;AACjC;AACA,mDAAmD,eAAe;AAClE;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,6CAAU;AACzC;AACA;AACA;AACA;AACA,gBAAgB,8CAAO;AACvB;AACA;AACA;AACA;AACA,wEAAwE;AACxE,iCAAiC,kBAAkB,qBAAqB,KAAK,qCAAqC,cAAc,KAAK,KAAK,SAAS,sDAAe;AAClK,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,OAAO;AAClB;AACA,0BAA0B,6DAAuB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,iBAAiB;AAC5B;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,oC;;;;;;;;;;;;;;;;;;;;ACnL0D;AACb;AACG;AACf;AACjC;AACA;AACA;AACA,qEAAqE,qCAAqC,EAAE,+DAA4B,IAAI,0BAA0B;AAC/J,kCAAkC,2CAAI;AACtC,4BAA4B,yCAAK;AACxC,6BAA6B,eAAe;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,gDAAS,iBAAiB,gDAAS;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yDAAW;AAC1B;AACA;AACA,qC;;;;;;;;;;;;;;;;;;;;;;ACnCkC;AACW;AACA;AACG;AACgB;AAChE;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA,0CAA0C,2CAAI,oBAAoB,2CAAI;AACtE;AACA;AACA;AACA;AACA,mCAAmC,iBAAiB,QAAQ,QAAQ,MAAM,4DAAmB,sBAAsB,KAAK,4DAAmB,sBAAsB;AACjK;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACO;AACP;AACA;AACA;AACA;AACA,cAAc,sDAAc;AAC5B;AACA;AACA;AACA;AACA;AACA,uBAAuB,yDAAW,mCAAmC,gDAAS,SAAS;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA,oBAAoB,gDAAK;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACO,0EAA0E;AACjF;AACA,wBAAwB,uDAAc;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;;ACpFyD;AACH;AACW;AAC1D;AACP;AACA,WAAW,mBAAmB;AAC9B,kCAAkC,+DAAkB,sDAAsD,+DAAkB,UAAU,kEAAwB;AAC9J;AACA,WAAW,qBAAqB;AAChC,QAAQ,2DAAkB;AAC1B,8BAA8B,OAAO,yDAAgB;AACrD;AACA;AACA;AACA;AACA;AACA,aAAa,GAAG;AAChB;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpBgF;AACxB;AACF;AACsB;AAC5B;AACA;AACJ;AACG;AACuB;AACC;AACd;AACtB;AACsD;AAClF;AACP,WAAW,oEAA8B;AACzC;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,WAAW,gBAAgB;AAC3B,uBAAuB;AACvB;AACA;AACA,8BAA8B,2CAAI;AAClC,oCAAoC,2DAAiB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,6DAAuB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,0BAA0B;AACrD,wBAAwB,yDAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,uBAAuB,YAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iEAAyB;AAChD,wCAAwC,+DAAuB;AAC/D;AACA;AACA;AACA;AACA,2BAA2B,4DAAmB;AAC9C;AACA;AACA;AACA,+BAA+B,sDAAe;AAC9C;AACA;AACA,mBAAmB,yDAAiB;AACpC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA,8BAA8B,yDAAW,sCAAsC,qDAAc;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,8DAAgB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,qDAAa;AAC3C,4BAA4B,+DAAkB;AAC9C,WAAW,eAAe;AAC1B;AACA,QAAQ,2DAAa;AACrB;AACA,wBAAwB,wDAAc;AACtC,iDAAiD,uDAAa;AAC9D;AACA;AACA;AACA;AACA;AACA,uBAAuB,2DAAa;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,iEAAyB;AACpD,kCAAkC,mDAAS,GAAG,mDAAS,yBAAyB,qDAAc;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kDAAkD,GAAG,qDAAc;AACtF,kBAAkB,uDAAa;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,6DAAsB;AACtC,gBAAgB,yDAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,oDAAiB;AACxC;AACA;AACA;AACA;AACA;AACA,iCAAiC,wDAAgB,8DAA8D;AAC/G,0CAA0C,4CAAa;AACvD,oCAAoC,8CAAO;AAC3C,uBAAuB;AACvB;AACA;AACA,KAAK,IAAI;AACT;AACA,SAAS,8CAAO;AAChB;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrQ8C;AACE;AACd;AACoD;AACtC;AACG;AACL;AACQ;AACN;AACY;AACH;AAChB;AAClC;AACP,aAAa,iBAAiB;AAC9B,cAAc,gCAAgC;AAC9C,eAAe,qBAAqB;AACpC,eAAe,qDAAW;AAC1B,KAAK;AACL,kBAAkB,mCAAmC;AACrD,eAAe,aAAa;AAC5B,eAAe,yDAAe;AAC9B,KAAK;AACL,YAAY,mCAAmC;AAC/C;AACA,YAAY,uDAAU,qBAAqB,8CAAQ;AACnD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,iBAAiB,iBAAiB;AAClC,kBAAkB,oCAAoC;AACtD,kBAAkB,aAAa;AAC/B,qBAAqB,oCAAoC;AACzD,kBAAkB,iCAAiC,MAAM,QAAQ,iHAAiH,EAAE;AACpL,oBAAoB,mCAAmC,MAAM,QAAQ,uHAAuH,uDAAU,iDAAiD,uDAAU,sDAAsD,EAAE;AACzT;AACA,cAAc,SAAS;AACvB,iBAAiB,mDAAmD;AACpE;AACA;AACA;AACA,wFAAwF,wDAAwD;AAChJ,KAAK;AACL,aAAa,uBAAuB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAmB,aAAa,2DAAc,kBAAkB,uDAAU,eAAe,2DAAc;AACtH,KAAK;AACL,cAAc,wBAAwB;AACtC,cAAc,8BAA8B,MAAM,QAAQ,iGAAiG;AAC3J;AACA;AACA;AACA;AACA;AACA;AACO;AACP,YAAY,yDAAiB,eAAe,uDAAU,eAAe,+CAAS;AAC9E;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,eAAe,yDAAW,4BAA4B,qDAAc;AACpE;AACA;AACA;AACA,eAAe,qBAAqB,GAAG,uDAAa;AACpD;AACA,mBAAmB,qDAAc;AACjC;AACA;AACA;AACA,4BAA4B,uCAAC;AAC7B,gBAAgB,+CAAQ,EAAE,0CAAO,EAAE,0CAAO;AAC1C,kBAAkB,uDAAU;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,iBAAiB,aAAa;AAC9B;AACO;AACP;AACA;AACA,gBAAgB,yDAAW;AAC3B;AACA,oCAAoC,yDAAW,eAAe,cAAc;AAC5E;AACA,qCAAqC,EAAE,MAAM,EAAE,oBAAoB,EAAE,MAAM,EAAE;AAC7E,4BAA4B,EAAE,mBAAmB,EAAE,QAAQ,YAAY;AACvE;AACA;AACA;AACA;AACA;AACA,gBAAgB,yDAAW;AAC3B;AACA,wBAAwB,YAAY,cAAc,GAAG,GAAG;AACxD;AACA;AACA;AACA;AACA,gBAAgB,yDAAW;AAC3B;AACA,qCAAqC,yDAAW,eAAe,cAAc;AAC7E;AACA;AACA,+BAA+B,EAAE,mBAAmB,EAAE,cAAc,EAAE,MAAM,EAAE,aAAa,OAAO,YAAY,EAAE,MAAM,EAAE,eAAe,aAAa;AACpJ;AACA;AACA;AACA;AACA;AACA,gBAAgB,yDAAW;AAC3B;AACA,wBAAwB,YAAY,cAAc,GAAG,GAAG;AACxD;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,yDAAW;AACnB;AACA,6BAA6B,yDAAW,eAAe,cAAc,QAAQ,WAAW;AACxF;AACA,wBAAwB,oCAAoC,kBAAkB,wBAAwB;AACtG,oBAAoB,WAAW,KAAK,EAAE,MAAM,EAAE,KAAK,iBAAiB,QAAQ,aAAa;AACzF;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,yDAAW;AACnB;AACA,gCAAgC,cAAc,GAAG,GAAG,IAAI,WAAW;AACnE;AACA,uBAAuB,aAAa;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,2BAA2B,+CAAQ;AACnC;AACA;AACA;AACA;AACO;AACP;AACA,yBAAyB,mDAAQ;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO,2BAA2B,iDAAiD;AACnF;AACA,kBAAkB,yDAAiB;AACnC,YAAY,uDAAU;AACtB,gBAAgB,+CAAS;AACzB;AACA,wBAAwB,iBAAiB,YAAY;AACrD;AACA;AACA,gBAAgB,+CAAQ,6CAA6C,4DAAiB;AACtF;AACA;AACA;AACA,gBAAgB,iBAAiB,YAAY;AAC7C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mDAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,kDAAO;AACf,eAAe,uDAAU;AACzB;AACA,aAAa,yDAAW;AACxB;AACA;AACA;AACA;AACO;AACP,2BAA2B,uDAAU;AACrC;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;;;;;;;;;;AC7P8B;AACkD;AACzC;AACF;AACA;AACF;AAC5B;AACP,QAAQ,kDAAW;AACnB,mBAAmB,8CAAU;AAC7B;AACA,aAAa,kDAAW;AACxB,mBAAmB,8CAAU;AAC7B;AACA,aAAa,iDAAU;AACvB,mBAAmB,4CAAS;AAC5B;AACA,aAAa,sDAAe;AAC5B,mBAAmB,gDAAW;AAC9B;AACA,oBAAoB,qDAAuB;AAC3C;AACA,sC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrBA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACwD;AAChB;AACJ;AACF;AACmB;AACR;AACtC;AACA;AACP,sBAAsB,kDAAO;AAC7B;AACA;AACA,yCAAyC,2BAA2B,YAAY;AAChF;AACO;AACP,QAAQ,gDAAS;AACjB,eAAe,OAAO;AACtB,8BAA8B,eAAe;AAC7C;AACA;AACA;AACO;AACP,QAAQ,gDAAS;AACjB,eAAe,OAAO;AACtB,8BAA8B,eAAe;AAC7C;AACA;AACA;AACO;AACP,QAAQ,gDAAS;AACjB,eAAe,OAAO;AACtB,8BAA8B,eAAe;AAC7C;AACA,QAAQ,yDAAW;AACnB;AACA;AACA,kCAAkC,QAAQ;AAC1C;AACO;AACP,QAAQ,yDAAW;AACnB;AACA;AACA,WAAW,sDAAW;AACtB;AACO;AACP,QAAQ,yDAAW;AACnB;AACA;AACA,8BAA8B,sDAAW;AACzC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO,4DAA4D;AACnE,WAAW,4BAA4B;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,+CAA+C,YAAY,KAAK;AACvE,WAAW,sDAAe;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP,aAAa,gDAAK;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,gDAAK;AAChB;AACA,qBAAqB,oDAAO;AAC5B;AACA;AACA,KAAK,GAAG,uBAAuB;AAC/B;AACO;AACP;AACA;AACA;AACA;AACA,gBAAgB,gDAAS;AACzB;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,QAAQ,gDAAS;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gDAAK,aAAa,gDAAK;AAC1C;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,8CAAM,WAAW,yDAAW,aAAa,8CAAM,WAAW,yDAAW;AACnF;AACA;AACA;AACA;AACA;AACA,aAAa,8CAAM,WAAW,yDAAW;AACzC;AACA;AACA;AACA;AACA;AACA,aAAa,8CAAM,WAAW,yDAAW;AACzC;AACA;AACA;AACA;AACA;AACA,cAAc,8CAAM,YAAY,yDAAW,YAAY,8CAAM,YAAY,yDAAW;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5LA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACkD;AACG;AACT;AACmB;AACjC;AACW;AACe;AAC4B;AACrD;AACW;AACS;AACA;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oCAAoC;AAC3C;AACA;AACA;AACA,QAAQ,qCAAO;AACf;AACA;AACA;AACA,QAAQ,0DAA4B;AACpC;AACA;AACA;AACA,uBAAuB,mDAAU,CAAC,sDAAW;AAC7C;AACA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA;AACA;AACA,sBAAsB,uDAAU;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iEAAgB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,uCAAS;AACrB;AACA;AACA;AACA,YAAY,4DAA8B;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA,aAAa,mDAAQ;AACrB,oBAAoB;AACpB;AACA,2BAA2B,yDAAS;AACpC;AACA,YAAY,sCAAQ,CAAC,qDAAuB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,qDAAuB,CAAC,iEAAuB;AACpE;AACA;AACA,4BAA4B,0DAAU;AACtC;AACA;AACA,uDAAuD,GAAG,2CAAI;AAC9D;AACA;AACA,eAAe;AACf,WAAW,WAAW,IAAI,yEAAyB,kBAAkB,yEAAyB;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE;AACvE;AACA,oCAAoC,+DAAsB;AAC1D;AACA;AACA,IAAI,iEAAgB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,WAAW,SAAS;AACpB,wJAAwJ,wDAAwD,wBAAwB,iCAAiC,KAAK,mCAAmC,QAAQ,KAAK,cAAc,QAAQ,KAAK,oBAAoB,UAAU,sBAAsB,EAAE,KAAK,KAAK,OAAO,8BAA8B,2BAA2B,KAAK;AAC9d;AACA;AACA,WAAW,oEAAwB;AACnC,sBAAsB,mBAAmB,KAAK,iBAAiB,WAAW,KAAK;AAC/E;AACA,mC;;;;;;;;;;;;;;;;;;;;;;;AC9K8B;AACyB;AACxB;AACW;AACD;AACqB;AACH;AAC3B;AACzB,0BAA0B,yCAAK;AACtC;AACA;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,kEAAoC;AACzD;AACA;AACA,mBAAmB,uDAAU;AAC7B,SAAS;AACT;AACA;AACA,8BAA8B,sDAAS;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,2CAAI;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oDAAa;AACzB;AACA;AACA,iBAAiB,oDAAa;AAC9B;AACA;AACA;AACA;AACA;AACA,QAAQ,wEAAqB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,2EAAqB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,8CAA8C,YAAY,QAAQ,KAAK,cAAc,QAAQ,KAAK,oBAAoB,UAAU,sBAAsB,EAAE,KAAK;AACzO,SAAS;AACT;AACA;AACA;AACA,6CAA6C,sBAAsB,mBAAmB,KAAK,KAAK;AAChG;AACA,2BAA2B;AAC3B;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;AChG2D;AACmE;AACvC;AACtD;AACgD;AAC1C;AACG;AAC1C;AACA,wBAAwB,mDAAW,yBAAyB,kEAAwB;AACpF,QAAQ,4DAAe;AACvB,QAAQ,mDAAW;AACnB,QAAQ,oDAAO;AACf,iBAAiB,oDAAO,aAAa;AACrC,iBAAiB,oDAAO,YAAY,gBAAgB;AACpD,4BAA4B,6DAAgB;AAC5C,qBAAqB,oDAAO,YAAY,qBAAqB;AAC7D;AACA;AACA,aAAa,8DAAoB;AACjC,2BAA2B,uEAA6B;AACxD;AACA;AACA;AACA,iBAAiB,oDAAO;AACxB;AACA;AACA;AACA;AACA;AACA,wBAAwB,2CAAI;AAC5B;AACA;AACA,yBAAyB,2CAAI;AAC7B;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACO,4BAA4B,mDAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,gDAAS;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mBAAmB;AACtC;AACA;AACA;AACA,kDAAkD,oDAAO,YAAY,cAAc;AACnF;AACA;AACA,wBAAwB,uDAAW,eAAe,uDAAW;AAC7D,mCAAmC,uDAAW;AAC9C;AACA;AACA,sDAAsD,oDAAO,EAAE,sBAAsB,GAAG,cAAc;AACtG;AACA;AACA;AACA,0DAA0D,oDAAO,YAAY,cAAc;AAC3F;AACA;AACA,wBAAwB,wDAAc;AACtC;AACA,sDAAsD,oDAAO,EAAE,0BAA0B,GAAG,cAAc;AAC1G,sDAAsD,oDAAO,EAAE,0BAA0B,GAAG,cAAc;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,wBAAwB,2CAAI;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gBAAgB;AACnC;AACA;AACA;AACA,4DAA4D,oDAAO,KAAK,cAAc;AACtF;AACA;AACA;AACA,yDAAyD,oDAAO,KAAK,cAAc;AACnF;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2CAAI;AAC5B;AACA;AACA;AACA;AACA;AACA,YAAY,+CAAQ;AACpB;AACA;AACA;AACA;AACA,YAAY,uCAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,2CAAI;AACnD;AACA;AACA;AACA,4BAA4B,2CAAI;AAChC,6BAA6B,2CAAI;AACjC;AACA;AACA,+BAA+B,GAAG,GAAG,MAAM;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2CAAI,EAAE,uDAAuD,EAAE;AAC3F;AACA;AACA;AACA;AACA;AACA,4BAA4B,2CAAI;AAChC,6BAA6B,2CAAI;AACjC;AACA;AACA;AACA,uDAAuD,yDAAkB;AACzE;AACA;AACA;AACA;AACA;AACA,8CAA8C,qDAAkB;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9LuC;AACK;AACZ;AACY;AACJ;AACS;AACb;AACE;AACc;AACH;AACN;AACD;AACF;AACE;AACE;AACE;AACR;AACuB;AAChB;AACP;AACa;AACI;AACV;AACE;AACL;AACJ;AACF;AACM;AACK;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,gDAAU;AACtC;AACA;AACA,sCAAsC,gDAAS;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,oDAAS;AACrC,uCAAuC,gDAAU;AACjD;AACA,kEAAkE,+DAA+D,KAAK,oCAAoC;AAC1K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,6CAAS;AACrC;AACA,0CAA0C,eAAe;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,sDAAa;AACzC,4BAA4B,oDAAY;AACxC,4BAA4B,6DAAiB;AAC7C,4BAA4B,+CAAU;AACtC,4BAA4B,qDAAa;AACzC,4BAA4B,oDAAY;AACxC,4BAA4B,kDAAW;AACvC,4BAA4B,qDAAa;AACzC,4BAA4B,gDAAU;AACtC,4BAA4B,yDAAmB;AAC/C,4BAA4B,uEAA0B;AACtD,4BAA4B,qDAAiB;AAC7C,4BAA4B,0DAAoB;AAChD,4BAA4B,0DAAoB;AAChD,4BAA4B,uDAAkB;AAC9C,4BAA4B,6DAAqB;AACjD,4BAA4B,iEAAuB;AACnD,4BAA4B,wDAAc;AAC1C,4BAA4B,yDAAmB;AAC/C,4BAA4B,uDAAkB;AAC9C;AACA;AACA,4BAA4B,yCAAO;AACnC,4BAA4B,oDAAY;AACxC,4BAA4B,gDAAU;AACtC,4BAA4B,8CAAS;AACrC;AACA;AACA,4BAA4B,iDAAU;AACtC;AACA;AACA;AACA,4CAA4C,iDAAU;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,eAAe;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,iDAAU;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,eAAe;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,cAAc;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;;;;;;;;AC7OA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACqC;AACiC;AACsB;AACW;AACvD;AACT;AACsB;AACnB;AAC1C;AACA;AACA,QAAQ,6DAAgB;AACxB;AACA,sBAAsB,mDAAW;AACjC,0IAA0I;AAC1I,2BAA2B,oDAAO,YAAY,gBAAgB;AAC9D,yBAAyB,oDAAO,YAAY,kCAAkC;AAC9E;AACA,uBAAuB,oDAAO,YAAY,kCAAkC;AAC5E,qBAAqB,4DAAmB;AACxC;AACA;AACA;AACA;AACA;AACA,cAAc,iDAAW,MAAM,GAAG,MAAM;AACxC;AACA;AACA;AACA,iCAAiC,IAAI;AACrC,uCAAuC,IAAI;AAC3C;AACA;AACO;AACP;AACA,gCAAgC,yDAAY;AAC5C;AACA,4BAA4B,IAAI;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,mDAAQ,mBAAmB,KAAK;AAC7C;AACA;AACA,cAAc,oDAAO,KAAK,cAAc,GAAG,oDAAO,KAAK,gCAAgC;AACvF;AACA,0CAA0C,EAAE,yDAAY;AACxD;AACA,WAAW,uBAAuB;AAClC,QAAQ,uDAAiB;AACzB;AACA;AACA,eAAe,yEAAuB,6BAA6B,8CAAO;AAC1E,oCAAoC;AACpC;AACA,oEAAoE,+CAA+C,aAAa,SAAS,KAAK,qBAAqB,eAAe,KAAK,aAAa,OAAO,KAAK;AAChN,YAAY;AACZ;AACO,sBAAsB,mDAAY;AACzC;AACA;AACA;AACA;AACA;AACA,iCAAiC,gDAAS;AAC1C;AACA;AACA;AACA,gBAAgB,4DAAe,cAAc,+CAAS;AACtD,uBAAuB,oBAAoB;AAC3C,qFAAqF;AACrF;AACA;AACA,SAAS,IAAI;AACb,YAAY,8CAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oBAAoB;AACnC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA;AACA;AACA,oCAAoC,6CAAM,gDAAgD,uCAAI;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2CAAI;AAC3B;AACA;AACA;AACA;AACA,uBAAuB,2CAAI;AAC3B;AACA;AACA,sBAAsB,2CAAI,YAAY;AACtC;AACA;AACA,eAAe,2CAAI;AACnB;AACA;AACA,iCAAiC,SAAS;AAC1C,wEAAwE,qBAAqB,yDAAkB,4CAA4C,IAAI,uDAAiB,YAAY,SAAS,IAAI,eAAe,iBAAiB,QAAQ,iBAAiB,SAAS,IAAI,EAAE,KAAK;AACtR;AACA;AACA;AACA,2BAA2B,yDAAkB;AAC7C;AACA,iBAAiB;AACjB,mCAAmC;AACnC;AACA;AACA;AACA,+BAA+B,OAAO;AACtC;AACA;AACA,8BAA8B,oDAAO,EAAE,kBAAkB,GAAG,gBAAgB;AAC5E;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,SAAS;AACT;AACA;AACA,+B;;;;;;;;;;;;;;;;;;;;;;AC3K4D;AACJ;AACf;AACI;AACH;AACS;AAC5C,4BAA4B,mDAAY;AAC/C;AACA;AACA;AACA,gCAAgC,gEAAkB;AAClD;AACA;AACA,uCAAuC,gDAAS;AAChD;AACA;AACA;AACA;AACA,iBAAiB,4DAAe;AAChC;AACA;AACA,gBAAgB,kDAAW;AAC3B,uBAAuB,kBAAkB;AACzC;AACA;AACA;AACA;AACA,8BAA8B,iEAAqB,EAAE,oCAAoC,EAAE,KAAK,EAAE;AAClG,iBAAiB;AACjB;AACA;AACA;AACA,gEAAgE,cAAc;AAC9E,iBAAiB;AACjB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2CAAI,iBAAiB;AACjD;AACA;AACO;AACP,WAAW,oDAAO,0BAA0B,wCAAwC,4CAA4C;AAChI;AACA,qC;;;;;;;;;;;;;;;;;;AC1DiC;AACK;AACtC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,8DAAgC;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,+CAAQ,GAAG;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;ACrJA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC6C;AACH;AAC1C;AACA;AACA;AACO,mCAAmC,mDAAY;AACtD;AACA;AACA;AACA;AACA,yBAAyB,gDAAS,YAAY;AAC9C;AACA;AACA;AACA;AACA,8CAA8C,gDAAS;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,2CAAI,iBAAiB;AACxD;AACA;AACA,oCAAoC,UAAU;AAC9C,sCAAsC,8BAA8B;AACpE;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;AC5CwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,gBAAgB,sDAAK;AACrB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,uC;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/BoC;AACE;AAC+C;AAC1C;AACV;AACe;AACU;AACxB;AACgB;AACkB;AACC;AACnB;AACR;AAC1C;AACA;AACA;AACO,wBAAwB,oDAAY;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAc;AAC5C;AACA;AACA,uBAAuB,YAAY;AACnC,+CAA+C,wBAAwB,QAAQ,oBAAoB,oDAAO,gBAAgB,+CAAS,SAAS,oDAAO,YAAY,mBAAmB,WAAW,GAAG,kDAAW;AAC3M,uBAAuB;AACvB,sBAAsB,kDAAO;AAC7B,2BAA2B,iBAAiB,gEAAmB;AAC/D,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAc;AAC5C;AACA,2BAA2B,kBAAkB,GAAG,2CAAI,gBAAgB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAc;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAc;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,6DAAuB;AACrD;AACA;AACA;AACA;AACA;AACA,oBAAoB,yDAAiB,UAAU,2DAAa;AAC5D,mCAAmC,8DAAc;AACjD,kCAAkC,kEAAkB;AACpD;AACA;AACA;AACA;AACA,wBAAwB,sCAAQ,CAAC,sDAAwB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,wBAAwB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,6CAA6C;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,6CAA6C;AAC7E;AACA,eAAe,4BAA4B;AAC3C;AACA,mBAAmB,MAAM,kDAAe,SAAS;AACjD;AACA;AACA,oBAAoB,oDAAO,aAAa,cAAc;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,mDAAmD;AAClF;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA,eAAe,UAAU;AACzB,eAAe,gBAAgB;AAC/B;AACA;AACA,oCAAoC,8DAAe;AACnD,qCAAqC,2DAAY;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,gBAAgB;AACpE;AACA;AACA,2BAA2B,iBAAiB,YAAY,KAAK,QAAQ;AACrE;AACA;AACA,2BAA2B,gBAAgB,YAAY,IAAI,QAAQ;AACnE,2BAA2B;AAC3B;AACA,6BAA6B,gBAAgB,GAAG,cAAc;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,eAAe,cAAc;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qBAAqB;AACpC;AACA;AACA,uCAAuC,iBAAiB,GAAG,cAAc;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,+BAA+B,4CAAM,EAAE,yCAAG;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;ACvOuC;AACG;AACA;AACS;AAC5C,yBAAyB,mDAAY;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sDAAU;AAC9B,gCAAgC,gEAAkB;AAClD;AACA;AACA,gDAAgD,gDAAS;AACzD;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,UAAU;AACnC;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;ACjC+C;AACQ;AACf;AACU;AACV;AACQ;AACN;AACnC,gCAAgC,mDAAY;AACnD;AACA;AACA;AACA;AACA;AACA,2DAA2D;AAC3D;AACA;AACA,eAAe,wBAAwB;AACvC,wBAAwB,4DAAmB;AAC3C;AACA;AACA;AACA;AACA,mCAAmC,wDAAc;AACjD;AACA;AACA;AACA;AACA;AACA,oBAAoB,2DAAmB,kDAAkD,iDAAU;AACnG,0DAA0D;AAC1D;AACA;AACA;AACA,SAAS,IAAI;AACb,aAAa,2CAAI;AACjB;AACA;AACA;AACA;AACA;AACA,uBAAuB,2CAAI;AAC3B;AACA;AACA,yBAAyB;AACzB;AACA;AACA,gCAAgC,2CAAI,cAAc;AAClD;AACA;AACA;AACA;AACA;AACA,wBAAwB,2CAAI;AAC5B;AACA,wBAAwB,oDAAQ,YAAY,gBAAgB;AAC5D;AACA;AACA,gDAAgD,IAAI,gBAAgB,IAAI,iBAAiB,IAAI;AAC7F;AACA;AACA,gDAAgD,IAAI;AACpD,kDAAkD,IAAI;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;;;;;;AC7E6C;AACH;AAC1C;AACA;AACA;AACO,mCAAmC,mDAAY;AACtD;AACA;AACA;AACA,yBAAyB,gDAAS,YAAY;AAC9C,eAAe,mBAAmB;AAClC,mDAAmD,QAAQ,wDAAwD,EAAE;AACrH;AACA;AACA,qDAAqD,gDAAS;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,2CAAI,iBAAiB;AACxD;AACA;AACA,eAAe,sBAAsB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;;ACnC6C;AACH;AAC1C;AACA;AACA;AACO,gCAAgC,mDAAY;AACnD;AACA;AACA;AACA;AACA,yBAAyB,gDAAS,YAAY;AAC9C;AACA;AACA;AACA;AACA,2CAA2C,gDAAS;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,2CAAI,iBAAiB;AACrD;AACA;AACA,eAAe,WAAW;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpC+C;AACF;AACO;AAC4D;AACvE;AACG;AACX;AACW;AACJ;AACkK;AACjK;AACqE;AACjE;AACQ;AACpB;AACS;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,2DAAmB;AACjC;AACA,2BAA2B,EAAE;AAC7B;AACA;AACA,4BAA4B,EAAE;AAC9B;AACA;AACA,2BAA2B,EAAE;AAC7B;AACA;AACA,yBAAyB,EAAE;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,EAAE,IAAI,UAAU;AAC5C;AACA;AACA;AACA,2BAA2B,EAAE,IAAI,UAAU;AAC3C;AACA;AACA,QAAQ,sCAAQ,CAAC,2DAA6B;AAC9C;AACA;AACA;AACO;AACP;AACA,IAAI,qDAAW;AACf;AACA,YAAY,4DAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA,gBAAgB,iEAAqB;AACrC,sBAAsB,0DAAgB;AACtC;AACA,qBAAqB,+DAAmB;AACxC,sBAAsB,0DAAgB;AACtC;AACA,qBAAqB,8DAAkB;AACvC,sBAAsB,0DAAgB;AACtC;AACA,qBAAqB,8DAAkB;AACvC,sBAAsB,0DAAgB;AACtC;AACA,qBAAqB,+DAAmB;AACxC,sBAAsB,0DAAgB;AACtC;AACA,qBAAqB,iEAAqB;AAC1C;AACA;AACA,qBAAqB,iEAAqB;AAC1C;AACA,aAAa;AACb;AACA,oBAAoB,qDAAU;AAC9B;AACA;AACA,yBAAyB,mDAAQ;AACjC;AACA;AACA,yBAAyB,mDAAQ;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,YAAY,2EAA8B;AAC1C;AACA;AACA;AACA,YAAY,sDAAU;AACtB;AACA;AACA;AACA,iBAAiB,uDAAe;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,4DAAe,cAAc,mDAAW,mBAAmB,uDAAe;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oDAAW,WAAW,qDAAY;AAC1C;AACA;AACA,gBAAgB,4DAAe;AAC/B;AACA;AACA;AACA,oCAAoC,6DAAmB;AACvD;AACA,kDAAkD,cAAc,0BAA0B;AAC1F;AACA,SAAS;AACT;AACA;AACA,QAAQ,oDAAW;AACnB,eAAe,0BAA0B;AACzC,YAAY,iDAAU;AACtB;AACA;AACA;AACA;AACA,gBAAgB,uDAAU;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,oDAAW;AACnB,2BAA2B,4CAAI;AAC/B;AACA;AACA,qCAAqC,uDAAe;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,oDAAY;AAC3C;AACA;AACA;AACA;AACA;AACA,mCAAmC,iDAAS;AAC5C;AACA;AACA,wBAAwB,4CAAI,cAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,kDAAW;AACxB;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,4CAAI;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sCAAQ,CAAC,wDAA0B;AACvD;AACA;AACA;AACA,4BAA4B,4CAAI;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sCAAQ,CAAC,wDAA0B;AACvD;AACA;AACA;AACA,0BAA0B,0CAAK;AAC/B;AACA;AACA;AACA;AACA,0BAA0B,4CAAI;AAC9B;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,4CAAI;AAChC;AACA,gBAAgB,uDAAe;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,4CAAI;AAC3B;AACA;AACA,uBAAuB,4CAAI;AAC3B;AACA;AACA,eAAe,4CAAI;AACnB,2CAA2C,uDAAe;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,2DAAmB;AACvC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,uC;;;;;;;;;;;;;;;;;;;;;AC5SqC;AAC6C;AACQ;AACrD;AACQ;AACH;AACnC,0BAA0B,mDAAY;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,gDAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,+CAAS,EAAE,8CAAQ;AAChC,aAAa,gDAAU,EAAE,+CAAS;AAClC;AACA;AACA,4BAA4B,+DAAkB;AAC9C,uBAAuB,uDAAU;AACjC;AACA,sBAAsB,uDAAU;AAChC,2BAA2B,UAAU,UAAU;AAC/C,0BAA0B,uDAAU;AACpC,+BAA+B,UAAU,aAAa;AACtD;AACA,aAAa;AACb;AACA,sFAAsF,iBAAiB;AACvG;AACA;AACA,kCAAkC,2CAAK;AACvC,iDAAiD,2CAAK;AACtD,kCAAkC,0CAAO;AACzC,gGAAgG,iBAAiB;AACjH;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF,+CAAQ;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,aAAa,GAAG,YAAY,GAAG,2CAAI,cAAc;AAC3E;AACA;AACA,0DAA0D,kBAAkB,kBAAkB,sBAAsB,KAAK,qBAAqB,wBAAwB,KAAK,KAAK,sBAAsB;AACtM;AACA;AACA,mC;;;;;;;;;;;;;;;;;;;;AC9DqC;AACsC;AACe;AAC7C;AACH;AACnC,2BAA2B,mDAAY;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,gDAAS,eAAe,gDAAS;AACxF;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,+CAAS,EAAE,8CAAQ;AAChC,aAAa,gDAAU,EAAE,+CAAS;AAClC;AACA;AACA,4BAA4B,+DAAkB;AAC9C,uBAAuB,uDAAU;AACjC;AACA,sBAAsB,uDAAU;AAChC,2BAA2B,UAAU,UAAU;AAC/C,0BAA0B,uDAAU;AACpC,+BAA+B,UAAU,aAAa;AACtD;AACA,aAAa;AACb,8CAA8C,gDAAU;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,+CAAQ;AAClD;AACA;AACA;AACA;AACA;AACA,2BAA2B,gBAAgB,GAAG,2CAAI,cAAc,GAAG,2CAAI,UAAU;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;AC7DkC;AACQ;AACnC,4BAA4B,mDAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA,4BAA4B,2CAAI,cAAc;AAC9C;AACA;AACA,8BAA8B,oBAAoB,4BAA4B;AAC9E;AACA;AACA,qC;;;;;;;;;;;;;;;;;ACvB+C;AACL;AACnC,6BAA6B,mDAAY;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oDAAY;AACpC;AACA;AACA;AACA;AACA;AACA,gBAAgB,yBAAyB,oDAAY;AACrD;AACA;AACA,sC;;;;;;;;;;;;;;;;;;;;ACtB8C;AACM;AACD;AACN;AACH;AACnC,yBAAyB,mDAAY;AAC5C;AACA;AACA;AACA;AACA;AACA,oCAAoC,gDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,wBAAwB;AACvC;AACA,gBAAgB,qBAAqB,OAAO;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,uDAAU,UAAU,uDAAU;AAC1C;AACA;AACA;AACA;AACA;AACA,mBAAmB,gCAAgC;AACnD,kCAAkC,6DAAkB;AACpD,iHAAiH,sDAAsD,aAAa,SAAS,KAAK,4BAA4B,QAAQ,KAAK,cAAc,QAAQ,KAAK,8BAA8B,UAAU,KAAK,6BAA6B,yBAAyB,KAAK;AAC9W;AACA;AACA;AACA;AACA,yBAAyB,2CAAI,iBAAiB;AAC9C;AACA;AACA,eAAe,qEAAqE;AACpF,yFAAyF,qCAAqC,cAAc,UAAU,4DAAgB,qDAAqD,KAAK,KAAK,kBAAkB,eAAe,UAAU,KAAK,KAAK,sDAAsD;AAChV;AACA,kDAAkD,iCAAiC,OAAO,sEAAsE,cAAc,UAAU,KAAK;AAC7L;AACA;AACA,+BAA+B,OAAO,4BAA4B,OAAO,iBAAiB,OAAO;AACjG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;AChEiC;AACjC;AACA;AACA;AACA;AACA;AACO,4BAA4B,yCAAK;AACxC,6BAA6B,eAAe;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;ACnB2C;AACE;AACT;AACM;AAC1C;AACA;AACA;AACO,yCAAyC,mDAAY;AAC5D;AACA;AACA;AACA;AACA;AACA,oDAAoD,gDAAS;AAC7D;AACA;AACA,iCAAiC,6CAAM;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gFAAgF,oDAAO;AACvF;AACA;AACA,yCAAyC,2CAAI,iBAAiB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA,oBAAoB,4BAA4B,UAAU,KAAK;AAC/D;AACA;AACA,yC;;;;;;;;;;;;;;;;;;;ACtD2C;AACe;AACZ;AACe;AACtD;AACP,WAAW,cAAc;AACzB;AACA;AACA;AACA;AACA,gBAAgB,kDAAW;AAC3B,uBAAuB,aAAa,kDAAe,EAAE;AACrD,yCAAyC,sEAA0B;AACnE;AACA;AACA;AACA;AACA,gCAAgC,0DAAkB,2BAA2B,cAAc;AAC3F;AACA;AACA,8BAA8B,oDAAO;AACrC,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,8C;;;;;;;;;;;;;;;;;AC5BA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC6C;AACH;AAC1C;AACA;AACA;AACO,iCAAiC,mDAAY;AACpD;AACA;AACA;AACA;AACA,yBAAyB,gDAAS,YAAY;AAC9C;AACA;AACA;AACA;AACA,4CAA4C,gDAAS;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,2CAAI,iBAAiB;AACtD;AACA;AACA,oCAAoC,YAAY;AAChD,sCAAsC,iCAAiC;AACvE;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;AC5C4C;AACX;AACiC;AACZ;AACA;AACjB;AACC;AACM;AACrC,yBAAyB,mDAAY;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,gDAAS;AAC7C;AACA;AACA;AACA,eAAe,OAAO;AACtB;AACA,YAAY,wDAAY;AACxB,6BAA6B,kDAAU;AACvC;AACA,iCAAiC,+CAAU;AAC3C;AACA;AACA,2DAA2D,QAAQ;AACnE,iCAAiC,iDAAU,6BAA6B,wDAAqB;AAC7F;AACA;AACA,iBAAiB,6DAAiB;AAClC;AACA,uCAAuC,cAAc;AACrD,yDAAyD,8CAAO;AAChE;AACA,gCAAgC,0DAA4B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,gDAAK;AAChD;AACA;AACA,yBAAyB,2CAAI,EAAE,uDAAuD,EAAE;AACxF;AACA;AACA;AACA;AACA;AACA,qCAAqC,qCAAqC,wBAAwB,KAAK,gDAAK,qBAAqB,KAAK;AACtI;AACA;AACA;AACA;AACA,iBAAiB,mDAAQ;AACzB,gBAAgB,sCAAQ,CAAC,4DAA8B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,sGAAsG,uCAAuC,kCAAkC,KAAK;AAChO;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;ACtEiC;AACU;AACD;AACnC;AACA;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,qEAAuC;AACvE,gCAAgC,yEAA2C;AAC3E;AACA;AACA,gCAAgC,6DAA+B;AAC/D;AACA;AACA;AACA;AACA,oCAAoC,oDAAsB;AAC1D,oCAAoC,kDAAoB;AACxD,oCAAoC,iEAAmC;AACvE,oCAAoC,mDAAqB;AACzD,oCAAoC,wDAA0B;AAC9D,oCAAoC,uDAAyB;AAC7D,oCAAoC,4DAA8B;AAClE,oCAAoC,qDAAuB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,mBAAmB,2BAA2B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,mDAAa;AAClC,mBAAmB,2BAA2B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sCAAQ,8BAA8B,sBAAsB;AACpE;AACA;AACA,oC;;;;;;;;;;;;;;;;;;;;;ACvFA,8BAA8B,SAAI,IAAI,SAAI;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,SAAI,IAAI,SAAI;AAC1C;AACA;AACA;AACA;AACA;AACA;AAC4C;AACF;AACJ;AACtC;AACA;AACA;AACO;AACP,2BAA2B,+CAAU,oBAAoB,qDAAa,oBAAoB,mDAAY;AACtG;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnF2F;AACxC;AACP;AACZ;AACQ;AACJ;AACE;AACI;AACI;AACiD;AACzD;AACI;AAC1C;AACA;AACA;AACA;AACA;AACO,kCAAkC,wDAAgB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,mBAAmB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2CAAI;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,+CAA+C,wDAAgB;AACtE;AACA;AACA,4CAA4C,+DAAmB;AAC/D;AACA;AACA,4BAA4B,uDAAc;AAC1C;AACA;AACA;AACA,iBAAiB,4DAAgB,wCAAwC,qDAAa,2BAA2B,mDAAS;AAC1H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uCAAuC,iDAAS;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,oDAAY;AACxC;AACA,gBAAgB,sDAAe;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,2CAA2C,wDAAgB;AAClE;AACA;AACA;AACA;AACA,4BAA4B,iDAAU;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,0BAA0B,yDAAiB;AAClD;AACA,YAAY,4DAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,mDAAS;AAC1C,oCAAoC,mDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA,wBAAwB,wDAAiB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,yDAAiB;AACjD;AACA;AACA,+EAA+E,mDAAS;AACxF;AACA;AACA;AACA;AACA;AACA,gCAAgC,2CAAI;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,8CAAO;AACxB;AACA,4CAA4C,mDAAS;AACrD;AACA,6CAA6C,mDAAS;AACtD,0CAA0C,2CAAI;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,mDAAS,IAAI,2CAAI;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,mCAAmC,yDAAiB;AAC3D;AACA,4BAA4B,iDAAU,8CAA8C,6CAAS;AAC7F;AACA;AACA,iCAAiC,gDAAU;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,6BAA6B,yDAAiB;AACrD;AACA,0EAA0E,oDAAY;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACO,8BAA8B,yDAAiB;AACtD;AACA,6EAA6E,qDAAa;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,2CAAI;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2CAAI;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,yDAAiB;AAChD;AACA;AACA;AACA;AACA;AACA,6BAA6B,4DAAgB;AAC7C,4BAA4B,+CAAU;AACtC,4BAA4B,mDAAS;AACrC,4BAA4B,uDAAc;AAC1C;AACA;AACA;AACA,iCAAiC,yCAAO;AACxC,mCAAmC,wDAAiB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,yCAAO;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,2BAA2B,yDAAiB;AACnD;AACA;AACA,+BAA+B,2CAAI,qCAAqC,iDAAU;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,iDAAU;AAC3C;AACA;AACA;AACA,4CAA4C,iDAAU;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClWkC;AACwG;AACzG;AACmM;AAClL;AACiB;AAChB;AACQ;AACf;AACZ;AACY;AACJ;AACS;AACb;AACE;AACc;AACH;AACN;AACkF;AACrF;AACE;AACE;AACE;AACR;AACuB;AACK;AACrB;AACP;AACO;AACM;AACI;AACR;AACL;AACJ;AACF;AACM;AACK;AACxC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mDAAY,UAAU,mDAAY;AAC9C,gBAAgB,gDAAS;AACzB;AACA;AACA;AACA,iBAAiB,gDAAS,UAAU,gDAAS;AAC7C;AACA;AACA;AACA;AACA,iBAAiB,kDAAW;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,gDAAU,EAAE,aAAa;AACxD;AACA;AACA;AACA;AACA;AACA,iBAAiB,kDAAW;AAC5B,6CAA6C,gDAAS,GAAG;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,gDAAU;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,uDAAW;AACvB,uCAAuC,sDAAa;AACpD;AACA;AACA,iBAAiB,oDAAQ;AACzB,6BAA6B,6EAA8B;AAC3D,yCAAyC,sEAA2B,SAAS;AAC7E,uBAAuB,gDAAU;AACjC;AACA,iBAAiB,iDAAK;AACtB,mCAAmC,2DAAyB;AAC5D;AACA;AACA,iBAAiB,sDAAU;AAC3B;AACA;AACA;AACA;AACA,2BAA2B,oDAAS,QAAQ,yBAAyB;AACrE;AACA;AACA,mCAAmC,sEAA8B;AACjE;AACA,iBAAiB,uDAAW;AAC5B,mCAAmC,uEAA+B;AAClE;AACA,gBAAgB,+DAAmB;AACnC,2BAA2B,wDAAc;AACzC;AACA;AACA,iBAAiB,oDAAQ;AACzB,mCAAmC,qDAAe;AAClD;AACA;AACA,iBAAiB,oDAAQ;AACzB,uCAAuC,yDAAmB;AAC1D;AACA;AACA,iBAAiB,2DAAe;AAChC,uCAAuC,uEAA0B;AACjE;AACA;AACA,iBAAiB,mDAAO;AACxB,mCAAmC,gEAA2B;AAC9D;AACA;AACA,iBAAiB,kDAAM;AACvB,uCAAuC,qDAAiB;AACxD;AACA;AACA,iBAAiB,qDAAS;AAC1B,uCAAuC,2DAAoB;AAC3D;AACA;AACA,iBAAiB,mDAAO;AACxB,uCAAuC,uDAAkB;AACzD;AACA;AACA,iBAAiB,oDAAQ;AACzB,uBAAuB,yDAAmB;AAC1C;AACA,iBAAiB,oDAAQ;AACzB,mCAAmC,kEAA4B;AAC/D;AACA;AACA,iBAAiB,qDAAS;AAC1B,uCAAuC,2DAAoB;AAC3D;AACA;AACA,iBAAiB,sDAAU;AAC3B,uCAAuC,6DAAqB;AAC5D;AACA;AACA,iBAAiB,wDAAY;AAC7B,uCAAuC,iEAAuB;AAC9D;AACA;AACA,iBAAiB,mDAAO;AACxB,uCAAuC,uDAAkB;AACzD;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,iEAAmC;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,WAAW,mCAAmC;AAC9C,iGAAiG,4CAAa;AAC9G;AACA,QAAQ,kDAAW;AACnB;AACA,YAAY,0DAAmB;AAC/B,uBAAuB,oDAAY;AACnC;AACA,iBAAiB,2DAAoB;AACrC,uBAAuB,sDAAa;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,iEAAsB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,wDAAc;AAC7B;AACA;AACA,0CAA0C,oDAAY;AACtD,QAAQ,mDAAW,WAAW,oDAAY;AAC1C;AACA,yBAAyB,0DAAwB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,uEAAwB;AACtD,6BAA6B,sEAAuB;AACpD,iBAAiB,sEAA2B,SAAS,gCAAgC;AACrF,QAAQ,mDAAW;AACnB,eAAe,2DAAoB;AACnC,eAAe,6DAAqB;AACpC;AACA,QAAQ,mDAAW,WAAW,oDAAY;AAC1C;AACA,yBAAyB,0DAAwB;AACjD;AACA,qBAAqB,qEAA6B;AAClD,eAAe,2EAAkC;AACjD;AACA;AACA,sCAAsC,qDAAkB;AACxD,oBAAoB,kDAAU,gBAAgB,qDAAkB;AAChE;AACA;AACA,QAAQ,mDAAW;AACnB,oBAAoB,sEAA8B;AAClD;AACA;AACA,gBAAgB,+DAAmB;AACnC,2BAA2B,wDAAc;AACzC;AACA;AACA,qBAAqB,iEAA2B;AAChD,qBAAqB,+DAA0B;AAC/C;AACA,QAAQ,mDAAW;AACnB,qBAAqB,mEAAsB;AAC3C;AACA;AACA,uCAAuC,sDAAmB;AAC1D,qBAAqB,kDAAU,iBAAiB,sDAAmB;AACnE;AACA;AACA,QAAQ,mDAAW;AACnB,QAAQ,uEAAqB;AAC7B;AACA;AACA;AACA,QAAQ,oDAAY;AACpB;AACA;AACA;AACA,qBAAqB,gFAA0B;AAC/C,wBAAwB,8CAAS;AACjC;AACA;AACA,yCAAyC,0BAA0B;AACnE;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA,iC;;;;;;;;;;;;;;;;;AC/WqD;AACX;AAC1C;AACA;AACA;AACO,iCAAiC,mDAAY;AACpD;AACA;AACA;AACA;AACA;AACA,4CAA4C,gDAAS;AACrD;AACA;AACA;AACA,iCAAiC,6CAAM;AACvC;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,2CAAI,iBAAiB;AACtD;AACA;AACA,eAAe,mCAAmC;AAClD,0DAA0D,qCAAqC,0BAA0B,QAAQ,KAAK,yBAAyB,KAAK,KAAK,8BAA8B,UAAU,KAAK;AACtN;AACA;AACA,iC;;;;;;;;;;;;;;;;;AChCA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC6C;AACH;AAC1C;AACA;AACA;AACO,oCAAoC,mDAAY;AACvD;AACA;AACA;AACA;AACA,yBAAyB,gDAAS,YAAY;AAC9C;AACA;AACA;AACA;AACA,+CAA+C,gDAAS;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,2CAAI,iBAAiB;AACzD;AACA;AACA,oCAAoC,WAAW;AAC/C,sCAAsC,oCAAoC;AAC1E;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;AC5CA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC6C;AACH;AAC1C;AACA;AACA;AACO,sCAAsC,mDAAY;AACzD;AACA;AACA;AACA;AACA,yBAAyB,gDAAS,YAAY;AAC9C;AACA;AACA;AACA;AACA,iDAAiD,gDAAS;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,2CAAI,iBAAiB;AAC3D;AACA;AACA,oCAAoC,iBAAiB;AACrD,sCAAsC,2CAA2C;AACjF;AACA;AACA;AACA,sC;;;;;;;;;;;;;;;;;AC5C6C;AACH;AAC1C;AACA;AACA;AACO,kCAAkC,mDAAY;AACrD;AACA;AACA;AACA;AACA;AACA,6CAA6C,gDAAS;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,2CAAI,iBAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;AC7BkC;AACQ;AACnC,2BAA2B,mDAAY;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2CAAI,cAAc;AACzC;AACA;AACA,8BAA8B,mBAAmB;AACjD;AACA;AACA,oC;;;;;;;;;;;;;;;;;;ACxBkG;AAC7C;AACX;AACnC,yBAAyB,mDAAY;AAC5C;AACA,oBAAoB;AACpB,0DAA0D;AAC1D;AACA,aAAa,kDAAW;AACxB,mDAAmD,EAAE,2CAAI;AACzD;AACA,YAAY,mDAAY;AACxB,0BAA0B;AAC1B;AACA,iBAAiB,gDAAS;AAC1B,0BAA0B;AAC1B;AACA;AACA;AACA;AACA,qBAAqB,+CAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,wDAAiB;AAClC;AACA,0BAA0B,WAAW,iBAAiB;AACtD;AACA,iBAAiB,kDAAW,UAAU,kDAAW;AACjD;AACA;AACA;AACA,0BAA0B,kDAAW;AACrC;AACA;AACA;AACA;AACA,uBAAuB,8CAAO;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,mBAAmB,gBAAgB,gBAAgB;AAC/F;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;AC9E8C;AACsB;AACN;AACvB;AACG;AAC1C;AACA;AACA;AACA,uBAAuB,oDAAO;AAC9B;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,WAAW,kDAAO,sBAAsB,mDAAQ;AAChD;AACO,wBAAwB,mDAAY;AAC3C;AACA;AACA;AACA;AACA;AACA,mCAAmC,gDAAS;AAC5C;AACA;AACA,eAAe,sCAAsC;AACrD;AACA;AACA;AACA;AACA;AACA,+BAA+B,sDAAe;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,mDAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,eAAe,WAAW;AAC1B;AACA;AACA;AACA,eAAe,+CAA+C;AAC9D;AACA;AACA;AACA,gCAAgC,wDAAW,OAAO;AAClD;AACA;AACA;AACA;AACA,YAAY,kDAAO,cAAc,uDAAU;AAC3C,mBAAmB,mDAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,GAAG,uBAAuB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,+BAA+B;AAC5E,6CAA6C,6BAA6B;AAC1E;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2CAAI,cAAc;AAC1C;AACA;AACA,eAAe,qCAAqC;AACpD;AACA;AACA;AACA;AACA;AACA,4BAA4B,oDAAO,qBAAqB,mBAAmB;AAC3E;AACA;AACA;AACA,oBAAoB,oDAAO,sBAAsB;AACjD,oBAAoB,oDAAO,qBAAqB,mBAAmB;AACnE;AACA;AACA,oBAAoB,oDAAO;AAC3B;AACA;AACA;AACA;AACA;AACA,eAAe,mFAAmF;AAClG;AACA;AACA,mBAAmB,kBAAkB;AACrC;AACA;AACA;AACA;AACA;AACA,6BAA6B,KAAK;AAClC,wBAAwB,oDAAO,qBAAqB,gBAAgB;AACpE,4BAA4B,SAAS;AACrC,wBAAwB,oDAAO,qBAAqB,kCAAkC;AACtF,wBAAwB,oDAAO,qBAAqB,gCAAgC;AACpF,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,qBAAqB,oDAAO,qBAAqB,mBAAmB;AACpE;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;AClL4C;AACA;AACJ;AACJ;AACyB;AACb;AACZ;AACW;AAC/C;AACA;AACA;AACA;AACA;AACA,8BAA8B,6CAAS;AACvC;AACA,gCAAgC,iDAAU;AAC1C,gCAAgC,yDAAkB;AAClD;AACA;AACA;AACA,qCAAqC,qDAAa;AAClD,gCAAgC,6CAAS;AACzC,gCAAgC,wDAAmB;AACnD,gCAAgC,sEAA0B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,wBAAwB,6CAAS;AACjC,sEAAsE,iDAAU;AAChF;AACA;AACA,iCAAiC,qDAAa;AAC9C,iCAAiC,6CAAS;AAC1C,iCAAiC,wDAAmB;AACpD,iCAAiC,sEAA0B;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iDAAU,kBAAkB,sDAAmB;AACvE;AACA;AACA,mCAAmC,6CAAS;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;;;;;;AChFA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACyD;AACL;AACiB;AACoB;AAClD;AACG;AACnC,2BAA2B,mDAAY;AAC9C;AACA;AACA;AACA;AACA;AACA,sCAAsC,gDAAS;AAC/C;AACA;AACA;AACA,mBAAmB,kBAAkB;AACrC,gCAAgC,mDAAW,yBAAyB,kEAAwB;AAC5F,yBAAyB,mDAAW,WAAW,oDAAO;AACtD;AACA,2BAA2B,oDAAO,YAAY,cAAc;AAC5D,kCAAkC,2CAAI;AACtC;AACA;AACA;AACA,iBAAiB,oBAAoB;AACrC;AACA,8BAA8B,WAAW,aAAa,KAAK;AAC3D;AACA;AACA,SAAS,IAAI;AACb,YAAY,8CAAO;AACnB;AACA;AACA;AACA;AACA;AACA,mCAAmC,OAAO,WAAW;AACrD,mCAAmC,4DAAiB;AACpD,wDAAwD,WAAW,+BAA+B;AAClG;AACA,aAAa,2CAAI;AACjB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,8CAAO;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2CAAI;AAC3B;AACA;AACA,uBAAuB,2CAAI;AAC3B;AACA;AACA,2BAA2B,2CAAI,eAAe;AAC9C;AACA;AACA;AACA,wBAAwB,2CAAI;AAC5B,mBAAmB,sBAAsB;AACzC,uBAAuB,4DAAiB,aAAa,YAAY;AACjE,qFAAqF,QAAQ,yDAAkB,2BAA2B,WAAW,QAAQ,2DAAgB,QAAQ,KAAK,YAAY,kBAAkB,KAAK,cAAc,aAAa,GAAG,QAAQ;AACnQ;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;;;ACzGgD;AACL;AACE;AACT;AACM;AAC1C;AACA;AACA;AACO,kCAAkC,mDAAY;AACrD;AACA;AACA;AACA;AACA;AACA,6CAA6C,gDAAS;AACtD;AACA;AACA,iCAAiC,6CAAM;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yEAAyE,oDAAO;AAChF;AACA;AACA,kCAAkC,2CAAI,iBAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,yDAAa;AAC3F;AACA,kCAAkC,8CAA8C,4BAA4B,UAAU,KAAK;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA,kBAAkB,gCAAgC,cAAc,KAAK,8BAA8B,UAAU,KAAK,4BAA4B,QAAQ,KAAK;AAC3J;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9EA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACoC;AACD;AAC+C;AAC5B;AACN;AAClB;AACe;AACU;AACR;AACN;AACM;AACL;AACU;AACG;AACd;AACc;AACe;AACH;AAChB;AACU;AACpB;AAC2B;AACR;AACrD;AACP,WAAW,oDAAO,sBAAsB,eAAe,oDAAO,WAAW,GAAG,4CAA4C;AACxH;AACO,yBAAyB,mDAAc;AAC9C;AACA;AACA,qBAAqB,wDAAU;AAC/B;AACA;AACA;AACA;AACA;AACA,aAAa,2DAAc;AAC3B,oBAAoB;AACpB;AACA,yBAAyB,2CAAI;AAC7B;AACA;AACA,iBAAiB,+CAAQ,EAAE,yCAAG,EAAE,4CAAM;AACtC;AACA,gBAAgB,sCAAQ,CAAC,6DAA+B;AACxD;AACA;AACA;AACA;AACA,gBAAgB,sCAAQ,CAAC,uDAAyB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB;AACA;AACA,8BAA8B,yDAAY;AAC1C;AACA,mCAAmC,4DAAqB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,uDAAS;AACvC;AACA;AACA;AACA,QAAQ,2EAAuB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iEAAiB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAc;AAC5C,qCAAqC,4DAAY;AACjD;AACA;AACA,uBAAuB,gBAAgB;AACvC;AACA,wCAAwC,kEAAiB;AACzD,wBAAwB,+CAAQ;AAChC,8CAA8C,iEAAgB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,cAAc;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,6CAA6C,UAAU,KAAK,KAAK,wBAAwB;AACpJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,yBAAyB,oBAAoB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;AACA;AACA,sCAAsC,QAAQ,oDAAO,qBAAqB,qBAAqB;AAC/F;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAO;AACrC;AACA;AACA,oCAAoC,MAAM;AAC1C;AACA;AACA;AACA,kCAAkC,6DAAuB;AACzD;AACA;AACA;AACA;AACA,wBAAwB,yDAAiB,UAAU,4DAAa;AAChE,uCAAuC,8DAAc;AACrD,sCAAsC,kEAAkB;AACxD;AACA;AACA;AACA,gDAAgD,MAAM;AACtD;AACA;AACA,4BAA4B,sCAAQ,CAAC,sDAAwB;AAC7D;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA,eAAe,aAAa;AAC5B,eAAe,cAAc;AAC7B,eAAe,kBAAkB;AACjC;AACA,8BAA8B,oDAAc;AAC5C;AACA;AACA,6BAA6B,oDAAO;AACpC,uBAAuB,YAAY;AACnC,oBAAoB,+CAAS;AAC7B,iCAAiC,oDAAO,YAAY,mBAAmB;AACvE;AACA,oBAAoB,kDAAW;AAC/B,2BAA2B,aAAa,kDAAe,EAAE;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kDAAO;AAChC,uCAAuC,qEAAmB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA,qBAAqB;AACrB;AACA,yDAAyD,YAAY,QAAQ,KAAK,sBAAsB,kBAAkB,KAAK;AAC/H;AACA,gBAAgB;AAChB;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA,gBAAgB,kDAAW;AAC3B,qEAAqE,gBAAgB;AACrF;AACA,qBAAqB,kDAAO;AAC5B,wBAAwB,qEAAmB,qBAAqB,gBAAgB;AAChF;AACA,oBAAoB,oDAAO,YAAY,gBAAgB;AACvD;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA,mBAAmB,OAAO;AAC1B,2BAA2B,kDAAW,uBAAuB,kDAAO;AACpE;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B;AACA;AACA,mBAAmB,qEAAkB;AACrC;AACA;AACA;AACA;AACA;AACA,8BAA8B,+DAAe;AAC7C;AACA,oCAAoC,kEAAiB;AACrD,oBAAoB,+CAAQ;AAC5B;AACA,2BAA2B,qEAAkB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA,qBAAqB,kEAAiB;AACtC;AACA;AACA;AACA,+GAA+G,4CAA4C,YAAY,QAAQ,KAAK,cAAc,QAAQ,KAAK,KAAK;AACpN;AACA,aAAa;AACb;AACA;AACA,uBAAuB,wDAAkB;AACzC,uBAAuB,wDAAkB;AACzC,aAAa,EAAE,uBAAuB,aAAa,KAAK,oBAAoB,UAAU,sBAAsB,EAAE,KAAK,wBAAwB,0EAAoB;AAC/J;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/VqC;AACF;AACkF;AAClE;AACd;AAC0D;AACxD;AACM;AACW;AACjD;AACP;AACA;AACA;AACA,cAAc,WAAW,GAAG,MAAM,EAAE,cAAc,uBAAuB,OAAO;AAChF;AACO;AACA,0BAA0B,oEAAoE;AACrG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,2EAA8B;AACtC,mDAAmD,uDAAU,0BAA0B,4DAAiB,iHAAiH,4DAAe,qGAAqG,iDAAa;AAC1V,yBAAyB,SAAS;AAClC;AACA,0BAA0B,2DAAc;AACxC,QAAQ,uDAAU,qBAAqB,+CAAS;AAChD,yBAAyB,oDAAO,mBAAmB,yBAAyB;AAC5E;AACA;AACA;AACA;AACA,uBAAuB,2DAAc;AACrC;AACA,uBAAuB,0BAA0B;AACjD;AACA;AACA;AACA,gBAAgB,oBAAoB,MAAM,MAAM,MAAM,QAAQ,MAAM;AACpE;AACA;AACA;AACA,QAAQ,uDAAU;AAClB;AACA,sBAAsB,oDAAO,mBAAmB,sBAAsB,EAAE,GAAG,oDAAO;AAClF;AACA;AACA,aAAa,EAAE;AACf;AACA;AACA,mBAAmB,oDAAO,mBAAmB,OAAO;AACpD;AACA;AACA;AACA,eAAe,qEAAc;AAC7B;AACA;AACO,2BAA2B,2EAA2E;AAC7G;AACA,QAAQ,uDAAU,qBAAqB,+CAAS;AAChD,yBAAyB,oDAAO,mBAAmB,yBAAyB;AAC5E;AACA;AACA;AACA;AACA,YAAY;AACZ;AACO;AACP;AACA;AACA;AACA,yBAAyB;AACzB;AACA,QAAQ,2EAA8B;AACtC,yBAAyB,uDAAU,0BAA0B,4DAAiB;AAC9E;AACA;AACA;AACA;AACO;AACP,uBAAuB,yDAAW;AAClC;AACA;AACA,QAAQ,2EAA8B;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,mDAAQ;AAChB;AACA;AACA,iBAAiB,+CAAY;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,oBAAoB,sEAA2B;AAC/C;AACA;AACA;AACA;AACA;AACA,qBAAqB,MAAM,KAAK,aAAa;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAQ;AAC5C;AACO;AACP;AACA;AACA,cAAc,+DAAmB,oBAAoB,cAAc,MAAM,MAAM,oBAAoB,MAAM,IAAI;AAC7G;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,iBAAiB,mDAAQ,kCAAkC;AAC3D,kBAAkB,4BAA4B,SAAS,MAAM,KAAK,OAAO;AACzE;AACA;AACA,eAAe,2DAAgB;AAC/B;AACA;AACA,kC;;;;;;;;;;;;;;;;;;ACxJ+B;AACa;AACE;AACvC;AACP,WAAW,2CAAI;AACf;AACA,6CAA6C,WAAW,2DAAa,kCAAkC,yDAAgB;AACvH,KAAK,IAAI;AACT;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACoC;AACW;AACJ;AAC+F;AACjG;AACS;AACyB;AACE;AACrB;AACZ;AACJ;AAC4C;AACzC;AAC3C;AACO;AACP;AACA;AACA;AACA;AACA;AACA,WAAW,2CAA2C,GAAG,6DAAmB;AAC5E,0BAA0B,0DAAgB;AAC1C,uBAAuB,qDAAc;AACrC;AACA,iBAAiB,QAAQ;AACzB;AACA,iBAAiB,cAAc;AAC/B,sFAAsF,cAAc,wBAAwB,iBAAiB,KAAK,KAAK,uBAAuB,sLAAsL,4DAAuB,EAAE,gEAA2B;AACxZ;AACA;AACO;AACP;AACA;AACA,oBAAoB;AACpB;AACA,oBAAoB;AACpB;AACA,kBAAkB,mEAAiB;AACnC,oBAAoB,QAAQ;AAC5B;AACO;AACP,qBAAqB,sEAAoB;AACzC,uBAAuB,WAAW;AAClC;AACO;AACP;AACA;AACA,6BAA6B,qDAAY;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,QAAQ,kDAAW;AACnB;AACA,mBAAmB,oDAAO,QAAQ,gBAAgB;AAClD;AACA;AACA;AACA,aAAa,kDAAO;AACpB;AACA,mBAAmB,oEAAmB,0BAA0B,gBAAgB;AAChF;AACA;AACA;AACA;AACA;AACA,mBAAmB,oDAAO,iBAAiB,gBAAgB;AAC3D;AACA;AACA;AACA;AACO;AACP,WAAW,sEAAsE,GAAG,6DAAmB;AACvG,0BAA0B,wDAAe,EAAE,6EAA6E;AACxH;AACA,0BAA0B,0DAAgB;AAC1C,kFAAkF;AAClF;AACA,kBAAkB,iDAAU,CAAC,iDAAU,0DAA0D,oDAAO,iBAAiB,iBAAiB;AAC1I;AACA,SAAS,EAAE,wBAAwB,iBAAiB,KAAK,KAAK,uCAAuC,sLAAsL,4DAAuB,EAAE,gEAA2B;AAC/U;AACO;AACP;AACA;AACA,eAAe,gBAAgB;AAC/B;AACA;AACA,mBAAmB,cAAc,GAAG,6DAAmB;AACvD;AACA,uCAAuC,+CAAQ;AAC/C,0CAA0C,+CAAQ;AAClD;AACA;AACA;AACA,qCAAqC,qDAAY,YAAY,2DAAc;AAC3E;AACA;AACA;AACA;AACA,0FAA0F,wBAAwB,QAAQ,GAAG,WAAW,4BAA4B,QAAQ,GAAG,WAAW,GAAG;AAC7L;AACA,2BAA2B,2CAA2C;AACtE;AACA;AACA,oBAAoB;AACpB;AACA,2BAA2B,qCAAqC,QAAQ;AACxE;AACA,oBAAoB,cAAc,QAAQ,KAAK;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB,OAAO,KAAK;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA,0BAA0B,oDAAc;AACxC;AACA;AACA,mBAAmB,2BAA2B,GAAG,6DAAmB;AACpE,kCAAkC,0DAAgB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,8CAAO;AAClB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,sBAAsB,2DAAiB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;;AChLuD;AACvD;AACA;AACA;AACO;AACP,QAAQ,+CAAQ;AAChB;AACA;AACA,aAAa,+CAAQ;AACrB;AACA;AACA;AACA;AACO;AACP;AACA,WAAW,sDAAe,cAAc;AACxC;AACO;AACP;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;AC3BO;AACA;AACP,qC;;;;;;;;;;;;;;;;;;;;;;;;ACFoC;AACW;AACW;AACH;AACP;AACA;AACD;AACF;AACtC;AACP,iDAAiD,yDAAW;AAC5D;AACA;AACA;AACA;AACA;AACO;AACP,0BAA0B,oDAAc;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,kCAAkC;AAC7C;AACA;AACA,4BAA4B,0DAAiB;AAC7C,oBAAoB,kDAAa;AACjC;AACA;AACA,SAAS;AACT;AACA;AACA,oBAAoB,kDAAO;AAC3B;AACA;AACA;AACA;AACA,4BAA4B,0DAAiB;AAC7C;AACA,uBAAuB,sDAAe;AACtC,2BAA2B,+CAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB;AACA,eAAe,yBAAyB;AACxC,gCAAgC,2DAAiB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,4DAAY,uCAAuC,eAAe;AACnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrF8B;AACoB;AACnB;AACuB;AACR;AACL;AACqB;AACJ;AACN;AACpB;AACmC;AAChC;AAC5B,yBAAyB,yCAAK;AACrC;AACA;AACA,uEAAuE,mCAAmC,oBAAoB,KAAK,oBAAoB,sBAAsB,KAAK;AAClL;AACA,gBAAgB,kDAAW;AAC3B;AACA;AACA,qBAAqB,iDAAU;AAC/B,2BAA2B,6CAAS;AACpC;AACA,4BAA4B,qDAAuB;AACnD,SAAS;AACT;AACA;AACA,8BAA8B,sDAAS;AACvC;AACA;AACA;AACA;AACA;AACA,QAAQ,uEAAoB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,2CAAI;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,2DAAc;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,EAAE,mEAAmB;AAC9B;AACA;AACA;AACA;AACA,SAAS,EAAE,2EAAqB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iFAA2B;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS,EAAE,iEAAe;AAC1B;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;ACpG2D;AACX;AACH;AACK;AACF;AACR;AACjC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yDAAiB,UAAU,2DAAa;AACxD;AACA,oBAAoB,oDAAY;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+EAA+E,UAAU;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,oEAA2B;AACxD,qCAAqC,KAAK,MAAM,KAAK,KAAK,aAAa;AACvE,iBAAiB,6BAA6B,4CAA4C,GAAG;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,yBAAyB,sDAAe;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY,IAAI,4DAAmB,eAAe,IAAI,4DAAmB,eAAe,MAAM,UAAU;AAChI;AACA,oC;;;;;;;;;;;;;;;ACxFO;AACP;AACA;AACA,qC;;;;;;;;;;;;;;;;;;;ACHwE;AACT;AAC9B;AACQ;AAClC,yBAAyB,iBAAiB;AACjD,0BAA0B,6DAAuB;AACjD,yBAAyB,wDAAc;AACvC,YAAY,kDAAM;AAClB,gBAAgB,wEAA2B;AAC3C;AACA,gBAAgB,sCAAQ,CAAC,qDAAuB;AAChD;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;AChBiG;AACX;AACtC;AACP;AACS;AACC;AACS;AACrD;AACP;AACA;AACA;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,yEAA6B;AAClD,oBAAoB,iEAAuB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,+DAAuB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACO;AACP,WAAW,kBAAkB;AAC7B,0BAA0B,6DAAuB;AACjD,yBAAyB,wDAAc;AACvC;AACA;AACA,+CAA+C,kDAAM;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,yDAAiB;AAC7B,yBAAyB,kEAAyB;AAClD,gBAAgB,2DAAa,WAAW,kDAAM;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oEAA2B;AAC9C;AACA;AACA;AACA;AACA,eAAe,oEAA2B;AAC1C;AACA;AACA,qBAAqB,kEAAyB;AAC9C,eAAe,kDAAM;AACrB;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;AC7HA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACqD;AACU;AACf;AACD;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA,2BAA2B,gDAAS;AACpC;AACA;AACA,+BAA+B,4DAAoB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,2CAAI;AACxB;AACA;AACA;AACA;AACA;AACO;AACP;AACA,sCAAsC,iCAAiC;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA,+BAA+B,0DAAqB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2IAA2I,yDAAW;AACtJ,mBAAmB,iDAAU;AAC7B;AACA,mDAAmD,eAAe;AAClE;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;;;ACnF4D;AAC1B;AACD;AACjC,sEAAsE,EAAE,iEAA4B,IAAI;AACxG;AACA;AACA;AACA,eAAe;AACR,oCAAoC,2CAAI;AACxC,8BAA8B,yCAAK;AAC1C;AACA,qC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACXwD;AACT;AACmC;AAClC;AACe;AACD;AACG;AACxB;AACJ;AAC9B;AACP;AACA;AACA;AACA;AACA;AACO,+BAA+B,0DAA0D;AAChG;AACA;AACA;AACA;AACA,WAAW,kCAAkC;AAC7C;AACA,4CAA4C,EAAE,wDAAe,GAAG,SAAS,qDAAkB,IAAI,+CAAY,SAAS,SAAS,GAAG;AAChI;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,2CAAK;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,yDAAgB;AAC/C,sCAAsC,yDAAgB;AACtD;AACA;AACA,qBAAqB,kDAAO;AAC5B;AACA;AACA,+BAA+B,yDAAgB;AAC/C;AACA;AACA;AACA;AACA;AACA,4DAA4D,2CAAK;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,kDAAO;AAC5B,+BAA+B,sDAAe;AAC9C;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA,oBAAoB,6CAAO;AAC3B,0BAA0B,uDAAU;AACpC;AACA;AACA,+BAA+B,kBAAkB,EAAE,yDAAgB;AACnE,gBAAgB,yDAAgB;AAChC;AACA;AACA;AACA,0BAA0B,yDAAgB;AAC1C;AACA;AACA,wCAAwC;AACxC,WAAW,8CAAO;AAClB;AACO,iCAAiC,gCAAgC;AACxE;AACA;AACA;AACA;AACA,WAAW,4BAA4B;AACvC;AACA;AACA;AACA;AACA;AACA,sBAAsB,yDAAgB;AACtC;AACA,wCAAwC;AACxC,WAAW,8CAAO;AAClB;AACO,sCAAsC,8CAA8C;AAC3F;AACA;AACA,sBAAsB,uDAAU;AAChC,kCAAkC,4BAA4B,GAAG,yCAAyC;AAC1G,WAAW,qBAAqB;AAChC,iBAAiB,2DAAkB;AACnC,UAAU,yDAAgB;AAC1B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,mEAAmE,cAAc,UAAU,KAAK,aAAa,OAAO,KAAK;AACzH,WAAW,8CAAO;AAClB;AACO,+BAA+B,aAAa;AACnD;AACA,uHAAuH,iBAAiB,QAAQ,uBAAuB,EAAE;AACzK;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,sDAAe;AAC9B,KAAK;AACL;AACA;AACA,QAAQ,mEAAsB;AAC9B,eAAe,gDAAK;AACpB;AACA,aAAa,uDAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,sDAAW;AAC7B;AACA;AACA,sBAAsB,sDAAW,CAAC,8CAAO,SAAS,6CAAK;AACvD,gCAAgC,MAAM,SAAS,KAAK,GAAG,MAAM,eAAe,KAAK,GAAG,MAAM;AAC1F,KAAK;AACL;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtJ6C;AACqB;AACb;AACF;AACd;AACqC;AAC1B;AACJ;AACL;AACQ;AAC0B;AACW;AACT;AAC9B;AAC2B;AACjE;AACP,4BAA4B,mDAAW;AACvC;AACA;AACA;AACA;AACA,WAAW,WAAW;AACtB;AACA,2BAA2B,2CAAK,KAAK,0DAAqB;AAC1D,oBAAoB,+DAAkB;AACtC;AACA;AACA;AACA,wBAAwB,2CAAK,IAAI,uDAAU,sBAAsB,0CAAO;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA,uCAAuC,cAAc,IAAI;AACzD;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACO;AACP;AACA;AACA,WAAW,4BAA4B;AACvC;AACA,2BAA2B,wDAAe,GAAG;AAC7C,IAAI,sFAAsB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,+DAAkB;AAC9C,qBAAqB,uDAAU,0BAA0B,4DAAiB;AAC1E;AACA,uBAAuB,2DAAa,EAAE,uCAAuC;AAC7E,sBAAsB,0DAAY,EAAE,2CAA2C;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,oEAA2B;AACtD;AACA;AACA;AACA;AACA,kCAAkC,qDAAW,GAAG,qDAAW;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC;AACA,mCAAmC,wDAAgB,gEAAgE;AACnH,8BAA8B,uDAAiB;AAC/C,cAAc,uDAAiB;AAC/B,iCAAiC;AACjC,oCAAoC,8CAAO;AAC3C,6EAA6E,kFAAkF,uDAAU;AACzK,mBAAmB,UAAU,8CAAO,wBAAwB,UAAU,KAAK;AAC3E,oBAAoB,oFAAoF,4BAA4B,KAAK,KAAK,gBAAgB;AAC9J;AACA;AACA,SAAS,8CAAO;AAChB;AACA;AACA;AACA;AACA;AACA,WAAW,mBAAmB;AAC9B;AACA;AACA,8BAA8B,2CAAI;AAClC,sCAAsC,2DAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,oEAA2B;AAClD,wCAAwC,gEAAuB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,4DAAmB;AAC9C;AACA;AACA;AACA,2BAA2B,qDAAY;AACvC;AACA,mBAAmB,0DAAiB;AACpC,SAAS;AACT;AACA;AACA;AACA;AACA,YAAY,2DAAoB;AAChC;AACA;AACA,YAAY,2DAAoB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxNoC;AACW;AACuB;AACf;AACA;AACP;AACS;AACP;AAC3C;AACP,iBAAiB,YAAY;AAC7B,cAAc,kCAAkC;AAChD,eAAe,qBAAqB;AACpC,eAAe,oDAAW;AAC1B,KAAK;AACL,kBAAkB,qCAAqC;AACvD,eAAe,aAAa;AAC5B,eAAe,wDAAe;AAC9B,KAAK;AACL;AACA;AACA,eAAe,uBAAuB;AACtC;AACA,KAAK;AACL,oBAAoB,kCAAkC,MAAM,YAAY,qKAAqK,EAAE;AAC/O,kBAAkB,qCAAqC,MAAM,QAAQ,0IAA0I,EAAE;AACjN,aAAa,0BAA0B,KAAK,kDAAa,2BAA2B,uBAAuB;AAC3G,YAAY,iCAAiC;AAC7C,YAAY,wDAAc,aAAa,gEAAwB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,cAAc,0BAA0B;AACxC;AACO;AACP;AACA,QAAQ,kDAAO;AACf,eAAe,uDAAU;AACzB;AACA,aAAa,yDAAW;AACxB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,4BAA4B,+DAAsB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,SAAS;AACpB,WAAW,sDAAe;AAC1B;AACO,sBAAsB,+BAA+B;AAC5D;AACA,QAAQ,wDAAc;AACtB,YAAY,+CAAQ;AACpB;AACA;AACA,YAAY,gEAAwB;AACpC;AACA;AACA;AACA;AACA;AACO,uBAAuB,2CAA2C;AACzE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACO,gCAAgC,oDAAoD;AAC3F,WAAW,iHAAiH;AAC5H,QAAQ,gEAAwB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kBAAkB,WAAW,IAAI,IAAI,IAAI,IAAI;AACzD;AACO;AACP,QAAQ,+CAAQ;AAChB;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;;;;;ACpJmC;AAC5B;AACP;AACA;AACA,uFAAuF,EAAE,oDAAsB;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,iDAAmB,2BAA2B,iDAAmB;AAClM;AACA;AACA,+B;;;;;;;;;;;;;;;;ACdmC;AAC5B;AACP;AACA;AACA,yEAAyE,EAAE,oDAAsB;AACjG;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,yDAA2B;AACxC;AACA;AACA;AACA,SAAS,IAAI,yDAA2B;AACxC;AACA;AACA;AACA,SAAS,IAAI,4CAAc;AAC3B;AACA;AACA,gC;;;;;;;;;;;;;;;;ACtBmC;AAC5B;AACP;AACA;AACA,2DAA2D,EAAE,oDAAsB;AACnF;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,iDAAmB,sBAAsB,iDAAmB;AACzE;AACA;AACA,+B;;;;;;;;;;;;;;;;;;;;;;ACdiD;AACoB;AACd;AACT;AACb;AACO;AACjC;AACP,WAAW,kBAAkB;AAC7B,uBAAuB,4DAAmB;AAC1C;AACA;AACA;AACA;AACA;AACA,uDAAuD,iBAAiB,mBAAmB,KAAK;AAChG;AACA;AACA,WAAW,wBAAwB;AACnC;AACA;AACA;AACA,yBAAyB,4DAAmB;AAC5C;AACA,gBAAgB,uBAAuB,sBAAsB;AAC7D;AACA,mBAAmB,uDAAa,KAAK,IAAI,uBAAuB,cAAc;AAC9E;AACO;AACP,WAAW,mCAAmC;AAC9C;AACA;AACA,eAAe,2DAAa,2CAA2C,8CAAO;AAC9E;AACA;AACA;AACA,6BAA6B,4DAAmB;AAChD;AACA;AACA,yBAAyB,yDAAgB;AACzC;AACA;AACA;AACA;AACA;AACA,iBAAiB,qDAAW;AAC5B,QAAQ,8CAAO;AACf;AACA;AACA;AACA;AACA,oBAAoB,8CAAO;AAC3B,kDAAkD,cAAc,QAAQ,EAAE,IAAI,SAAS,MAAM;AAC7F;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxDkC;AACgB;AACP;AACU;AAChB;AACkB;AACc;AACvC;AACE;AACY;AACd;AACM;AACe;AACjB;AACF;AACc;AACF;AACK;AACsB;AACxB;AACjB;AACM;AACpC;AACO;AACP,WAAW,uCAAuC,gCAAgC,6CAAK;AACvF,qLAAqL,yIAAyI,yDAAW,qBAAqB,yDAAW,yBAAyB,yDAAW,2BAA2B,yDAAW,yBAAyB,yDAAW,wBAAwB,gDAAM,UAAU,kDAAO,UAAU,4CAAI,kBAAkB,2CAAI;AAC1iB;AACA;AACA;AACA,WAAW,wBAAwB;AACnC,oBAAoB,4DAAmB;AACvC,2CAA2C,iDAAU;AACrD;AACA;AACA,uDAAuD,0BAA0B,oDAAc,EAAE;AACjG;AACA;AACA;AACA;AACA;AACA,qBAAqB,oBAAoB;AACzC,uBAAuB,gDAAK;AAC5B;AACA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA,WAAW,gEAAsB;AACjC;AACA,sBAAsB,yDAAgB;AACtC;AACA;AACA,KAAK,IAAI;AACT;AACA,2CAA2C,4BAA4B;AACvE;AACA;AACA;AACA;AACA,kDAAkD,gBAAgB;AAClE;AACA,yBAAyB,2DAAmB;AAC5C;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT,mBAAmB,2CAAI;AACvB;AACA;AACA,mCAAmC,iEAAqB,2BAA2B,GAAG;AACtF;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;AC5EoC;AACK;AAC4B;AACzB;AACrC,6BAA6B,oBAAoB;AACxD;AACA,WAAW,4BAA4B;AACvC,WAAW,iBAAiB;AAC5B;AACA,sEAAsE,4DAAmB;AACzF,gCAAgC,+CAAQ;AACxC;AACA;AACA,oCAAoC,4DAAmB,0DAA0D,oBAAoB;AACrI;AACA;AACA;AACA;AACA;AACA,gCAAgC,4DAAmB,2DAA2D,sBAAsB;AACpI;AACA;AACA;AACA,qEAAqE,kBAAkB,OAAO,yDAAgB,eAAe,KAAK,sBAAsB,SAAS,yDAAgB,iBAAiB,KAAK;AACvM;AACA,QAAQ,sCAAQ,CAAC,uDAAyB,cAAc,uDAAuD;AAC/G;AACA,qEAAqE,+BAA+B,yDAAW;AAC/G;AACA;AACA,KAAK,IAAI,yDAAW;AACpB;AACA;AACA,KAAK,IAAI,yDAAW;AACpB;AACA;AACA,KAAK;AACL;AACA,iC;;;;;;;;;;;;;;;;;;;ACtCkC;AAC6C;AAClC;AACmB;AAChE;AACA;AACA;AACA;AACO;AACP,sBAAsB,6DAAgB;AACtC;AACA;AACA,2BAA2B,gDAAK;AAChC;AACA;AACA,yBAAyB,mEAAsB;AAC/C,kBAAkB,yEAAuB;AACzC,kBAAkB,sDAAU,gBAAgB;AAC5C,kCAAkC,OAAO;AACzC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,yCAAyC,wBAAwB;AACjE;AACA;AACA,uC;;;;;;;;;;;;;;;;;;;;;AC5B2D;AACN;AAChB;AACgC;AAClB;AAC5C;AACP,WAAW,kBAAkB;AAC7B,oBAAoB,4DAAmB;AACvC;AACA,yDAAyD,WAAW,6DAAuB,EAAE;AAC7F;AACA,oBAAoB,WAAW,SAAS;AACxC;AACA;AACA;AACA;AACA,2CAA2C,4BAA4B;AACvE;AACA;AACA;AACA;AACA,kDAAkD,gBAAgB;AAClE;AACA,yBAAyB,2DAAmB;AAC5C;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT,mBAAmB,2CAAI;AACvB;AACA;AACA,mCAAmC,gEAAqB,2BAA2B,GAAG;AACtF;AACA;AACA;AACO;AACP;AACA,gBAAgB,SAAS,yDAAgB;AACzC;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1CyC;AACT;AACc;AACM;AACR;AACK;AACsB;AACP;AAClC;AAC6B;AAC7B;AAC9B,iC;;;;;;;;;;;;;;;;;;ACXqE;AACvB;AACZ;AAClC;AACA;AACA;AACO,6CAA6C;AACpD,WAAW,4BAA4B;AACvC,WAAW,YAAY;AACvB,SAAS,2BAA2B;AACpC;AACA;AACA,yFAAyF,4DAAmB,4BAA4B,kCAAkC;AAC1K;AACA,yBAAyB,yDAAgB;AACzC;AACA;AACA;AACA,WAAW,2DAAa;AACxB,eAAe,+CAAY;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA,uC;;;;;;;;;;;;;;;;AC/BoD;AAC7C;AACP,0BAA0B,0DAAgB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;ACVwD;AACpB;AACe;AACA;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,8DAAoB;AACnC;AACA;AACA,kBAAkB,4DAAmB;AACrC;AACA,QAAQ,yDAAW;AACnB,QAAQ,sCAAQ,CAAC,8EAAgD;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;;;;;;;;;;;;;;;;;;ACnC+H;AAClD;AAClC;AACF;AACU;AACd;AACH;AAClC;AACA;AACA;AACO,wCAAwC,oCAAoC;AACnF,WAAW,mCAAmC;AAC9C;AACA,iCAAiC,kEAAwB;AACzD;AACA;AACA,mBAAmB,kDAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,oCAAoC,gDAAM;AAC1C;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,uBAAuB,mCAAmC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,6EAA6E;AACxF;AACA,QAAQ,8DAAiB;AACzB,YAAY,uDAAU;AACtB,yBAAyB,oDAAO;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,uBAAuB,4DAAyB;AAChD;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,eAAe,iEAA8B,yBAAyB,gBAAgB,GAAG,SAAS;AAClG;AACA,WAAW,yEAAsC;AACjD;AACO,kCAAkC,+CAA+C;AACxF,WAAW,kBAAkB;AAC7B;AACA,4BAA4B,6DAAmB;AAC/C,0BAA0B,8DAAoB;AAC9C,qCAAqC,4DAAmB,4BAA4B,YAAY;AAChG;AACA,mBAAmB,kEAA+B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,+CAAQ,EAAE,iDAAa,EAAE,kDAAc,EAAE,iDAAa;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,SAAS,kBAAkB,EAAE,IAAI;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,mBAAmB,GAAG,oBAAoB;AACzF;AACA;AACA,oCAAoC;AACpC;AACA,oCAAoC,SAAS,iBAAiB;AAC9D;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA,sCAAsC,wDAAc;AACpD,qDAAqD,aAAa,YAAY;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;;;;;;;;;;;;;;;;;;ACtIuH;AAC/D;AACN;AACb;AACuB;AACc;AACxC;AAClC;AACA;AACA;AACO,+CAA+C,iCAAiC;AACvF;AACA,8CAA8C,0BAA0B;AACxE;AACA,WAAW,8DAAa,kBAAkB,aAAa;AACvD;AACO,wCAAwC,0BAA0B;AACzE,WAAW,kBAAkB;AAC7B,qBAAqB,kEAAwB;AAC7C,wBAAwB,wDAAc;AACtC;AACA;AACA;AACA,YAAY,yEAAwB;AACpC;AACA,YAAY,8DAAoB;AAChC,yCAAyC,EAAE,8DAAa,kBAAkB,wBAAwB;AAClG;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,yCAAyC;AACpD,wBAAwB,6DAAmB;AAC3C,wBAAwB,wDAAc;AACtC,sBAAsB,8DAAoB;AAC1C;AACA;AACA;AACA;AACA,UAAU,kDAAS;AACnB,UAAU,kDAAS;AACnB;AACA;AACA,gBAAgB,eAAe,gCAAgC;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2DAAkB;AACzC,2BAA2B,2DAAkB;AAC7C,SAAS;AACT;AACA;AACA,qBAAqB,wEAAuB;AAC5C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACO,uBAAuB,iGAAiG;AAC/H,QAAQ,8DAAiB;AACzB;AACA;AACA;AACA,eAAe,iEAA8B,yBAAyB,kBAAkB,GAAG,SAAS;AACpG;AACA,WAAW,yEAAsC;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,wBAAwB,wDAAc;AACtC,sBAAsB,8DAAoB;AAC1C;AACA,gBAAgB,cAAc,kEAA+B;AAC7D;AACA;AACA,gBAAgB,cAAc,kEAA+B;AAC7D;AACA;AACA,gBAAgB,gBAAgB,kEAA+B;AAC/D;AACA;AACA;AACA,0C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClH8C;AACkB;AACkE;AAC5C;AACZ;AACtC;AAC0B;AACd;AACkB;AACM;AAC5B;AACP;AACuB;AACD;AACV;AACf;AAC3B;AACP;AACA,WAAW,mCAAmC;AAC9C,qBAAqB,kEAAwB;AAC7C,wBAAwB,wDAAc;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,2IAA2I,4DAAmB,2BAA2B,yBAAyB;AAClN;AACA;AACA,QAAQ,uDAAU;AAClB,SAAS,+CAAS,oBAAoB,8CAAQ;AAC9C;AACA,SAAS,yDAAiB;AAC1B,qBAAqB,oDAAO,EAAE,wDAAwD;AACtF;AACA,4IAA4I;AAC5I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,gDAAM,YAAY,4DAAmB;AAC1D;AACA;AACA,SAAS;AACT;AACA,eAAe,8DAAiB,gBAAgB,yDAAiB;AACjE;AACA;AACA;AACA,eAAe,+DAAa,kBAAkB,oDAAoD;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA,8BAA8B,mDAAe;AAC7C;AACA,oBAAoB,2DAAa,gBAAgB,mDAAQ;AACzD,4BAA4B;AAC5B;AACA,wBAAwB,QAAQ,iDAAY;AAC5C;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA,iBAAiB,kEAAyB;AAC1C,kBAAkB,sDAAe;AACjC;AACA;AACA,kCAAkC,QAAQ;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,mCAAmC;AAC9C;AACA;AACA;AACA,0BAA0B,wDAAc;AACxC,qBAAqB,kEAAwB;AAC7C;AACA;AACA,iCAAiC,4DAAmB;AACpD;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,yBAAyB,0DAAW,iBAAiB,+DAA+D;AACpH;AACA;AACA,YAAY,sCAAQ,CAAC,0EAA4C;AACjE;AACA;AACA;AACA,wBAAwB,8DAAiB,aAAa,oDAAO,EAAE,4CAA4C;AAC3G,gCAAgC;AAChC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,0EAAwB;AAC9C,mBAAmB,mDAAS;AAC5B,mBAAmB,0EAAsC;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,yEAAuB,EAAE,sDAAsD;AACnG;AACA,KAAK;AACL;AACA,8BAA8B,sBAAsB;AACpD;AACA;AACA;AACA;AACA,2BAA2B,8DAAoB;AAC/C;AACA,kEAAkE,aAAa,SAAS;AACxF;AACA;AACA;AACA,0BAA0B,kDAAO;AACjC,4DAA4D,eAAe,qBAAqB;AAChG,gDAAgD,YAAY,qBAAqB;AACjF;AACA;AACA;AACA;AACA,QAAQ,gEAAsB;AAC9B;AACA;AACA;AACA,QAAQ,yDAAW,aAAa,yDAAW,YAAY,yDAAW;AAClE,4BAA4B,4DAAmB;AAC/C,2BAA2B,4DAAmB;AAC9C,8BAA8B,4DAAmB;AACjD,qCAAqC,cAAc;AACnD,oCAAoC,YAAY;AAChD,mCAAmC,WAAW,KAAK,cAAc;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,0BAA0B,sGAAsG;AACvI,qBAAqB,kEAAwB;AAC7C,sBAAsB,8DAAoB;AAC1C,uBAAuB,8DAAoB;AAC3C,mBAAmB,mDAAS;AAC5B,QAAQ,+CAAS;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa,8CAAQ;AACrB,yBAAyB,kEAA8B,wBAAwB,GAAG,2EAA2E;AAC7J,YAAY,uDAAU;AACtB;AACA;AACA,6BAA6B,kEAA8B,yBAAyB,GAAG,0EAA0E;AACjK;AACA;AACA,iBAAiB,iDAAW;AAC5B;AACA;AACA;AACA,sCAAsC,UAAU,KAAK,oDAAO,YAAY,gBAAgB,EAAE,KAAK,kBAAkB;AACjH;AACA;AACA;AACA;AACA;AACA,IAAI,sCAAQ,CAAC,kEAAoC;AACjD;AACA;AACA;AACA;AACA;AACO,qBAAqB,8DAA8D;AAC1F,cAAc,6DAAyB;AACvC;AACA;AACA;AACA;AACA,KAAK;AACL,WAAW,+DAA2B;AACtC;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,yC;;;;;;;;;;;;;;;;;;;;ACrPqF;AACrC;AACD;AACD;AACvC;AACP;AACA,WAAW,2DAAa;AACxB;AACO;AACP;AACA;AACA,YAAY,uDAAU;AACtB,mBAAmB,yDAAgB;AACnC;AACA,YAAY,8DAAiB;AAC7B,mBAAmB,qBAAqB,GAAG,4DAAe;AAC1D,mBAAmB,wDAAe,EAAE,gEAAgE;AACpG;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrB+D;AACvB;AACuB;AACgF;AACnG;AACJ;AACW;AACA;AACiB;AACtB;AACb;AAC1B,gCAAgC;AACvC,WAAW,mCAAmC;AAC9C;AACA,QAAQ,kDAAO;AACf,gBAAgB,iCAAiC,sBAAsB;AACvE;AACA;AACA;AACA,eAAe,2DAAa;AAC5B;AACA,6CAA6C,+CAAO;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,4DAAmB;AACjD;AACA,+BAA+B;AAC/B;AACA,gBAAgB,mDAAQ;AACxB,wBAAwB;AACxB;AACA,qBAAqB,mDAAQ;AAC7B,kCAAkC,+BAA+B;AACjE,oBAAoB,yDAAW;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA,SAAS;AACT;AACA;AACO,+CAA+C,eAAe,KAAK;AAC1E;AACA;AACA;AACA;AACA,4BAA4B,6DAAmB;AAC/C,yBAAyB,4DAAe;AACxC;AACA,4CAA4C,UAAU;AACtD,cAAc;AACd,wCAAwC,yDAAY;AACpD,oBAAoB,gDAAK;AACzB;AACA,YAAY,gDAAM;AAClB;AACA,8BAA8B,wDAAW;AACzC,gBAAgB,8CAAQ;AACxB,mCAAmC,oDAAO,YAAY,OAAO;AAC7D,iCAAiC,oDAAO,aAAa,OAAO;AAC5D,uBAAuB,qBAAqB,GAAG,4DAAe;AAC9D,wBAAwB,4DAAmB;AAC3C;AACA;AACA;AACA,uBAAuB,qBAAqB,GAAG,4DAAe;AAC9D,wBAAwB,wDAAe,EAAE,oFAAoF;AAC7H;AACA;AACA;AACA,6DAA6D,+CAAO;AACpE,qBAAqB,sBAAsB;AAC3C;AACA,IAAI,kDAAO;AACX,YAAY,uDAAU;AACtB;AACA;AACA,iBAAiB,mEAAsB;AACvC;AACA;AACA,KAAK;AACL;AACA,gBAAgB,sBAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACO,yDAAyD,eAAe,KAAK;AACpF,uDAAuD,eAAe;AACtE,sBAAsB,8CAAO,iCAAiC,IAAI,KAAK,MAAM;AAC7E,mCAAmC,WAAW,EAAE,sBAAsB,GAAG;AACzE;AACA,mC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzGiD;AACU;AACR;AACe;AAC+E;AAClF;AACrB;AACN;AACO;AACc;AACoB;AACpC;AACA;AACU;AACkB;AAC9D;AACP,WAAW,8CAA8C;AACzD;AACA;AACA;AACA;AACA,IAAI,uDAAU;AACd,SAAS,iEAAqB;AAC9B;AACA;AACA,QAAQ,iEAAwB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACO,kCAAkC,0CAA0C;AACnF,QAAQ,iDAAU;AAClB;AACA;AACA;AACA,oBAAoB,6DAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,wBAAwB,6DAAmB,UAAU;AACrD;AACA,WAAW,SAAS,kBAAkB;AACtC;AACA,aAAa;AACb,0BAA0B,OAAO;AACjC;AACO;AACP,WAAW,+DAAmB,CAAC,mDAAQ,kBAAkB,oDAAO,SAAS,gBAAgB;AACzF;AACO;AACP,WAAW,QAAQ;AACnB,QAAQ,qDAAU;AAClB,eAAe,yDAAc;AAC7B;AACA,cAAc,sBAAsB;AACpC;AACO;AACP;AACA;AACA;AACA;AACA,QAAQ,uDAAU;AAClB,eAAe,QAAQ;AACvB,YAAY,qDAAU;AACtB,yBAAyB,yDAAc;AACvC;AACA,iBAAiB,0DAAW;AAC5B;AACA;AACA,iBAAiB,gDAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oDAAO;AAC3B;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,gCAAgC,gFAAgF;AACvH;AACA,kBAAkB,oDAAO,mBAAmB,4BAA4B;AACxE;AACA,UAAU,oDAAO,oBAAoB,OAAO;AAC5C,UAAU,oDAAO,mBAAmB,sBAAsB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,KAAK,KAAK,MAAM,KAAK,SAAS,KAAK,IAAI;AAChE,+BAA+B,UAAU,KAAK,MAAM;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,WAAW;AACxB;AACO,mBAAmB,uGAAuG;AACjI;AACA;AACA;AACA;AACA,YAAY,8DAAiB;AAC7B,gBAAgB,4DAAe;AAC/B,iEAAiE,oDAAO;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,uBAAuB,sBAAsB;AAC7C,oBAAoB,+CAAS,uCAAuC,4CAAQ;AAC5E;AACA;AACA;AACA;AACA,kFAAkF,mBAAmB,GAAG,SAAS;AACjH;AACA;AACA;AACA;AACA,sDAAsD,uDAAuD;AAC7G;AACA,6EAA6E,6DAAgB,yBAAyB,qBAAqB,KAAK;AAChJ;AACA,qBAAqB;AACrB;AACA,yBAAyB,8CAAQ;AACjC,wBAAwB,uDAAU;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA,qDAAqD,uCAAC,GAAG,wCAAE,GAAG,wCAAE;AAChE,wBAAwB,sCAAQ,CAAC,kEAAoC;AACrE;AACA;AACA;AACA;AACA,qEAAqE,0DAAiB,eAAe,qBAAqB,KAAK;AAC/H;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,iBAAiB,uDAAU;AAC3B;AACA,2CAA2C,SAAS;AACpD,iDAAiD;AACjD;AACA;AACA;AACA;AACA,QAAQ,qDAAU;AAClB;AACA;AACA;AACA;AACA,6CAA6C,0BAA0B,SAAS,KAAK;AACrF;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,gDAAQ;AAChB,gBAAgB,SAAS,iBAAiB;AAC1C;AACA,aAAa,gDAAQ;AACrB,gBAAgB,SAAS,kBAAkB;AAC3C;AACA,WAAW,0DAAgB;AAC3B;AACA,oC;;;;;;;;;;;;;;;;;;;ACvNiD;AACN;AACK;AACF;AACvC;AACP,WAAW,iBAAiB;AAC5B;AACA,SAAS,iDAAU,UAAU,uDAAU;AACvC,eAAe,2DAAa,+BAA+B,yDAAgB;AAC3E;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;;ACZuD;AAClB;AACF;AAC5B;AACP;AACA;AACA,+BAA+B,EAAE,oDAAsB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA,eAAe,WAAW;AAC1B;AACA,yCAAyC,uDAAuD,eAAe,uDAAU,gCAAgC,0CAAO;AAChK,eAAe,QAAQ,oDAAO,YAAY,gBAAgB;AAC1D,gBAAgB;AAChB;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;ACxBmC;AAC5B;AACP;AACA;AACA,yEAAyE,EAAE,oDAAsB;AACjG;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,iDAAmB,wBAAwB,iDAAmB,wBAAwB,yCAAW;AAC9G;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;ACdgD;AAC6C;AAChD;AACM;AAClB;AAC0H;AACvG;AACG;AACQ;AACxD;AACP,oBAAoB,4DAAqB;AACzC;AACA,4BAA4B,4DAAmB;AAC/C;AACA;AACA,QAAQ,sCAAQ,CAAC,0DAA4B;AAC7C;AACA;AACA,gCAAgC,4DAAmB;AACnD;AACA;AACA;AACA,kBAAkB,0DAA2B;AAC7C;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA,6BAA6B,4DAAmB;AAChD;AACA;AACA;AACA;AACA,4BAA4B,4DAAmB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,4DAAmB;AAC5D;AACA;AACA;AACA;AACA;AACA,QAAQ,+CAAQ,EAAE,wCAAK,EAAE,uCAAI,EAAE,yCAAM,EAAE,yCAAM;AAC7C;AACA,aAAa,sDAAW;AACxB;AACA;AACA;AACA;AACA;AACO,yCAAyC,YAAY;AAC5D;AACA;AACA;AACA,yBAAyB,sDAAa;AACtC;AACA,WAAW,sDAAe,wBAAwB,wCAAK,aAAa,uCAAI,aAAa,uCAAI;AACzF;AACA;AACA;AACA,aAAa,wCAAK;AAClB,aAAa,yCAAM;AACnB,aAAa,yCAAM;AACnB,aAAa,uCAAI;AACjB,aAAa,uCAAI;AACjB,aAAa,wCAAK;AAClB;AACA;AACA;AACA,WAAW,eAAe;AAC1B;AACA,aAAa,sCAAG;AAChB,gBAAgB,uDAAU,QAAQ,8CAAQ,YAAY,uDAAU;AAChE;AACA;AACA,gBAAgB,uDAAU,QAAQ,8CAAQ,YAAY,uDAAU;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,uDAAU,kBAAkB,+CAAY,KAAK,+CAAS,YAAY,6DAAgB;AAC3G;AACA;AACA;AACA;AACA;AACA,yBAAyB,uDAAU,kBAAkB,+CAAY,KAAK,+CAAS,YAAY,6DAAgB;AAC3G;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAI;AACjB;AACA;AACA,wBAAwB,uDAAU,OAAO,8CAAQ,oBAAoB,uDAAU,OAAO,8CAAQ;AAC9F;AACA;AACA;AACA,aAAa,uCAAI;AACjB;AACA;AACA,oBAAoB,uDAAU,OAAO,8CAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uDAAU,OAAO,8CAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,uCAAI;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAI;AACjB,aAAa,uCAAI;AACjB;AACA,kCAAkC,wEAA2B;AAC7D,kCAAkC,wEAA2B;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA,kDAAkD,2CAAQ;AAC1D,kDAAkD,2CAAQ;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;AC1LmC;AAC5B;AACP;AACA;AACA,uFAAuF,EAAE,oDAAsB;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,gDAAkB;AACnJ;AACA,SAAS,IAAI,4CAAc;AAC3B;AACA;AACO;AACP;AACA;AACA,uFAAuF,EAAE,oDAAsB;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,gDAAkB,kBAAkB,4CAAc;AACnL;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7BoC;AAC+B;AACvB;AACqB;AACD;AACL;AAC6B;AAC3B;AAC2C;AAC5E;AACE;AACF;AACU;AACN;AACK;AACW;AAClB;AACA;AACA;AACA;AAC9B;AACA,OAAO;AACP,QAAQ;AACR,OAAO;AACP,UAAU;AACV,YAAY;AACZ,SAAS;AACT,QAAQ;AACR,SAAS;AACT,QAAQ;AACR,QAAQ;AACR,UAAU;AACV,QAAQ;AACR,QAAQ;AACR,SAAS;AACT;AACO;AACP,QAAQ,+CAAQ,EAAE,uCAAI,EAAE,uCAAI,EAAE,wCAAK;AACnC,wBAAwB,6DAAkB;AAC1C;AACA;AACA;AACA;AACA;AACA,aAAa,+CAAQ,EAAE,sCAAG;AAC1B,gCAAgC,uEAA6B,SAAS,4DAAmB;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,sDAAmB;AACzF,gDAAgD,sDAAmB;AACnE;AACA;AACA,aAAa;AACb;AACA;AACA,4BAA4B,SAAS,iBAAiB,EAAE;AACxD,6BAA6B,SAAS,kBAAkB;AACxD;AACA,aAAa;AACb;AACA,wCAAwC,kCAAkC;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,iCAAiC;AACzE;AACA;AACA,gCAAgC;AAChC;AACA;AACA;AACA,wBAAwB,uCAAuC;AAC/D,wBAAwB,uCAAuC;AAC/D,wBAAwB,qCAAqC;AAC7D,wBAAwB,qCAAqC;AAC7D;AACA,kBAAkB,KAAK,GAAG,qCAAqC,WAAW,IAAI,MAAM,cAAc;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,EAAE,2CAAI,oDAAoD,kEAAwB,MAAM,KAAK,0CAA0C,OAAO,0CAA0C,SAAS,cAAc,EAAE;AACrQ;AACA;AACA,gBAAgB,SAAS,aAAa,YAAY;AAClD,qBAAqB,SAAS,kBAAkB;AAChD;AACA;AACA;AACA,2DAA2D,EAAE,2CAAI,2CAA2C,UAAU,SAAS,kBAAkB,EAAE,EAAE;AACrJ;AACA;AACA,oDAAoD,EAAE,2CAAI,oDAAoD,KAAK,0CAA0C,OAAO,0CAA0C,SAAS,cAAc,EAAE;AACvO;AACA,gBAAgB,SAAS,aAAa,YAAY;AAClD,oBAAoB,SAAS,iBAAiB;AAC9C;AACA,2DAA2D,EAAE,2CAAI,2CAA2C,SAAS,SAAS,iBAAiB,EAAE,EAAE;AACnJ;AACA;AACA,sBAAsB,kEAAwB;AAC9C,4BAA4B,sDAAa;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,yDAAgB;AAC/C;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA,oBAAoB,oDAAO,kBAAkB,oDAAO;AACpD;AACA,qBAAqB,oDAAO,gBAAgB,mBAAmB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,YAAY,mCAAmC;AAChG;AACA;AACA,gCAAgC,sDAAa;AAC7C;AACA,qDAAqD,YAAY,SAAS,yDAAgB,eAAe;AACzG;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,wCAAwC;AACxC,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,sDAAmB;AACnE,qEAAqE,sDAAmB;AACxF;AACA;AACA;AACA,wCAAwC,kBAAkB;AAC1D,wCAAwC,kBAAkB;AAC1D,wCAAwC,gBAAgB;AACxD,wCAAwC,gBAAgB;AACxD;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,6BAA6B,2BAA2B;AACxD;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,yCAAyC;AACpD;AACA,UAAU,kDAAO,WAAW,uDAAU,WAAW,oDAAa;AAC9D,mBAAmB,oDAAa,CAAC,4DAAmB;AACpD;AACA;AACA,cAAc,kDAAO,WAAW,uDAAU;AAC1C;AACA,eAAe,mDAAU,SAAS,gBAAgB;AAClD;AACA,aAAa,iDAAU;AACvB;AACA;AACA;AACA,YAAY,uDAAU;AACtB;AACA,gBAAgB,kDAAO;AACvB;AACA,2BAA2B,oDAAO,uBAAuB,gEAAgE;AACzH;AACA;AACA,qBAAqB,kDAAW;AAChC;AACA,2BAA2B,oDAAO;AAClC;AACA;AACA,mCAAmC,sDAAW;AAC9C;AACA,qBAAqB,GAAG,gBAAgB;AACxC;AACA;AACA,qBAAqB,uDAAgB;AACrC;AACA;AACA,2BAA2B,oDAAO,kBAAkB,gBAAgB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,oDAAO;AAClC;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,iBAAiB;AACrD,WAAW,kCAAkC;AAC7C,iBAAiB,sDAAe;AAChC,kBAAkB,kDAAS;AAC3B;AACA;AACA;AACA,iBAAiB,4DAAmB;AACpC;AACA;AACA;AACA;AACA,yHAAyH,gEAAgE,WAAW,aAAa,KAAK,cAAc,QAAQ,KAAK,YAAY,iBAAiB,KAAK,aAAa,OAAO,KAAK,mCAAmC,uBAAuB,OAAO,KAAK,KAAK,QAAQ,8CAA8C,sDAAmB,GAAG;AACnc;AACA,aAAa,EAAE;AACf;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,2CAAI;AAC1B;AACA;AACA;AACA,sBAAsB,2CAAI;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;ACjUmC;AACnC;AACA,WAAW,SAAS;AACpB,iGAAiG,EAAE,oDAAsB;AACzH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,gDAAkB,kBAAkB,gDAAkB;AACnL;AACO;AACP;AACA,gBAAgB,SAAS,oBAAoB;AAC7C;AACA,WAAW,gDAAkB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;ACpCmC;AAC5B;AACP;AACA;AACA,2DAA2D,EAAE,oDAAsB;AACnF;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,iDAAmB,uBAAuB,iDAAmB;AAC1E;AACA;AACA,gC;;;;;;;;;;;;;;;;ACdmC;AAC5B;AACP;AACA;AACA,eAAe,UAAU;AACzB;AACA;AACA;AACA;AACA;AACA,yEAAyE,EAAE,oDAAsB;AACjG;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,yDAA2B;AACxC;AACA;AACA;AACA,SAAS,IAAI,yDAA2B;AACxC;AACA;AACA;AACA,SAAS,IAAI,gDAAkB;AAC/B;AACA,SAAS;AACT;AACA;AACA,gC;;;;;;;;;;;;;;;;;AC9BgD;AACb;AAC5B;AACP;AACA;AACA,eAAe,mBAAmB;AAClC,6JAA6J,EAAE,oDAAsB;AACrL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,kDAAoB,cAAc,oBAAoB,IAAI,yCAAW,UAAU,gDAAkB;AACxK;AACA,SAAS,IAAI,gDAAkB,mBAAmB,mDAAqB,oDAAoD,mDAAqB,0DAA0D,kDAAoB,mBAAmB,qCAAqC,IAAI,kDAAoB,kBAAkB,qCAAqC;AACrW;AACA;AACA;AACA,cAAc,4DAAmB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,4DAAmB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;AClCqC;AACoB;AACP;AACgB;AAC/B;AAC5B;AACP;AACA;AACA,eAAe,kBAAkB;AACjC;AACA;AACA;AACA,uFAAuF,EAAE,oDAAsB;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI,kDAAoB,cAAc,qCAAqC,IAAI,kDAAoB,cAAc,qCAAqC,IAAI,gDAAkB;AACrL;AACA;AACA,SAAS,KAAK,uBAAuB,yDAAgB,CAAC,4DAAmB,iCAAiC;AAC1G;AACA;AACA;AACA;AACA,WAAW,kBAAkB;AAC7B,WAAW,SAAS;AACpB;AACA;AACA,mCAAmC,4DAAmB,2BAA2B,2BAA2B;AAC5G;AACA;AACA;AACA;AACA;AACA,0BAA0B,2DAAa,gBAAgB,mDAAQ;AAC/D;AACA;AACA,gCAAgC,kEAAyB;AACzD;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5CA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACgG;AAC3C;AACZ;AACK;AACE;AAClB;AACe;AACP;AACkB;AACF;AACJ;AACoB;AACvB;AACA;AACe;AACwC;AACjD;AACJ;AACsB;AACnB;AACP;AACe;AACP;AACH;AACkB;AACxB;AACZ;AACzB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4DAAqB;AACzC;AACA;AACA,qBAAqB,8CAAM,gBAAgB,mBAAmB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,+DAAkB;AAC5C,8DAA8D,GAAG,oEAAwB;AACzF;AACA;AACA;AACA,4EAA4E;AAC5E,4FAA4F;AAC5F;AACA,2BAA2B,kDAAW;AACtC,aAAa;AACb,4BAA4B,0CAAK;AACjC,4BAA4B,QAAQ,YAAY,WAAW,EAAE;AAC7D;AACA,oCAAoC,UAAU,UAAU,YAAY,EAAE,aAAa,iDAAS,cAAc;AAC1G;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA,sBAAsB,4CAAI;AAC1B;AACA,kBAAkB,0DAAgB;AAClC;AACA;AACA,kCAAkC,0DAAgB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA,yBAAyB,mCAAmC,+CAA+C;AAC3G,mCAAmC;AACnC,4BAA4B;AAC5B,8BAA8B;AAC9B;AACA;AACA,QAAQ,0DAAW;AACnB;AACA;AACA,QAAQ,mEAAe;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,2DAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,WAAW;AAC1B;AACA,+BAA+B,4CAAI;AACnC;AACA;AACA,8BAA8B,0DAAgB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,0DAAgB;AAC7D;AACA;AACA;AACA;AACA,sCAAsC,iFAAiF,oEAAoE;AAC3L;AACA;AACA,eAAe,+CAAO;AACtB;AACA;AACA;AACA;AACA;AACA,iCAAiC,UAAU;AAC3C,eAAe,oBAAoB;AACnC,0BAA0B,0EAAuB;AACjD,0DAA0D,mBAAmB,wDAAwD,YAAY,KAAK;AACtJ;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B;AACA,8BAA8B,oDAAc;AAC5C;AACA,iCAAiC,qEAAkB;AACnD;AACA;AACA,8BAA8B,+DAAe;AAC7C,6CAA6C,uEAAoB;AACjE;AACA;AACA;AACA;AACA,eAAe,6DAAY;AAC3B;AACA;AACA,eAAe,kEAAe;AAC9B;AACA;AACA,eAAe,0EAAmB;AAClC;AACA;AACA;AACA,wEAAwE,GAAG,WAAW;AACtF,kEAAkE,EAAE,0DAAkB,6DAA6D,UAAU,mBAAmB,EAAE,KAAK;AACvL;AACA,gBAAgB,gDAAQ;AACxB;AACA,oBAAoB,gDAAQ;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,+CAAO;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,gEAAc;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,+CAAO;AACtB;AACA;AACA,4BAA4B,iDAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,qFAA6B;AAC1D,4BAA4B,iEAAuB;AACnD;AACA;AACA;AACA;AACA;AACA,oBAAoB,yDAAiB,UAAU,4DAAa;AAC5D;AACA,mCAAmC,8DAAc;AACjD,kCAAkC,kEAAkB;AACpD;AACA,yCAAyC,oDAAO,EAAE,+BAA+B,GAAG,gBAAgB;AACpG;AACA,oCAAoC,+DAAQ;AAC5C;AACA;AACA;AACA,wBAAwB,sCAAQ,CAAC,sDAAwB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,mDAAS,uBAAuB,wDAAc;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2DAA6B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,eAAe,oDAAO;AACtB;AACA;AACA,eAAe,iDAAM;AACrB,6BAA6B,wDAAW;AACxC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,kDAAO;AACf,6BAA6B,wDAAW;AACxC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;AC7dqC;AACsC;AACrC;AACsB;AAC5D;AACA;AACA;AACA;AACO;AACP,WAAW,kDAAW;AACtB,YAAY,mDAAQ;AACpB;AACA;AACA,iBAAiB,gEAAoB;AACrC,mBAAmB,yEAAuB;AAC1C;AACA;AACA;AACA,mBAAmB,iEAAqB;AACxC;AACA,KAAK;AACL;AACA,qC;;;;;;;;;;;;;;;;;;;;ACtBsC;AACU;AACO;AAChD;AACP,QAAQ,oDAAY,WAAW,qDAAa;AAC5C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,KAAK;AACL;AACO;AACP;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO,cAAc;AAChC;AACA;AACA;AACA,yCAAyC,OAAO,GAAG,aAAa,oCAAoC,EAAE;AACtG;AACA;AACA;AACA;AACA;AACA,wBAAwB,iDAAiD;AACzE;AACA;AACA,2BAA2B,yDAAW,gCAAgC,6BAA6B;AACnG,iBAAiB,+CAAQ;AACzB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA,kDAAkD,gBAAgB;AAClE,iBAAiB,EAAE;AACnB;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;ACrDiC;AAC1B,kCAAkC,yCAAK;AAC9C;AACA,8BAA8B;AAC9B,SAAS,OAAO;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;;;;;;;;;;;;;AClB2C;AACuC;AAC5B;AACV;AACa;AACpB;AACoB;AAClB;AACW;AAC3C;AACP,iCAAiC,mDAAW;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2DAAmB,2DAA2D,qEAAqE,iDAAiD;AACvN;AACA;AACA;AACA;AACA;AACA,WAAW,WAAW;AACtB;AACA,SAAS,+CAAS,EAAE,8CAAQ;AAC5B,SAAS,gDAAU,EAAE,+CAAS;AAC9B;AACA,YAAY,+DAAkB,gCAAgC,+DAAkB;AAChF;AACA,iDAAiD,YAAY;AAC7D,aAAa;AACb;AACA;AACA,8BAA8B,2CAAK,yBAAyB,2CAAK,WAAW,0CAAO;AACnF;AACA,6CAA6C,YAAY;AACzD,SAAS;AACT;AACA;AACA;AACA,wCAAwC,sDAAmB;AAC3D;AACA;AACA;AACA;AACA,gCAAgC,4CAAK,CAAC,8DAAqB;AAC3D;AACA,aAAa,yDAAc,2BAA2B,yDAAc;AACpE;AACA;AACA;AACA,YAAY,yDAAc;AAC1B,YAAY,yDAAc;AAC1B;AACA,YAAY,gDAAS,sBAAsB,gDAAS;AACpD;AACA;AACA;AACA,KAAK;AACL,iBAAiB,gDAAS,iBAAiB,gDAAS;AACpD;AACA;AACA;AACA;AACA,iBAAiB,gDAAS,qBAAqB,gDAAS,GAAG;AAC3D;AACA;AACA,iBAAiB,gDAAS,sBAAsB,gDAAS,GAAG;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,4CAAK;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,oCAAoC,2DAAmB,sEAAsE,gDAAS;AACtI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;AC9HoC;AACN;AACsC;AAC7D;AACP,QAAQ,oDAAY,WAAW,oDAAY;AAC3C;AACA;AACA,aAAa,qDAAa;AAC1B,eAAe,gDAAM;AACrB;AACA;AACA;AACA;AACO;AACP;AACA,kBAAkB,gDAAM;AACxB;AACA;AACA,YAAY,sCAAQ,CAAC,+EAAiD;AACtE;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;;;;;;;;;ACxBA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACqC;AACE;AACL;AACiC;AACZ;AACc;AAC3B;AACnC;AACP,QAAQ,oDAAY,WAAW,qDAAa;AAC5C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,2CAAI;AACf;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,+DAA+D;AAC9E;AACA;AACA;AACA,wBAAwB,iFAA4B;AACpD;AACA,uBAAuB,uDAAc;AACrC,2FAA2F;AAC3F,kBAAkB,aAAa,SAAS,KAAK,kBAAkB,YAAY,KAAK,KAAK,QAAQ,6BAA6B,mBAAmB,KAAK;AAClJ;AACA,KAAK;AACL;AACO;AACP;AACA,QAAQ,gDAAM;AACd,YAAY,2DAAa;AACzB;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA,aAAa,mDAAQ,gBAAgB,6DAAe;AACpD,6CAA6C,gBAAgB,gDAAgD;AAC7G;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;;AClEoC;AACF;AACD;AAC1B,6BAA6B,yCAAK;AACzC;AACA,gBAAgB;AAChB,SAAS,OAAO;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,2CAAI,2BAA2B,kDAAO;AACrD;AACA;AACA,qC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrBA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC+C;AAC2G;AACpF;AACG;AACoD;AACjF;AACX;AACqD;AACG;AACtC;AAChB;AAC6E;AACjE;AACS;AACF;AACD;AACR;AACkC;AACxE;AACP,QAAQ,oDAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,wCAAS;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,qDAAY;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,8DAAe;AACvC;AACA,sCAAsC,+DAAkB,uBAAuB,+DAAkB;AACjG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,wCAAS;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,gEAAuB;AACrD;AACA;AACA;AACA,oBAAoB,sCAAQ,CAAC,8DAAgC;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B;AACA,YAAY,sCAAQ;AACpB;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,WAAW,WAAW;AACtB;AACA;AACA,uEAAuE,oCAAoC,SAAS;AACpH;AACA;AACA,2BAA2B,+DAAkB;AAC7C,YAAY,+DAAkB;AAC9B,mBAAmB,gEAAuB;AAC1C;AACA;AACA;AACA;AACA;AACA,gCAAgC,+DAAkB;AAClD,YAAY,+DAAkB;AAC9B,mBAAmB,gEAAuB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,sDAAS,KAAK,iBAAiB;AACpD,gBAAgB,WAAW,QAAQ,MAAM;AACzC,KAAK;AACL;AACA;AACA;AACA;AACA,qCAAqC,4DAAiB;AACtD;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,WAAW,WAAW;AACtB,4BAA4B,+DAAkB;AAC9C,WAAW,OAAO;AAClB;AACA,QAAQ,yDAAiB;AACzB;AACA;AACA,eAAe,qDAAY;AAC3B;AACA,aAAa,0DAAW;AACxB,eAAe,qDAAY;AAC3B;AACA,qDAAqD,yDAAiB;AACtE,eAAe,qDAAY;AAC3B;AACA;AACA;AACA;AACA,mBAAmB,qDAAY;AAC/B;AACA,2CAA2C,sDAAmB;AAC9D,eAAe,qDAAY;AAC3B;AACA;AACA,+CAA+C,kBAAkB;AACjE,aAAa;AACb;AACA;AACA,+CAA+C,gBAAgB;AAC/D;AACA;AACA;AACA,iBAAiB,wDAAc,aAAa,uDAAU;AACtD,QAAQ,uDAAU;AAClB;AACA,eAAe,qDAAY;AAC3B;AACA,qCAAqC;AACrC;AACA,2CAA2C,sDAAmB;AAC9D,eAAe,QAAQ;AACvB,eAAe,qDAAY;AAC3B;AACA;AACA,uBAAuB,oDAAO,EAAE,0BAA0B;AAC1D,aAAa;AACb;AACA;AACA,uBAAuB,oDAAO,EAAE,0BAA0B;AAC1D;AACA;AACA;AACA,aAAa,+CAAS;AACtB,YAAY,yDAAiB;AAC7B;AACA;AACA,uBAAuB,qDAAY;AACnC;AACA;AACA;AACA,mBAAmB,qDAAY;AAC/B;AACA;AACA;AACA,0BAA0B,6CAAc;AACxC,gDAAgD,sDAAmB;AACnE,gDAAgD,qDAAkB;AAClE;AACA,kDAAkD,6DAAgB,uBAAuB,qBAAqB,KAAK;AACnH;AACA,4CAA4C,mDAAQ;AACpD;AACA,4DAA4D;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,MAAM;AACzB,gBAAgB,+CAAS;AACzB,kCAAkC,4DAAgB;AAClD,uBAAuB,qDAAY;AACnC,wBAAwB,sDAAgB;AACxC;AACA,mCAAmC,OAAO,UAAU,OAAO;AAC3D,qBAAqB;AACrB;AACA;AACA;AACA,uBAAuB,qDAAY;AACnC;AACA,oDAAoD,sDAAmB;AACvE,wDAAwD;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,4CAAa;AACrB,QAAQ,oDAAO,oBAAoB,oDAAW,yBAAyB,kEAAwB;AAC/F,2CAA2C,sDAAmB;AAC9D,eAAe,qDAAY;AAC3B;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,+CAA+C,gBAAgB;AAC/D;AACA;AACA;AACA;AACA,eAAe,qDAAY;AAC3B;AACA;AACA;AACA,sBAAsB,6CAAc;AACpC,4CAA4C,sDAAmB;AAC/D,4CAA4C,qDAAkB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qDAAY;AAC3B;AACA,4CAA4C,sDAAmB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,mBAAmB;AAC9B,wC;AACA;AACA,4EAA4E,kDAAe,GAAG,YAAY,QAAQ,sDAAuB,SAAS,KAAK,cAAc,QAAQ,KAAK;AAClL;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,yDAAiB;AACpC,mBAAmB,iDAAW,SAAS,uDAAiB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,SAAS,yDAAiB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,kDAAW;AACnB;AACA;AACA,mBAAmB,qEAAmB;AACtC;AACA;AACA;AACA,WAAW,QAAQ;AACnB;AACA;AACA;AACA;AACA,QAAQ,kDAAW;AACnB,2CAA2C,4CAAa;AACxD;AACA;AACA,aAAa,uDAAgB;AAC7B,eAAe,kBAAkB;AACjC;AACA,eAAe,mBAAmB;AAClC,2CAA2C,4CAAa;AACxD,YAAY,uDAAW,eAAe,uDAAW;AACjD;AACA,uBAAuB,oDAAO;AAC9B;AACA,aAAa;AACb;AACA,iBAAiB,yDAAa;AAC9B;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,4CAAa;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,QAAQ;AACpB;AACA;AACA;AACA;AACO;AACP,WAAW,kBAAkB;AAC7B;AACA;AACA;AACA,oBAAoB,iFAAmD;AACvE;AACA;AACA,QAAQ,mDAAQ,gBAAgB,8DAAsB;AACtD;AACA;AACA,oBAAoB,gFAAkD;AACtE;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,wEAA0C;AAClE;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sCAAQ,CAAC,wEAA0C;AAC3D;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;AACO;AACP,0BAA0B,0CAAW;AACrC;AACA,YAAY,8DAAe;AAC3B,mBAAmB,WAAW;AAC9B;AACA;AACA;AACA,KAAK,GAAG,wCAAS;AACjB,kBAAkB,0CAAW;AAC7B;AACA,YAAY,8DAAe;AAC3B;AACA,oCAAoC,6CAAc;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,uCAAuC,wCAAS;AAChD;AACA;AACA;AACA;AACA;AACA,YAAY,8DAAe;AAC3B;AACA;AACA,gBAAgB,sCAAQ,CAAC,4DAA8B;AACvD;AACA;AACA;AACA;AACA,oBAAoB,mDAAQ;AAC5B;AACA;AACA,6CAA6C,oBAAoB;AACjE;AACA;AACA;AACA,iDAAiD,YAAY,OAAO;AACpE;AACA;AACA;AACA;AACA,6BAA6B,0CAAW;AACxC,YAAY,6CAAc,wBAAwB,mDAAQ,kBAAkB,iEAAyB;AACrG;AACA;AACA,QAAQ,sCAAQ,CAAC,2DAA6B;AAC9C;AACA,KAAK,GAAG,wCAAS;AACjB;AACA;AACA;AACA;AACA;AACA,QAAQ,sCAAQ,CAAC,4DAA8B;AAC/C;AACA;AACA,oBAAoB,0CAAW;AAC/B,YAAY,8DAAe;AAC3B;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,sCAAsC,4DAA4D,WAAW,OAAO,KAAK;AACzH;AACA;AACA,0BAA0B,wBAAwB,WAAW,OAAO,KAAK;AACzE;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,8DAAe,YAAY,mDAAQ;AAC3C;AACA;AACA,aAAa,qEAAsB;AACnC;AACA;AACA,gBAAgB,8DAAe,oBAAoB,mDAAQ;AAC3D;AACA;AACA;AACA;AACA,oBAAoB,sCAAQ,CAAC,+EAAiD;AAC9E;AACA;AACA;AACA;AACA,QAAQ,sCAAQ,CAAC,2FAA6D;AAC9E;AACA;AACA,aAAa,oEAAqB;AAClC,QAAQ,sCAAQ,CAAC,yEAA2C;AAC5D;AACA,eAAe,mDAAQ;AACvB;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,8DAAe;AAC3B;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5hBsD;AACA;AAChB;AAC0E;AAC3E;AACH;AACK;AACU;AACuB;AAC3B;AACD;AACuB;AAChC;AAC5B,6BAA6B,cAAc,KAAK;AACvD;AACA,IAAI,0DAAgB;AACpB,uBAAuB,+EAA2C;AAClE,QAAQ,gEAAkB;AAC1B;AACA;AACA;AACA,QAAQ,6DAAe;AACvB;AACA;AACO;AACP,QAAQ,mDAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,iBAAiB;AAC5B,WAAW,2DAAqB;AAChC,gCAAgC,+DAAkB,oBAAoB;AACtE;AACA,wCAAwC,2CAAQ,gBAAgB,2CAAK,6BAA6B,0CAAO;AACzG;AACA;AACA;AACA;AACA;AACA,0BAA0B,iDAAS;AACnC,2CAA2C,sDAAc;AACzD;AACA;AACA,aAAa;AACb;AACA;AACA,KAAK,IAAI;AACT;AACA,4BAA4B,2DAAmB,eAAe,2DAAmB,QAAQ,2DAAmB;AAC5G;AACA;AACA,wDAAwD;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,2CAAI;AAClC;AACA,oGAAoG,6DAAmB;AACvH;AACA;AACA;AACA;AACA,wBAAwB,uDAAe;AACvC;AACA,8DAA8D,+DAAuB;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA;AACA;AACA,uCAAuC,sDAAc;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1GoC;AACyB;AAC6E;AAChD;AAC9C;AACX;AAC6I;AAC3I;AAC0B;AACb;AACD;AACR;AACM;AAC2B;AAC1B;AACvC;AACP,QAAQ,oDAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,6CAA6C;AACxD,0BAA0B,2CAAI;AAC9B;AACA;AACA;AACA,gCAAgC,+DAAkB;AAClD;AACA;AACA;AACA;AACA,qCAAqC,gEAAwB;AAC7D,uCAAuC,2EAAmC;AAC1E;AACA;AACA;AACA,gBAAgB,sCAAQ,CAAC,2EAA6C;AACtE;AACA;AACA;AACA,gBAAgB,sCAAQ;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,qDAAU;AACtC,0DAA0D,SAAS,sDAAS,4BAA4B,iBAAiB,GAAG;AAC5H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,YAAY,yBAAyB,MAAM,uDAAU;AACrD,mBAAmB,2BAA2B;AAC9C,YAAY,sCAAsC;AAClD,eAAe,uDAAuD;AACtE,oBAAoB,yCAAyC;AAC7D,oBAAoB,uEAAuE;AAC3F,eAAe,8CAA8C;AAC7D,qBAAqB,uDAAU;AAC/B;AACA,KAAK;AACL,YAAY,uDAAuD;AACnE;AACA;AACO;AACP,QAAQ,oDAAW;AACnB,QAAQ,4DAAmB;AAC3B;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA;AACA;AACA;AACA;AACA,oCAAoC,gEAAuB,+DAA+D,4DAAmB;AAC7I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,+CAAS;AACjB,0BAA0B,2DAAgB;AAC1C,mBAAmB,sDAAgB;AACnC;AACA,SAAS;AACT;AACA,aAAa,8CAAQ,SAAS,iDAAW;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,+CAAQ,EAAE,2CAAK,EAAE,0CAAI,EAAE,4CAAM;AACrC;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,wDAAW,mEAAmE,2CAAa,EAAE,kDAAc,EAAE,iDAAa;AACzI;AACA;AACA,sBAAsB,kEAA4B;AAClD;AACO;AACP,mBAAmB,kEAA4B;AAC/C,YAAY,gEAAwB;AACpC;AACA;AACA;AACA,mBAAmB,eAAe;AAClC,oCAAoC,uDAAU;AAC9C;AACA;AACA;AACA;AACA;AACA,0BAA0B,mDAAe;AACzC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,mBAAmB,kEAA4B;AAC/C;AACA;AACA;AACA,eAAe,8DAA8D;AAC7E,eAAe,sDAAe;AAC9B;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,mBAAmB,kEAA4B;AAC/C;AACA;AACA,0BAA0B,kDAAc;AACxC,mBAAmB,mBAAmB;AACtC,mBAAmB,sDAAe;AAClC;AACA;AACA;AACA;AACA,YAAY,yDAAW,uBAAuB,YAAY,yBAAyB,KAAK;AACxF;AACA;AACA;AACA;AACO;AACP;AACA,YAAY,2DAAmB;AAC/B,gBAAgB,yDAAW;AAC3B,wBAAwB,aAAa,4BAA4B;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,2DAAmB;AAC3B;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,YAAY,2DAAmB;AAC/B,gBAAgB,kDAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,8DAAsB;AACzF;AACA;AACA;AACA;AACA,UAAU,uDAAU;AACpB,QAAQ,2CAAa,KAAK,6DAAuB,KAAK,mEAA6B;AACnF,eAAe,eAAe;AAC9B,YAAY,+CAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzRwD;AAClB;AAC6I;AAC7H;AAC8B;AACxC;AACX;AAC6I;AACrI;AACN;AACa;AACA;AACD;AACF;AACS;AAC/C;AACP;AACA;AACA;AACO;AACP;AACA;AACA,0BAA0B,oDAAc;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,+CAAS;AAC7C,0BAA0B,4DAAgB;AAC1C;AACA;AACA;AACA,mBAAmB,sDAAgB;AACnC;AACA,iCAAiC,YAAY,UAAU,YAAY,YAAY,YAAY;AAC3F,sBAAsB,gCAAgC,MAAM,SAAS;AACrE,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,gEAAwB;AACjE,2CAA2C,2EAAmC;AAC9E;AACA,gBAAgB,sCAAQ,CAAC,2EAA6C;AACtE;AACA;AACA;AACA,gBAAgB,sCAAQ;AACxB;AACA;AACA;AACA;AACA;AACA,4BAA4B,kDAAO;AACnC,gCAAgC,gDAAM;AACtC,uCAAuC,qDAAY;AACnD;AACA;AACA;AACA;AACA;AACA,+CAA+C,+DAAyB;AACxE;AACA;AACA,iCAAiC;AACjC;AACA;AACA,iCAAiC,mDAAQ;AACzC,mCAAmC,qDAAY;AAC/C,4DAA4D,sDAAmB;AAC/E;AACA,uCAAuC;AACvC,6BAA6B;AAC7B;AACA,+BAA+B,qDAAY;AAC3C;AACA;AACA,+BAA+B,qDAAY;AAC3C;AACA;AACA;AACA;AACA,oBAAoB,uCAAC,gBAAgB,uCAAC;AACtC,wCAAwC,uCAAC;AACzC;AACA,YAAY,kDAAM;AAClB,gBAAgB,yDAAiB;AACjC,uBAAuB,qDAAY,EAAE,uBAAuB;AAC5D;AACA;AACA,gBAAgB,sCAAQ,CAAC,qDAAuB;AAChD;AACA;AACA;AACA,WAAW,qBAAqB;AAChC;AACA;AACA;AACA,QAAQ,gEAAwB;AAChC,QAAQ,kDAAO;AACf;AACA,eAAe,qDAAY;AAC3B;AACA,WAAW,qDAAY;AACvB;AACA;AACA,QAAQ,wDAAgB;AACxB,8BAA8B,sBAAsB,EAAE,uCAAS;AAC/D;AACA,YAAY;AACZ;AACA;AACA,WAAW,+BAA+B;AAC1C;AACA,WAAW,OAAO,GAAG,+DAAkB;AACvC;AACA;AACA,WAAW,oBAAoB;AAC/B;AACA,aAAa,uCAAC;AACd,aAAa,uCAAC;AACd;AACA,gBAAgB,2CAAa;AAC7B,gCAAgC,uCAAC;AACjC,8BAA8B,kEAAyB;AACvD,wBAAwB,kDAAM;AAC9B;AACA;AACA;AACA,qCAAqC,uCAAC;AACtC,8BAA8B,kEAAyB;AACvD,wBAAwB,kDAAM;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,uCAAC,IAAI,2DAAmB;AACpD;AACA,wBAAwB,+DAAyB;AACjD;AACA;AACA,2BAA2B,+DAAyB;AACpD;AACA;AACA,aAAa,0CAAI;AACjB;AACA;AACA;AACA;AACA,gBAAgB,8DAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,2CAAK;AAClB;AACA,aAAa,2CAAK;AAClB;AACA;AACA;AACA,aAAa,4CAAM;AACnB;AACA;AACA;AACA,oBAAoB,sDAAgB;AACpC;AACA;AACA,kCAAkC,EAAE,GAAG,EAAE;AACzC,iBAAiB;AACjB;AACA;AACA,aAAa,iDAAW;AACxB;AACA;AACA,aAAa,gDAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,2CAAK;AAClB;AACA,aAAa,2CAAK;AAClB,aAAa,0CAAI;AACjB,aAAa,4CAAM;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,6CAAO;AACpB,aAAa,iDAAW;AACxB,aAAa,mDAAa;AAC1B;AACA;AACA;AACA;AACA,yDAAyD,QAAQ;AACjE;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,kDAAO;AAC/C;AACA;AACA;AACA,gBAAgB,sCAAQ,CAAC,yEAA2C;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,qBAAqB,6DAAmB;AACxC,qBAAqB,6DAAmB;AACxC,yBAAyB,KAAK,KAAK,KAAK,OAAO,YAAY;AAC3D,2BAA2B,KAAK,IAAI,KAAK,KAAK,KAAK,IAAI,KAAK;AAC5D;AACA,QAAQ,0DAAW;AACnB,mBAAmB,sDAAgB;AACnC;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA,YAAY,0DAAW;AACvB,oBAAoB,YAAY,YAAY,SAAS,kCAAkC;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,6DAA+B;AACnD;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mDAAQ;AACxB;AACA;AACA;AACA,2BAA2B,sDAAgB,UAAU,WAAW;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mDAAQ;AACxB;AACA;AACA;AACA,2BAA2B,sDAAgB,cAAc,0BAA0B,KAAK,iBAAiB;AACzG;AACA;AACA;AACA;AACA;AACA,oBAAoB,6DAA+B;AACnD;AACA;AACA,aAAa,OAAO;AACpB;AACA;AACA,sBAAsB,kDAAM,iCAAiC,kEAAyB;AACtF,uBAAuB,kDAAM,mCAAmC,kEAAyB;AACzF;AACA,mBAAmB,sDAAgB;AACnC;AACA;AACA;AACA;AACA,0BAA0B,iBAAiB;AAC3C,SAAS;AACT;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;AC1WsC;AACoC;AACD;AACxC;AAC+C;AAC7B;AAChB;AACgE;AACnG;AACA;AACA;AACA;AACA;AACO;AACP;AACA,WAAW,OAAO;AAClB,SAAS,wDAAc;AACvB;AACA;AACA;AACA;AACA;AACA,aAAa,+DAAuB;AACpC,YAAY,sCAAQ,CAAC,qEAAuC;AAC5D;AACA;AACA;AACA,YAAY,uDAAU,eAAe,gEAAwB;AAC7D,YAAY,sCAAQ,CAAC,sEAAwC;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,wDAAc,aAAa,mDAAS;AACpD;AACA,oBAAoB,sCAAQ,CAAC,qEAAuC;AACpE;AACA;AACA;AACA,2BAA2B,kEAA4B;AACvD,oBAAoB,2CAAa;AACjC;AACA;AACA;AACA;AACA;AACA,kDAAkD,wEAAkC;AACpF;AACA;AACA,gDAAgD,sEAAyB;AACzE;AACA;AACA;AACA;AACA;AACA,gBAAgB,wDAAc;AAC9B;AACA;AACA,qBAAqB,mDAAS;AAC9B,gBAAgB,sCAAQ,CAAC,qEAAuC;AAChE;AACA;AACA;AACA,qBAAqB,uDAAU,mCAAmC,4DAAiB;AACnF;AACA;AACA;AACA;AACA,gBAAgB,wDAAc;AAC9B,oBAAoB,uDAAU,cAAc,+CAAS;AACrD;AACA;AACA;AACA;AACA,qBAAqB,mDAAS;AAC9B,gBAAgB,sCAAQ,CAAC,qEAAuC;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,0DAA4B;AAChD;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjGA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACgE;AACL;AACgC;AACV;AACtC;AACJ;AACoB;AACT;AAC3C,kDAAkD,+CAAQ;AACjE,QAAQ,kDAAO;AACf;AACA,4BAA4B,qBAAqB;AACjD;AACA,aAAa,qDAAU;AACvB;AACA,wBAAwB,yDAAc;AACtC;AACA;AACA,wBAAwB,8DAAmB;AAC3C;AACA;AACA;AACA;AACO;AACP,IAAI,mDAAgB;AACpB;AACA;AACA;AACA,QAAQ,wEAAgB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,yBAAyB,qCAAM;AAC/B;AACA;AACA,6BAA6B,wBAAwB,oCAAK,EAAE;AAC5D,sCAAsC,sDAAW,gBAAgB,oCAAK,EAAE,IAAI,WAAW;AACvF;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACO;AACP,qCAAqC,2CAAI;AACzC,qBAAqB,sDAAW;AAChC;AACA;AACA,qBAAqB;AACrB;AACA;AACA,4BAA4B,6DAAa;AACzC,8DAA8D,KAAK;AACnE;AACA;AACA,SAAS;AACT;AACA;AACA;AACO;AACP;AACA,IAAI,mDAAgB;AACpB;AACA,sBAAsB,sDAAW,QAAQ,oCAAK;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,mDAAoB,CAAC,GAAG,MAAM,IAAI,sDAAW,UAAU,EAAE,QAAQ;AAC5F,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,QAAQ,wEAAgB;AACxB;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,sBAAsB,mEAAmE;AACzF,aAAa;AACb;AACA;AACA;AACA;AACO;AACP;AACA,IAAI,mDAAgB;AACpB,sBAAsB,sBAAsB,oCAAK;AACjD;AACA;AACA,uBAAuB,UAAU;AACjC;AACA,aAAa;AACb;AACA;AACA;AACA,wBAAwB,OAAO,2CAAQ,SAAS,gBAAgB,2BAA2B;AAC3F,wCAAwC,OAAO,2CAAQ,SAAS,gBAAgB,sBAAsB;AACtG;AACA,wEAAwE,oCAAK;AAC7E;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,IAAI,mDAAgB;AACpB;AACA,QAAQ,wEAAgB;AACxB;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACO;AACP;AACA,YAAY,mDAAW;AACvB;AACA;AACA;AACA;AACA;AACO;AACP;AACA,sDAAsD,8CAAO;AAC7D,YAAY,SAAS,+DAAuB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,oC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpKwC;AACO;AACA;AACb;AACM;AACN;AACN;AACE;AACvB;AACA;AACA;AACA;AACA;AACP,mBAAmB,OAAO,qDAAO,uDAAU;AACpC;AACP;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oDAAY;AACxB;AACA;AACA;AACA;AACA;AACA;AACO,0BAA0B,SAAS,IAAI,eAAe;AAC7D,wBAAwB,sDAAW;AACnC;AACA;AACA,eAAe,QAAQ;AACvB,8BAA8B,oDAAc;AAC5C;AACA,uCAAuC,QAAQ,cAAc,sDAAW,8BAA8B;AACtG;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,qFAAqF,oDAAY;AACjG,KAAK;AACL;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;ACtDA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC+C;AACJ;AACN;AACJ;AACiB;AAChB;AACQ;AACU;AACX;AAClC;AACA;AACP;AACA;AACA;AACA,gCAAgC,6DAAY;AAC5C,0BAA0B,2DAAU;AACpC;AACA;AACA;AACA;AACA,0EAA0E,sDAAW,eAAe;AACpG;AACA;AACA,gCAAgC,gDAAK;AACrC;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,4BAA4B,uCAAC,gBAAgB,uCAAC;AAC9C,gBAAgB,0CAAI;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,sDAAW;AACzC;AACA,0BAA0B,2DAAmB;AAC7C;AACA;AACA;AACA;AACA,mCAAmC,MAAM;AACzC,wBAAwB,MAAM,SAAS,UAAU,IAAI,MAAM,WAAW,MAAM,EAAE,MAAM;AACpF,uBAAuB,MAAM,SAAS,UAAU,IAAI,MAAM,WAAW,MAAM,EAAE,MAAM;AACnF,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA,yDAAyD,qBAAqB;AAC9E,oFAAoF,qBAAqB,KAAK;AAC9G;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,gCAAgC,2CAAQ,QAAQ,YAAY,SAAS;AACrE,2DAA2D,cAAc,oCAAK,EAAE,WAAW,SAAS,EAAE,OAAO,IAAI,uDAAY,QAAQ,GAAG,KAAK,KAAK;AAClJ;AACA,8BAA8B,mCAAmC;AACjE,4DAA4D,EAAE,OAAO,KAAK,YAAY,EAAE;AACxF;AACA,eAAe;AACf,KAAK;AACL;AACA,mCAAmC,oCAAK;AACxC,uEAAuE,QAAQ,2CAAQ,SAAS;AAChG,KAAK;AACL;AACA;AACA,eAAe,OAAO;AACtB;AACA;AACA,8BAA8B,sDAAW,gBAAgB,oCAAK,EAAE;AAChE;AACA,YAAY,2DAAU;AACtB;AACA;AACA;AACA,kCAAkC,YAAY,OAAO,MAAM,IAAI,WAAW;AAC1E,kCAAkC,YAAY,OAAO,MAAM,IAAI,WAAW;AAC1E,mCAAmC,YAAY,OAAO,MAAM,IAAI,SAAS,iBAAiB,EAAE;AAC5F,mCAAmC,YAAY,OAAO,MAAM,IAAI,SAAS,kBAAkB;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,2CAAI;AAClC;AACA,mCAAmC,UAAU,MAAM,aAAa,MAAM,eAAe,2CAAQ,QAAQ,GAAG;AACxG,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,4BAA4B;AAC9D,yBAAyB,2CAAI;AAC7B;AACA;AACA,iDAAiD,OAAO,UAAU,OAAO,4BAA4B,OAAO,UAAU,OAAO;AAC7H;AACA;AACA;AACA,iBAAiB;AACjB,iBAAiB;AACjB;AACA;AACA,SAAS,IAAI;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,cAAc;AAC7C,sCAAsC;AACtC,qBAAqB;AACrB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,aAAa,UAAU,gBAAgB,EAAE,KAAK,KAAK,QAAQ,uBAAuB,EAAE;AAC7I,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA,iEAAe,QAAQ,EAAC;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,2DAAU;AAChC,sBAAsB,sDAAW;AACjC;AACA;AACA,qCAAqC,UAAU,IAAI,IAAI;AACvD,oDAAoD,uCAAC;AACrD,qBAAqB,QAAQ;AAC7B;AACA;AACA;AACA,aAAa,qCAAqC,MAAM,IAAI,MAAM,IAAI;AACtE,aAAa,0BAA0B,MAAM,aAAa,MAAM,OAAO,KAAK,KAAK;AACjF;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,iBAAiB,uCAAuC;AACxD,gBAAgB,2DAAmB,kBAAkB,UAAU,MAAM,MAAM,IAAI,UAAU,MAAM,MAAM;AACrG,KAAK;AACL;AACA,YAAY,sBAAsB;AAClC;AACA,yCAAyC,cAAc,WAAW,OAAO,uDAAY,sBAAsB,IAAI,YAAY,KAAK,SAAS;AACzI,yCAAyC,cAAc,WAAW,OAAO,uDAAY,QAAQ,KAAK,KAAK;AACvG;AACA,iCAAiC,gBAAgB;AACjD,mCAAmC,MAAM,UAAU,MAAM,sBAAsB,UAAU,IAAI,MAAM;AACnG;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA,YAAY,0CAAI,IAAI,IAAI;AACxB;AACA;AACA;AACA,KAAK;AACL;AACA,oC;;;;;;;;;;;;;;;;;;;ACrNwC;AACJ;AACgB;AAC7C;AACP;AACA,4BAA4B,6DAAY;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,MAAM,GAAG,sDAAW,4BAA4B,GAAG;AACrE,mBAAmB,MAAM,GAAG,sDAAW,2BAA2B,mBAAmB,GAAG;AACxF,iBAAiB,MAAM,GAAG,sDAAW,UAAU;AAC/C,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA,4BAA4B,2CAAQ,QAAQ,YAAY,SAAS;AACjE;AACA;AACA;AACA,yBAAyB,oCAAK;AAC9B;AACA;AACA;AACA;AACA,8EAA8E,EAAE,OAAO,KAAK,OAAO,EAAE;AACrG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,oCAAK;AACxC,uEAAuE,QAAQ,2CAAQ,SAAS;AAChG;AACA;AACA,iEAAe,KAAK,EAAC;AACrB,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;AClDA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACgE;AACd;AACN;AACX;AACkC;AACrB;AACF;AACe;AACf;AACrC;AACP;AACA;AACA;AACA,uBAAuB,2CAAI,sDAAsD;AACjF,uBAAuB,gDAAS;AAChC,kDAAkD,oBAAoB,iDAAiD;AACvH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D;AAC5D;AACA;AACA;AACA;AACA;AACA,yBAAyB,8CAAO;AAChC,4EAA4E,YAAY,yBAAyB,mDAAQ,cAAc,6DAAa,uBAAuB,gDAAS,aAAa;AACjM,QAAQ,wEAAgB;AACxB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACO;AACP;AACA;AACA,sBAAsB,8CAAO;AAC7B;AACA,sBAAsB,sDAAW,SAAS,oCAAK;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,MAAM,IAAI,MAAM,+CAA+C,sDAAW,kBAAkB;AAC/H;AACA,yBAAyB,kDAAW;AACpC,mEAAmE,EAAE,wCAAwC,aAAa;AAC1H;AACO;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,0CAAI;AAChB,kCAAkC,sDAAW,QAAQ;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0CAAI;AAChB,4BAA4B,sDAAW,WAAW,gCAAgC,sDAAW,mBAAmB;AAChH,kCAAkC,sDAAW,QAAQ;AACrD;AACA;AACA;AACA;AACA;AACA,cAAc,aAAa,GAAG,sDAAW,QAAQ;AACjD;AACO;AACP,IAAI,mDAAgB;AACpB;AACA,mDAAmD,UAAU;AAC7D,kFAAkF,sDAAU,KAAK,oDAAU,eAAe,YAAY,eAAe,wDAAqB;AAC1K,KAAK;AACL;AACA,iC;;;;;;;;;;;;;;;;;AC7GoC;AACW;AAC/C;AACA,aAAa,wDAAoB;AACjC;AACA,mCAAmC,oCAAK;AACxC,uEAAuE,QAAQ,2CAAQ,SAAS;AAChG;AACA;AACA,iEAAe,MAAM,EAAC;AACtB,kC;;;;;;;;;;;;;;;;;;;;;ACVgE;AAC3B;AACV;AACa;AACH;AACK;AAC1C;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,4BAA4B,mDAAQ,iBAAiB,6DAAa;AAClE;AACA,KAAK;AACL;AACA,YAAY,gDAAiB;AAC7B;AACA,8DAA8D,8CAAO,IAAI,aAAa,GAAG,WAAW;AACpG;AACA,0CAA0C,wCAAwC;AAClF;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,sCAAsC,gCAAgC;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,oCAAK;AAC7E;AACA,gBAAgB,gDAAU;AAC1B,wEAAwE,2CAAM;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA,iEAAe,KAAK,EAAC;AACrB,iC;;;;;;;;;;;;;;;;;;;;;;ACvDwC;AACb;AACa;AACG;AACX;AACS;AACY;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,2DAAe;AAC5B,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,qDAAqD;AACrD,sBAAsB,iDAAW;AACjC;AACA;AACA,2BAA2B,8CAAO,IAAI,KAAK,GAAG,QAAQ;AACtD;AACA;AACA,6DAA6D,eAAe,WAAW,OAAO,uDAAY,WAAW,IAAI,cAAc,KAAK;AAC5I;AACA;AACA;AACA,uFAAuF,MAAM,GAAG,sDAAW,UAAU;AACrH;AACA;AACA,wJAAwJ;AACxJ;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA,6DAA6D,oCAAK;AAClE,8BAA8B,kDAAY;AAC1C,2CAA2C,8CAAO,IAAI,KAAK,GAAG,QAAQ;AACtE,yCAAyC,EAAE;AAC3C;AACA,+BAA+B,MAAM,IAAI,UAAU,OAAO,aAAa,kBAAkB,EAAE;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA,iEAAe,aAAa,EAAC;AAC7B,kC;;;;;;;;;;;;;;;;;;;;;;;;AC9DgE;AACpB;AACC;AACT;AACsD;AACvC;AACV;AACP;AAClC;AACA;AACA,qEAAqE,2DAAe;AACpF,iGAAiG,oDAAY;AAC7G;AACA,YAAY,sCAAQ,CAAC,8EAAgD;AACrE;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,gDAAK;AAClC;AACA;AACA;AACA;AACA;AACA,oBAAoB,iEAAqB;AACzC,uBAAuB,mDAAQ,QAAQ,6DAAa,gBAAgB,gDAAK;AACzE,wBAAwB,UAAU,gBAAgB;AAClD,KAAK;AACL;AACA;AACA,uBAAuB,iEAAqB;AAC5C;AACA,uBAAuB,gDAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,8CAAO,aAAa;AAClD,8BAA8B,QAAQ,GAAG,OAAO;AAChD;AACA;AACA;AACA,qCAAqC,OAAO;AAC5C,yDAAyD,OAAO;AAChE,yDAAyD,OAAO;AAChE,6DAA6D,eAAe,oBAAoB,cAAc,KAAK,KAAK;AACxH;AACA,yBAAyB,qFAAqF;AAC9G,yBAAyB,iEAAiE,OAAO;AACjG,uBAAuB;AACvB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,0DAA0D,oCAAK;AAC/D,8BAA8B,kDAAY;AAC1C,oEAAoE,8CAAO,IAAI,KAAK,GAAG,8CAAO,UAAU;AACxG,yCAAyC,EAAE;AAC3C,0BAA0B,MAAM,IAAI,UAAU,OAAO,aAAa,kBAAkB,EAAE;AACtF;AACA;AACA,+CAA+C,SAAS;AACxD;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,2CAAM;AACjE,uBAAuB,iEAAqB;AAC5C;AACA;AACA;AACA;AACA,6DAA6D,kBAAkB,SAAS;AACxF;AACA;AACA;AACA;AACA,iEAAe,cAAc,EAAC;AACvB;AACP;AACA;AACA,IAAI,mDAAgB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,mC;;;;;;;;;;;;;;;;;;AC/GoC;AACO;AACC;AAC5C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,eAAe,OAAO;AACtB;AACA,YAAY,iDAAU;AACtB,YAAY,sCAAQ,CAAC,wEAA0C;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,+BAA+B;AAClD;AACA,uCAAuC,QAAQ,uBAAuB,gBAAgB,cAAc,WAAW,uBAAuB,cAAc,cAAc,EAAE,EAAE,qDAAO,SAAS,qBAAqB;AAC3M,aAAa;AACb;AACA;AACA;AACA,wBAAwB,6CAA6C;AACrE,wBAAwB,6CAA6C;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,iEAAe,OAAO,EAAC;AACvB,mC;;;;;;;;;;;;;;;;;;;;;;;AC5DA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACkC;AACwB;AACtB;AACiB;AAC4B;AAC9B;AAC5C;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,8CAAO,IAAI,KAAK,GAAG,OAAO;AAC/C,iCAAiC,iBAAiB;AAClD,qBAAqB,8CAAO,IAAI,KAAK,GAAG,OAAO,GAAG,QAAQ;AAC1D;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,gDAAK;AACxC,sCAAsC,2CAAI;AAC1C,4BAA4B,gEAAsB;AAClD;AACA;AACA;AACA;AACA,gCAAgC,sCAAQ,CAAC,uEAAyC;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sCAAQ,CAAC,gEAAkC;AAC/D;AACA;AACA;AACA,oBAAoB,sCAAQ,CAAC,4EAA8C;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,2CAAI;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2DAAmB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B,8DAA8D;AAC9D;AACA;AACA;AACA;AACA;AACA,gBAAgB,sCAAQ,CAAC,4EAA8C;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,gDAAK;AAClC;AACA;AACA;AACA,aAAa,8CAAO;AACpB,gCAAgC,wDAAY;AAC5C;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,qBAAqB;AAChD,iCAAiC,yDAAkB;AACnD;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA,iEAAe,OAAO,EAAC;AACvB,mC;;;;;;;;;;;;;;;;;;;;;;ACnKwC;AACE;AACQ;AACd;AACiB;AACV;AAC3C;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,iBAAiB,wDAAc;AAC/B;AACA;AACA;AACA;AACA,2BAA2B,2DAAmB;AAC9C,gBAAgB,sCAAQ,CAAC,mEAAqC;AAC9D;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,mDAAoB;AAC/C,+BAA+B,EAAE,qBAAqB,sDAAW,aAAa,IAAI,kBAAkB,eAAe;AACnH;AACA;AACA;AACA,mCAAmC,sDAAW,aAAa,IAAI,kBAAkB;AACjF;AACA,gCAAgC,uCAAuC,IAAI,SAAS;AACpF;AACA;AACA;AACA;AACA,kDAAkD,0BAA0B;AAC5E,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAe,aAAa,EAAC;AACtB;AACP,kBAAkB,sDAAW;AAC7B,qBAAqB,MAAM;AAC3B;AACA;AACA;AACA,2BAA2B,oDAAY;AACvC;AACA,kC;;;;;;;;;;;;;;;;;AC/EqC;AAC9B;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,kBAAkB,iDAAiD;AACnE,SAAS;AACT,KAAK;AACL;AACA,mCAAmC,oCAAK;AACxC;AACA,mBAAmB,OAAO,YAAY,IAAI;AAC1C,+CAA+C,OAAO,uBAAuB,OAAO,WAAW,QAAQ,2CAAQ,SAAS;AACxH,eAAe,OAAO,KAAK,IAAI;AAC/B;AACA;AACA,iEAAe,MAAM,EAAC;AACtB,kC;;;;;;;;;;;;;;;;;;;;;;;;ACtB4B;AACE;AACE;AACA;AACF;AACE;AACF;AACM;AACV;AAC1B,mBAAmB,6CAAO,EAAE,4CAAM,EAAE,4CAAM,EAAE,6CAAO,EAAE,+CAAS,EAAE,0CAAI,EAAE,4CAAM,EAAE,6CAAO,EAAE,2CAAK;AACrF;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;;;;;;;;ACjBgE;AACxB;AACc;AACJ;AAClD;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,0BAA0B,gDAAkB;AAC5C;AACA,eAAe,OAAO;AACtB,qBAAqB,6DAAa;AAClC;AACA,sEAAsE,4CAAc;AACpF;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,8BAA8B;AAC9B,yEAAyE,+CAAM,QAAQ,uCAAC,aAAa,iBAAiB;AACtH,yEAAyE,+CAAM,QAAQ,uCAAC,aAAa,iBAAiB;AACtH,0BAA0B;AAC1B;AACA;AACA,SAAS;AACT;AACA,qBAAqB;AACrB;AACA;AACA;AACA,8BAA8B,KAAK,OAAO,mBAAmB,OAAO,aAAa;AACjF;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAe,SAAS,EAAC;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,gDAAkB;AACxC;AACA;AACA;AACA;AACA,0CAA0C,uCAAC,YAAY;AACvD,sBAAsB,OAAO,UAAU,QAAQ;AAC/C,sBAAsB,KAAK,EAAE,MAAM,GAAG,QAAQ,uBAAuB,OAAO,YAAY,OAAO;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,MAAM,GAAG,OAAO,IAAI,OAAO;AACjD,iDAAiD,oEAAoE;AACrH;AACA;AACA,iBAAiB,gBAAgB;AACjC,mDAAmD,OAAO,OAAO,OAAO;AACxE,KAAK;AACL;AACA,qC;;;;;;;;;;;;;;;;;;;;AChFgE;AACxB;AACA;AACc;AACO;AAC7D;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,0BAA0B,gDAAkB;AAC5C;AACA,eAAe,OAAO;AACtB,mBAAmB,sDAAW,iBAAiB,uCAAC;AAChD,mBAAmB,sDAAW,iBAAiB,uCAAC;AAChD,qBAAqB,6DAAa;AAClC;AACA,2DAA2D,4CAAc;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,uBAAuB;AACnD,4BAA4B;AAC5B,+CAA+C,GAAG,oCAAoC,GAAG;AACzF;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAe,IAAI,EAAC;AACpB;AACA;AACA;AACA;AACA,sBAAsB,gDAAkB;AACxC;AACA;AACA;AACA;AACA,6BAA6B,+CAAM;AACnC;AACA,sBAAsB,KAAK,EAAE,OAAO,GAAG,QAAQ;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,OAAO,GAAG,KAAK,IAAI,OAAO,IAAI,MAAM;AAC1D,iDAAiD,oEAAoE;AACrH;AACA;AACA,iBAAiB,gBAAgB;AACjC,mDAAmD,OAAO,OAAO,OAAO;AACxE,KAAK;AACL;AACA,gC;;;;;;;;;;;;;;;ACnFA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;ACf8B;AACwC;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,6BAA6B,eAAe;AAC5C;AACA;AACA;AACA;AACA,yBAAyB,gDAAS,iBAAiB,gDAAS;AAC5D;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA,eAAe,sDAAe;AAC9B;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,oBAAoB;AACpB;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,sCAAQ,CAAC,kEAAoC;AACrD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,gDAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzHoC;AACa;AAC2F;AACxC;AACrD;AACL;AACC;AACK;AACF;AACD;AACZ;AACF;AACuB;AACT;AAC8B;AAClC;AACqB;AACX;AACM;AACA;AACX;AACS;AAC6F;AAC7F;AACvD;AACA;AACA;AACO,wBAAwB,mDAAc;AAC7C,mEAAmE;AACnE,wEAAwE,yDAAa;AACrF;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gDAAS,8BAA8B,gBAAgB;AAC/E;AACA;AACA;AACA,6BAA6B,0DAAa;AAC1C,wCAAwC,2DAAoB;AAC5D,aAAa;AACb;AACA,0CAA0C,uDAAY,oBAAoB;AAC1E,uBAAuB,wDAAW;AAClC,oBAAoB,iEAAc;AAClC;AACA,kBAAkB,yDAAa;AAC/B,8DAA8D,mCAAmC,oBAAoB,KAAK,oBAAoB,sBAAsB,KAAK;AACzK,SAAS;AACT;AACA,qBAAqB,6CAAK;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,WAAW;AAC1B,6CAA6C,2CAAQ;AACrD,2CAA2C,+DAAyB,YAAY,8DAAiB;AACjG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,2DAAqB;AACpC;AACA,oCAAoC,+DAAkB;AACtD;AACA,iHAAiH;AACjH;AACA;AACA,SAAS,IAAI;AACb;AACA;AACA,eAAe,gBAAgB;AAC/B,8BAA8B,4DAAqB;AACnD,YAAY,kDAAO;AACnB,8CAA8C,sDAAgB;AAC9D;AACA,YAAY,kDAAO;AACnB,4CAA4C,sDAAgB;AAC5D;AACA;AACA;AACA;AACA,eAAe,oEAA8B;AAC7C;AACA;AACA;AACA,gBAAgB,8DAAiB;AACjC,6BAA6B,uCAAC,IAAI,8DAAiB;AACnD,6BAA6B,uCAAC,IAAI,8DAAiB;AACnD,iCAAiC,8DAAiB;AAClD;AACA,oDAAoD;AACpD;AACA;AACA;AACA,SAAS,IAAI;AACb;AACA;AACA,sBAAsB,4CAAI;AAC1B;AACA;AACA;AACA,iCAAiC,6DAAsB;AACvD,kBAAkB,uEAA6B;AAC/C,kBAAkB,0DAAgB;AAClC;AACA;AACA;AACA;AACA,eAAe,uEAAiC;AAChD,oCAAoC,+DAAkB;AACtD,mCAAmC,uDAAa;AAChD;AACA;AACA,sBAAsB,4DAAqB;AAC3C;AACA;AACA;AACA,SAAS,IAAI;AACb;AACA;AACA,8BAA8B,uDAAS;AACvC;AACA;AACA,QAAQ,uEAAmB;AAC3B;AACA;AACA,mCAAmC,qEAAkB;AACrD;AACA;AACA,8BAA8B,4DAAe;AAC7C;AACA;AACA,8BAA8B,2DAAa;AAC3C;AACA;AACA,eAAe,6EAAuB;AACtC;AACA;AACA,mBAAmB,oEAAmB,WAAW,kFAA4B;AAC7E;AACA;AACA,eAAe,+EAAyB;AACxC;AACA;AACA;AACA;AACA;AACA,eAAe,4EAAqB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,qDAAY;AACzC,oBAAoB,gFAA0B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sDAA0B;AACzC;AACA;AACA;AACA,eAAe,wDAAW;AAC1B;AACA;AACA;AACA,YAAY,4DAAe;AAC3B;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;AC1MsC;AACI;AACnC;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,sDAAU;AACtB,mBAAmB,kDAAW;AAC9B;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;ACdA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC+C;AACS;AACuB;AACjD;AACM;AACI;AACS;AACoJ;AAC9L;AACA;AACA,8BAA8B,0DAAuB;AACrD;AACP,QAAQ,mDAAQ;AAChB;AACA;AACA,qEAAqE,aAAa;AAClF;AACA;AACO,iCAAiC,SAAS;AACjD;AACA;AACA,yCAAyC,UAAU,WAAW,4DAAiB,yBAAyB;AACxG,WAAW,uDAAuD;AAClE,oBAAoB,gDAAS,iBAAiB;AAC9C;AACA;AACA,QAAQ,sCAAQ,CAAC,+DAAiC;AAClD;AACA;AACA,sBAAsB,oEAAmB;AACzC;AACA;AACA,WAAW,uLAAuL;AAClM,WAAW,cAAc;AACzB;AACA,eAAe,0EAAiC;AAChD;AACA;AACA;AACA,6EAA6E,uDAAuD,OAAO,KAAK;AAChJ,uCAAuC,gEAAuB;AAC9D,SAAS,yFAAyF;AAClG,SAAS,+CAA+C;AACxD,SAAS,iDAAiD;AAC1D,SAAS,+CAA+C;AACxD,SAAS;AACT;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,YAAY,gEAAuB;AACnC,iBAAiB,8DAA8D;AAC/E,iBAAiB;AACjB;AACA;AACA;AACA;AACA,mBAAmB,2CAA2C;AAC9D;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,mBAAmB,2CAA2C;AAC9D;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,cAAc,gBAAgB,kBAAkB,KAAK,KAAK,+DAA+D;AACxK;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6DAA6D,8BAA8B,GAAG,mDAAQ,0DAA0D,qCAAqC,KAAK,kBAAkB,kBAAkB,KAAK,KAAK,mCAAmC;AAC3R;AACA;AACA,SAAS;AACT;AACA;AACA,6CAA6C,eAAe,kHAAkH;AAC9K;AACA;AACA,6CAA6C,+BAA+B;AAC5E,6CAA6C,+BAA+B;AAC5E,wBAAwB,aAAa,KAAK,aAAa;AACvD,gCAAgC,aAAa,KAAK,OAAO,KAAK,QAAQ;AACtE,gCAAgC,aAAa,KAAK,OAAO,KAAK,QAAQ;AACtE,gCAAgC,+BAA+B;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,iBAAiB,MAAM,UAAU,QAAQ,UAAU,MAAM,iBAAiB;AACtG,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB,WAAW,cAAc;AACzB,kBAAkB,iDAAQ;AAC1B,6BAA6B,2CAAI;AACjC,gCAAgC,wDAAe;AAC/C,qBAAqB,aAAa,UAAU,KAAK,iBAAiB,QAAQ,UAAU,KAAK,iBAAiB,IAAI;AAC9G;AACA,6DAA6D,8DAA8D,6EAA6E,0BAA0B,QAAQ,KAAK,4BAA4B,QAAQ,KAAK,KAAK,8CAAO,uBAAuB,IAAI,yBAAyB,IAAI,+DAA+D,QAAQ,KAAK,4CAA4C,+CAA+C,KAAK;AACxgB,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,eAAe;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,4DAAmB;AACtC,WAAW,2CAA2C,GAAG,oEAA2B;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,oBAAoB,wBAAwB,oBAAoB;AAC/G;AACA,aAAa;AACb;AACA,mDAAmD,oBAAoB,kBAAkB,oBAAoB,OAAO,OAAO,eAAe,oBAAoB;AAC9J;AACA,aAAa;AACb;AACA,mDAAmD,oBAAoB,kBAAkB,oBAAoB,OAAO,OAAO,eAAe,oBAAoB;AAC9J;AACA;AACA;AACA;AACA,WAAW,wDAAwD,GAAG,yEAAgC;AACtG,WAAW,+EAA+E,GAAG,wEAA6B;AAC1H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClRA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACyD;AAC+C;AAChE;AACV;AACM;AACoB;AACX;AACM;AAC5C;AACP,WAAW,UAAU;AACrB;AACA,gBAAgB;AAChB;AACA;AACA;AACA,QAAQ,kDAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,kDAAO;AACf;AACA;AACA,YAAY;AACZ;AACO;AACP;AACA,gBAAgB;AAChB;AACA,oDAAoD,2BAA2B;AAC/E,iDAAiD,mCAAmC;AACpF;AACA;AACA;AACA,mBAAmB,yDAAW,iBAAiB,2BAA2B,kBAAkB,IAAI;AAChG;AACA,KAAK;AACL,6BAA6B,oDAAS,oCAAoC,yDAAgB;AAC1F;AACA;AACA;AACA;AACA,eAAe,6CAAM,mBAAmB,uCAAI;AAC5C;AACA;AACA;AACO;AACP,WAAW,eAAe;AAC1B,WAAW,sDAAe;AAC1B;AACO;AACP,WAAW,cAAc;AACzB,aAAa,kFAAkF,EAAE;AACjG;AACA;AACA;AACA,iEAAiE,8DAA8D,oGAAoG,0BAA0B,QAAQ,KAAK,4BAA4B,QAAQ,KAAK,2BAA2B,OAAO,KAAK,IAAI,GAAG,mDAAQ;AACzW;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB,SAAS;AACT;AACA;AACO;AACP,WAAW,uBAAuB;AAClC;AACA;AACA;AACA,0CAA0C,kBAAkB,2GAA2G,uCAAuC,OAAO,KAAK,cAAc,QAAQ,KAAK,gBAAgB,UAAU,KAAK,KAAK,gDAAS,2CAA2C,0BAA0B,KAAK,WAAW,KAAK,GAAG,KAAK,GAAG,IAAI,oDAAS,oBAAoB,oBAAoB;AAC5b;AACA;AACA;AACA;AACO;AACP,WAAW,WAAW;AACtB;AACA,8DAA8D;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,YAAY;AAC3B;AACA,YAAY,sCAAQ,CAAC,sFAAwD;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,iBAAiB;AAC5B,WAAW,OAAO;AAClB,QAAQ,gDAAS;AACjB;AACA;AACA,QAAQ,wEAA2B;AACnC;AACA,YAAY,wEAA2B;AACvC;AACA,+BAA+B,uDAAU;AACzC,+BAA+B,uDAAU;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,2EAA8B,QAAQ,2EAA8B;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,wEAA2B;AACxC;AACA;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;;ACjLgD;AAClB;AACmB;AACY;AACjB;AACrC;AACA;AACA,gCAAgC,0DAAuB;AACvD,mCAAmC,SAAS;AACnD;AACA,yCAAyC,UAAU,WAAW,4DAAiB,yBAAyB;AACxG,WAAW,0HAA0H,GAAG,yDAAc;AACtJ;AACA,8BAA8B,0EAAiC;AAC/D;AACA,oBAAoB;AACpB,uBAAuB;AACvB,sDAAsD,+BAA+B,wCAAwC,KAAK,yDAAyD,gCAAgC,KAAK;AAChO;AACA,+DAA+D,4BAA4B,mCAAmC;AAC9H,kEAAkE,+BAA+B,cAAc;AAC/G;AACA;AACA,QAAQ,sCAAQ,CAAC,+DAAiC;AAClD;AACA;AACA,QAAQ,sCAAQ,CAAC,+DAAiC;AAClD;AACA,yCAAyC,eAAe;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,WAAW;AACX;AACA,qC;;;;;;;;;;;;;;;;;;;;;;;;;;AClDA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACsF;AACP;AACjD;AACM;AACY;AACC;AACuF;AACjI;AACA;AACA,+BAA+B,0DAAuB;AACtD,kCAAkC,SAAS;AAClD;AACA,yCAAyC,UAAU,WAAW,4DAAiB,yBAAyB;AACxG,WAAW,uIAAuI;AAClJ;AACA,6BAA6B,0EAAiC;AAC9D;AACA;AACA,8CAA8C,iDAAiD,8BAA8B,YAAY,KAAK,2BAA2B,OAAO,KAAK;AACrL;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,iCAAiC,gDAAgD,8BAA8B,kBAAkB,KAAK;AACtI;AACA;AACA;AACA,SAAS;AACT;AACA,uDAAuD,eAAe,YAAY,wBAAwB,QAAQ,mBAAmB;AACrI;AACA;AACA,WAAW,WAAW;AACtB;AACA;AACA,oBAAoB,4DAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,cAAc;AAC7C;AACA;AACA;AACA,YAAY,8DAAiB,QAAQ,8DAAiB;AACtD;AACA,+BAA+B,cAAc;AAC7C;AACA,iBAAiB,8DAAiB;AAClC,gBAAgB,wEAA2B;AAC3C;AACA,wBAAwB;AACxB;AACA;AACA;AACA,4EAA4E,cAAc;AAC1F;AACA;AACA,iBAAiB,8DAAiB;AAClC;AACA,gBAAgB,wEAA2B;AAC3C;AACA,wBAAwB;AACxB;AACA;AACA;AACA,4EAA4E,cAAc;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8DAAiB,cAAc,8DAAiB;AAC5D;AACA,+BAA+B,cAAc;AAC7C;AACA,YAAY,8DAAiB,cAAc,8DAAiB;AAC5D;AACA,+BAA+B,cAAc;AAC7C;AACA,YAAY,8DAAiB,YAAY,8DAAiB;AAC1D;AACA,+BAA+B,cAAc;AAC7C;AACA,iBAAiB,8DAAiB;AAClC,gBAAgB,wEAA2B;AAC3C;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,8DAAiB;AAClC,gBAAgB,wEAA2B;AAC3C;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAiB,gBAAgB,8DAAiB;AAC/D,SAAS,8DAAiB;AAC1B,SAAS,8DAAiB;AAC1B,SAAS,8DAAiB;AAC1B,SAAS,8DAAiB;AAC1B,SAAS,8DAAiB;AAC1B,SAAS,8DAAiB;AAC1B;AACA;AACA,WAAW,8DAAiB,iBAAiB,8DAAiB;AAC9D;AACA;AACA,YAAY,8DAAiB;AAC7B,QAAQ,8DAAiB;AACzB,QAAQ,8DAAiB;AACzB,QAAQ,8DAAiB;AACzB;AACO;AACP;AACA;AACA,WAAW,4CAA4C;AACvD,oBAAoB,gDAAS,iBAAiB;AAC9C;AACA;AACA,QAAQ,sCAAQ,CAAC,+DAAiC;AAClD;AACA,WAAW,oBAAoB;AAC/B,WAAW,qIAAqI,GAAG,oEAA2B;AAC9K,WAAW,gGAAgG;AAC3G;AACA,WAAW,yGAAyG,GAAG,wEAA6B;AACpJ;AACA;AACA,4BAA4B,gEAAuB;AACnD;AACA;AACA;AACA;AACA;AACA,gDAAgD,qBAAqB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,6EAA+C;AACpE;AACA;AACA;AACA,iBAAiB,8EAA8E;AAC/F,iBAAiB;AACjB;AACA;AACA;AACA,gDAAgD,oBAAoB,qBAAqB,oBAAoB;AAC7G;AACA,iBAAiB;AACjB;AACA,gDAAgD,oBAAoB,qBAAqB,oBAAoB;AAC7G;AACA;AACA;AACA;AACA,iBAAiB,sCAAsC,gDAAS,UAAU;AAC1E,iBAAiB,0EAA0E;AAC3F,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oFAAoF;AACrG,iBAAiB,oFAAoF;AACrG,iBAAiB;AACjB;AACA;AACA;AACA;AACA,iCAAiC,kDAAK,EAAE,6EAA6E;AACrH;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA,iCAAiC,kDAAK,EAAE,6EAA6E;AACrH;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA,iCAAiC,kDAAK,EAAE,wEAAwE;AAChH;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,6EAA+C;AACpE;AACA;AACA;AACA;AACA,iBAAiB,sBAAsB,gCAAgC,yCAAyC;AAChH,iBAAiB,sBAAsB,oBAAoB;AAC3D;AACA;AACA;AACA,+BAA+B,oDAAoD;AACnF;AACA;AACA,yCAAyC,oBAAoB,cAAc,oCAAoC;AAC/G;AACA;AACA;AACA;AACA;AACA,yCAAyC,oBAAoB,cAAc,qCAAqC;AAChH;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yCAAyC,oBAAoB,cAAc,oCAAoC;AAC/G;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,6BAA6B,iDAAU,CAAC,iDAAU;AAClD,aAAa;AACb;AACA;AACA,YAAY;AACZ;AACA;AACA,WAAW,gDAAS;AACpB;AACA,oC;;;;;;;;;;;;;;;;;;;;;;AC9T+B;AACkB;AACoB;AACQ;AACJ;AACzE;AACA;AACA;AACA;AACO;AACP,2BAA2B,0DAAuB;AAClD,mCAAmC;AACnC;AACO;AACP;AACA;AACO;AACP,WAAW,2CAAI;AACf;AACA,IAAI,6CAAO,EAAE,sDAAgB,EAAE,mDAAa;AAC5C,IAAI,+CAAQ,EAAE,wDAAiB,EAAE,qDAAc;AAC/C,IAAI,iDAAS,EAAE,0DAAkB,EAAE,uDAAe;AAClD,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtBA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACkD;AACY;AACqB;AAC5B;AACR;AACC;AACN;AACK;AAChB;AACqG;AAC7E;AACV;AACyB;AAChB;AACT;AAC4B;AAClE;AACP;AACA,gJAAgJ;AAChJ;AACO;AACP;AACA,WAAW,mDAAM;AACjB;AACO;AACP;AACA,kJAAkJ;AAClJ,WAAW,uDAAe,QAAQ,wBAAwB;AAC1D;AACO;AACA;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,UAAU,oDAAsB;AAChC,WAAW;AACX,YAAY;AACZ,SAAS,mDAAqB;AAC9B,cAAc;AACd,gBAAgB;AAChB,aAAa;AACb,YAAY;AACZ,aAAa;AACb,UAAU,oDAAsB;AAChC,WAAW,iBAAiB;AAC5B,cAAc;AACd,WAAW,iBAAiB;AAC5B,UAAU,oDAAsB;AAChC,aAAa;AACb;AACA;AACA;AACA,eAAe;AACf,iBAAiB,iBAAiB;AAClC,oBAAoB;AACpB,gBAAgB;AAChB;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL,WAAW,uDAAkB;AAC7B,kBAAkB;AAClB,YAAY,wDAAmB;AAC/B,aAAa,qCAAqC;AAClD,oBAAoB;AACpB,iBAAiB;AACjB,mBAAmB;AACnB,eAAe,sDAAsB;AACrC,aAAa;AACb,aAAa;AACb,YAAY,UAAU,wDAAe,EAAE;AACvC,aAAa,UAAU,wDAAe;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qCAAqC;AAC5C;AACA;AACA;AACA;AACA,uBAAuB,mDAAQ,wCAAwC;AACvE;AACA;AACA,eAAe,SAAS,uBAAuB,EAAE;AACjD,eAAe,SAAS,wBAAwB,EAAE;AAClD;AACA,oBAAoB;AACpB,SAAS;AACT;AACA;AACA,uBAAuB;AACvB,aAAa;AACb;AACA,uBAAuB;AACvB,aAAa;AACb;AACA,uBAAuB;AACvB,aAAa;AACb;AACA,uBAAuB;AACvB,aAAa;AACb;AACA,yBAAyB;AACzB;AACA,SAAS;AACT;AACA,0BAA0B,yBAAyB;AACnD,wBAAwB,wBAAwB;AAChD,wBAAwB;AACxB,SAAS;AACT;AACA;AACA,iBAAiB,uBAAuB;AACxC,iBAAiB,yBAAyB;AAC1C,iBAAiB,sBAAsB;AACvC,iBAAiB,uBAAuB;AACxC,iBAAiB,wBAAwB;AACzC,iBAAiB,yBAAyB;AAC1C,iBAAiB,yBAAyB;AAC1C,iBAAiB,uBAAuB;AACxC,iBAAiB,wBAAwB;AACzC,iBAAiB;AACjB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,uBAAuB,mDAAQ,2CAA2C;AAC1E;AACA;AACA;AACA,uBAAuB;AACvB,SAAS;AACT;AACA;AACA,2BAA2B;AAC3B,aAAa;AACb;AACA,2BAA2B;AAC3B,aAAa;AACb;AACA,2BAA2B;AAC3B,aAAa;AACb;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,OAAO;AACtB;AACA,4BAA4B,OAAO;AACnC,4BAA4B,OAAO;AACnC,4BAA4B,OAAO;AACnC,+BAA+B;AAC/B;AACA;AACA;AACA;AACA,kBAAkB,4CAAI,iBAAiB;AACvC;AACA;AACA;AACA,mCAAmC,6DAAsB;AACzD,cAAc,8EAA6B;AAC3C,cAAc,iEAAgB;AAC9B;AACA;AACA;AACA;AACA,kBAAkB,4CAAI;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,+CAAY;AACnB,OAAO,+CAAY;AACnB,OAAO,mDAAc;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wCAAwC;AAC/C,WAAW,wBAAwB;AACnC,yBAAyB,sDAAW,GAAG,6CAA6C,uCAAuC,gDAAgD,kBAAkB;AAC7L,yBAAyB,4CAAI;AAC7B;AACA;AACA,iCAAiC,iEAAgB;AACjD;AACA;AACA,iCAAiC,+CAAiB;AAClD;AACA,2CAA2C,4DAAqB;AAChE;AACA;AACA,iCAAiC,+CAAY;AAC7C;AACA;AACA;AACA;AACA,mCAAmC,mDAAc;AACjD;AACA,6CAA6C,4DAAqB;AAClE;AACA;AACA;AACA,8BAA8B,4DAAqB;AACnD;AACA;AACA,6BAA6B,4DAAqB;AAClD;AACA;AACA;AACA;AACA;AACA,6BAA6B,4DAAqB;AAClD;AACA;AACA,4BAA4B,4DAAqB;AACjD;AACA;AACA;AACA,gCAAgC,kDAAe;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,2FAA2F,EAAE,8EAA2C;AACxM;AACP,aAAa,iDAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,6DAAsB;AACtC;AACA;AACA;AACA;AACA;AACA,2BAA2B,yDAAqB;AAChD;AACA;AACA;AACA;AACA;AACA,2BAA2B,iEAA8B;AACzD;AACA;AACA,mCAAmC,mDAAQ;AAC3C;AACA;AACA;AACA;AACA,uDAAuD,oEAAwB;AAC/E;AACA;AACA;AACA;AACA,2BAA2B,iEAA8B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oEAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mDAAQ,kBAAkB,+CAAO;AAC7C;AACA;AACA;AACA,WAAW,+CAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,gDAAgD,GAAG,2DAAkB;AAChF;AACA,SAAS,+CAAO;AAChB,oEAAoE;AACpE;AACA;AACA,SAAS,+CAAO;AAChB,uEAAuE;AACvE;AACA;AACA,SAAS,+CAAO;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA,gDAAgD;AAChD;AACA,SAAS,+CAAO;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;;;;;;;;;;;AClcO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC,gC;;;;;;;;;;;;;;;;;;;;;;;;;;AC7BA;AAC+C;AAClB;AACe;AACQ;AAC7C;AACP,aAAa,mDAAQ;AACrB,2BAA2B,qDAAc;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACA;AACP;AACA,QAAQ,gDAAS;AACjB;AACA;AACA,QAAQ,mDAAQ;AAChB;AACA,YAAY,sCAAQ,CAAC,yDAA2B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yDAA2B;AACnD;AACA;AACA;AACA,QAAQ,gDAAS;AACjB;AACA;AACA,QAAQ,mDAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yDAA2B;AACnD;AACA;AACA;AACA,QAAQ,gDAAS;AACjB;AACA;AACA,QAAQ,mDAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yDAA2B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2CAAI;AAChB,YAAY,sCAAQ,CAAC,oDAAsB;AAC3C,gBAAgB,gDAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mDAAQ;AAC3B;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mDAAQ;AAC3B;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,sBAAsB,OAAO;AAC7B;AACA;AACA,2BAA2B,OAAO;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,sBAAsB,OAAO;AAC7B;AACA;AACA,2BAA2B,OAAO;AAClC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjMA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC2C;AACY;AACX;AACyU;AACjK;AACvL;AACmB;AACZ;AACQ;AACrC;AACP;AACA;AACA,YAAY,kDAAO;AACnB,mBAAmB,2CAAI;AACvB;AACA;AACA,mBAAmB,uDAAU,gBAAgB,mEAAsB;AACnE;AACA;AACA;AACA;AACO;AACP,WAAW,2CAAI,CAAC,8CAAQ;AACxB;AACA;AACA,gBAAgB,kDAAO;AACvB,uBAAuB,2CAAI;AAC3B;AACA;AACA,iCAAiC,wDAAW;AAC5C;AACA;AACA;AACA;AACA,KAAK;AACL;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,uDAAU;AACtB,mBAAmB,yCAAyC;AAC5D;AACA,8BAA8B,qDAAQ;AACtC;AACA,+BAA+B,oDAAO,cAAc,cAAc;AAClE,gFAAgF,0BAA0B,QAAQ,kDAAK,sBAAsB,uBAAuB,GAAG,iB;AACvK;AACA,qCAAqC;AACrC;AACA;AACA,wBAAwB,uDAAW;AACnC;AACA,mCAAmC,oDAAO,EAAE,oCAAoC,GAAG,cAAc;AACjG,+CAA+C,SAAS,GAAG,MAAM;AACjE;AACA,6BAA6B,uDAAW;AACxC;AACA,mCAAmC,oDAAO,EAAE,oCAAoC,GAAG,cAAc;AACjG,+CAA+C,SAAS,GAAG,MAAM;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,4DAAe,gBAAgB,+CAAS;AAChE,mCAAmC,2BAA2B;AAC9D;AACA,qCAAqC,oDAAO,cAAc,mBAAmB;AAC7E,4BAA4B,6DAAgB;AAC5C,yCAAyC,oDAAO,cAAc,qBAAqB;AACnF;AACA;AACA,4BAA4B,gDAAM;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iEAAuB;AACpD,kDAAkD,+CAAY;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,2CAA2C,4DAAe,oCAAoC,2CAAQ;AACtG;AACA,4CAA4C,0CAAI,gBAAgB,6CAAO;AACvE;AACA;AACA,qCAAqC,mEAAyB;AAC9D,uEAAuE,aAAa;AACpF;AACA,qCAAqC,gDAAM;AAC3C,qEAAqE,aAAa;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,0BAA0B,qDAAW;AACrC;AACA;AACA;AACA;AACA,qDAAqD,wCAAE,GAAG,uCAAC,GAAG,uCAAC;AAC/D;AACA;AACA,YAAY,uDAAU,qBAAqB,uDAAU,uBAAuB,8CAAQ;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,2CAAI;AACf,aAAa,mDAAS;AACtB;AACA,YAAY,sCAAQ,CAAC,gEAAkC;AACvD;AACA;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,kEAAoC;AACzD,sBAAsB,2CAAK;AAC3B;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,6DAA+B;AACpD;AACA;AACA;AACA,wBAAwB,0CAAI;AAC5B,6BAA6B,wDAAW;AACxC;AACA,gBAAgB,sCAAQ,CAAC,gEAAkC;AAC3D;AACA;AACA;AACA;AACA,wBAAwB,2CAAK;AAC7B,YAAY,sCAAQ,CAAC,uDAAyB,cAAc,yDAAyD;AACrH;AACA;AACA,wBAAwB,4CAAM;AAC9B,yBAAyB,2CAAK,KAAK,kDAAO,iBAAiB,uDAAU;AACrE,yBAAyB,6CAAO,IAAI,kDAAO;AAC3C;AACA;AACA,8CAA8C,gDAAK;AACnD,yBAAyB,uDAAU;AACnC,wBAAwB,sCAAQ,CAAC,uDAAyB;AAC1D;AACA;AACA,kCAAkC,yDAAY;AAC9C;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,4BAA4B,6CAAO;AACnC;AACA;AACA;AACA,sBAAsB,uDAAU;AAChC,iBAAiB,uDAAU;AAC3B,iBAAiB,uDAAU;AAC3B,iBAAiB,6DAAgB;AACjC,iBAAiB,yDAAW;AAC5B,gBAAgB,sCAAQ,CAAC,uDAAyB;AAClD;AACA;AACA,0CAA0C,2DAAc;AACxD;AACA;AACA,KAAK,IAAI;AACT;AACA;AACA;AACA;AACO;AACP;AACA,0BAA0B,2CAAI;AAC9B,8BAA8B,2DAAc,sCAAsC,sBAAsB;AACxG;AACA;AACA;AACA;AACO;AACP;AACA,0BAA0B,2CAAI;AAC9B;AACA;AACA,oCAAoC,gDAAK;AACzC;AACA,oBAAoB,uDAAU;AAC9B;AACA;AACA,yBAAyB,mEAAsB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA,YAAY,kDAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,WAAW,2CAAI;AACf;AACA,YAAY,kDAAO;AACnB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACO;AACP,WAAW,2CAAI;AACf;AACA;AACA,iBAAiB,uCAAC;AAClB,iBAAiB,uCAAC;AAClB,iBAAiB,0CAAI;AACrB,iBAAiB,iDAAW;AAC5B,iBAAiB,yCAAG;AACpB,iBAAiB,wCAAE;AACnB,iBAAiB,wCAAE;AACnB,iBAAiB,2CAAK;AACtB,iBAAiB,4CAAM;AACvB,iBAAiB,4CAAM;AACvB,iBAAiB,6CAAO;AACxB;AACA,iBAAiB,8CAAQ;AACzB,iBAAiB,+CAAS;AAC1B,iBAAiB,+CAAS;AAC1B,iBAAiB,gDAAU;AAC3B;AACA;AACA,iBAAiB,0CAAI;AACrB,iBAAiB,2CAAK;AACtB,iBAAiB,2CAAK;AACtB;AACA;AACA,iBAAiB,6CAAO;AACxB;AACA,iBAAiB,2CAAK;AACtB;AACA;AACA;AACA;AACA;AACA,iBAAiB,4CAAM;AACvB,iBAAiB,yCAAG;AACpB;AACA,oBAAoB,kDAAO,gBAAgB,uDAAU;AACrD,2CAA2C,gDAAK;AAChD;AACA,yCAAyC,oDAAO,aAAa;AAC7D;AACA;AACA;AACA;AACA;AACA,iBAAiB,0CAAI;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,2CAAK;AACtB,iBAAiB,0CAAI;AACrB,iBAAiB,4CAAM;AACvB,iBAAiB,6CAAO;AACxB,iBAAiB,iDAAW;AAC5B,iBAAiB,mDAAa;AAC9B,iBAAiB,gDAAU;AAC3B,iBAAiB,iDAAW;AAC5B;AACA;AACA,iCAAiC,wDAAW;AAC5C;AACA,iCAAiC,oDAAO,aAAa;AACrD;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,oC;;;;;;;;;;;;;;;;;;;;ACpXoD;AACtB;AACc;AACrC;AACP;AACA;AACO;AACP,2BAA2B,yDAAW;AACtC;AACO;AACP,kBAAkB,2CAAI,YAAY;AAClC;AACA;AACA,yBAAyB,iEAAgB;AACzC;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;ACjBO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;ACP8B;AACvB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,gCAAgC,2CAAI;AACpC,gCAAgC,2CAAI;AAC3C;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,2CAAI;AAClC,kC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxC0C;AACF;AACI;AACrB;AACO;AAC9B,iC;;;;;;;;;;;;;;;;;;;ACL8B;AACvB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,0BAA0B,2CAAI;AACrC,kC;;;;;;;;;;;;;;;;;;;;;;;;;ACrFA;AACA;AACA;AACA,8BAA8B,SAAI,IAAI,SAAI;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,SAAI,IAAI,SAAI;AAC1C;AACA;AACA;AACA;AACA;AACA;AAC2E;AACpC;AACP;AAChC;AACA;AACA;AACA,aAAa,iDAAM,CAAC,2CAAI;AACxB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,yBAAyB,2CAAI;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,2CAAI;AACxD;AACA;AACA;AACA;AACA,oDAAoD,2CAAI;AACxD;AACA;AACA;AACA;AACA,oDAAoD,4CAAK;AACzD;AACA;AACA;AACA;AACA,oDAAoD,4CAAU;AAC9D;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjG4C;AACR;AAC7B;AACP,oCAAoC,qBAAqB;AACzD;AACA;AACO;AACA;AACP;AACA,cAAc,MAAM;AACpB;AACO;AACP;AACA;AACA,cAAc,MAAM,2DAA2D,aAAa;AAC5F;AACO;AACP;AACA,2BAA2B,QAAQ,8BAA8B,wDAAc,UAAU;AACzF;AACA;AACA;AACO;AACP,gCAAgC,QAAQ;AACxC;AACA;AACO;AACP,8DAA8D,QAAQ;AACtE;AACO;AACP,8DAA8D,QAAQ,uCAAuC,UAAU;AACvH;AACO;AACP,2DAA2D,KAAK;AAChE;AACO;AACP,0CAA0C,KAAK;AAC/C;AACO;AACP,6CAA6C,KAAK;AAClD;AACO;AACA;AACA;AACP,6CAA6C,KAAK;AAClD;AACA;AACO;AACA;AACP;AACO;AACP,sCAAsC,MAAM;AAC5C;AACO;AACP,0DAA0D,KAAK;AAC/D;AACA;AACO;AACP;AACO;AACP,kCAAkC,EAAE;AACpC;AACO;AACP,wCAAwC,MAAM,OAAO,SAAS,2CAA2C,MAAM;AAC/G;AACO;AACP;AACO;AACP,6CAA6C,gDAAS,YAAY;AAClE;AACO;AACP;AACO;AACP,mGAAmG,QAAQ;AAC3G;AACO;AACP,WAAW,+BAA+B;AAC1C,wCAAwC,gDAAS,mBAAmB,uCAAuC,gDAAS,aAAa;AACjI;AACO;AACA;AACP,sBAAsB,QAAQ,QAAQ,KAAK,gBAAgB,SAAS,gDAAS,SAAS;AACtF;AACO;AACP,kCAAkC,KAAK;AACvC;AACO;AACP,kCAAkC,KAAK,oBAAoB,UAAU;AACrE;AACO;AACP,4CAA4C,UAAU;AACtD;AACO;AACP,wCAAwC,QAAQ,YAAY,QAAQ;AACpE;AACO;AACP,WAAW,eAAe;AAC1B,6BAA6B,KAAK,wBAAwB,8DAA8D;AACxH;AACO;AACP,uBAAuB,gDAAS,WAAW,iBAAiB,QAAQ;AACpE;AACO;AACP,cAAc,QAAQ,sBAAsB,KAAK,iCAAiC,WAAW;AAC7F;AACO;AACA;AACP,cAAc,QAAQ,uCAAuC,YAAY,GAAG,gBAAgB,KAAK,OAAO;AACxG;AACO;AACP,cAAc,QAAQ,0BAA0B,QAAQ;AACxD;AACO;AACP,cAAc,QAAQ;AACtB;AACO;AACP,wCAAwC,uBAAuB,GAAG,mCAAmC;AACrG;AACO;AACP,sCAAsC,QAAQ,eAAe,KAAK,kDAAkD,2CAA2C;AAC/J;AACA;AACO;AACP,kBAAkB,MAAM;AACxB;AACO;AACP;AACA,6EAA6E,SAAS;AACtF;AACO;AACP,gCAAgC,SAAS,qBAAqB,OAAO;AACrE;AACA;AACO;AACA,qIAAqI,YAAY;AACjJ;AACP,6CAA6C,KAAK;AAClD;AACO;AACP,sEAAsE,gDAAS,WAAW;AAC1F;AACO;AACP,sDAAsD,UAAU;AAChE;AACO;AACP,0EAA0E,gDAAS,WAAW;AAC9F;AACO;AACP,sDAAsD,KAAK;AAC3D;AACO;AACP,uBAAuB,QAAQ,wBAAwB,UAAU,yBAAyB,iBAAiB;AAC3G;AACO;AACP,2CAA2C,UAAU,yBAAyB,iBAAiB;AAC/F;AACO;AACP,cAAc,QAAQ,YAAY,SAAS,wCAAwC,UAAU;AAC7F;AACO;AACP,0BAA0B,UAAU,6BAA6B,KAAK;AACtE;AACO;AACP,4BAA4B,QAAQ,2BAA2B,gCAAgC;AAC/F;AACO;AACP,0BAA0B,sBAAsB,aAAa,oBAAoB,KAAK,gDAAS,KAAK,OAAO,gDAAS,KAAK,WAAW,gDAAS,KAAK;AAClJ;AACO;AACP,0BAA0B,sBAAsB,aAAa,oBAAoB,KAAK,gDAAS,KAAK,OAAO,gDAAS,KAAK;AACzH;AACO;AACP,uDAAuD,QAAQ;AAC/D;AACO;AACP,qCAAqC,gDAAS,OAAO;AACrD;AACO;AACA;AACA;AACA;AACP;AACO;AACP;AACO;AACP,4BAA4B,QAAQ,yBAAyB,QAAQ;AACrE;AACO;AACP,6CAA6C,UAAU;AACvD;AACO;AACP,wFAAwF,UAAU;AAClG;AACA;AACO;AACP,sBAAsB,SAAS,IAAI,gDAAS,QAAQ;AACpD;AACO;AACP,yCAAyC,gDAAS,IAAI;AACtD;AACO;AACP,cAAc,wBAAwB,EAAE,+BAA+B,EAAE,wBAAwB,EAAE,kCAAkC;AACrI;AACO;AACP,cAAc,OAAO,4BAA4B,OAAO,OAAO,KAAK;AACpE;AACO;AACP,8EAA8E,WAAW,GAAG,cAAc;AAC1G;AACO;AACP,6CAA6C,SAAS;AACtD;AACA;AACO;AACP,sBAAsB,QAAQ;AAC9B;AACO;AACP,sBAAsB,QAAQ;AAC9B;AACO;AACP,yBAAyB,QAAQ;AACjC;AACA,mC;;;;;;;;;;;;;;;;;;;AC9NO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,gBAAgB;AAChB;AACA;AACA,gBAAgB;AAChB;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzCkC;AACM;AACxC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACP;AACA;AACO;AACP,WAAW,+CAAQ;AACnB;AACO;AACP,WAAW,+CAAQ;AACnB;AACO,wBAAwB,2CAAI;AAC5B;AACP;AACA;AACA,6BAA6B,gDAAK;AAC3B;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uCAAuC,2CAAI;AAC3C;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,2CAAI;AACzB;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9HA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACoC;AACY;AAC6C;AAChC;AACI;AACF;AACjB;AAChB;AACiB;AACN;AACU;AACT;AACa;AACV;AACS;AACJ;AAC6B;AACb;AAC3D,6BAA6B,iDAAU;AAC9C;AACA;AACA;AACA,YAAY,qEAAiB;AAC7B,YAAY,uEAAkB;AAC9B,YAAY,yEAAmB;AAC/B,gBAAgB,gEAAqB;AACrC,gBAAgB,4EAA2B;AAC3C,gBAAgB,4DAAmB;AACnC;AACA;AACA;AACA;AACA,YAAY,uDAAU;AACtB,2BAA2B,0DAAe,gBAAgB,yCAAG;AAC7D,8BAA8B,0DAAe,gBAAgB,4CAAM;AACnE,6BAA6B,0DAAe,gBAAgB,2CAAK;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mCAAmC;AAClD,yBAAyB,qEAAyB;AAClD,uEAAuE,sBAAsB,WAAW,KAAK;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gEAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,0BAA0B;AACzC,eAAe,qBAAqB;AACpC,eAAe,cAAc,uBAAuB;AACpD;AACA,gEAAgE,UAAU,uCAAuC,UAAU,MAAM,KAAK,eAAe,SAAS,KAAK;AACnK,6BAA6B,QAAQ;AACrC;AACA,iBAAiB,EAAE;AACnB;AACA;AACA,iDAAiD,UAAU;AAC3D,wEAAwE,cAAc,oBAAoB;AAC1G,gGAAgG,+CAAO,aAAa;AACpH,+FAA+F,YAAY,qDAAqD;AAChK;AACA;AACA,iBAAiB,GAAG;AACpB;AACA;AACA;AACA;AACA,eAAe,gCAAgC;AAC/C,aAAa,kDAAO;AACpB;AACA,mBAAmB,4CAAI;AACvB,YAAY,sCAAQ,CAAC,mEAAqC;AAC1D;AACA;AACA,eAAe,cAAc,uBAAuB;AACpD,sBAAsB,kDAAO;AAC7B,yBAAyB,kDAAO;AAChC,8BAA8B,kDAAO;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kDAAO;AAChC,iCAAiC,+CAAO,cAAc;AACtD,mDAAmD,+CAAO,WAAW;AACrE,2DAA2D,+CAAO,cAAc;AAChF,oFAAoF,YAAY,qDAAqD;AACrJ;AACA;AACA,gCAAgC,4CAAI;AACpC;AACA;AACA;AACA,wBAAwB,kDAAO;AAC/B,4CAA4C,kFAAkF,yBAAyB;AACvJ,oBAAoB;AACpB;AACA;AACA,eAAe,QAAQ;AACvB,YAAY,2DAAc;AAC1B;AACA,mBAAmB,4CAAI;AACvB,YAAY,sCAAQ,CAAC,mEAAqC;AAC1D;AACA;AACA;AACA;AACA,eAAe,uBAAuB;AACtC,eAAe,2CAA2C;AAC1D,kDAAkD,+BAA+B;AACjF;AACA;AACA,sBAAsB,qEAAyB;AAC/C,SAAS;AACT,wEAAwE,8BAA8B,+BAA+B,KAAK,uBAAuB,2BAA2B,KAAK,KAAK,SAAS;AAC/M;AACA;AACA;AACA;AACA,mCAAmC,qBAAqB;AACxD;AACA,eAAe,gEAAgE;AAC/E,eAAe,uBAAuB,kCAAkC,qBAAqB;AAC7F,4BAA4B,qEAAyB;AACrD,yEAAyE,wB;AACzE;AACA,6HAA6H,YAAY,QAAQ,KAAK,eAAe,SAAS,KAAK,aAAa,OAAO,KAAK,mBAAmB,aAAa,KAAK,KAAK,8BAA8B,iBAAiB,YAAY,KAAK,IAAI;AAC1T;AACA;AACA;AACA,eAAe,qBAAqB;AACpC;AACA;AACA,gBAAgB,sCAAQ,CAAC,6DAA+B,aAAa,yCAAG,uBAAuB,4CAAM;AACrG;AACA;AACA;AACA,mCAAmC,yCAAG,EAAE,4CAAM;AAC9C;AACA;AACA,2BAA2B,kCAAkC;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,mBAAmB,kCAAkC;AACrD;AACA,8BAA8B,kEAAsB;AACpD,kFAAkF,YAAY,QAAQ,KAAK,eAAe,SAAS,KAAK,gBAAgB,UAAU,KAAK,gBAAgB,UAAU,KAAK;AACtM;AACA;AACA;AACA;AACA;AACA,aAAa,mCAAmC;AAChD,eAAe,uBAAuB;AACtC,qDAAqD,iBAAiB,gCAAgC,wCAAwC,sCAAsC,+BAA+B,GAAG;AACtN;AACA;AACA;AACA,wBAAwB,8BAA8B,SAAS;AAC/D;AACA;AACA,qCAAqC,4CAAI,qBAAqB,4CAAI;AAClE;AACA;AACA;AACA,gBAAgB,8DAAiB;AACjC;AACA;AACA,uEAAuE;AACvE;AACA;AACA,qBAAqB,0EAA6B;AAClD,gEAAgE,gBAAgB,0CAA0C,4CAA4C;AACtK;AACA;AACA;AACA;AACA;AACA,gBAAgB,uDAAU;AAC1B,gBAAgB,0DAAW;AAC3B,gBAAgB,8DAAiB;AACjC,gBAAgB,kDAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,+CAAO;AAC7B;AACA;AACA,WAAW,+BAA+B;AAC1C;AACA,QAAQ,sCAAQ,CAAC,8DAAgC,EAAE,+BAA+B;AAClF;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;ACzPqC;AACE;AACT;AACoB;AACd;AACI;AACjC;AACP;AACA,iBAAiB,mDAAU;AAC3B;AACA;AACA,WAAW,gBAAgB;AAC3B,wDAAwD,yCAAyC;AACjG,yCAAyC,gCAAgC,WAAW,KAAK;AACzF;AACA,uBAAuB,iDAAc;AACrC;AACA;AACA;AACA,+CAA+C;AAC/C,iCAAiC,SAAS;AAC1C;AACA;AACA,WAAW,mDAAQ,cAAc,iBAAiB;AAClD;AACA;AACA;AACA;AACO;AACP,SAAS,gBAAgB;AACzB,4BAA4B,iDAAU,UAAU,kDAAW;AAC3D;AACA;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,gEAAkC;AACvD;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,gEAAkC;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,cAAc,sEAAsE;AACpJ;AACA,QAAQ,sCAAQ,CAAC,wDAA0B;AAC3C;AACA;AACA;AACA,QAAQ,sCAAQ,CAAC,gFAAkD;AACnE;AACA;AACA,QAAQ,sCAAQ,CAAC,gFAAkD;AACnE;AACA;AACA,QAAQ,gDAAS,YAAY,cAAc;AAC3C;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;AC3EA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACqC;AACW;AACZ;AACM;AACT;AACU;AAC3C;AACA,WAAW,6BAA6B;AACxC,WAAW,2CAAI;AACf;AACA;AACA;AACA;AACA,mDAAmD,Y;AACnD;AACA,wBAAwB,2CAAI,mCAAmC;AAC/D;AACA;AACA;AACA;AACA,iDAAiD;AACjD;AACA,gBAAgB;AAChB;AACA;AACA;AACA,eAAe,mDAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mDAAQ;AAC3B;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,YAAY,sDAAU;AACtB,mBAAmB,iBAAiB;AACpC,4BAA4B,gDAAS,iBAAiB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB,eAAe,2CAA2C;AAC1D;AACA,yBAAyB,4DAAiB;AAC1C,wBAAwB,gDAAS,iBAAiB;AAClD;AACA;AACA;AACA,0CAA0C,gBAAgB,YAAY,KAAK,KAAK,sDAAsD;AACtI,uBAAuB;AACvB,wBAAwB;AACxB;AACA,0BAA0B,2CAAI,uBAAuB;AACrD;AACA;AACA;AACA,2BAA2B,6CAAK;AAChC;AACA;AACA,mBAAmB,0CAA0C;AAC7D,4DAA4D,cAAc,oDAAoD,2CAA2C,gBAAgB,KAAK,IAAI;AAClM;AACA;AACA,qDAAqD,iBAAiB,aAAa,KAAK,KAAK,oCAAoC,eAAe,EAAE,2CAAI,oGAAoG;AAC1P;AACA;AACA,qDAAqD,iBAAiB,aAAa,KAAK,KAAK,oCAAoC,0CAA0C,EAAE,2CAAI,2EAA2E;AAC5P;AACA,uDAAuD,eAAe,QAAQ,iCAAiC,YAAY,6CAA6C;AACxK;AACA;AACA,uC;;;;;;;;;;;;;;;;;;;;AC9HA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACqE;AACnB;AACpB;AACY;AACR;AAC3B;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,sDAAU;AACtB,kCAAkC,6DAAuB;AACzD;AACA,2BAA2B,8DAAiB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC,8BAA8B,6DAAuB;AACrD,6BAA6B,wDAAc;AAC3C;AACA,uBAAuB,8DAAiB;AACxC;AACA,2BAA2B,QAAQ;AACnC,uCAAuC,YAAY;AACnD,4CAA4C;AAC5C,oBAAoB,sCAAQ,CAAC,+DAAiC;AAC9D,6DAA6D,cAAc,0CAA0C,qBAAqB,8CAAO,4BAA4B,IAAI,+BAA+B,IAAI;AACpN;AACA;AACA;AACA,2DAA2D,uBAAuB,WAAW;AAC7F;AACA;AACA,qC;;;;;;;;;;;;;;;;;;;;;ACtDA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACoD;AAC4F;AAClH;AACQ;AACS;AACxC;AACP;AACA;AACA;AACA,QAAQ,2DAAc;AACtB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,wDAAW;AACnB;AACA,iDAAiD,OAAO,+BAA+B;AACvF;AACA;AACA,YAAY,sCAAQ,CAAC,6DAA+B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAkB,cAAc,kDAAW;AACnD;AACA,iDAAiD,sBAAsB,OAAO,KAAK;AACnF;AACA;AACA;AACA;AACA,QAAQ,uDAAU;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8DAAiB;AACzB;AACA;AACA;AACA;AACA,iBAAiB,6DAAgB;AACjC,oBAAoB;AACpB;AACA;AACA;AACA,YAAY,0EAA6B;AACzC;AACA;AACA,qDAAqD,gBAAgB,gBAAgB;AACrF;AACA;AACA,uBAAuB,YAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,yDAAc;AAC1B;AACA,gBAAgB,kDAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;;;;AC3HkC;AACwC;AACnB;AACzB;AACY;AACnC;AACP;AACA;AACA;AACA;AACA,YAAY,sDAAU;AACtB,mBAAmB,iBAAiB;AACpC;AACA,sCAAsC,6DAAuB;AAC7D,wCAAwC,6DAAmB;AAC3D;AACA;AACA,6BAA6B,uDAAU,qBAAqB,8CAAQ,yBAAyB,uDAAU;AACvG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,WAAW;AAC1B,QAAQ,sCAAQ,CAAC,uDAAyB;AAC1C,uDAAuD,UAAU,eAAe;AAChF;AACA;AACA,6C;;;;;;;;;;;;;;;AChCA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA,yDAAyD,UAAU,mBAAmB;AACtF;AACA;AACA;AACA,uEAAuE,kBAAkB,eAAe,KAAK,aAAa,OAAO,KAAK;AACtI;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3BoC;AACc;AAC6B;AACnC;AACrC;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA,YAAY,kDAAO;AACnB;AACA;AACA,iBAAiB,yDAAW;AAC5B;AACA;AACA;AACA;AACA;AACO;AACP,+CAA+C,kDAAO,qBAAqB,kDAAO;AAClF;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,sDAAS,KAAK,2BAA2B;AACpD;AACA;AACA;AACA;AACA;AACO;AACP;AACA,WAAW,QAAQ;AACnB,2BAA2B,4DAAiB;AAC5C;AACA;AACA;AACA;AACA,sBAAsB,oDAAiB;AACvC,UAAU,oDAAO,aAAa,gBAAgB;AAC9C;AACA;AACA;AACA;AACA;AACA,kBAAkB,UAAU,GAAG,oCAAoC;AACnE;AACA;AACA;AACA,kBAAkB,UAAU,GAAG,oCAAoC;AACnE;AACA;AACA;AACA,kBAAkB,UAAU,IAAI,oCAAoC;AACpE;AACA;AACA;AACA,kBAAkB,UAAU,IAAI,oCAAoC;AACpE;AACA;AACA,2BAA2B,yDAAyD,KAAK,UAAU;AACnG;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,sBAAsB,yDAAW,WAAW,YAAY,aAAa,MAAM;AAC3E,sBAAsB,yDAAW,WAAW,YAAY,aAAa,MAAM;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,UAAU,MAAM,oCAAoC;AAC9E;AACA;AACA,0BAA0B,UAAU,MAAM,oCAAoC;AAC9E;AACA;AACA;AACA;AACA,gDAAgD,0BAA0B;AAC1E;AACO;AACP;AACA,0BAA0B,UAAU,iBAAiB,UAAU;AAC/D;AACA;AACA,2BAA2B,UAAU,kBAAkB,UAAU;AACjE;AACA;AACO;AACP;AACA;AACA,6CAA6C,OAAO,iBAAiB,4DAAiB,4DAA4D;AAClJ;AACA;AACA;AACA,qC;;;;;;;;;;;;;;;ACnIO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnBA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC4C;AACP;AACM;AACd;AACqC;AAC1B;AACjC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,2CAAI;AAC/B;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP,uCAAuC,gDAAK;AACrC;AACP,kCAAkC,gDAAK;AAChC;AACP;AACA;AACO;AACP,qCAAqC,gDAAK;AACnC;AACP;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gDAAK;AAC9B;AACP,8BAA8B,gDAAK;AAC5B;AACA;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,YAAY,mDAAQ;AACpB;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,2CAAI;AACpC,OAAO,kDAAkD;AAClD,oDAAoD,2CAAI;AACxD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,+CAAQ;AAC5B;AACA,oBAAoB,+CAAQ;AAC5B;AACA;AACA;AACA;AACA;AACA,0DAA0D,+CAAQ;AAClE;AACA;AACA,mBAAmB,+CAAQ;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,+CAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,iBAAiB,wDAAc;AAC/B,uBAAuB,4EAA8C;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACO;AACP,QAAQ,+CAAQ,EAAE,0CAAO,EAAE,0CAAO;AAClC;AACA;AACA,8BAA8B,2CAAQ;AACtC,eAAe,+CAAQ;AACvB;AACA,8BAA8B,+CAAY;AAC1C,eAAe,+CAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,SAAS,oDAAsB;AAC/B;AACA;AACA;AACA,aAAa,uCAAS;AACtB,aAAa,uCAAS;AACtB,aAAa,2CAAa;AAC1B,aAAa,4CAAc;AAC3B,0DAA0D,+CAAQ;AAClE,aAAa,0CAAY;AACzB,aAAa,iDAAmB;AAChC,aAAa,6CAAe;AAC5B,aAAa,iDAAmB;AAChC,aAAa,mDAAqB;AAClC,aAAa,2CAAa;AAC1B;AACA;AACA;AACA;AACA,gBAAgB,+CAAQ;AACxB,aAAa,2CAAa;AAC1B,aAAa,0CAAY;AACzB,aAAa,4CAAc;AAC3B,wCAAwC;AACxC,aAAa,gDAAkB;AAC/B;AACA,aAAa,2CAAa;AAC1B,2CAA2C;AAC3C;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;ACvUqC;AAC9B;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,eAAe,oDAAoD;AACnE;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP,oCAAoC,mDAAQ;AAC5C;AACA,qC;;;;;;;;;;;;;;;;;;;;AClCoC;AAC7B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP,qBAAqB,kDAAO;AAC5B;AACA,gC;;;;;;;;;;;;;;;;;;;;;;AC5B+C;AAChB;AACwB;AACD;AAC/C;AACP,WAAW,mDAAQ;AACnB;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,2CAAI;AACnC;AACP;AACA;AACA;AACA;AACA,WAAW,kCAAkC;AAC7C;AACA;AACA;AACA;AACA,aAAa,mDAAW,WAAW,sDAAc,iBAAiB,qDAAY;AAC9E;AACA;AACA;AACA,QAAQ,sDAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,mDAAQ;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;ACvDO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA,kC;;;;;;;;;;;;;;;;;ACZO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;ACTyE;AACnC;AACA;AACE;AACJ;AACpC,iC;;;;;;;;;;;;;;;ACLO;AACP;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;ACHA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC8B;AACwC;AAChC;AACA;AACE;AACJ;AAC7B;AACP;AACA,YAAY,mDAAW;AACvB;AACA;AACA,iBAAiB,qDAAY;AAC7B;AACA;AACA,iBAAiB,sDAAa;AAC9B;AACA;AACA,iBAAiB,sDAAa;AAC9B;AACA;AACA,iBAAiB,qDAAY;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mDAAW;AACvB;AACA;AACA,iBAAiB,iDAAU;AAC3B;AACA;AACA,wBAAwB,qDAAuB;AAC/C;AACA;AACA,6CAA6C,UAAU,yEAAyE;AAChI;AACA;AACA,6CAA6C,UAAU,kEAAkE;AACzH;AACA;AACA,6CAA6C,UAAU,kEAAkE;AACzH;AACA;AACA,eAAe,SAAS;AACxB,6CAA6C,UAAU,2DAA2D;AAClH;AACA;AACA,6CAA6C,U;AAC7C;AACA,+CAA+C;AAC/C;AACA;AACA,6CAA6C,U;AAC7C;AACA,+CAA+C;AAC/C;AACA;AACA,+B;;;;;;;;;;;;;;;;;ACvEoC;AAC7B;AACP;AACA;AACO;AACP,YAAY,kDAAO;AACnB;AACA,kC;;;;;;;;;;;;;;;;;;;ACPqD;AACA;AAC9C;AACP;AACA;AACO;AACP,6BAA6B,iEAAuB,WAAW;AAC/D;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mBAAmB,iEAAgB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;ACzBO;AACP;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;ACH6C;AACP;AACqC;AACwB;AACzC;AAC7B;AACiF;AAC1E;AACF;AAClC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO,iCAAiC,sCAAG,EAAE,sCAAG,EAAE,uCAAI,EAAE,uCAAI,EAAE,wCAAK,EAAE,yCAAM,EAAE,yCAAM,EAAE,uCAAI,EAAE,uCAAI,EAAE,uCAAI;AAC9F,wCAAwC,sCAAG,EAAE,uCAAI,EAAE,sCAAG;AAC7D;AACA;AACA;AACA;AACA;AACA,QAAQ,uDAAU,UAAU,uDAAU;AACtC,YAAY,2DAAc,6BAA6B,2DAAc;AACrE;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,uDAAU;AACzC,+BAA+B,uDAAU;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,2DAAc;AAC/B;AACA;AACA,iBAAiB,2DAAc;AAC/B;AACA;AACA;AACA,aAAa,2DAAc;AAC3B;AACA;AACA,aAAa,2DAAc;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oCAAoC;AAC3C,iBAAiB,gDAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,uDAAU,oBAAoB,oDAAO,oBAAoB;AAClF;AACA;AACA,yBAAyB,uDAAU,iBAAiB,oDAAO,iBAAiB;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iEAA2B;AAC/C;AACA,qCAAqC,0DAAe;AACpD;AACA,+BAA+B,gDAAK;AACpC,iCAAiC,wDAAW;AAC5C;AACA;AACA;AACA;AACA,0BAA0B,oDAAO,aAAa;AAC9C;AACA;AACA;AACA;AACA;AACA,6BAA6B,oBAAoB;AACjD;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,YAAY,oDAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,sDAAW;AACnB;AACA;AACA;AACA,8FAA8F,oDAAgB;AAC9G;AACA;AACA;AACA;AACA,YAAY,sCAAQ,CAAC,mEAAqC;AAC1D;AACA;AACA;AACA,QAAQ,8DAAiB,UAAU,kEAAwB;AAC3D;AACA,YAAY,sCAAQ,CAAC,+DAAiC;AACtD;AACA;AACA;AACA;AACA,QAAQ,uDAAU,mDAAmD,+CAAQ,CAAC,+CAAO;AACrF,QAAQ,sCAAQ,CAAC,oEAAsC;AACvD;AACA;AACA;AACA;AACA;AACA,0DAA0D,iDAAU;AACpE;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/KA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AACmD;AACJ;AACC;AACY;AAC5D;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,2CAAI;AAC3B;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yCAAyC,MAAM,IAAI,aAAa;AACvE,qBAAqB,0DAAmB;AACxC;AACA;AACA;AACA;AACA,uBAAuB,IAAI,UAAU,SAAS;AAC9C;AACA;AACA,sBAAsB,IAAI,EAAE,SAAS,GAAG,SAAS;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,6DAAkB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA,gCAAgC,iEAAS,gBAAgB,IAAI,iEAAS,sBAAsB;AAC5F;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,qBAAqB,SAAS,MAAM,IAAI,KAAK;AAC3D;AACO;AACP;AACA;AACA;AACA;AACA,QAAQ,mDAAQ;AAChB;AACA;AACA;AACA;AACA,aAAa,mDAAQ;AACrB,+CAA+C,+BAA+B,sBAAsB,KAAK;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,uCAAuC,MAAM;AAC7C;AACA;AACA,YAAY,2CAAI;AAChB,0BAA0B,8CAAO,IAAI,wBAAwB,EAAE,GAAG,EAAE,QAAQ;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2CAAI;AAChB,0BAA0B,8CAAO,KAAK,EAAE,GAAG,QAAQ;AACnD;AACA;AACA;AACA,oC;;;;;;;;;;;;;;;;;;ACxOA,cAAc,SAAI,IAAI,SAAI;AAC1B;AACA;AACA;AACA;AACA,4DAA4D,cAAc;AAC1E;AACA;AACA;AACA;AACA;AAC8C;AAChB;AACvB;AACP,W;AACA;AACA;AACA;AACA;AACA;AACA,+HAA+H;AAC/H;AACA;AACA,0DAA0D,mBAAmB,cAAc,KAAK;AAChG;AACA,8EAA8E,aAAa,SAAS,KAAK,cAAc,QAAQ,KAAK,eAAe,SAAS,KAAK,eAAe,SAAS,KAAK;AAC9L;AACA,yHAAyH,oBAAoB,gBAAgB,KAAK,qBAAqB,eAAe,KAAK,yBAAyB,mBAAmB,KAAK,0BAA0B,oBAAoB,KAAK,2BAA2B,qBAAqB,KAAK,2BAA2B,qBAAqB,KAAK,wBAAwB,kBAAkB,KAAK;AACxc,+BAA+B,2CAAI;AACnC,YAAY;AACZ;AACO;AACP,WAAW,mDAAQ,QAAQ,kDAAO,OAAO,mDAAQ;AACjD;AACA,iC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClCwD;AACP;AAC1C;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA,wBAAwB,qEAA2B,WAAW,0DAAkB;AAChF;AACA;AACA;AACA,KAAK;AACL;AACA,qC;;;;;;;;;;;;;;;;;;;;;;;;AC3E8B;AAC9B;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACA;AACA;AACA;AACA;AACA,cAAc,2CAAI;AACzB;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChD6B;AACa;AACD;AACgB;AACiD;AACtC;AAC7D,kBAAkB,wDAAU;AAC5B,kBAAkB,8CAAM;AAC/B;AACA;AACA;AACA,iBAAiB;AACjB;AACA,SAAS;AACT;AACA;AACO;AACP;AACA;AACA,YAAY,yDAAc;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACO;AACP,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,mBAAmB,iEAAe,eAAe;AACnE;AACA;AACA;AACA;AACO,kBAAkB,mEAAe;AACxC;AACA;AACA;AACO;AACP,QAAQ,mDAAQ;AAChB;AACA;AACA,gBAAgB,mDAAQ,UAAU,iEAAe;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gBAAgB;AACnC;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,4DAA4D;AAC5D;AACA;AACA;AACA;AACA;AACA,QAAQ,sDAAW;AACnB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,2BAA2B,0DAAe;AAC1C;AACA,iFAAiF,EAAE;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACA;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,sDAAY;AACpB;AACA;AACA,aAAa,sDAAY;AACzB;AACA;AACA,aAAa,qDAAW;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,mBAAmB,0DAAe;AAClC;AACA,mBAAmB,oBAAoB;AACvC,2BAA2B,uBAAuB,kDAAW,aAAa;AAC1E,yBAAyB,MAAM,EAAE,OAAO;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,cAAc,MAAM,GAAG,sDAAW,CAAC,0DAAe,kBAAkB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,cAAc,0DAAe,yCAAyC;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,sEAAsE;AACtE;AACA;AACA;AACA;AACA;AACO;AACP,cAAc,0DAAe,iBAAiB;AAC9C;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,WAAW,0DAAe;AAC1B;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP,+CAA+C,KAAK;AACpD;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,mDAAQ;AAChB;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;;;;;;;;;;;;;ACzVoC;AACN;AACvB;AACP;AACA;AACO;AACP;AACA;AACO;AACP,SAAS,kDAAO;AAChB;AACA;AACA;AACA;AACO;AACP,SAAS,kDAAO;AAChB;AACA;AACA;AACA;AACO;AACP,SAAS,kDAAO;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,2CAAI;AAC5B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,uC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrH+E;;AAE/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,+CAA+C,OAAO;AACtD;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;;AAE9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;;AAE3B;AACA;AACA,8wLAA8wL;AAC9wL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kCAAkC;AAClC;;AAEA;AACA;AACA;;AAEA;AACA;AACA,CAAC;;;AAGD;AACA;AACA,CAAC;;;AAGD;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa,SAAS;AACtB;AACA;AACA;AACA,KAAK;AACL,mBAAmB;AACnB;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,WAAW;;AAEX,eAAe;AACf,iBAAiB;AACjB;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA,kCAAkC;AAClC,iBAAiB;AACjB,GAAG;;;AAGH;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,+BAA+B;;AAE/B;AACA;AACA,mBAAmB;AACnB;;AAEA;AACA;;AAEA;AACA,mBAAmB;AACnB;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,kCAAkC;;AAElC;AACA;;AAEA;AACA,qBAAqB;AACrB;;AAEA;AACA;;AAEA;AACA,qBAAqB;AACrB;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,gBAAgB;;AAEhB,oFAAoF;AACpF;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA,mBAAmB;;AAEnB;;AAEA,mBAAmB;;AAEnB,mBAAmB;;AAEnB;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,2CAA2C;;AAE3C;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,uBAAuB;;AAEvB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,GAAG;;;AAGH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;;AAGH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;;AAGH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iBAAiB;AACjB,GAAG;;;AAGH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe;AACf,CAAC;;;AAGD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,iBAAiB;AACjB;;AAEA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,uBAAuB;AACvB;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,OAAO;;;AAGP;AACA,qBAAqB;AACrB;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL,mBAAmB;AACnB;AACA;;AAEA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA,aAAa;AACb;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,4CAA4C;;AAE5C;AACA;AACA;;AAEA;AACA;AACA,sEAAsE;AACtE;;AAEA;AACA;AACA;AACA;;AAEA;AACA,aAAa;AACb;AACA;;AAEA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,GAAG;AAC7D;AACA;AACA,4BAA4B,gBAAgB;AAC5C;AACA;AACA;;AAEA,mBAAmB;AACnB,KAAK;AACL,GAAG;;;AAGH;AACA;AACA,GAAG;AACH,iBAAiB;AACjB,GAAG;AACH;AACA;;;AAGA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,2BAA2B;;AAE3B;AACA,qBAAqB;AACrB;;AAEA;AACA,KAAK;AACL,mBAAmB;AACnB,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA,iBAAiB;AACjB,GAAG;;;AAGH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,mBAAmB;AACnB,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,GAAG;;;AAGH;AACA;AACA,GAAG;;;AAGH;AACA;AACA,GAAG;AACH;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,GAAG;;;AAGH;AACA,CAAC;AACD;;;AAGA;AACA;;AAEA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA,CAAC;;;AAGD;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,CAAC;;;AAGD;AACA;AACA,sBAAsB;AACtB;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,WAAW;;AAEX,kBAAkB;AAClB;;AAEA;AACA;AACA,KAAK;AACL;AACA;;AAEA;;AAEA;AACA,mBAAmB;AACnB,KAAK;AACL;AACA;;AAEA;;AAEA,iBAAiB;AACjB;AACA;AACA;;AAEA,WAAW;AACX;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,cAAc;AACd;AACA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;;AAGL;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;;AAGH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC;;;AAGD;AACA;;AAEA;AACA,8BAA8B;AAC9B;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,gDAAK;AAChC,2BAA2B,gDAAK;AAChC;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,gDAAK;AAChC,2BAA2B,gDAAK;AAChC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,gCAAgC,gDAAK,kBAAkB;AACvD,oCAAoC,gDAAK,oBAAoB;AAC7D;AACA;AACA;AACA;AACA,uBAAuB,qDAAU;AACjC,kBAAkB;AAClB,iBAAiB;AACjB;;AAEA;AACA,QAAQ,mDAAQ;AAChB;AACA,2BAA2B,gDAAK;AAChC;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,OAAO,UAAU,yDAAc;AAC/B,eAAe,gDAAK;AACpB,OAAO,UAAU,yDAAc;AAC/B;AACA,OAAO,UAAU,yDAAc;AAC/B;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA,QAAQ,gDAAK;AACb;;AAEA;AACA;AACA,iBAAiB,yDAAc;AAC/B,eAAe,gDAAK;AACpB,aAAa,qDAAU;AACvB,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,6BAA6B,0CAA0C;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEuR","file":"vendors-node_modules_vega-lite_build_src_index_js.ce831e2df7e37f2624b4.js","sourcesContent":["Array.prototype.flat||Object.defineProperty(Array.prototype,\"flat\",{configurable:!0,value:function r(){var t=isNaN(arguments[0])?1:Number(arguments[0]);return t?Array.prototype.reduce.call(this,function(a,e){return Array.isArray(e)?a.push.apply(a,r.call(e,t-1)):a.push(e),a},[]):Array.prototype.slice.call(this)},writable:!0}),Array.prototype.flatMap||Object.defineProperty(Array.prototype,\"flatMap\",{configurable:!0,value:function(r){return Array.prototype.map.apply(this,arguments).flat()},writable:!0})\n","var clone = (function() {\n'use strict';\n\nfunction _instanceof(obj, type) {\n  return type != null && obj instanceof type;\n}\n\nvar nativeMap;\ntry {\n  nativeMap = Map;\n} catch(_) {\n  // maybe a reference error because no `Map`. Give it a dummy value that no\n  // value will ever be an instanceof.\n  nativeMap = function() {};\n}\n\nvar nativeSet;\ntry {\n  nativeSet = Set;\n} catch(_) {\n  nativeSet = function() {};\n}\n\nvar nativePromise;\ntry {\n  nativePromise = Promise;\n} catch(_) {\n  nativePromise = function() {};\n}\n\n/**\n * Clones (copies) an Object using deep copying.\n *\n * This function supports circular references by default, but if you are certain\n * there are no circular references in your object, you can save some CPU time\n * by calling clone(obj, false).\n *\n * Caution: if `circular` is false and `parent` contains circular references,\n * your program may enter an infinite loop and crash.\n *\n * @param `parent` - the object to be cloned\n * @param `circular` - set to true if the object to be cloned may contain\n *    circular references. (optional - true by default)\n * @param `depth` - set to a number if the object is only to be cloned to\n *    a particular depth. (optional - defaults to Infinity)\n * @param `prototype` - sets the prototype to be used when cloning an object.\n *    (optional - defaults to parent prototype).\n * @param `includeNonEnumerable` - set to true if the non-enumerable properties\n *    should be cloned as well. Non-enumerable properties on the prototype\n *    chain will be ignored. (optional - false by default)\n*/\nfunction clone(parent, circular, depth, prototype, includeNonEnumerable) {\n  if (typeof circular === 'object') {\n    depth = circular.depth;\n    prototype = circular.prototype;\n    includeNonEnumerable = circular.includeNonEnumerable;\n    circular = circular.circular;\n  }\n  // maintain two arrays for circular references, where corresponding parents\n  // and children have the same index\n  var allParents = [];\n  var allChildren = [];\n\n  var useBuffer = typeof Buffer != 'undefined';\n\n  if (typeof circular == 'undefined')\n    circular = true;\n\n  if (typeof depth == 'undefined')\n    depth = Infinity;\n\n  // recurse this function so we don't reset allParents and allChildren\n  function _clone(parent, depth) {\n    // cloning null always returns null\n    if (parent === null)\n      return null;\n\n    if (depth === 0)\n      return parent;\n\n    var child;\n    var proto;\n    if (typeof parent != 'object') {\n      return parent;\n    }\n\n    if (_instanceof(parent, nativeMap)) {\n      child = new nativeMap();\n    } else if (_instanceof(parent, nativeSet)) {\n      child = new nativeSet();\n    } else if (_instanceof(parent, nativePromise)) {\n      child = new nativePromise(function (resolve, reject) {\n        parent.then(function(value) {\n          resolve(_clone(value, depth - 1));\n        }, function(err) {\n          reject(_clone(err, depth - 1));\n        });\n      });\n    } else if (clone.__isArray(parent)) {\n      child = [];\n    } else if (clone.__isRegExp(parent)) {\n      child = new RegExp(parent.source, __getRegExpFlags(parent));\n      if (parent.lastIndex) child.lastIndex = parent.lastIndex;\n    } else if (clone.__isDate(parent)) {\n      child = new Date(parent.getTime());\n    } else if (useBuffer && Buffer.isBuffer(parent)) {\n      if (Buffer.allocUnsafe) {\n        // Node.js >= 4.5.0\n        child = Buffer.allocUnsafe(parent.length);\n      } else {\n        // Older Node.js versions\n        child = new Buffer(parent.length);\n      }\n      parent.copy(child);\n      return child;\n    } else if (_instanceof(parent, Error)) {\n      child = Object.create(parent);\n    } else {\n      if (typeof prototype == 'undefined') {\n        proto = Object.getPrototypeOf(parent);\n        child = Object.create(proto);\n      }\n      else {\n        child = Object.create(prototype);\n        proto = prototype;\n      }\n    }\n\n    if (circular) {\n      var index = allParents.indexOf(parent);\n\n      if (index != -1) {\n        return allChildren[index];\n      }\n      allParents.push(parent);\n      allChildren.push(child);\n    }\n\n    if (_instanceof(parent, nativeMap)) {\n      parent.forEach(function(value, key) {\n        var keyChild = _clone(key, depth - 1);\n        var valueChild = _clone(value, depth - 1);\n        child.set(keyChild, valueChild);\n      });\n    }\n    if (_instanceof(parent, nativeSet)) {\n      parent.forEach(function(value) {\n        var entryChild = _clone(value, depth - 1);\n        child.add(entryChild);\n      });\n    }\n\n    for (var i in parent) {\n      var attrs;\n      if (proto) {\n        attrs = Object.getOwnPropertyDescriptor(proto, i);\n      }\n\n      if (attrs && attrs.set == null) {\n        continue;\n      }\n      child[i] = _clone(parent[i], depth - 1);\n    }\n\n    if (Object.getOwnPropertySymbols) {\n      var symbols = Object.getOwnPropertySymbols(parent);\n      for (var i = 0; i < symbols.length; i++) {\n        // Don't need to worry about cloning a symbol because it is a primitive,\n        // like a number or string.\n        var symbol = symbols[i];\n        var descriptor = Object.getOwnPropertyDescriptor(parent, symbol);\n        if (descriptor && !descriptor.enumerable && !includeNonEnumerable) {\n          continue;\n        }\n        child[symbol] = _clone(parent[symbol], depth - 1);\n        if (!descriptor.enumerable) {\n          Object.defineProperty(child, symbol, {\n            enumerable: false\n          });\n        }\n      }\n    }\n\n    if (includeNonEnumerable) {\n      var allPropertyNames = Object.getOwnPropertyNames(parent);\n      for (var i = 0; i < allPropertyNames.length; i++) {\n        var propertyName = allPropertyNames[i];\n        var descriptor = Object.getOwnPropertyDescriptor(parent, propertyName);\n        if (descriptor && descriptor.enumerable) {\n          continue;\n        }\n        child[propertyName] = _clone(parent[propertyName], depth - 1);\n        Object.defineProperty(child, propertyName, {\n          enumerable: false\n        });\n      }\n    }\n\n    return child;\n  }\n\n  return _clone(parent, depth);\n}\n\n/**\n * Simple flat clone using prototype, accepts only objects, usefull for property\n * override on FLAT configuration object (no nested props).\n *\n * USE WITH CAUTION! This may not behave as you wish if you do not know how this\n * works.\n */\nclone.clonePrototype = function clonePrototype(parent) {\n  if (parent === null)\n    return null;\n\n  var c = function () {};\n  c.prototype = parent;\n  return new c();\n};\n\n// private utility functions\n\nfunction __objToStr(o) {\n  return Object.prototype.toString.call(o);\n}\nclone.__objToStr = __objToStr;\n\nfunction __isDate(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object Date]';\n}\nclone.__isDate = __isDate;\n\nfunction __isArray(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object Array]';\n}\nclone.__isArray = __isArray;\n\nfunction __isRegExp(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object RegExp]';\n}\nclone.__isRegExp = __isRegExp;\n\nfunction __getRegExpFlags(re) {\n  var flags = '';\n  if (re.global) flags += 'g';\n  if (re.ignoreCase) flags += 'i';\n  if (re.multiline) flags += 'm';\n  return flags;\n}\nclone.__getRegExpFlags = __getRegExpFlags;\n\nreturn clone;\n})();\n\nif (typeof module === 'object' && module.exports) {\n  module.exports = clone;\n}\n","'use strict';\n\n// do not edit .js files directly - edit src/index.jst\n\n\n\nmodule.exports = function equal(a, b) {\n  if (a === b) return true;\n\n  if (a && b && typeof a == 'object' && typeof b == 'object') {\n    if (a.constructor !== b.constructor) return false;\n\n    var length, i, keys;\n    if (Array.isArray(a)) {\n      length = a.length;\n      if (length != b.length) return false;\n      for (i = length; i-- !== 0;)\n        if (!equal(a[i], b[i])) return false;\n      return true;\n    }\n\n\n\n    if (a.constructor === RegExp) return a.source === b.source && a.flags === b.flags;\n    if (a.valueOf !== Object.prototype.valueOf) return a.valueOf() === b.valueOf();\n    if (a.toString !== Object.prototype.toString) return a.toString() === b.toString();\n\n    keys = Object.keys(a);\n    length = keys.length;\n    if (length !== Object.keys(b).length) return false;\n\n    for (i = length; i-- !== 0;)\n      if (!Object.prototype.hasOwnProperty.call(b, keys[i])) return false;\n\n    for (i = length; i-- !== 0;) {\n      var key = keys[i];\n\n      if (!equal(a[key], b[key])) return false;\n    }\n\n    return true;\n  }\n\n  // true if both NaN, false otherwise\n  return a!==a && b!==b;\n};\n","'use strict';\n\nmodule.exports = function (data, opts) {\n    if (!opts) opts = {};\n    if (typeof opts === 'function') opts = { cmp: opts };\n    var cycles = (typeof opts.cycles === 'boolean') ? opts.cycles : false;\n\n    var cmp = opts.cmp && (function (f) {\n        return function (node) {\n            return function (a, b) {\n                var aobj = { key: a, value: node[a] };\n                var bobj = { key: b, value: node[b] };\n                return f(aobj, bobj);\n            };\n        };\n    })(opts.cmp);\n\n    var seen = [];\n    return (function stringify (node) {\n        if (node && node.toJSON && typeof node.toJSON === 'function') {\n            node = node.toJSON();\n        }\n\n        if (node === undefined) return;\n        if (typeof node == 'number') return isFinite(node) ? '' + node : 'null';\n        if (typeof node !== 'object') return JSON.stringify(node);\n\n        var i, out;\n        if (Array.isArray(node)) {\n            out = '[';\n            for (i = 0; i < node.length; i++) {\n                if (i) out += ',';\n                out += stringify(node[i]) || 'null';\n            }\n            return out + ']';\n        }\n\n        if (node === null) return 'null';\n\n        if (seen.indexOf(node) !== -1) {\n            if (cycles) return JSON.stringify('__cycle__');\n            throw new TypeError('Converting circular structure to JSON');\n        }\n\n        var seenIndex = seen.push(node) - 1;\n        var keys = Object.keys(node).sort(cmp && cmp(node));\n        out = '';\n        for (i = 0; i < keys.length; i++) {\n            var key = keys[i];\n            var value = stringify(node[key]);\n\n            if (!value) continue;\n            if (out) out += ',';\n            out += JSON.stringify(key) + ':' + value;\n        }\n        seen.splice(seenIndex, 1);\n        return '{' + out + '}';\n    })(data);\n};\n","const VIEW = 'view',\n      LBRACK = '[',\n      RBRACK = ']',\n      LBRACE = '{',\n      RBRACE = '}',\n      COLON = ':',\n      COMMA = ',',\n      NAME = '@',\n      GT = '>',\n      ILLEGAL = /[[\\]{}]/,\n      DEFAULT_MARKS = {\n  '*': 1,\n  arc: 1,\n  area: 1,\n  group: 1,\n  image: 1,\n  line: 1,\n  path: 1,\n  rect: 1,\n  rule: 1,\n  shape: 1,\n  symbol: 1,\n  text: 1,\n  trail: 1\n};\nlet DEFAULT_SOURCE, MARKS;\n/**\n * Parse an event selector string.\n * Returns an array of event stream definitions.\n */\n\nfunction eventSelector (selector, source, marks) {\n  DEFAULT_SOURCE = source || VIEW;\n  MARKS = marks || DEFAULT_MARKS;\n  return parseMerge(selector.trim()).map(parseSelector);\n}\n\nfunction isMarkType(type) {\n  return MARKS[type];\n}\n\nfunction find(s, i, endChar, pushChar, popChar) {\n  const n = s.length;\n  let count = 0,\n      c;\n\n  for (; i < n; ++i) {\n    c = s[i];\n    if (!count && c === endChar) return i;else if (popChar && popChar.indexOf(c) >= 0) --count;else if (pushChar && pushChar.indexOf(c) >= 0) ++count;\n  }\n\n  return i;\n}\n\nfunction parseMerge(s) {\n  const output = [],\n        n = s.length;\n  let start = 0,\n      i = 0;\n\n  while (i < n) {\n    i = find(s, i, COMMA, LBRACK + LBRACE, RBRACK + RBRACE);\n    output.push(s.substring(start, i).trim());\n    start = ++i;\n  }\n\n  if (output.length === 0) {\n    throw 'Empty event selector: ' + s;\n  }\n\n  return output;\n}\n\nfunction parseSelector(s) {\n  return s[0] === '[' ? parseBetween(s) : parseStream(s);\n}\n\nfunction parseBetween(s) {\n  const n = s.length;\n  let i = 1,\n      b;\n  i = find(s, i, RBRACK, LBRACK, RBRACK);\n\n  if (i === n) {\n    throw 'Empty between selector: ' + s;\n  }\n\n  b = parseMerge(s.substring(1, i));\n\n  if (b.length !== 2) {\n    throw 'Between selector must have two elements: ' + s;\n  }\n\n  s = s.slice(i + 1).trim();\n\n  if (s[0] !== GT) {\n    throw 'Expected \\'>\\' after between selector: ' + s;\n  }\n\n  b = b.map(parseSelector);\n  const stream = parseSelector(s.slice(1).trim());\n\n  if (stream.between) {\n    return {\n      between: b,\n      stream: stream\n    };\n  } else {\n    stream.between = b;\n  }\n\n  return stream;\n}\n\nfunction parseStream(s) {\n  const stream = {\n    source: DEFAULT_SOURCE\n  },\n        source = [];\n  let throttle = [0, 0],\n      markname = 0,\n      start = 0,\n      n = s.length,\n      i = 0,\n      j,\n      filter; // extract throttle from end\n\n  if (s[n - 1] === RBRACE) {\n    i = s.lastIndexOf(LBRACE);\n\n    if (i >= 0) {\n      try {\n        throttle = parseThrottle(s.substring(i + 1, n - 1));\n      } catch (e) {\n        throw 'Invalid throttle specification: ' + s;\n      }\n\n      s = s.slice(0, i).trim();\n      n = s.length;\n    } else throw 'Unmatched right brace: ' + s;\n\n    i = 0;\n  }\n\n  if (!n) throw s; // set name flag based on first char\n\n  if (s[0] === NAME) markname = ++i; // extract first part of multi-part stream selector\n\n  j = find(s, i, COLON);\n\n  if (j < n) {\n    source.push(s.substring(start, j).trim());\n    start = i = ++j;\n  } // extract remaining part of stream selector\n\n\n  i = find(s, i, LBRACK);\n\n  if (i === n) {\n    source.push(s.substring(start, n).trim());\n  } else {\n    source.push(s.substring(start, i).trim());\n    filter = [];\n    start = ++i;\n    if (start === n) throw 'Unmatched left bracket: ' + s;\n  } // extract filters\n\n\n  while (i < n) {\n    i = find(s, i, RBRACK);\n    if (i === n) throw 'Unmatched left bracket: ' + s;\n    filter.push(s.substring(start, i).trim());\n    if (i < n - 1 && s[++i] !== LBRACK) throw 'Expected left bracket: ' + s;\n    start = ++i;\n  } // marshall event stream specification\n\n\n  if (!(n = source.length) || ILLEGAL.test(source[n - 1])) {\n    throw 'Invalid event selector: ' + s;\n  }\n\n  if (n > 1) {\n    stream.type = source[1];\n\n    if (markname) {\n      stream.markname = source[0].slice(1);\n    } else if (isMarkType(source[0])) {\n      stream.marktype = source[0];\n    } else {\n      stream.source = source[0];\n    }\n  } else {\n    stream.type = source[0];\n  }\n\n  if (stream.type.slice(-1) === '!') {\n    stream.consume = true;\n    stream.type = stream.type.slice(0, -1);\n  }\n\n  if (filter != null) stream.filter = filter;\n  if (throttle[0]) stream.throttle = throttle[0];\n  if (throttle[1]) stream.debounce = throttle[1];\n  return stream;\n}\n\nfunction parseThrottle(s) {\n  const a = s.split(COMMA);\n  if (!s.length || a.length > 2) throw s;\n  return a.map(_ => {\n    const x = +_;\n    if (x !== x) throw s;\n    return x;\n  });\n}\n\nexport { eventSelector as selector };\n","import { isString, toSet } from 'vega-util';\nimport { contains, keys } from './util';\nconst AGGREGATE_OP_INDEX = {\n    argmax: 1,\n    argmin: 1,\n    average: 1,\n    count: 1,\n    distinct: 1,\n    product: 1,\n    max: 1,\n    mean: 1,\n    median: 1,\n    min: 1,\n    missing: 1,\n    q1: 1,\n    q3: 1,\n    ci0: 1,\n    ci1: 1,\n    stderr: 1,\n    stdev: 1,\n    stdevp: 1,\n    sum: 1,\n    valid: 1,\n    values: 1,\n    variance: 1,\n    variancep: 1\n};\nexport const MULTIDOMAIN_SORT_OP_INDEX = {\n    count: 1,\n    min: 1,\n    max: 1\n};\nexport function isArgminDef(a) {\n    return !!a && !!a['argmin'];\n}\nexport function isArgmaxDef(a) {\n    return !!a && !!a['argmax'];\n}\nexport const AGGREGATE_OPS = keys(AGGREGATE_OP_INDEX);\nexport function isAggregateOp(a) {\n    return isString(a) && !!AGGREGATE_OP_INDEX[a];\n}\nexport const COUNTING_OPS = ['count', 'valid', 'missing', 'distinct'];\nexport function isCountingAggregateOp(aggregate) {\n    return isString(aggregate) && contains(COUNTING_OPS, aggregate);\n}\nexport function isMinMaxOp(aggregate) {\n    return isString(aggregate) && contains(['min', 'max'], aggregate);\n}\n/** Additive-based aggregation operations. These can be applied to stack. */\nexport const SUM_OPS = ['count', 'sum', 'distinct', 'valid', 'missing'];\n/**\n * Aggregation operators that always produce values within the range [domainMin, domainMax].\n */\nexport const SHARED_DOMAIN_OPS = ['mean', 'average', 'median', 'q1', 'q3', 'min', 'max'];\nexport const SHARED_DOMAIN_OP_INDEX = toSet(SHARED_DOMAIN_OPS);\n//# sourceMappingURL=aggregate.js.map","import { keys } from './util';\nexport const CONDITIONAL_AXIS_PROP_INDEX = {\n    labelAlign: {\n        part: 'labels',\n        vgProp: 'align'\n    },\n    labelBaseline: {\n        part: 'labels',\n        vgProp: 'baseline'\n    },\n    labelColor: {\n        part: 'labels',\n        vgProp: 'fill'\n    },\n    labelFont: {\n        part: 'labels',\n        vgProp: 'font'\n    },\n    labelFontSize: {\n        part: 'labels',\n        vgProp: 'fontSize'\n    },\n    labelFontStyle: {\n        part: 'labels',\n        vgProp: 'fontStyle'\n    },\n    labelFontWeight: {\n        part: 'labels',\n        vgProp: 'fontWeight'\n    },\n    labelOpacity: {\n        part: 'labels',\n        vgProp: 'opacity'\n    },\n    labelOffset: null,\n    labelPadding: null,\n    gridColor: {\n        part: 'grid',\n        vgProp: 'stroke'\n    },\n    gridDash: {\n        part: 'grid',\n        vgProp: 'strokeDash'\n    },\n    gridDashOffset: {\n        part: 'grid',\n        vgProp: 'strokeDashOffset'\n    },\n    gridOpacity: {\n        part: 'grid',\n        vgProp: 'opacity'\n    },\n    gridWidth: {\n        part: 'grid',\n        vgProp: 'strokeWidth'\n    },\n    tickColor: {\n        part: 'ticks',\n        vgProp: 'stroke'\n    },\n    tickDash: {\n        part: 'ticks',\n        vgProp: 'strokeDash'\n    },\n    tickDashOffset: {\n        part: 'ticks',\n        vgProp: 'strokeDashOffset'\n    },\n    tickOpacity: {\n        part: 'ticks',\n        vgProp: 'opacity'\n    },\n    tickSize: null,\n    tickWidth: {\n        part: 'ticks',\n        vgProp: 'strokeWidth'\n    }\n};\nexport function isConditionalAxisValue(v) {\n    return v && v['condition'];\n}\nexport const AXIS_PARTS = ['domain', 'grid', 'labels', 'ticks', 'title'];\n/**\n * A dictionary listing whether a certain axis property is applicable for only main axes or only grid axes.\n */\nexport const AXIS_PROPERTY_TYPE = {\n    grid: 'grid',\n    gridCap: 'grid',\n    gridColor: 'grid',\n    gridDash: 'grid',\n    gridDashOffset: 'grid',\n    gridOpacity: 'grid',\n    gridScale: 'grid',\n    gridWidth: 'grid',\n    orient: 'main',\n    bandPosition: 'both',\n    aria: 'main',\n    description: 'main',\n    domain: 'main',\n    domainCap: 'main',\n    domainColor: 'main',\n    domainDash: 'main',\n    domainDashOffset: 'main',\n    domainOpacity: 'main',\n    domainWidth: 'main',\n    format: 'main',\n    formatType: 'main',\n    labelAlign: 'main',\n    labelAngle: 'main',\n    labelBaseline: 'main',\n    labelBound: 'main',\n    labelColor: 'main',\n    labelFlush: 'main',\n    labelFlushOffset: 'main',\n    labelFont: 'main',\n    labelFontSize: 'main',\n    labelFontStyle: 'main',\n    labelFontWeight: 'main',\n    labelLimit: 'main',\n    labelLineHeight: 'main',\n    labelOffset: 'main',\n    labelOpacity: 'main',\n    labelOverlap: 'main',\n    labelPadding: 'main',\n    labels: 'main',\n    labelSeparation: 'main',\n    maxExtent: 'main',\n    minExtent: 'main',\n    offset: 'both',\n    position: 'main',\n    tickCap: 'main',\n    tickColor: 'main',\n    tickDash: 'main',\n    tickDashOffset: 'main',\n    tickMinStep: 'main',\n    tickOffset: 'both',\n    tickOpacity: 'main',\n    tickRound: 'both',\n    ticks: 'main',\n    tickSize: 'main',\n    tickWidth: 'both',\n    title: 'main',\n    titleAlign: 'main',\n    titleAnchor: 'main',\n    titleAngle: 'main',\n    titleBaseline: 'main',\n    titleColor: 'main',\n    titleFont: 'main',\n    titleFontSize: 'main',\n    titleFontStyle: 'main',\n    titleFontWeight: 'main',\n    titleLimit: 'main',\n    titleLineHeight: 'main',\n    titleOpacity: 'main',\n    titlePadding: 'main',\n    titleX: 'main',\n    titleY: 'main',\n    encode: 'both',\n    scale: 'both',\n    tickBand: 'both',\n    tickCount: 'both',\n    tickExtra: 'both',\n    translate: 'both',\n    values: 'both',\n    zindex: 'both' // this is actually set afterward, so it doesn't matter\n};\nexport const COMMON_AXIS_PROPERTIES_INDEX = {\n    orient: 1,\n    aria: 1,\n    bandPosition: 1,\n    description: 1,\n    domain: 1,\n    domainCap: 1,\n    domainColor: 1,\n    domainDash: 1,\n    domainDashOffset: 1,\n    domainOpacity: 1,\n    domainWidth: 1,\n    format: 1,\n    formatType: 1,\n    grid: 1,\n    gridCap: 1,\n    gridColor: 1,\n    gridDash: 1,\n    gridDashOffset: 1,\n    gridOpacity: 1,\n    gridWidth: 1,\n    labelAlign: 1,\n    labelAngle: 1,\n    labelBaseline: 1,\n    labelBound: 1,\n    labelColor: 1,\n    labelFlush: 1,\n    labelFlushOffset: 1,\n    labelFont: 1,\n    labelFontSize: 1,\n    labelFontStyle: 1,\n    labelFontWeight: 1,\n    labelLimit: 1,\n    labelLineHeight: 1,\n    labelOffset: 1,\n    labelOpacity: 1,\n    labelOverlap: 1,\n    labelPadding: 1,\n    labels: 1,\n    labelSeparation: 1,\n    maxExtent: 1,\n    minExtent: 1,\n    offset: 1,\n    position: 1,\n    tickBand: 1,\n    tickCap: 1,\n    tickColor: 1,\n    tickCount: 1,\n    tickDash: 1,\n    tickDashOffset: 1,\n    tickExtra: 1,\n    tickMinStep: 1,\n    tickOffset: 1,\n    tickOpacity: 1,\n    tickRound: 1,\n    ticks: 1,\n    tickSize: 1,\n    tickWidth: 1,\n    title: 1,\n    titleAlign: 1,\n    titleAnchor: 1,\n    titleAngle: 1,\n    titleBaseline: 1,\n    titleColor: 1,\n    titleFont: 1,\n    titleFontSize: 1,\n    titleFontStyle: 1,\n    titleFontWeight: 1,\n    titleLimit: 1,\n    titleLineHeight: 1,\n    titleOpacity: 1,\n    titlePadding: 1,\n    titleX: 1,\n    titleY: 1,\n    translate: 1,\n    values: 1,\n    zindex: 1\n};\nconst AXIS_PROPERTIES_INDEX = Object.assign(Object.assign({}, COMMON_AXIS_PROPERTIES_INDEX), { style: 1, labelExpr: 1, encoding: 1 });\nexport function isAxisProperty(prop) {\n    return !!AXIS_PROPERTIES_INDEX[prop];\n}\n// Export for dependent projects\nexport const AXIS_PROPERTIES = keys(AXIS_PROPERTIES_INDEX);\nconst AXIS_CONFIGS_INDEX = {\n    axis: 1,\n    axisBand: 1,\n    axisBottom: 1,\n    axisDiscrete: 1,\n    axisLeft: 1,\n    axisPoint: 1,\n    axisQuantitative: 1,\n    axisRight: 1,\n    axisTemporal: 1,\n    axisTop: 1,\n    axisX: 1,\n    axisXBand: 1,\n    axisXDiscrete: 1,\n    axisXPoint: 1,\n    axisXQuantitative: 1,\n    axisXTemporal: 1,\n    axisY: 1,\n    axisYBand: 1,\n    axisYDiscrete: 1,\n    axisYPoint: 1,\n    axisYQuantitative: 1,\n    axisYTemporal: 1\n};\nexport const AXIS_CONFIGS = keys(AXIS_CONFIGS_INDEX);\n//# sourceMappingURL=axis.js.map","import { isBoolean, isObject } from 'vega-util';\nimport { COLOR, COLUMN, FILL, FILLOPACITY, OPACITY, ROW, SHAPE, SIZE, STROKE, STROKEDASH, STROKEOPACITY, STROKEWIDTH } from './channel';\nimport { normalizeBin } from './channeldef';\nimport { entries, keys, varName } from './util';\n/**\n * Create a key for the bin configuration. Not for prebinned bin.\n */\nexport function binToString(bin) {\n    if (isBoolean(bin)) {\n        bin = normalizeBin(bin, undefined);\n    }\n    return ('bin' +\n        keys(bin)\n            .map(p => (isSelectionExtent(bin[p]) ? varName(`_${p}_${entries(bin[p])}`) : varName(`_${p}_${bin[p]}`)))\n            .join(''));\n}\n/**\n * Vega-Lite should bin the data.\n */\nexport function isBinning(bin) {\n    return bin === true || (isBinParams(bin) && !bin.binned);\n}\n/**\n * The data is already binned and so Vega-Lite should not bin it again.\n */\nexport function isBinned(bin) {\n    return bin === 'binned' || (isBinParams(bin) && bin.binned === true);\n}\nexport function isBinParams(bin) {\n    return isObject(bin);\n}\nexport function isSelectionExtent(extent) {\n    return extent === null || extent === void 0 ? void 0 : extent['selection'];\n}\nexport function autoMaxBins(channel) {\n    switch (channel) {\n        case ROW:\n        case COLUMN:\n        case SIZE:\n        case COLOR:\n        case FILL:\n        case STROKE:\n        case STROKEWIDTH:\n        case OPACITY:\n        case FILLOPACITY:\n        case STROKEOPACITY:\n        // Facets and Size shouldn't have too many bins\n        // We choose 6 like shape to simplify the rule [falls through]\n        case SHAPE:\n            return 6; // Vega's \"shape\" has 6 distinct values\n        case STROKEDASH:\n            return 4; // We only provide 5 different stroke dash values (but 4 is more effective)\n        default:\n            return 10;\n    }\n}\n//# sourceMappingURL=bin.js.map","/*\n * Constants and utilities for encoding channels (Visual variables)\n * such as 'x', 'y', 'color'.\n */\nvar __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { keys } from './util';\n// Facet\nexport const ROW = 'row';\nexport const COLUMN = 'column';\nexport const FACET = 'facet';\n// Position\nexport const X = 'x';\nexport const Y = 'y';\nexport const X2 = 'x2';\nexport const Y2 = 'y2';\n// Arc-Position\nexport const RADIUS = 'radius';\nexport const RADIUS2 = 'radius2';\nexport const THETA = 'theta';\nexport const THETA2 = 'theta2';\n// Geo Position\nexport const LATITUDE = 'latitude';\nexport const LONGITUDE = 'longitude';\nexport const LATITUDE2 = 'latitude2';\nexport const LONGITUDE2 = 'longitude2';\n// Mark property with scale\nexport const COLOR = 'color';\nexport const FILL = 'fill';\nexport const STROKE = 'stroke';\nexport const SHAPE = 'shape';\nexport const SIZE = 'size';\nexport const ANGLE = 'angle';\nexport const OPACITY = 'opacity';\nexport const FILLOPACITY = 'fillOpacity';\nexport const STROKEOPACITY = 'strokeOpacity';\nexport const STROKEWIDTH = 'strokeWidth';\nexport const STROKEDASH = 'strokeDash';\n// Non-scale channel\nexport const TEXT = 'text';\nexport const ORDER = 'order';\nexport const DETAIL = 'detail';\nexport const KEY = 'key';\nexport const TOOLTIP = 'tooltip';\nexport const HREF = 'href';\nexport const URL = 'url';\nexport const DESCRIPTION = 'description';\nconst POSITION_CHANNEL_INDEX = {\n    x: 1,\n    y: 1,\n    x2: 1,\n    y2: 1\n};\nconst POLAR_POSITION_CHANNEL_INDEX = {\n    theta: 1,\n    theta2: 1,\n    radius: 1,\n    radius2: 1\n};\nexport function isPolarPositionChannel(c) {\n    return c in POLAR_POSITION_CHANNEL_INDEX;\n}\nconst GEO_POSIITON_CHANNEL_INDEX = {\n    longitude: 1,\n    longitude2: 1,\n    latitude: 1,\n    latitude2: 1\n};\nexport function getPositionChannelFromLatLong(channel) {\n    switch (channel) {\n        case LATITUDE:\n            return 'y';\n        case LATITUDE2:\n            return 'y2';\n        case LONGITUDE:\n            return 'x';\n        case LONGITUDE2:\n            return 'x2';\n    }\n}\nexport function isGeoPositionChannel(c) {\n    return c in GEO_POSIITON_CHANNEL_INDEX;\n}\nexport const GEOPOSITION_CHANNELS = keys(GEO_POSIITON_CHANNEL_INDEX);\nconst UNIT_CHANNEL_INDEX = Object.assign(Object.assign(Object.assign(Object.assign({}, POSITION_CHANNEL_INDEX), POLAR_POSITION_CHANNEL_INDEX), GEO_POSIITON_CHANNEL_INDEX), { \n    // color\n    color: 1, fill: 1, stroke: 1, \n    // other non-position with scale\n    opacity: 1, fillOpacity: 1, strokeOpacity: 1, strokeWidth: 1, strokeDash: 1, size: 1, angle: 1, shape: 1, \n    // channels without scales\n    order: 1, text: 1, detail: 1, key: 1, tooltip: 1, href: 1, url: 1, description: 1 });\nexport function isColorChannel(channel) {\n    return channel === COLOR || channel === FILL || channel === STROKE;\n}\nconst FACET_CHANNEL_INDEX = {\n    row: 1,\n    column: 1,\n    facet: 1\n};\nexport const FACET_CHANNELS = keys(FACET_CHANNEL_INDEX);\nconst CHANNEL_INDEX = Object.assign(Object.assign({}, UNIT_CHANNEL_INDEX), FACET_CHANNEL_INDEX);\nexport const CHANNELS = keys(CHANNEL_INDEX);\nconst { order: _o, detail: _d, tooltip: _tt1 } = CHANNEL_INDEX, SINGLE_DEF_CHANNEL_INDEX = __rest(CHANNEL_INDEX, [\"order\", \"detail\", \"tooltip\"]);\nconst { row: _r, column: _c, facet: _f } = SINGLE_DEF_CHANNEL_INDEX, SINGLE_DEF_UNIT_CHANNEL_INDEX = __rest(SINGLE_DEF_CHANNEL_INDEX, [\"row\", \"column\", \"facet\"]);\n/**\n * Channels that cannot have an array of channelDef.\n * model.fieldDef, getFieldDef only work for these channels.\n *\n * (The only two channels that can have an array of channelDefs are \"detail\" and \"order\".\n * Since there can be multiple fieldDefs for detail and order, getFieldDef/model.fieldDef\n * are not applicable for them. Similarly, selection projection won't work with \"detail\" and \"order\".)\n */\nexport const SINGLE_DEF_CHANNELS = keys(SINGLE_DEF_CHANNEL_INDEX);\nexport const SINGLE_DEF_UNIT_CHANNELS = keys(SINGLE_DEF_UNIT_CHANNEL_INDEX);\nexport function isSingleDefUnitChannel(str) {\n    return !!SINGLE_DEF_UNIT_CHANNEL_INDEX[str];\n}\nexport function isChannel(str) {\n    return !!CHANNEL_INDEX[str];\n}\nexport const SECONDARY_RANGE_CHANNEL = [X2, Y2, LATITUDE2, LONGITUDE2, THETA2, RADIUS2];\nexport function isSecondaryRangeChannel(c) {\n    const main = getMainRangeChannel(c);\n    return main !== c;\n}\n/**\n * Get the main channel for a range channel. E.g. `x` for `x2`.\n */\nexport function getMainRangeChannel(channel) {\n    switch (channel) {\n        case X2:\n            return X;\n        case Y2:\n            return Y;\n        case LATITUDE2:\n            return LATITUDE;\n        case LONGITUDE2:\n            return LONGITUDE;\n        case THETA2:\n            return THETA;\n        case RADIUS2:\n            return RADIUS;\n    }\n    return channel;\n}\nexport function getVgPositionChannel(channel) {\n    if (isPolarPositionChannel(channel)) {\n        switch (channel) {\n            case THETA:\n                return 'startAngle';\n            case THETA2:\n                return 'endAngle';\n            case RADIUS:\n                return 'outerRadius';\n            case RADIUS2:\n                return 'innerRadius';\n        }\n    }\n    return channel;\n}\n/**\n * Get the main channel for a range channel. E.g. `x` for `x2`.\n */\nexport function getSecondaryRangeChannel(channel) {\n    switch (channel) {\n        case X:\n            return X2;\n        case Y:\n            return Y2;\n        case LATITUDE:\n            return LATITUDE2;\n        case LONGITUDE:\n            return LONGITUDE2;\n        case THETA:\n            return THETA2;\n        case RADIUS:\n            return RADIUS2;\n    }\n    return undefined;\n}\nexport function getSizeChannel(channel) {\n    switch (channel) {\n        case X:\n        case X2:\n            return 'width';\n        case Y:\n        case Y2:\n            return 'height';\n    }\n    return undefined;\n}\n/**\n * Get the main channel for a range channel. E.g. `x` for `x2`.\n */\nexport function getOffsetChannel(channel) {\n    switch (channel) {\n        case X:\n            return 'xOffset';\n        case Y:\n            return 'yOffset';\n        case X2:\n            return 'x2Offset';\n        case Y2:\n            return 'y2Offset';\n        case THETA:\n            return 'thetaOffset';\n        case RADIUS:\n            return 'radiusOffset';\n        case THETA2:\n            return 'theta2Offset';\n        case RADIUS2:\n            return 'radius2Offset';\n    }\n    return undefined;\n}\n// CHANNELS without COLUMN, ROW\nexport const UNIT_CHANNELS = keys(UNIT_CHANNEL_INDEX);\n// NONPOSITION_CHANNELS = UNIT_CHANNELS without X, Y, X2, Y2;\nconst { x: _x, y: _y, \n// x2 and y2 share the same scale as x and y\nx2: _x2, y2: _y2, latitude: _latitude, longitude: _longitude, latitude2: _latitude2, longitude2: _longitude2, theta: _theta, theta2: _theta2, radius: _radius, radius2: _radius2 } = UNIT_CHANNEL_INDEX, \n// The rest of unit channels then have scale\nNONPOSITION_CHANNEL_INDEX = __rest(UNIT_CHANNEL_INDEX, [\"x\", \"y\", \"x2\", \"y2\", \"latitude\", \"longitude\", \"latitude2\", \"longitude2\", \"theta\", \"theta2\", \"radius\", \"radius2\"]);\nexport const NONPOSITION_CHANNELS = keys(NONPOSITION_CHANNEL_INDEX);\nexport const POSITION_SCALE_CHANNEL_INDEX = {\n    x: 1,\n    y: 1\n};\nexport const POSITION_SCALE_CHANNELS = keys(POSITION_SCALE_CHANNEL_INDEX);\nexport function isXorY(channel) {\n    return channel in POSITION_SCALE_CHANNEL_INDEX;\n}\nexport const POLAR_POSITION_SCALE_CHANNEL_INDEX = {\n    theta: 1,\n    radius: 1\n};\nexport const POLAR_POSITION_SCALE_CHANNELS = keys(POLAR_POSITION_SCALE_CHANNEL_INDEX);\nexport function getPositionScaleChannel(sizeType) {\n    return sizeType === 'width' ? X : Y;\n}\n// NON_POSITION_SCALE_CHANNEL = SCALE_CHANNELS without X, Y\nconst { \n// x2 and y2 share the same scale as x and y\n// text and tooltip have format instead of scale,\n// href has neither format, nor scale\ntext: _t, tooltip: _tt, href: _hr, url: _u, description: _al, \n// detail and order have no scale\ndetail: _dd, key: _k, order: _oo } = NONPOSITION_CHANNEL_INDEX, NONPOSITION_SCALE_CHANNEL_INDEX = __rest(NONPOSITION_CHANNEL_INDEX, [\"text\", \"tooltip\", \"href\", \"url\", \"description\", \"detail\", \"key\", \"order\"]);\nexport const NONPOSITION_SCALE_CHANNELS = keys(NONPOSITION_SCALE_CHANNEL_INDEX);\nexport function isNonPositionScaleChannel(channel) {\n    return !!NONPOSITION_CHANNEL_INDEX[channel];\n}\n/**\n * @returns whether Vega supports legends for a particular channel\n */\nexport function supportLegend(channel) {\n    switch (channel) {\n        case COLOR:\n        case FILL:\n        case STROKE:\n        case SIZE:\n        case SHAPE:\n        case OPACITY:\n        case STROKEWIDTH:\n        case STROKEDASH:\n            return true;\n        case FILLOPACITY:\n        case STROKEOPACITY:\n        case ANGLE:\n            return false;\n    }\n}\n// Declare SCALE_CHANNEL_INDEX\nconst SCALE_CHANNEL_INDEX = Object.assign(Object.assign(Object.assign({}, POSITION_SCALE_CHANNEL_INDEX), POLAR_POSITION_SCALE_CHANNEL_INDEX), NONPOSITION_SCALE_CHANNEL_INDEX);\n/** List of channels with scales */\nexport const SCALE_CHANNELS = keys(SCALE_CHANNEL_INDEX);\nexport function isScaleChannel(channel) {\n    return !!SCALE_CHANNEL_INDEX[channel];\n}\n/**\n * Return whether a channel supports a particular mark type.\n * @param channel  channel name\n * @param mark the mark type\n * @return whether the mark supports the channel\n */\nexport function supportMark(channel, mark) {\n    return getSupportedMark(channel)[mark];\n}\nconst ALL_MARKS = {\n    // all marks\n    arc: 'always',\n    area: 'always',\n    bar: 'always',\n    circle: 'always',\n    geoshape: 'always',\n    image: 'always',\n    line: 'always',\n    rule: 'always',\n    point: 'always',\n    rect: 'always',\n    square: 'always',\n    trail: 'always',\n    text: 'always',\n    tick: 'always'\n};\nconst { geoshape: _g } = ALL_MARKS, ALL_MARKS_EXCEPT_GEOSHAPE = __rest(ALL_MARKS, [\"geoshape\"]);\n/**\n * Return a dictionary showing whether a channel supports mark type.\n * @param channel\n * @return A dictionary mapping mark types to 'always', 'binned', or undefined\n */\nfunction getSupportedMark(channel) {\n    switch (channel) {\n        case COLOR:\n        case FILL:\n        case STROKE:\n        // falls through\n        case DESCRIPTION:\n        case DETAIL:\n        case KEY:\n        case TOOLTIP:\n        case HREF:\n        case ORDER: // TODO: revise (order might not support rect, which is not stackable?)\n        case OPACITY:\n        case FILLOPACITY:\n        case STROKEOPACITY:\n        case STROKEWIDTH:\n        // falls through\n        case FACET:\n        case ROW: // falls through\n        case COLUMN:\n            return ALL_MARKS;\n        case X:\n        case Y:\n        case LATITUDE:\n        case LONGITUDE:\n            // all marks except geoshape. geoshape does not use X, Y -- it uses a projection\n            return ALL_MARKS_EXCEPT_GEOSHAPE;\n        case X2:\n        case Y2:\n        case LATITUDE2:\n        case LONGITUDE2:\n            return {\n                area: 'always',\n                bar: 'always',\n                image: 'always',\n                rect: 'always',\n                rule: 'always',\n                circle: 'binned',\n                point: 'binned',\n                square: 'binned',\n                tick: 'binned',\n                line: 'binned',\n                trail: 'binned'\n            };\n        case SIZE:\n            return {\n                point: 'always',\n                tick: 'always',\n                rule: 'always',\n                circle: 'always',\n                square: 'always',\n                bar: 'always',\n                text: 'always',\n                line: 'always',\n                trail: 'always'\n            };\n        case STROKEDASH:\n            return {\n                line: 'always',\n                point: 'always',\n                tick: 'always',\n                rule: 'always',\n                circle: 'always',\n                square: 'always',\n                bar: 'always',\n                geoshape: 'always'\n            };\n        case SHAPE:\n            return { point: 'always', geoshape: 'always' };\n        case TEXT:\n            return { text: 'always' };\n        case ANGLE:\n            return { point: 'always', square: 'always', text: 'always' };\n        case URL:\n            return { image: 'always' };\n        case THETA:\n            return { text: 'always', arc: 'always' };\n        case RADIUS:\n            return { text: 'always', arc: 'always' };\n        case THETA2:\n        case RADIUS2:\n            return { arc: 'always' };\n    }\n}\nexport function rangeType(channel) {\n    switch (channel) {\n        case X:\n        case Y:\n        case THETA:\n        case RADIUS:\n        case SIZE:\n        case ANGLE:\n        case STROKEWIDTH:\n        case OPACITY:\n        case FILLOPACITY:\n        case STROKEOPACITY:\n        // X2 and Y2 use X and Y scales, so they similarly have continuous range. [falls through]\n        case X2:\n        case Y2:\n        case THETA2:\n        case RADIUS2:\n            return undefined;\n        case FACET:\n        case ROW:\n        case COLUMN:\n        case SHAPE:\n        case STROKEDASH:\n        // TEXT, TOOLTIP, URL, and HREF have no scale but have discrete output [falls through]\n        case TEXT:\n        case TOOLTIP:\n        case HREF:\n        case URL:\n        case DESCRIPTION:\n            return 'discrete';\n        // Color can be either continuous or discrete, depending on scale type.\n        case COLOR:\n        case FILL:\n        case STROKE:\n            return 'flexible';\n        // No scale, no range type.\n        case LATITUDE:\n        case LONGITUDE:\n        case LATITUDE2:\n        case LONGITUDE2:\n        case DETAIL:\n        case KEY:\n        case ORDER:\n            return undefined;\n    }\n}\n//# sourceMappingURL=channel.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isArray, isBoolean, isNumber, isString } from 'vega-util';\nimport { isAggregateOp, isArgmaxDef, isArgminDef, isCountingAggregateOp } from './aggregate';\nimport { autoMaxBins, binToString, isBinned, isBinning } from './bin';\nimport { ANGLE, COLOR, COLUMN, DESCRIPTION, DETAIL, FACET, FILL, FILLOPACITY, HREF, isScaleChannel, isSecondaryRangeChannel, isXorY, KEY, LATITUDE, LATITUDE2, LONGITUDE, LONGITUDE2, OPACITY, ORDER, RADIUS, RADIUS2, ROW, SHAPE, SIZE, STROKE, STROKEDASH, STROKEOPACITY, STROKEWIDTH, TEXT, THETA, THETA2, TOOLTIP, URL, X, X2, Y, Y2 } from './channel';\nimport { getMarkConfig } from './compile/common';\nimport { isCustomFormatType } from './compile/format';\nimport { dateTimeToExpr, isDateTime } from './datetime';\nimport { isExprRef } from './expr';\nimport * as log from './log';\nimport { isRectBasedMark } from './mark';\nimport { SCALE_CATEGORY_INDEX } from './scale';\nimport { isSortByChannel } from './sort';\nimport { isFacetFieldDef } from './spec/facet';\nimport { getTimeUnitParts, isLocalSingleTimeUnit, normalizeTimeUnit, timeUnitToString } from './timeunit';\nimport { getFullName, QUANTITATIVE } from './type';\nimport { contains, flatAccessWithDatum, getFirstDefined, internalField, omit, removePathFromField, replacePathInField, titleCase } from './util';\nimport { isSignalRef } from './vega.schema';\nexport function isConditionalSelection(c) {\n    return c['selection'];\n}\nexport function isRepeatRef(field) {\n    return field && !isString(field) && 'repeat' in field;\n}\nexport function toFieldDefBase(fieldDef) {\n    const { field, timeUnit, bin, aggregate } = fieldDef;\n    return Object.assign(Object.assign(Object.assign(Object.assign({}, (timeUnit ? { timeUnit } : {})), (bin ? { bin } : {})), (aggregate ? { aggregate } : {})), { field });\n}\nexport function isSortableFieldDef(fieldDef) {\n    return 'sort' in fieldDef;\n}\nexport function getBand({ channel, fieldDef, fieldDef2, markDef: mark, stack, config, isMidPoint }) {\n    if (isFieldOrDatumDef(fieldDef) && fieldDef.band !== undefined) {\n        return fieldDef.band;\n    }\n    if (isFieldDef(fieldDef)) {\n        const { timeUnit, bin } = fieldDef;\n        if (timeUnit && !fieldDef2) {\n            if (isMidPoint) {\n                return getMarkConfig('timeUnitBandPosition', mark, config);\n            }\n            else {\n                return isRectBasedMark(mark.type) ? getMarkConfig('timeUnitBand', mark, config) : 0;\n            }\n        }\n        else if (isBinning(bin)) {\n            return isRectBasedMark(mark.type) && !isMidPoint ? 1 : 0.5;\n        }\n    }\n    if ((stack === null || stack === void 0 ? void 0 : stack.fieldChannel) === channel && isMidPoint) {\n        return 0.5;\n    }\n    return undefined;\n}\nexport function hasBand(channel, fieldDef, fieldDef2, stack, markDef, config) {\n    if (isBinning(fieldDef.bin) || (fieldDef.timeUnit && isTypedFieldDef(fieldDef) && fieldDef.type === 'temporal')) {\n        return !!getBand({ channel, fieldDef, fieldDef2, stack, markDef, config });\n    }\n    return false;\n}\nexport function isConditionalDef(channelDef) {\n    return !!channelDef && 'condition' in channelDef;\n}\n/**\n * Return if a channelDef is a ConditionalValueDef with ConditionFieldDef\n */\nexport function hasConditionalFieldDef(channelDef) {\n    const condition = channelDef && channelDef['condition'];\n    return !!condition && !isArray(condition) && isFieldDef(condition);\n}\nexport function hasConditionalFieldOrDatumDef(channelDef) {\n    const condition = channelDef && channelDef['condition'];\n    return !!condition && !isArray(condition) && isFieldOrDatumDef(condition);\n}\nexport function hasConditionalValueDef(channelDef) {\n    const condition = channelDef && channelDef['condition'];\n    return !!condition && (isArray(condition) || isValueDef(condition));\n}\nexport function isFieldDef(channelDef) {\n    // TODO: we can't use field in channelDef here as it's somehow failing runtime test\n    return !!channelDef && (!!channelDef['field'] || channelDef['aggregate'] === 'count');\n}\nexport function channelDefType(channelDef) {\n    return channelDef && channelDef['type'];\n}\nexport function isDatumDef(channelDef) {\n    return !!channelDef && 'datum' in channelDef;\n}\nexport function isContinuousFieldOrDatumDef(cd) {\n    // TODO: make datum support DateTime object\n    return (isTypedFieldDef(cd) && isContinuous(cd)) || isNumericDataDef(cd);\n}\nexport function isQuantitativeFieldOrDatumDef(cd) {\n    // TODO: make datum support DateTime object\n    return channelDefType(cd) === 'quantitative' || isNumericDataDef(cd);\n}\nexport function isNumericDataDef(cd) {\n    return isDatumDef(cd) && isNumber(cd.datum);\n}\nexport function isFieldOrDatumDef(channelDef) {\n    return isFieldDef(channelDef) || isDatumDef(channelDef);\n}\nexport function isTypedFieldDef(channelDef) {\n    return !!channelDef && ('field' in channelDef || channelDef['aggregate'] === 'count') && 'type' in channelDef;\n}\nexport function isValueDef(channelDef) {\n    return channelDef && 'value' in channelDef && 'value' in channelDef;\n}\nexport function isScaleFieldDef(channelDef) {\n    return !!channelDef && ('scale' in channelDef || 'sort' in channelDef);\n}\nexport function isPositionFieldOrDatumDef(channelDef) {\n    return channelDef && ('axis' in channelDef || 'stack' in channelDef || 'impute' in channelDef);\n}\nexport function isMarkPropFieldOrDatumDef(channelDef) {\n    return !!channelDef && 'legend' in channelDef;\n}\nexport function isStringFieldOrDatumDef(channelDef) {\n    return !!channelDef && ('format' in channelDef || 'formatType' in channelDef);\n}\nexport function toStringFieldDef(fieldDef) {\n    // omit properties that don't exist in string field defs\n    return omit(fieldDef, ['legend', 'axis', 'header', 'scale']);\n}\nfunction isOpFieldDef(fieldDef) {\n    return 'op' in fieldDef;\n}\n/**\n * Get a Vega field reference from a Vega-Lite field def.\n */\nexport function vgField(fieldDef, opt = {}) {\n    var _a, _b, _c;\n    let field = fieldDef.field;\n    const prefix = opt.prefix;\n    let suffix = opt.suffix;\n    let argAccessor = ''; // for accessing argmin/argmax field at the end without getting escaped\n    if (isCount(fieldDef)) {\n        field = internalField('count');\n    }\n    else {\n        let fn;\n        if (!opt.nofn) {\n            if (isOpFieldDef(fieldDef)) {\n                fn = fieldDef.op;\n            }\n            else {\n                const { bin, aggregate, timeUnit } = fieldDef;\n                if (isBinning(bin)) {\n                    fn = binToString(bin);\n                    suffix = ((_a = opt.binSuffix) !== null && _a !== void 0 ? _a : '') + ((_b = opt.suffix) !== null && _b !== void 0 ? _b : '');\n                }\n                else if (aggregate) {\n                    if (isArgmaxDef(aggregate)) {\n                        argAccessor = `[\"${field}\"]`;\n                        field = `argmax_${aggregate.argmax}`;\n                    }\n                    else if (isArgminDef(aggregate)) {\n                        argAccessor = `[\"${field}\"]`;\n                        field = `argmin_${aggregate.argmin}`;\n                    }\n                    else {\n                        fn = String(aggregate);\n                    }\n                }\n                else if (timeUnit) {\n                    fn = timeUnitToString(timeUnit);\n                    suffix = ((!contains(['range', 'mid'], opt.binSuffix) && opt.binSuffix) || '') + ((_c = opt.suffix) !== null && _c !== void 0 ? _c : '');\n                }\n            }\n        }\n        if (fn) {\n            field = field ? `${fn}_${field}` : fn;\n        }\n    }\n    if (suffix) {\n        field = `${field}_${suffix}`;\n    }\n    if (prefix) {\n        field = `${prefix}_${field}`;\n    }\n    if (opt.forAs) {\n        return removePathFromField(field);\n    }\n    else if (opt.expr) {\n        // Expression to access flattened field. No need to escape dots.\n        return flatAccessWithDatum(field, opt.expr) + argAccessor;\n    }\n    else {\n        // We flattened all fields so paths should have become dot.\n        return replacePathInField(field) + argAccessor;\n    }\n}\nexport function isDiscrete(def) {\n    switch (def.type) {\n        case 'nominal':\n        case 'ordinal':\n        case 'geojson':\n            return true;\n        case 'quantitative':\n            return isFieldDef(def) && !!def.bin;\n        case 'temporal':\n            return false;\n    }\n    throw new Error(log.message.invalidFieldType(def.type));\n}\nexport function isContinuous(fieldDef) {\n    return !isDiscrete(fieldDef);\n}\nexport function isCount(fieldDef) {\n    return fieldDef.aggregate === 'count';\n}\nexport function verbalTitleFormatter(fieldDef, config) {\n    var _a;\n    const { field, bin, timeUnit, aggregate } = fieldDef;\n    if (aggregate === 'count') {\n        return config.countTitle;\n    }\n    else if (isBinning(bin)) {\n        return `${field} (binned)`;\n    }\n    else if (timeUnit) {\n        const unit = (_a = normalizeTimeUnit(timeUnit)) === null || _a === void 0 ? void 0 : _a.unit;\n        if (unit) {\n            return `${field} (${getTimeUnitParts(unit).join('-')})`;\n        }\n    }\n    else if (aggregate) {\n        if (isArgmaxDef(aggregate)) {\n            return `${field} for max ${aggregate.argmax}`;\n        }\n        else if (isArgminDef(aggregate)) {\n            return `${field} for min ${aggregate.argmin}`;\n        }\n        else {\n            return `${titleCase(aggregate)} of ${field}`;\n        }\n    }\n    return field;\n}\nexport function functionalTitleFormatter(fieldDef) {\n    const { aggregate, bin, timeUnit, field } = fieldDef;\n    if (isArgmaxDef(aggregate)) {\n        return `${field} for argmax(${aggregate.argmax})`;\n    }\n    else if (isArgminDef(aggregate)) {\n        return `${field} for argmin(${aggregate.argmin})`;\n    }\n    const timeUnitParams = normalizeTimeUnit(timeUnit);\n    const fn = aggregate || (timeUnitParams === null || timeUnitParams === void 0 ? void 0 : timeUnitParams.unit) || ((timeUnitParams === null || timeUnitParams === void 0 ? void 0 : timeUnitParams.maxbins) && 'timeunit') || (isBinning(bin) && 'bin');\n    if (fn) {\n        return fn.toUpperCase() + '(' + field + ')';\n    }\n    else {\n        return field;\n    }\n}\nexport const defaultTitleFormatter = (fieldDef, config) => {\n    switch (config.fieldTitle) {\n        case 'plain':\n            return fieldDef.field;\n        case 'functional':\n            return functionalTitleFormatter(fieldDef);\n        default:\n            return verbalTitleFormatter(fieldDef, config);\n    }\n};\nlet titleFormatter = defaultTitleFormatter;\nexport function setTitleFormatter(formatter) {\n    titleFormatter = formatter;\n}\nexport function resetTitleFormatter() {\n    setTitleFormatter(defaultTitleFormatter);\n}\nexport function title(fieldOrDatumDef, config, { allowDisabling, includeDefault = true }) {\n    var _a, _b;\n    const guideTitle = (_a = getGuide(fieldOrDatumDef)) === null || _a === void 0 ? void 0 : _a.title;\n    if (!isFieldDef(fieldOrDatumDef)) {\n        return guideTitle;\n    }\n    const fieldDef = fieldOrDatumDef;\n    const def = includeDefault ? defaultTitle(fieldDef, config) : undefined;\n    if (allowDisabling) {\n        return getFirstDefined(guideTitle, fieldDef.title, def);\n    }\n    else {\n        return (_b = guideTitle !== null && guideTitle !== void 0 ? guideTitle : fieldDef.title) !== null && _b !== void 0 ? _b : def;\n    }\n}\nexport function getGuide(fieldDef) {\n    if (isPositionFieldOrDatumDef(fieldDef) && fieldDef.axis) {\n        return fieldDef.axis;\n    }\n    else if (isMarkPropFieldOrDatumDef(fieldDef) && fieldDef.legend) {\n        return fieldDef.legend;\n    }\n    else if (isFacetFieldDef(fieldDef) && fieldDef.header) {\n        return fieldDef.header;\n    }\n    return undefined;\n}\nexport function defaultTitle(fieldDef, config) {\n    return titleFormatter(fieldDef, config);\n}\nexport function getFormatMixins(fieldDef) {\n    var _a;\n    if (isStringFieldOrDatumDef(fieldDef)) {\n        const { format, formatType } = fieldDef;\n        return { format, formatType };\n    }\n    else {\n        const guide = (_a = getGuide(fieldDef)) !== null && _a !== void 0 ? _a : {};\n        const { format, formatType } = guide;\n        return { format, formatType };\n    }\n}\nexport function defaultType(fieldDef, channel) {\n    var _a;\n    switch (channel) {\n        case 'latitude':\n        case 'longitude':\n            return 'quantitative';\n        case 'row':\n        case 'column':\n        case 'facet':\n        case 'shape':\n        case 'strokeDash':\n            return 'nominal';\n        case 'order':\n            return 'ordinal';\n    }\n    if (isSortableFieldDef(fieldDef) && isArray(fieldDef.sort)) {\n        return 'ordinal';\n    }\n    const { aggregate, bin, timeUnit } = fieldDef;\n    if (timeUnit) {\n        return 'temporal';\n    }\n    if (bin || (aggregate && !isArgmaxDef(aggregate) && !isArgminDef(aggregate))) {\n        return 'quantitative';\n    }\n    if (isScaleFieldDef(fieldDef) && ((_a = fieldDef.scale) === null || _a === void 0 ? void 0 : _a.type)) {\n        switch (SCALE_CATEGORY_INDEX[fieldDef.scale.type]) {\n            case 'numeric':\n            case 'discretizing':\n                return 'quantitative';\n            case 'time':\n                return 'temporal';\n        }\n    }\n    return 'nominal';\n}\n/**\n * Returns the fieldDef -- either from the outer channelDef or from the condition of channelDef.\n * @param channelDef\n */\nexport function getFieldDef(channelDef) {\n    if (isFieldDef(channelDef)) {\n        return channelDef;\n    }\n    else if (hasConditionalFieldDef(channelDef)) {\n        return channelDef.condition;\n    }\n    return undefined;\n}\nexport function getFieldOrDatumDef(channelDef) {\n    if (isFieldOrDatumDef(channelDef)) {\n        return channelDef;\n    }\n    else if (hasConditionalFieldOrDatumDef(channelDef)) {\n        return channelDef.condition;\n    }\n    return undefined;\n}\n/**\n * Convert type to full, lowercase type, or augment the fieldDef with a default type if missing.\n */\nexport function initChannelDef(channelDef, channel, config, opt = {}) {\n    if (isString(channelDef) || isNumber(channelDef) || isBoolean(channelDef)) {\n        const primitiveType = isString(channelDef) ? 'string' : isNumber(channelDef) ? 'number' : 'boolean';\n        log.warn(log.message.primitiveChannelDef(channel, primitiveType, channelDef));\n        return { value: channelDef };\n    }\n    // If a fieldDef contains a field, we need type.\n    if (isFieldOrDatumDef(channelDef)) {\n        return initFieldOrDatumDef(channelDef, channel, config, opt);\n    }\n    else if (hasConditionalFieldOrDatumDef(channelDef)) {\n        return Object.assign(Object.assign({}, channelDef), { \n            // Need to cast as normalizeFieldDef normally return FieldDef, but here we know that it is definitely Condition<FieldDef>\n            condition: initFieldOrDatumDef(channelDef.condition, channel, config, opt) });\n    }\n    return channelDef;\n}\nexport function initFieldOrDatumDef(fd, channel, config, opt) {\n    if (isStringFieldOrDatumDef(fd)) {\n        const { format, formatType } = fd, rest = __rest(fd, [\"format\", \"formatType\"]);\n        if (isCustomFormatType(formatType) && !config.customFormatTypes) {\n            log.warn(log.message.customFormatTypeNotAllowed(channel));\n            return initFieldOrDatumDef(rest, channel, config, opt);\n        }\n    }\n    else {\n        const guideType = isPositionFieldOrDatumDef(fd)\n            ? 'axis'\n            : isMarkPropFieldOrDatumDef(fd)\n                ? 'legend'\n                : isFacetFieldDef(fd)\n                    ? 'header'\n                    : null;\n        if (guideType && fd[guideType]) {\n            const _a = fd[guideType], { format, formatType } = _a, newGuide = __rest(_a, [\"format\", \"formatType\"]);\n            if (isCustomFormatType(formatType) && !config.customFormatTypes) {\n                log.warn(log.message.customFormatTypeNotAllowed(channel));\n                return initFieldOrDatumDef(Object.assign(Object.assign({}, fd), { [guideType]: newGuide }), channel, config, opt);\n            }\n        }\n    }\n    if (isFieldDef(fd)) {\n        return initFieldDef(fd, channel, opt);\n    }\n    return initDatumDef(fd);\n}\nfunction initDatumDef(datumDef) {\n    let type = datumDef['type'];\n    if (type) {\n        return datumDef;\n    }\n    const { datum } = datumDef;\n    type = isNumber(datum) ? 'quantitative' : isString(datum) ? 'nominal' : isDateTime(datum) ? 'temporal' : undefined;\n    return Object.assign(Object.assign({}, datumDef), { type });\n}\nexport function initFieldDef(fd, channel, { compositeMark = false } = {}) {\n    const { aggregate, timeUnit, bin, field } = fd;\n    const fieldDef = Object.assign({}, fd);\n    // Drop invalid aggregate\n    if (!compositeMark && aggregate && !isAggregateOp(aggregate) && !isArgmaxDef(aggregate) && !isArgminDef(aggregate)) {\n        log.warn(log.message.invalidAggregate(aggregate));\n        delete fieldDef.aggregate;\n    }\n    // Normalize Time Unit\n    if (timeUnit) {\n        fieldDef.timeUnit = normalizeTimeUnit(timeUnit);\n    }\n    if (field) {\n        fieldDef.field = `${field}`;\n    }\n    // Normalize bin\n    if (isBinning(bin)) {\n        fieldDef.bin = normalizeBin(bin, channel);\n    }\n    if (isBinned(bin) && !isXorY(channel)) {\n        log.warn(log.message.channelShouldNotBeUsedForBinned(channel));\n    }\n    // Normalize Type\n    if (isTypedFieldDef(fieldDef)) {\n        const { type } = fieldDef;\n        const fullType = getFullName(type);\n        if (type !== fullType) {\n            // convert short type to full type\n            fieldDef.type = fullType;\n        }\n        if (type !== 'quantitative') {\n            if (isCountingAggregateOp(aggregate)) {\n                log.warn(log.message.invalidFieldTypeForCountAggregate(type, aggregate));\n                fieldDef.type = 'quantitative';\n            }\n        }\n    }\n    else if (!isSecondaryRangeChannel(channel)) {\n        // If type is empty / invalid, then augment with default type\n        const newType = defaultType(fieldDef, channel);\n        fieldDef['type'] = newType;\n    }\n    if (isTypedFieldDef(fieldDef)) {\n        const { compatible, warning } = channelCompatibility(fieldDef, channel) || {};\n        if (compatible === false) {\n            log.warn(warning);\n        }\n    }\n    if (isSortableFieldDef(fieldDef) && isString(fieldDef.sort)) {\n        const { sort } = fieldDef;\n        if (isSortByChannel(sort)) {\n            return Object.assign(Object.assign({}, fieldDef), { sort: { encoding: sort } });\n        }\n        const sub = sort.substr(1);\n        if (sort.charAt(0) === '-' && isSortByChannel(sub)) {\n            return Object.assign(Object.assign({}, fieldDef), { sort: { encoding: sub, order: 'descending' } });\n        }\n    }\n    if (isFacetFieldDef(fieldDef)) {\n        const { header } = fieldDef;\n        const { orient } = header, rest = __rest(header, [\"orient\"]);\n        if (orient) {\n            return Object.assign(Object.assign({}, fieldDef), { header: Object.assign(Object.assign({}, rest), { labelOrient: header.labelOrient || orient, titleOrient: header.titleOrient || orient }) });\n        }\n    }\n    return fieldDef;\n}\nexport function normalizeBin(bin, channel) {\n    if (isBoolean(bin)) {\n        return { maxbins: autoMaxBins(channel) };\n    }\n    else if (bin === 'binned') {\n        return {\n            binned: true\n        };\n    }\n    else if (!bin.maxbins && !bin.step) {\n        return Object.assign(Object.assign({}, bin), { maxbins: autoMaxBins(channel) });\n    }\n    else {\n        return bin;\n    }\n}\nconst COMPATIBLE = { compatible: true };\nexport function channelCompatibility(fieldDef, channel) {\n    const type = fieldDef.type;\n    if (type === 'geojson' && channel !== 'shape') {\n        return {\n            compatible: false,\n            warning: `Channel ${channel} should not be used with a geojson data.`\n        };\n    }\n    switch (channel) {\n        case ROW:\n        case COLUMN:\n        case FACET:\n            if (isContinuous(fieldDef)) {\n                return {\n                    compatible: false,\n                    warning: log.message.facetChannelShouldBeDiscrete(channel)\n                };\n            }\n            return COMPATIBLE;\n        case X:\n        case Y:\n        case COLOR:\n        case FILL:\n        case STROKE:\n        case TEXT:\n        case DETAIL:\n        case KEY:\n        case TOOLTIP:\n        case HREF:\n        case URL:\n        case ANGLE:\n        case THETA:\n        case RADIUS:\n        case DESCRIPTION:\n            return COMPATIBLE;\n        case LONGITUDE:\n        case LONGITUDE2:\n        case LATITUDE:\n        case LATITUDE2:\n            if (type !== QUANTITATIVE) {\n                return {\n                    compatible: false,\n                    warning: `Channel ${channel} should be used with a quantitative field only, not ${fieldDef.type} field.`\n                };\n            }\n            return COMPATIBLE;\n        case OPACITY:\n        case FILLOPACITY:\n        case STROKEOPACITY:\n        case STROKEWIDTH:\n        case SIZE:\n        case THETA2:\n        case RADIUS2:\n        case X2:\n        case Y2:\n            if (type === 'nominal' && !fieldDef['sort']) {\n                return {\n                    compatible: false,\n                    warning: `Channel ${channel} should not be used with an unsorted discrete field.`\n                };\n            }\n            return COMPATIBLE;\n        case STROKEDASH:\n            if (!contains(['ordinal', 'nominal'], fieldDef.type)) {\n                return {\n                    compatible: false,\n                    warning: 'StrokeDash channel should be used with only discrete data.'\n                };\n            }\n            return COMPATIBLE;\n        case SHAPE:\n            if (!contains(['ordinal', 'nominal', 'geojson'], fieldDef.type)) {\n                return {\n                    compatible: false,\n                    warning: 'Shape channel should be used with only either discrete or geojson data.'\n                };\n            }\n            return COMPATIBLE;\n        case ORDER:\n            if (fieldDef.type === 'nominal' && !('sort' in fieldDef)) {\n                return {\n                    compatible: false,\n                    warning: `Channel order is inappropriate for nominal field, which has no inherent order.`\n                };\n            }\n            return COMPATIBLE;\n    }\n}\n/**\n * Check if the field def uses a time format or does not use any format but is temporal\n * (this does not cover field defs that are temporal but use a number format).\n */\nexport function isFieldOrDatumDefForTimeFormat(fieldOrDatumDef) {\n    const { formatType } = getFormatMixins(fieldOrDatumDef);\n    return formatType === 'time' || (!formatType && isTimeFieldDef(fieldOrDatumDef));\n}\n/**\n * Check if field def has type `temporal`. If you want to also cover field defs that use a time format, use `isTimeFormatFieldDef`.\n */\nexport function isTimeFieldDef(def) {\n    return def && (def['type'] === 'temporal' || (isFieldDef(def) && !!def.timeUnit));\n}\n/**\n * Getting a value associated with a fielddef.\n * Convert the value to Vega expression if applicable (for datetime object, or string if the field def is temporal or has timeUnit)\n */\nexport function valueExpr(v, { timeUnit, type, wrapTime, undefinedIfExprNotRequired }) {\n    var _a;\n    const unit = timeUnit && ((_a = normalizeTimeUnit(timeUnit)) === null || _a === void 0 ? void 0 : _a.unit);\n    let isTime = unit || type === 'temporal';\n    let expr;\n    if (isExprRef(v)) {\n        expr = v.expr;\n    }\n    else if (isSignalRef(v)) {\n        expr = v.signal;\n    }\n    else if (isDateTime(v)) {\n        isTime = true;\n        expr = dateTimeToExpr(v);\n    }\n    else if (isString(v) || isNumber(v)) {\n        if (isTime) {\n            expr = `datetime(${JSON.stringify(v)})`;\n            if (isLocalSingleTimeUnit(unit)) {\n                // for single timeUnit, we will use dateTimeToExpr to convert number/string to match the timeUnit\n                if ((isNumber(v) && v < 10000) || (isString(v) && isNaN(Date.parse(v)))) {\n                    expr = dateTimeToExpr({ [unit]: v });\n                }\n            }\n        }\n    }\n    if (expr) {\n        return wrapTime && isTime ? `time(${expr})` : expr;\n    }\n    // number or boolean or normal string\n    return undefinedIfExprNotRequired ? undefined : JSON.stringify(v);\n}\n/**\n * Standardize value array -- convert each value to Vega expression if applicable\n */\nexport function valueArray(fieldOrDatumDef, values) {\n    const { type } = fieldOrDatumDef;\n    return values.map(v => {\n        const expr = valueExpr(v, {\n            timeUnit: isFieldDef(fieldOrDatumDef) ? fieldOrDatumDef.timeUnit : undefined,\n            type,\n            undefinedIfExprNotRequired: true\n        });\n        // return signal for the expression if we need an expression\n        if (expr !== undefined) {\n            return { signal: expr };\n        }\n        // otherwise just return the original value\n        return v;\n    });\n}\n/**\n * Checks whether a fieldDef for a particular channel requires a computed bin range.\n */\nexport function binRequiresRange(fieldDef, channel) {\n    if (!isBinning(fieldDef.bin)) {\n        console.warn('Only call this method for binned field defs.');\n        return false;\n    }\n    // We need the range only when the user explicitly forces a binned field to be use discrete scale. In this case, bin range is used in axis and legend labels.\n    // We could check whether the axis or legend exists (not disabled) but that seems overkill.\n    return isScaleChannel(channel) && contains(['ordinal', 'nominal'], fieldDef.type);\n}\n//# sourceMappingURL=channeldef.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { array, isArray } from 'vega-util';\nimport { AXIS_PARTS, AXIS_PROPERTY_TYPE, CONDITIONAL_AXIS_PROP_INDEX, isConditionalAxisValue } from '../../axis';\nimport { POSITION_SCALE_CHANNELS } from '../../channel';\nimport { defaultTitle } from '../../channeldef';\nimport { isText } from '../../title';\nimport { getFirstDefined, isEmpty, replaceAll } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { exprFromValueOrSignalRef } from '../common';\nimport { expression } from '../predicate';\nfunction assembleTitle(title, config) {\n    if (!title) {\n        return undefined;\n    }\n    if (isArray(title) && !isText(title)) {\n        return title.map(fieldDef => defaultTitle(fieldDef, config)).join(', ');\n    }\n    return title;\n}\nfunction setAxisEncode(axis, part, vgProp, vgRef) {\n    var _a, _b, _c;\n    axis.encode = (_a = axis.encode) !== null && _a !== void 0 ? _a : {};\n    axis.encode[part] = (_b = axis.encode[part]) !== null && _b !== void 0 ? _b : {};\n    axis.encode[part].update = (_c = axis.encode[part].update) !== null && _c !== void 0 ? _c : {};\n    // TODO: remove as any after https://github.com/prisma/nexus-prisma/issues/291\n    axis.encode[part].update[vgProp] = vgRef;\n}\nexport function assembleAxis(axisCmpt, kind, config, opt = { header: false }) {\n    var _a, _b;\n    const _c = axisCmpt.combine(), { disable, orient, scale, labelExpr, title, zindex } = _c, axis = __rest(_c, [\"disable\", \"orient\", \"scale\", \"labelExpr\", \"title\", \"zindex\"]);\n    if (disable) {\n        return undefined;\n    }\n    for (const prop in axis) {\n        const propType = AXIS_PROPERTY_TYPE[prop];\n        const propValue = axis[prop];\n        if (propType && propType !== kind && propType !== 'both') {\n            // Remove properties that are not valid for this kind of axis\n            delete axis[prop];\n        }\n        else if (isConditionalAxisValue(propValue)) {\n            // deal with conditional axis value\n            const { condition } = propValue, valueOrSignalRef = __rest(propValue, [\"condition\"]);\n            const conditions = array(condition);\n            const propIndex = CONDITIONAL_AXIS_PROP_INDEX[prop];\n            if (propIndex) {\n                const { vgProp, part } = propIndex;\n                // If there is a corresponding Vega property for the channel,\n                // use Vega's custom axis encoding and delete the original axis property to avoid conflicts\n                const vgRef = [\n                    ...conditions.map(c => {\n                        const { test } = c, valueOrSignalCRef = __rest(c, [\"test\"]);\n                        return Object.assign({ test: expression(null, test) }, valueOrSignalCRef);\n                    }),\n                    valueOrSignalRef\n                ];\n                setAxisEncode(axis, part, vgProp, vgRef);\n                delete axis[prop];\n            }\n            else if (propIndex === null) {\n                // If propIndex is null, this means we support conditional axis property by converting the condition to signal instead.\n                const signalRef = {\n                    signal: conditions\n                        .map(c => {\n                        const { test } = c, valueOrSignalCRef = __rest(c, [\"test\"]);\n                        return `${expression(null, test)} ? ${exprFromValueOrSignalRef(valueOrSignalCRef)} : `;\n                    })\n                        .join('') + exprFromValueOrSignalRef(valueOrSignalRef)\n                };\n                axis[prop] = signalRef;\n            }\n        }\n        else if (isSignalRef(propValue)) {\n            const propIndex = CONDITIONAL_AXIS_PROP_INDEX[prop];\n            if (propIndex) {\n                const { vgProp, part } = propIndex;\n                setAxisEncode(axis, part, vgProp, propValue);\n                delete axis[prop];\n            } // else do nothing since the property already supports signal\n        }\n    }\n    if (kind === 'grid') {\n        if (!axis.grid) {\n            return undefined;\n        }\n        // Remove unnecessary encode block\n        if (axis.encode) {\n            // Only need to keep encode block for grid\n            const { grid } = axis.encode;\n            axis.encode = Object.assign({}, (grid ? { grid } : {}));\n            if (isEmpty(axis.encode)) {\n                delete axis.encode;\n            }\n        }\n        return Object.assign(Object.assign({ scale,\n            orient }, axis), { domain: false, labels: false, aria: false, \n            // Always set min/maxExtent to 0 to ensure that `config.axis*.minExtent` and `config.axis*.maxExtent`\n            // would not affect gridAxis\n            maxExtent: 0, minExtent: 0, ticks: false, zindex: getFirstDefined(zindex, 0) // put grid behind marks by default\n         });\n    }\n    else {\n        // kind === 'main'\n        if (!opt.header && axisCmpt.mainExtracted) {\n            // if mainExtracted has been extracted to a separate facet\n            return undefined;\n        }\n        if (labelExpr !== undefined) {\n            let expr = labelExpr;\n            if (((_b = (_a = axis.encode) === null || _a === void 0 ? void 0 : _a.labels) === null || _b === void 0 ? void 0 : _b.update) && isSignalRef(axis.encode.labels.update.text)) {\n                expr = replaceAll(labelExpr, 'datum.label', axis.encode.labels.update.text.signal);\n            }\n            setAxisEncode(axis, 'labels', 'text', { signal: expr });\n        }\n        if (axis.labelAlign === null) {\n            delete axis.labelAlign;\n        }\n        // Remove unnecessary encode block\n        if (axis.encode) {\n            for (const part of AXIS_PARTS) {\n                if (!axisCmpt.hasAxisPart(part)) {\n                    delete axis.encode[part];\n                }\n            }\n            if (isEmpty(axis.encode)) {\n                delete axis.encode;\n            }\n        }\n        const titleString = assembleTitle(title, config);\n        return Object.assign(Object.assign(Object.assign(Object.assign({ scale,\n            orient, grid: false }, (titleString ? { title: titleString } : {})), axis), (config.aria === false ? { aria: false } : {})), { zindex: getFirstDefined(zindex, 0) // put axis line above marks by default\n         });\n    }\n}\n/**\n * Add axis signals so grid line works correctly\n * (Fix https://github.com/vega/vega-lite/issues/4226)\n */\nexport function assembleAxisSignals(model) {\n    const { axes } = model.component;\n    const signals = [];\n    for (const channel of POSITION_SCALE_CHANNELS) {\n        if (axes[channel]) {\n            for (const axis of axes[channel]) {\n                if (!axis.get('disable') && !axis.get('gridScale')) {\n                    // If there is x-axis but no y-scale for gridScale, need to set height/width so x-axis can draw the grid with the right height. Same for y-axis and width.\n                    const sizeType = channel === 'x' ? 'height' : 'width';\n                    const update = model.getSizeSignalRef(sizeType).signal;\n                    if (sizeType !== update) {\n                        signals.push({\n                            name: sizeType,\n                            update: update\n                        });\n                    }\n                }\n            }\n        }\n    }\n    return signals;\n}\nexport function assembleAxes(axisComponents, config) {\n    const { x = [], y = [] } = axisComponents;\n    return [\n        ...x.map(a => assembleAxis(a, 'grid', config)),\n        ...y.map(a => assembleAxis(a, 'grid', config)),\n        ...x.map(a => assembleAxis(a, 'main', config)),\n        ...y.map(a => assembleAxis(a, 'main', config))\n    ].filter(a => a); // filter undefined\n}\n//# sourceMappingURL=assemble.js.map","import { COMMON_AXIS_PROPERTIES_INDEX } from '../../axis';\nimport { duplicate, keys } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { Split } from '../split';\nfunction isFalseOrNull(v) {\n    return v === false || v === null;\n}\nconst AXIS_COMPONENT_PROPERTIES_INDEX = Object.assign(Object.assign({ disable: 1, gridScale: 1, scale: 1 }, COMMON_AXIS_PROPERTIES_INDEX), { labelExpr: 1, encode: 1 });\nexport const AXIS_COMPONENT_PROPERTIES = keys(AXIS_COMPONENT_PROPERTIES_INDEX);\nexport class AxisComponent extends Split {\n    constructor(explicit = {}, implicit = {}, mainExtracted = false) {\n        super();\n        this.explicit = explicit;\n        this.implicit = implicit;\n        this.mainExtracted = mainExtracted;\n    }\n    clone() {\n        return new AxisComponent(duplicate(this.explicit), duplicate(this.implicit), this.mainExtracted);\n    }\n    hasAxisPart(part) {\n        // FIXME(https://github.com/vega/vega-lite/issues/2552) this method can be wrong if users use a Vega theme.\n        if (part === 'axis') {\n            // always has the axis container part\n            return true;\n        }\n        if (part === 'grid' || part === 'title') {\n            return !!this.get(part);\n        }\n        // Other parts are enabled by default, so they should not be false or null.\n        return !isFalseOrNull(this.get(part));\n    }\n    hasOrientSignalRef() {\n        return isSignalRef(this.explicit.orient);\n    }\n}\n//# sourceMappingURL=component.js.map","import { array } from 'vega-util';\nimport { isQuantitative } from '../../scale';\nimport { keys, titleCase } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { getStyleConfig, signalOrStringValue } from '../common';\nfunction getAxisConfigFromConfigTypes(configTypes, config, channel, orient) {\n    // TODO: add special casing to add conditional value based on orient signal\n    return Object.assign.apply(null, [\n        {},\n        ...configTypes.map(configType => {\n            if (configType === 'axisOrient') {\n                const orient1 = channel === 'x' ? 'bottom' : 'left';\n                const orientConfig1 = config[channel === 'x' ? 'axisBottom' : 'axisLeft'] || {};\n                const orientConfig2 = config[channel === 'x' ? 'axisTop' : 'axisRight'] || {};\n                const props = new Set([...keys(orientConfig1), ...keys(orientConfig2)]);\n                const conditionalOrientAxisConfig = {};\n                for (const prop of props.values()) {\n                    conditionalOrientAxisConfig[prop] = {\n                        // orient is surely signal in this case\n                        signal: `${orient['signal']} === \"${orient1}\" ? ${signalOrStringValue(orientConfig1[prop])} : ${signalOrStringValue(orientConfig2[prop])}`\n                    };\n                }\n                return conditionalOrientAxisConfig;\n            }\n            return config[configType];\n        })\n    ]);\n}\nexport function getAxisConfigs(channel, scaleType, orient, config) {\n    const typeBasedConfigTypes = scaleType === 'band'\n        ? ['axisDiscrete', 'axisBand']\n        : scaleType === 'point'\n            ? ['axisDiscrete', 'axisPoint']\n            : isQuantitative(scaleType)\n                ? ['axisQuantitative']\n                : scaleType === 'time' || scaleType === 'utc'\n                    ? ['axisTemporal']\n                    : [];\n    const axisChannel = channel === 'x' ? 'axisX' : 'axisY';\n    const axisOrient = isSignalRef(orient) ? 'axisOrient' : 'axis' + titleCase(orient); // axisTop, axisBottom, ...\n    const vlOnlyConfigTypes = [\n        // technically Vega does have axisBand, but if we make another separation here,\n        // it will further introduce complexity in the code\n        ...typeBasedConfigTypes,\n        ...typeBasedConfigTypes.map(c => axisChannel + c.substr(4))\n    ];\n    const vgConfigTypes = ['axis', axisOrient, axisChannel];\n    return {\n        vlOnlyAxisConfig: getAxisConfigFromConfigTypes(vlOnlyConfigTypes, config, channel, orient),\n        vgAxisConfig: getAxisConfigFromConfigTypes(vgConfigTypes, config, channel, orient),\n        axisConfigStyle: getAxisConfigStyle([...vgConfigTypes, ...vlOnlyConfigTypes], config)\n    };\n}\nexport function getAxisConfigStyle(axisConfigTypes, config) {\n    var _a;\n    const toMerge = [{}];\n    for (const configType of axisConfigTypes) {\n        // TODO: add special casing to add conditional value based on orient signal\n        let style = (_a = config[configType]) === null || _a === void 0 ? void 0 : _a.style;\n        if (style) {\n            style = array(style);\n            for (const s of style) {\n                toMerge.push(config.style[s]);\n            }\n        }\n    }\n    return Object.assign.apply(null, toMerge);\n}\nexport function getAxisConfig(property, styleConfigIndex, style, axisConfigs = {}) {\n    var _a;\n    const styleConfig = getStyleConfig(property, style, styleConfigIndex);\n    if (styleConfig !== undefined) {\n        return {\n            configFrom: 'style',\n            configValue: styleConfig\n        };\n    }\n    for (const configFrom of ['vlOnlyAxisConfig', 'vgAxisConfig', 'axisConfigStyle']) {\n        if (((_a = axisConfigs[configFrom]) === null || _a === void 0 ? void 0 : _a[property]) !== undefined) {\n            return { configFrom, configValue: axisConfigs[configFrom][property] };\n        }\n    }\n    return {};\n}\n//# sourceMappingURL=config.js.map","import { getSecondaryRangeChannel } from '../../channel';\nimport { getFieldOrDatumDef } from '../../channeldef';\nimport { formatCustomType, isCustomFormatType } from '../format';\nexport function labels(model, channel, specifiedLabelsSpec) {\n    var _a;\n    const { encoding, config } = model;\n    const fieldOrDatumDef = (_a = getFieldOrDatumDef(encoding[channel])) !== null && _a !== void 0 ? _a : getFieldOrDatumDef(encoding[getSecondaryRangeChannel(channel)]);\n    const axis = model.axis(channel) || {};\n    const { format, formatType } = axis;\n    if (isCustomFormatType(formatType)) {\n        return Object.assign({ text: formatCustomType({\n                fieldOrDatumDef,\n                field: 'datum.value',\n                format,\n                formatType,\n                config\n            }) }, specifiedLabelsSpec);\n    }\n    return specifiedLabelsSpec;\n}\n//# sourceMappingURL=encode.js.map","import { AXIS_PARTS, isAxisProperty, isConditionalAxisValue } from '../../axis';\nimport { POSITION_SCALE_CHANNELS } from '../../channel';\nimport { getFieldOrDatumDef } from '../../channeldef';\nimport { getFirstDefined, isEmpty, keys, normalizeAngle } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { mergeTitleComponent } from '../common';\nimport { guideEncodeEntry } from '../guide';\nimport { parseGuideResolve } from '../resolve';\nimport { defaultTieBreaker, mergeValuesWithExplicit } from '../split';\nimport { AxisComponent, AXIS_COMPONENT_PROPERTIES } from './component';\nimport { getAxisConfig, getAxisConfigs } from './config';\nimport * as encode from './encode';\nimport { axisRules, defaultOrient, getFieldDefTitle, getLabelAngle } from './properties';\nexport function parseUnitAxes(model) {\n    return POSITION_SCALE_CHANNELS.reduce((axis, channel) => {\n        if (model.component.scales[channel]) {\n            axis[channel] = [parseAxis(channel, model)];\n        }\n        return axis;\n    }, {});\n}\nconst OPPOSITE_ORIENT = {\n    bottom: 'top',\n    top: 'bottom',\n    left: 'right',\n    right: 'left'\n};\nexport function parseLayerAxes(model) {\n    var _a;\n    const { axes, resolve } = model.component;\n    const axisCount = { top: 0, bottom: 0, right: 0, left: 0 };\n    for (const child of model.children) {\n        child.parseAxesAndHeaders();\n        for (const channel of keys(child.component.axes)) {\n            resolve.axis[channel] = parseGuideResolve(model.component.resolve, channel);\n            if (resolve.axis[channel] === 'shared') {\n                // If the resolve says shared (and has not been overridden)\n                // We will try to merge and see if there is a conflict\n                axes[channel] = mergeAxisComponents(axes[channel], child.component.axes[channel]);\n                if (!axes[channel]) {\n                    // If merge returns nothing, there is a conflict so we cannot make the axis shared.\n                    // Thus, mark axis as independent and remove the axis component.\n                    resolve.axis[channel] = 'independent';\n                    delete axes[channel];\n                }\n            }\n        }\n    }\n    // Move axes to layer's axis component and merge shared axes\n    for (const channel of POSITION_SCALE_CHANNELS) {\n        for (const child of model.children) {\n            if (!child.component.axes[channel]) {\n                // skip if the child does not have a particular axis\n                continue;\n            }\n            if (resolve.axis[channel] === 'independent') {\n                // If axes are independent, concat the axisComponent array.\n                axes[channel] = ((_a = axes[channel]) !== null && _a !== void 0 ? _a : []).concat(child.component.axes[channel]);\n                // Automatically adjust orient\n                for (const axisComponent of child.component.axes[channel]) {\n                    const { value: orient, explicit } = axisComponent.getWithExplicit('orient');\n                    if (isSignalRef(orient)) {\n                        continue;\n                    }\n                    if (axisCount[orient] > 0 && !explicit) {\n                        // Change axis orient if the number do not match\n                        const oppositeOrient = OPPOSITE_ORIENT[orient];\n                        if (axisCount[orient] > axisCount[oppositeOrient]) {\n                            axisComponent.set('orient', oppositeOrient, false);\n                        }\n                    }\n                    axisCount[orient]++;\n                    // TODO(https://github.com/vega/vega-lite/issues/2634): automatically add extra offset?\n                }\n            }\n            // After merging, make sure to remove axes from child\n            delete child.component.axes[channel];\n        }\n        // Suppress grid lines for dual axis charts (https://github.com/vega/vega-lite/issues/4676)\n        if (resolve.axis[channel] === 'independent' && axes[channel] && axes[channel].length > 1) {\n            for (const axisCmpt of axes[channel]) {\n                if (!!axisCmpt.get('grid') && !axisCmpt.explicit.grid) {\n                    axisCmpt.implicit.grid = false;\n                }\n            }\n        }\n    }\n}\nfunction mergeAxisComponents(mergedAxisCmpts, childAxisCmpts) {\n    if (mergedAxisCmpts) {\n        // FIXME: this is a bit wrong once we support multiple axes\n        if (mergedAxisCmpts.length !== childAxisCmpts.length) {\n            return undefined; // Cannot merge axis component with different number of axes.\n        }\n        const length = mergedAxisCmpts.length;\n        for (let i = 0; i < length; i++) {\n            const merged = mergedAxisCmpts[i];\n            const child = childAxisCmpts[i];\n            if (!!merged !== !!child) {\n                return undefined;\n            }\n            else if (merged && child) {\n                const mergedOrient = merged.getWithExplicit('orient');\n                const childOrient = child.getWithExplicit('orient');\n                if (mergedOrient.explicit && childOrient.explicit && mergedOrient.value !== childOrient.value) {\n                    // TODO: throw warning if resolve is explicit (We don't have info about explicit/implicit resolve yet.)\n                    // Cannot merge due to inconsistent orient\n                    return undefined;\n                }\n                else {\n                    mergedAxisCmpts[i] = mergeAxisComponent(merged, child);\n                }\n            }\n        }\n    }\n    else {\n        // For first one, return a copy of the child\n        return childAxisCmpts.map(axisComponent => axisComponent.clone());\n    }\n    return mergedAxisCmpts;\n}\nfunction mergeAxisComponent(merged, child) {\n    for (const prop of AXIS_COMPONENT_PROPERTIES) {\n        const mergedValueWithExplicit = mergeValuesWithExplicit(merged.getWithExplicit(prop), child.getWithExplicit(prop), prop, 'axis', \n        // Tie breaker function\n        (v1, v2) => {\n            switch (prop) {\n                case 'title':\n                    return mergeTitleComponent(v1, v2);\n                case 'gridScale':\n                    return {\n                        explicit: v1.explicit,\n                        value: getFirstDefined(v1.value, v2.value)\n                    };\n            }\n            return defaultTieBreaker(v1, v2, prop, 'axis');\n        });\n        merged.setWithExplicit(prop, mergedValueWithExplicit);\n    }\n    return merged;\n}\n// eslint-disable-next-line @typescript-eslint/ban-types\nfunction isExplicit(value, property, axis, model, channel) {\n    if (property === 'disable') {\n        return axis !== undefined; // if axis is specified or null/false, then it's enable/disable state is explicit\n    }\n    axis = axis || {};\n    switch (property) {\n        case 'titleAngle':\n        case 'labelAngle':\n            return value === (isSignalRef(axis.labelAngle) ? axis.labelAngle : normalizeAngle(axis.labelAngle));\n        case 'values':\n            return !!axis.values;\n        // specified axis.values is already respected, but may get transformed.\n        case 'encode':\n            // both VL axis.encoding and axis.labelAngle affect VG axis.encode\n            return !!axis.encoding || !!axis.labelAngle;\n        case 'title':\n            // title can be explicit if fieldDef.title is set\n            if (value === getFieldDefTitle(model, channel)) {\n                return true;\n            }\n    }\n    // Otherwise, things are explicit if the returned value matches the specified property\n    return value === axis[property];\n}\n/**\n * Properties to always include values from config\n */\nconst propsToAlwaysIncludeConfig = new Set([\n    'grid',\n    'translate',\n    // the rest are not axis configs in Vega, but are in VL, so we need to set too.\n    'format',\n    'formatType',\n    'orient',\n    'labelExpr',\n    'tickCount',\n    'position',\n    'tickMinStep'\n]);\nfunction parseAxis(channel, model) {\n    var _a, _b, _c;\n    let axis = model.axis(channel);\n    const axisComponent = new AxisComponent();\n    const fieldOrDatumDef = getFieldOrDatumDef(model.encoding[channel]);\n    const { mark, config } = model;\n    const orient = (axis === null || axis === void 0 ? void 0 : axis.orient) || ((_a = config[channel === 'x' ? 'axisX' : 'axisY']) === null || _a === void 0 ? void 0 : _a.orient) || ((_b = config.axis) === null || _b === void 0 ? void 0 : _b.orient) ||\n        defaultOrient(channel);\n    const scaleType = model.getScaleComponent(channel).get('type');\n    const axisConfigs = getAxisConfigs(channel, scaleType, orient, model.config);\n    const disable = axis !== undefined ? !axis : getAxisConfig('disable', config.style, axis === null || axis === void 0 ? void 0 : axis.style, axisConfigs).configValue;\n    axisComponent.set('disable', disable, axis !== undefined);\n    if (disable) {\n        return axisComponent;\n    }\n    axis = axis || {};\n    const labelAngle = getLabelAngle(fieldOrDatumDef, axis, channel, config.style, axisConfigs);\n    const ruleParams = {\n        fieldOrDatumDef,\n        axis,\n        channel,\n        model,\n        scaleType,\n        orient,\n        labelAngle,\n        mark,\n        config\n    };\n    // 1.2. Add properties\n    for (const property of AXIS_COMPONENT_PROPERTIES) {\n        const value = property in axisRules ? axisRules[property](ruleParams) : isAxisProperty(property) ? axis[property] : undefined;\n        const hasValue = value !== undefined;\n        const explicit = isExplicit(value, property, axis, model, channel);\n        if (hasValue && explicit) {\n            axisComponent.set(property, value, explicit);\n        }\n        else {\n            const { configValue = undefined, configFrom = undefined } = isAxisProperty(property) && property !== 'values'\n                ? getAxisConfig(property, config.style, axis.style, axisConfigs)\n                : {};\n            const hasConfigValue = configValue !== undefined;\n            if (hasValue && !hasConfigValue) {\n                // only set property if it is explicitly set or has no config value (otherwise we will accidentally override config)\n                axisComponent.set(property, value, explicit);\n            }\n            else if (\n            // Cases need implicit values\n            // 1. Axis config that aren't available in Vega\n            !(configFrom === 'vgAxisConfig') ||\n                // 2. Certain properties are always included (see `propsToAlwaysIncludeConfig`'s declaration for more details)\n                (propsToAlwaysIncludeConfig.has(property) && hasConfigValue) ||\n                // 3. Conditional axis values and signals\n                isConditionalAxisValue(configValue) ||\n                isSignalRef(configValue)) {\n                // If a config is specified and is conditional, copy conditional value from axis config\n                axisComponent.set(property, configValue, false);\n            }\n        }\n    }\n    // 2) Add guide encode definition groups\n    const axisEncoding = (_c = axis.encoding) !== null && _c !== void 0 ? _c : {};\n    const axisEncode = AXIS_PARTS.reduce((e, part) => {\n        var _a;\n        if (!axisComponent.hasAxisPart(part)) {\n            // No need to create encode for a disabled part.\n            return e;\n        }\n        const axisEncodingPart = guideEncodeEntry((_a = axisEncoding[part]) !== null && _a !== void 0 ? _a : {}, model);\n        const value = part === 'labels' ? encode.labels(model, channel, axisEncodingPart) : axisEncodingPart;\n        if (value !== undefined && !isEmpty(value)) {\n            e[part] = { update: value };\n        }\n        return e;\n    }, {});\n    // FIXME: By having encode as one property, we won't have fine grained encode merging.\n    if (!isEmpty(axisEncode)) {\n        axisComponent.set('encode', axisEncode, !!axis.encoding || axis.labelAngle !== undefined);\n    }\n    return axisComponent;\n}\n//# sourceMappingURL=parse.js.map","import { isArray, isObject } from 'vega-util';\nimport { isBinned, isBinning } from '../../bin';\nimport { X } from '../../channel';\nimport { isDiscrete, isFieldDef, toFieldDefBase, valueArray } from '../../channeldef';\nimport { hasDiscreteDomain } from '../../scale';\nimport { normalizeTimeUnit } from '../../timeunit';\nimport { NOMINAL, ORDINAL } from '../../type';\nimport { contains, normalizeAngle } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { mergeTitle, mergeTitleFieldDefs } from '../common';\nimport { guideFormat, guideFormatType } from '../format';\nimport { getAxisConfig } from './config';\nexport const axisRules = {\n    scale: ({ model, channel }) => model.scaleName(channel),\n    format: ({ fieldOrDatumDef, config, axis }) => {\n        const { format, formatType } = axis;\n        return guideFormat(fieldOrDatumDef, fieldOrDatumDef.type, format, formatType, config, true);\n    },\n    formatType: ({ axis, fieldOrDatumDef, scaleType }) => {\n        const { formatType } = axis;\n        return guideFormatType(formatType, fieldOrDatumDef, scaleType);\n    },\n    grid: ({ fieldOrDatumDef, axis, scaleType }) => {\n        var _a;\n        if (isFieldDef(fieldOrDatumDef) && isBinned(fieldOrDatumDef.bin)) {\n            return false;\n        }\n        else {\n            return (_a = axis.grid) !== null && _a !== void 0 ? _a : defaultGrid(scaleType, fieldOrDatumDef);\n        }\n    },\n    gridScale: ({ model, channel }) => gridScale(model, channel),\n    labelAlign: ({ axis, labelAngle, orient, channel }) => axis.labelAlign || defaultLabelAlign(labelAngle, orient, channel),\n    labelAngle: ({ labelAngle }) => labelAngle,\n    labelBaseline: ({ axis, labelAngle, orient, channel }) => axis.labelBaseline || defaultLabelBaseline(labelAngle, orient, channel),\n    labelFlush: ({ axis, fieldOrDatumDef, channel }) => { var _a; return (_a = axis.labelFlush) !== null && _a !== void 0 ? _a : defaultLabelFlush(fieldOrDatumDef.type, channel); },\n    labelOverlap: ({ axis, fieldOrDatumDef, scaleType }) => { var _a; return (_a = axis.labelOverlap) !== null && _a !== void 0 ? _a : defaultLabelOverlap(fieldOrDatumDef.type, scaleType, isFieldDef(fieldOrDatumDef) && !!fieldOrDatumDef.timeUnit, isFieldDef(fieldOrDatumDef) ? fieldOrDatumDef.sort : undefined); },\n    // we already calculate orient in parse\n    orient: ({ orient }) => orient,\n    tickCount: ({ channel, model, axis, fieldOrDatumDef, scaleType }) => {\n        var _a;\n        const sizeType = channel === 'x' ? 'width' : channel === 'y' ? 'height' : undefined;\n        const size = sizeType ? model.getSizeSignalRef(sizeType) : undefined;\n        return (_a = axis.tickCount) !== null && _a !== void 0 ? _a : defaultTickCount({ fieldOrDatumDef, scaleType, size, values: axis.values });\n    },\n    title: ({ axis, model, channel }) => {\n        if (axis.title !== undefined) {\n            return axis.title;\n        }\n        const fieldDefTitle = getFieldDefTitle(model, channel);\n        if (fieldDefTitle !== undefined) {\n            return fieldDefTitle;\n        }\n        const fieldDef = model.typedFieldDef(channel);\n        const channel2 = channel === 'x' ? 'x2' : 'y2';\n        const fieldDef2 = model.fieldDef(channel2);\n        // If title not specified, store base parts of fieldDef (and fieldDef2 if exists)\n        return mergeTitleFieldDefs(fieldDef ? [toFieldDefBase(fieldDef)] : [], isFieldDef(fieldDef2) ? [toFieldDefBase(fieldDef2)] : []);\n    },\n    values: ({ axis, fieldOrDatumDef }) => values(axis, fieldOrDatumDef),\n    zindex: ({ axis, fieldOrDatumDef, mark }) => { var _a; return (_a = axis.zindex) !== null && _a !== void 0 ? _a : defaultZindex(mark, fieldOrDatumDef); }\n};\n// TODO: we need to refactor this method after we take care of config refactoring\n/**\n * Default rules for whether to show a grid should be shown for a channel.\n * If `grid` is unspecified, the default value is `true` for ordinal scales that are not binned\n */\nexport function defaultGrid(scaleType, fieldDef) {\n    return !hasDiscreteDomain(scaleType) && isFieldDef(fieldDef) && !isBinning(fieldDef === null || fieldDef === void 0 ? void 0 : fieldDef.bin);\n}\nexport function gridScale(model, channel) {\n    const gridChannel = channel === 'x' ? 'y' : 'x';\n    if (model.getScaleComponent(gridChannel)) {\n        return model.scaleName(gridChannel);\n    }\n    return undefined;\n}\nexport function getLabelAngle(fieldOrDatumDef, axis, channel, styleConfig, axisConfigs) {\n    const labelAngle = axis === null || axis === void 0 ? void 0 : axis.labelAngle;\n    // try axis value\n    if (labelAngle !== undefined) {\n        return isSignalRef(labelAngle) ? labelAngle : normalizeAngle(labelAngle);\n    }\n    else {\n        // try axis config value\n        const { configValue: angle } = getAxisConfig('labelAngle', styleConfig, axis === null || axis === void 0 ? void 0 : axis.style, axisConfigs);\n        if (angle !== undefined) {\n            return normalizeAngle(angle);\n        }\n        else {\n            // get default value\n            if (channel === X &&\n                contains([NOMINAL, ORDINAL], fieldOrDatumDef.type) &&\n                !(isFieldDef(fieldOrDatumDef) && fieldOrDatumDef.timeUnit)) {\n                return 270;\n            }\n            // no default\n            return undefined;\n        }\n    }\n}\nexport function normalizeAngleExpr(angle) {\n    return `(((${angle.signal} % 360) + 360) % 360)`;\n}\nexport function defaultLabelBaseline(angle, orient, channel, alwaysIncludeMiddle) {\n    if (angle !== undefined) {\n        if (channel === 'x') {\n            if (isSignalRef(angle)) {\n                const a = normalizeAngleExpr(angle);\n                const orientIsTop = isSignalRef(orient) ? `(${orient.signal} === \"top\")` : orient === 'top';\n                return {\n                    signal: `(45 < ${a} && ${a} < 135) || (225 < ${a} && ${a} < 315) ? \"middle\" :` +\n                        `(${a} <= 45 || 315 <= ${a}) === ${orientIsTop} ? \"bottom\" : \"top\"`\n                };\n            }\n            if ((45 < angle && angle < 135) || (225 < angle && angle < 315)) {\n                return 'middle';\n            }\n            if (isSignalRef(orient)) {\n                const op = angle <= 45 || 315 <= angle ? '===' : '!==';\n                return { signal: `${orient.signal} ${op} \"top\" ? \"bottom\" : \"top\"` };\n            }\n            return (angle <= 45 || 315 <= angle) === (orient === 'top') ? 'bottom' : 'top';\n        }\n        else {\n            if (isSignalRef(angle)) {\n                const a = normalizeAngleExpr(angle);\n                const orientIsLeft = isSignalRef(orient) ? `(${orient.signal} === \"left\")` : orient === 'left';\n                const middle = alwaysIncludeMiddle ? '\"middle\"' : 'null';\n                return {\n                    signal: `${a} <= 45 || 315 <= ${a} || (135 <= ${a} && ${a} <= 225) ? ${middle} : (45 <= ${a} && ${a} <= 135) === ${orientIsLeft} ? \"top\" : \"bottom\"`\n                };\n            }\n            if (angle <= 45 || 315 <= angle || (135 <= angle && angle <= 225)) {\n                return alwaysIncludeMiddle ? 'middle' : null;\n            }\n            if (isSignalRef(orient)) {\n                const op = 45 <= angle && angle <= 135 ? '===' : '!==';\n                return { signal: `${orient.signal} ${op} \"left\" ? \"top\" : \"bottom\"` };\n            }\n            return (45 <= angle && angle <= 135) === (orient === 'left') ? 'top' : 'bottom';\n        }\n    }\n    return undefined;\n}\nexport function defaultLabelAlign(angle, orient, channel) {\n    if (angle === undefined) {\n        return undefined;\n    }\n    const isX = channel === 'x';\n    const startAngle = isX ? 0 : 90;\n    const mainOrient = isX ? 'bottom' : 'left';\n    if (isSignalRef(angle)) {\n        const a = normalizeAngleExpr(angle);\n        const orientIsMain = isSignalRef(orient) ? `(${orient.signal} === \"${mainOrient}\")` : orient === mainOrient;\n        return {\n            signal: `(${startAngle ? '(' + a + ' + 90)' : a} % 180 === 0) ? ${isX ? null : '\"center\"'} :` +\n                `(${startAngle} < ${a} && ${a} < ${180 + startAngle}) === ${orientIsMain} ? \"left\" : \"right\"`\n        };\n    }\n    if ((angle + startAngle) % 180 === 0) {\n        // For bottom, use default label align so label flush still works\n        return isX ? null : 'center';\n    }\n    if (isSignalRef(orient)) {\n        const op = startAngle < angle && angle < 180 + startAngle ? '===' : '!==';\n        const orientIsMain = `${orient.signal} ${op} \"${mainOrient}\"`;\n        return {\n            signal: `${orientIsMain} ? \"left\" : \"right\"`\n        };\n    }\n    if ((startAngle < angle && angle < 180 + startAngle) === (orient === mainOrient)) {\n        return 'left';\n    }\n    return 'right';\n}\nexport function defaultLabelFlush(type, channel) {\n    if (channel === 'x' && contains(['quantitative', 'temporal'], type)) {\n        return true;\n    }\n    return undefined;\n}\nexport function defaultLabelOverlap(type, scaleType, hasTimeUnit, sort) {\n    // do not prevent overlap for nominal data because there is no way to infer what the missing labels are\n    if ((hasTimeUnit && !isObject(sort)) || (type !== 'nominal' && type !== 'ordinal')) {\n        if (scaleType === 'log' || scaleType === 'symlog') {\n            return 'greedy';\n        }\n        return true;\n    }\n    return undefined;\n}\nexport function defaultOrient(channel) {\n    return channel === 'x' ? 'bottom' : 'left';\n}\nexport function defaultTickCount({ fieldOrDatumDef, scaleType, size, values: vals }) {\n    var _a;\n    if (!vals && !hasDiscreteDomain(scaleType) && scaleType !== 'log') {\n        if (isFieldDef(fieldOrDatumDef)) {\n            if (isBinning(fieldOrDatumDef.bin)) {\n                // for binned data, we don't want more ticks than maxbins\n                return { signal: `ceil(${size.signal}/10)` };\n            }\n            if (fieldOrDatumDef.timeUnit &&\n                contains(['month', 'hours', 'day', 'quarter'], (_a = normalizeTimeUnit(fieldOrDatumDef.timeUnit)) === null || _a === void 0 ? void 0 : _a.unit)) {\n                return undefined;\n            }\n        }\n        return { signal: `ceil(${size.signal}/40)` };\n    }\n    return undefined;\n}\nexport function getFieldDefTitle(model, channel) {\n    const channel2 = channel === 'x' ? 'x2' : 'y2';\n    const fieldDef = model.fieldDef(channel);\n    const fieldDef2 = model.fieldDef(channel2);\n    const title1 = fieldDef ? fieldDef.title : undefined;\n    const title2 = fieldDef2 ? fieldDef2.title : undefined;\n    if (title1 && title2) {\n        return mergeTitle(title1, title2);\n    }\n    else if (title1) {\n        return title1;\n    }\n    else if (title2) {\n        return title2;\n    }\n    else if (title1 !== undefined) {\n        // falsy value to disable config\n        return title1;\n    }\n    else if (title2 !== undefined) {\n        // falsy value to disable config\n        return title2;\n    }\n    return undefined;\n}\nexport function values(axis, fieldOrDatumDef) {\n    const vals = axis.values;\n    if (isArray(vals)) {\n        return valueArray(fieldOrDatumDef, vals);\n    }\n    else if (isSignalRef(vals)) {\n        return vals;\n    }\n    return undefined;\n}\nexport function defaultZindex(mark, fieldDef) {\n    if (mark === 'rect' && isDiscrete(fieldDef)) {\n        return 1;\n    }\n    return 0;\n}\n//# sourceMappingURL=properties.js.map","import * as log from '../log';\nimport { isAnyConcatSpec, isFacetSpec, isLayerSpec, isUnitSpec } from '../spec';\nimport { ConcatModel } from './concat';\nimport { FacetModel } from './facet';\nimport { LayerModel } from './layer';\nimport { UnitModel } from './unit';\nexport function buildModel(spec, parent, parentGivenName, unitSize, config) {\n    if (isFacetSpec(spec)) {\n        return new FacetModel(spec, parent, parentGivenName, config);\n    }\n    else if (isLayerSpec(spec)) {\n        return new LayerModel(spec, parent, parentGivenName, unitSize, config);\n    }\n    else if (isUnitSpec(spec)) {\n        return new UnitModel(spec, parent, parentGivenName, unitSize, config);\n    }\n    else if (isAnyConcatSpec(spec)) {\n        return new ConcatModel(spec, parent, parentGivenName, config);\n    }\n    throw new Error(log.message.invalidSpec(spec));\n}\n//# sourceMappingURL=buildmodel.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { array, isArray, stringValue } from 'vega-util';\nimport { vgField } from '../channeldef';\nimport { isExprRef } from '../expr';\nimport { isText } from '../title';\nimport { deepEqual, getFirstDefined } from '../util';\nimport { isSignalRef } from '../vega.schema';\nexport const BIN_RANGE_DELIMITER = ' \\u2013 ';\nexport function signalOrValueRefWithCondition(val) {\n    const condition = isArray(val.condition)\n        ? val.condition.map(conditionalSignalRefOrValue)\n        : conditionalSignalRefOrValue(val.condition);\n    return Object.assign(Object.assign({}, signalRefOrValue(val)), { condition });\n}\nexport function signalRefOrValue(value) {\n    if (isExprRef(value)) {\n        const { expr } = value, rest = __rest(value, [\"expr\"]);\n        return Object.assign({ signal: expr }, rest);\n    }\n    return value;\n}\nexport function conditionalSignalRefOrValue(value) {\n    if (isExprRef(value)) {\n        const { expr } = value, rest = __rest(value, [\"expr\"]);\n        return Object.assign({ signal: expr }, rest);\n    }\n    return value;\n}\nexport function signalOrValueRef(value) {\n    if (isExprRef(value)) {\n        const { expr } = value, rest = __rest(value, [\"expr\"]);\n        return Object.assign({ signal: expr }, rest);\n    }\n    if (isSignalRef(value)) {\n        return value;\n    }\n    return value !== undefined ? { value } : undefined;\n}\nexport function exprFromValueOrSignalRef(ref) {\n    if (isSignalRef(ref)) {\n        return ref.signal;\n    }\n    return stringValue(ref.value);\n}\nexport function signalOrStringValue(v) {\n    if (isSignalRef(v)) {\n        return v.signal;\n    }\n    return v == null ? null : stringValue(v);\n}\nexport function applyMarkConfig(e, model, propsList) {\n    for (const property of propsList) {\n        const value = getMarkConfig(property, model.markDef, model.config);\n        if (value !== undefined) {\n            e[property] = signalOrValueRef(value);\n        }\n    }\n    return e;\n}\nexport function getStyles(mark) {\n    var _a;\n    return [].concat(mark.type, (_a = mark.style) !== null && _a !== void 0 ? _a : []);\n}\nexport function getMarkPropOrConfig(channel, mark, config, opt = {}) {\n    const { vgChannel, ignoreVgConfig } = opt;\n    if (vgChannel && mark[vgChannel] !== undefined) {\n        return mark[vgChannel];\n    }\n    else if (mark[channel] !== undefined) {\n        return mark[channel];\n    }\n    else if (ignoreVgConfig && (!vgChannel || vgChannel === channel)) {\n        return undefined;\n    }\n    return getMarkConfig(channel, mark, config, opt);\n}\n/**\n * Return property value from style or mark specific config property if exists.\n * Otherwise, return general mark specific config.\n */\nexport function getMarkConfig(channel, mark, config, { vgChannel } = {}) {\n    return getFirstDefined(\n    // style config has highest precedence\n    vgChannel ? getMarkStyleConfig(channel, mark, config.style) : undefined, getMarkStyleConfig(channel, mark, config.style), \n    // then mark-specific config\n    vgChannel ? config[mark.type][vgChannel] : undefined, config[mark.type][channel], // Need to cast because MarkDef doesn't perfectly match with AnyMarkConfig, but if the type isn't available, we'll get nothing here, which is fine\n    // If there is vgChannel, skip vl channel.\n    // For example, vl size for text is vg fontSize, but config.mark.size is only for point size.\n    vgChannel ? config.mark[vgChannel] : config.mark[channel] // Need to cast for the same reason as above\n    );\n}\nexport function getMarkStyleConfig(prop, mark, styleConfigIndex) {\n    return getStyleConfig(prop, getStyles(mark), styleConfigIndex);\n}\nexport function getStyleConfig(p, styles, styleConfigIndex) {\n    styles = array(styles);\n    let value;\n    for (const style of styles) {\n        const styleConfig = styleConfigIndex[style];\n        if (styleConfig && styleConfig[p] !== undefined) {\n            value = styleConfig[p];\n        }\n    }\n    return value;\n}\n/**\n * Return Vega sort parameters (tuple of field and order).\n */\nexport function sortParams(orderDef, fieldRefOption) {\n    return array(orderDef).reduce((s, orderChannelDef) => {\n        var _a;\n        s.field.push(vgField(orderChannelDef, fieldRefOption));\n        s.order.push((_a = orderChannelDef.sort) !== null && _a !== void 0 ? _a : 'ascending');\n        return s;\n    }, { field: [], order: [] });\n}\nexport function mergeTitleFieldDefs(f1, f2) {\n    const merged = [...f1];\n    f2.forEach(fdToMerge => {\n        for (const fieldDef1 of merged) {\n            // If already exists, no need to append to merged array\n            if (deepEqual(fieldDef1, fdToMerge)) {\n                return;\n            }\n        }\n        merged.push(fdToMerge);\n    });\n    return merged;\n}\nexport function mergeTitle(title1, title2) {\n    if (deepEqual(title1, title2) || !title2) {\n        // if titles are the same or title2 is falsy\n        return title1;\n    }\n    else if (!title1) {\n        // if title1 is falsy\n        return title2;\n    }\n    else {\n        return [...array(title1), ...array(title2)].join(', ');\n    }\n}\nexport function mergeTitleComponent(v1, v2) {\n    const v1Val = v1.value;\n    const v2Val = v2.value;\n    if (v1Val == null || v2Val === null) {\n        return {\n            explicit: v1.explicit,\n            value: null\n        };\n    }\n    else if ((isText(v1Val) || isSignalRef(v1Val)) && (isText(v2Val) || isSignalRef(v2Val))) {\n        return {\n            explicit: v1.explicit,\n            value: mergeTitle(v1Val, v2Val)\n        };\n    }\n    else if (isText(v1Val) || isSignalRef(v1Val)) {\n        return {\n            explicit: v1.explicit,\n            value: v1Val\n        };\n    }\n    else if (isText(v2Val) || isSignalRef(v2Val)) {\n        return {\n            explicit: v1.explicit,\n            value: v2Val\n        };\n    }\n    else if (!isText(v1Val) && !isSignalRef(v1Val) && !isText(v2Val) && !isSignalRef(v2Val)) {\n        return {\n            explicit: v1.explicit,\n            value: mergeTitleFieldDefs(v1Val, v2Val)\n        };\n    }\n    /* istanbul ignore next: Condition should not happen -- only for warning in development. */\n    throw new Error('It should never reach here');\n}\n//# sourceMappingURL=common.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isString, mergeConfig } from 'vega-util';\nimport { getPositionScaleChannel } from '../channel';\nimport * as vlFieldDef from '../channeldef';\nimport { initConfig, stripAndRedirectConfig } from '../config';\nimport * as log from '../log';\nimport { normalize } from '../normalize';\nimport { assembleParameterSignals } from '../parameter';\nimport { extractTopLevelProperties, getFitType, isFitType } from '../spec/toplevel';\nimport { keys } from '../util';\nimport { buildModel } from './buildmodel';\nimport { assembleRootData } from './data/assemble';\nimport { optimizeDataflow } from './data/optimize';\n/**\n * Vega-Lite's main function, for compiling Vega-Lite spec into Vega spec.\n *\n * At a high-level, we make the following transformations in different phases:\n *\n * Input spec\n *     |\n *     |  (Normalization)\n *     v\n * Normalized Spec (Row/Column channels in single-view specs becomes faceted specs, composite marks becomes layered specs.)\n *     |\n *     |  (Build Model)\n *     v\n * A model tree of the spec\n *     |\n *     |  (Parse)\n *     v\n * A model tree with parsed components (intermediate structure of visualization primitives in a format that can be easily merged)\n *     |\n *     | (Optimize)\n *     v\n * A model tree with parsed components with the data component optimized\n *     |\n *     | (Assemble)\n *     v\n * Vega spec\n *\n * @param inputSpec The Vega-Lite specification.\n * @param opt       Optional arguments passed to the Vega-Lite compiler.\n * @returns         An object containing the compiled Vega spec and normalized Vega-Lite spec.\n */\nexport function compile(inputSpec, opt = {}) {\n    // 0. Augment opt with default opts\n    if (opt.logger) {\n        // set the singleton logger to the provided logger\n        log.set(opt.logger);\n    }\n    if (opt.fieldTitle) {\n        // set the singleton field title formatter\n        vlFieldDef.setTitleFormatter(opt.fieldTitle);\n    }\n    try {\n        // 1. Initialize config by deep merging default config with the config provided via option and the input spec.\n        const config = initConfig(mergeConfig(opt.config, inputSpec.config));\n        // 2. Normalize: Convert input spec -> normalized spec\n        // - Decompose all extended unit specs into composition of unit spec. For example, a box plot get expanded into multiple layers of bars, ticks, and rules. The shorthand row/column channel is also expanded to a facet spec.\n        // - Normalize autosize and width or height spec\n        const spec = normalize(inputSpec, config);\n        // 3. Build Model: normalized spec -> Model (a tree structure)\n        // This phases instantiates the models with default config by doing a top-down traversal. This allows us to pass properties that child models derive from their parents via their constructors.\n        // See the abstract `Model` class and its children (UnitModel, LayerModel, FacetModel, ConcatModel) for different types of models.\n        const model = buildModel(spec, null, '', undefined, config);\n        // 4 Parse: Model --> Model with components\n        // Note that components = intermediate representations that are equivalent to Vega specs.\n        // We need these intermediate representation because we need to merge many visualization \"components\" like projections, scales, axes, and legends.\n        // We will later convert these components into actual Vega specs in the assemble phase.\n        // In this phase, we do a bottom-up traversal over the whole tree to\n        // parse for each type of components once (e.g., data, layout, mark, scale).\n        // By doing bottom-up traversal, we start parsing components of unit specs and\n        // then merge child components of parent composite specs.\n        //\n        // Please see inside model.parse() for order of different components parsed.\n        model.parse();\n        // drawDataflow(model.component.data.sources);\n        // 5. Optimize the dataflow. This will modify the data component of the model.\n        optimizeDataflow(model.component.data, model);\n        // drawDataflow(model.component.data.sources);\n        // 6. Assemble: convert model components --> Vega Spec.\n        const vgSpec = assembleTopLevelModel(model, getTopLevelProperties(inputSpec, spec.autosize, config, model), inputSpec.datasets, inputSpec.usermeta);\n        return {\n            spec: vgSpec,\n            normalized: spec\n        };\n    }\n    finally {\n        // Reset the singleton logger if a logger is provided\n        if (opt.logger) {\n            log.reset();\n        }\n        // Reset the singleton field title formatter if provided\n        if (opt.fieldTitle) {\n            vlFieldDef.resetTitleFormatter();\n        }\n    }\n}\nfunction getTopLevelProperties(inputSpec, autosize, config, model) {\n    const width = model.component.layoutSize.get('width');\n    const height = model.component.layoutSize.get('height');\n    if (autosize === undefined) {\n        autosize = { type: 'pad' };\n        if (model.hasAxisOrientSignalRef()) {\n            autosize.resize = true;\n        }\n    }\n    else if (isString(autosize)) {\n        autosize = { type: autosize };\n    }\n    if (width && height && isFitType(autosize.type)) {\n        if (width === 'step' && height === 'step') {\n            log.warn(log.message.droppingFit());\n            autosize.type = 'pad';\n        }\n        else if (width === 'step' || height === 'step') {\n            // effectively XOR, because else if\n            // get step dimension\n            const sizeType = width === 'step' ? 'width' : 'height';\n            // log that we're dropping fit for respective channel\n            log.warn(log.message.droppingFit(getPositionScaleChannel(sizeType)));\n            // setting type to inverse fit (so if we dropped fit-x, type is now fit-y)\n            const inverseSizeType = sizeType === 'width' ? 'height' : 'width';\n            autosize.type = getFitType(inverseSizeType);\n        }\n    }\n    return Object.assign(Object.assign(Object.assign({}, (keys(autosize).length === 1 && autosize.type\n        ? autosize.type === 'pad'\n            ? {}\n            : { autosize: autosize.type }\n        : { autosize })), extractTopLevelProperties(config, false)), extractTopLevelProperties(inputSpec, true));\n}\n/*\n * Assemble the top-level model to a Vega spec.\n *\n * Note: this couldn't be `model.assemble()` since the top-level model\n * needs some special treatment to generate top-level properties.\n */\nfunction assembleTopLevelModel(model, topLevelProperties, datasets = {}, usermeta) {\n    // Config with Vega-Lite only config removed.\n    const vgConfig = model.config ? stripAndRedirectConfig(model.config) : undefined;\n    const data = [].concat(model.assembleSelectionData([]), \n    // only assemble data in the root\n    assembleRootData(model.component.data, datasets));\n    const projections = model.assembleProjections();\n    const title = model.assembleTitle();\n    const style = model.assembleGroupStyle();\n    const encodeEntry = model.assembleGroupEncodeEntry(true);\n    let layoutSignals = model.assembleLayoutSignals();\n    // move width and height signals with values to top level\n    layoutSignals = layoutSignals.filter(signal => {\n        if ((signal.name === 'width' || signal.name === 'height') && signal.value !== undefined) {\n            topLevelProperties[signal.name] = +signal.value;\n            return false;\n        }\n        return true;\n    });\n    const { params } = topLevelProperties, otherTopLevelProps = __rest(topLevelProperties, [\"params\"]);\n    return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ $schema: 'https://vega.github.io/schema/vega/v5.json' }, (model.description ? { description: model.description } : {})), otherTopLevelProps), (title ? { title } : {})), (style ? { style } : {})), (encodeEntry ? { encode: { update: encodeEntry } } : {})), { data }), (projections.length > 0 ? { projections: projections } : {})), model.assembleGroup([\n        ...layoutSignals,\n        ...model.assembleSelectionTopLevelSignals([]),\n        ...assembleParameterSignals(params)\n    ])), (vgConfig ? { config: vgConfig } : {})), (usermeta ? { usermeta } : {}));\n}\n//# sourceMappingURL=compile.js.map","import * as log from '../log';\nimport { isHConcatSpec, isVConcatSpec } from '../spec';\nimport { keys } from '../util';\nimport { buildModel } from './buildmodel';\nimport { parseData } from './data/parse';\nimport { assembleLayoutSignals } from './layoutsize/assemble';\nimport { parseConcatLayoutSize } from './layoutsize/parse';\nimport { Model } from './model';\nexport class ConcatModel extends Model {\n    constructor(spec, parent, parentGivenName, config) {\n        var _a, _b, _c, _d;\n        super(spec, 'concat', parent, parentGivenName, config, spec.resolve);\n        if (((_b = (_a = spec.resolve) === null || _a === void 0 ? void 0 : _a.axis) === null || _b === void 0 ? void 0 : _b.x) === 'shared' || ((_d = (_c = spec.resolve) === null || _c === void 0 ? void 0 : _c.axis) === null || _d === void 0 ? void 0 : _d.y) === 'shared') {\n            log.warn(log.message.CONCAT_CANNOT_SHARE_AXIS);\n        }\n        this.children = this.getChildren(spec).map((child, i) => {\n            return buildModel(child, this, this.getName('concat_' + i), undefined, config);\n        });\n    }\n    parseData() {\n        this.component.data = parseData(this);\n        for (const child of this.children) {\n            child.parseData();\n        }\n    }\n    parseSelections() {\n        // Merge selections up the hierarchy so that they may be referenced\n        // across unit specs. Persist their definitions within each child\n        // to assemble signals which remain within output Vega unit groups.\n        this.component.selection = {};\n        for (const child of this.children) {\n            child.parseSelections();\n            for (const key of keys(child.component.selection)) {\n                this.component.selection[key] = child.component.selection[key];\n            }\n        }\n    }\n    parseMarkGroup() {\n        for (const child of this.children) {\n            child.parseMarkGroup();\n        }\n    }\n    parseAxesAndHeaders() {\n        for (const child of this.children) {\n            child.parseAxesAndHeaders();\n        }\n        // TODO(#2415): support shared axes\n    }\n    getChildren(spec) {\n        if (isVConcatSpec(spec)) {\n            return spec.vconcat;\n        }\n        else if (isHConcatSpec(spec)) {\n            return spec.hconcat;\n        }\n        return spec.concat;\n    }\n    parseLayoutSize() {\n        parseConcatLayoutSize(this);\n    }\n    parseAxisGroup() {\n        return null;\n    }\n    assembleSelectionTopLevelSignals(signals) {\n        return this.children.reduce((sg, child) => child.assembleSelectionTopLevelSignals(sg), signals);\n    }\n    assembleSignals() {\n        this.children.forEach(child => child.assembleSignals());\n        return [];\n    }\n    assembleLayoutSignals() {\n        const layoutSignals = assembleLayoutSignals(this);\n        for (const child of this.children) {\n            layoutSignals.push(...child.assembleLayoutSignals());\n        }\n        return layoutSignals;\n    }\n    assembleSelectionData(data) {\n        return this.children.reduce((db, child) => child.assembleSelectionData(db), data);\n    }\n    assembleMarks() {\n        // only children have marks\n        return this.children.map(child => {\n            const title = child.assembleTitle();\n            const style = child.assembleGroupStyle();\n            const encodeEntry = child.assembleGroupEncodeEntry(false);\n            return Object.assign(Object.assign(Object.assign(Object.assign({ type: 'group', name: child.getName('group') }, (title ? { title } : {})), (style ? { style } : {})), (encodeEntry ? { encode: { update: encodeEntry } } : {})), child.assembleGroup());\n        });\n    }\n    assembleDefaultLayout() {\n        const columns = this.layout.columns;\n        return Object.assign(Object.assign({}, (columns != null ? { columns: columns } : {})), { bounds: 'full', \n            // Use align each so it can work with multiple plots with different size\n            align: 'each' });\n    }\n}\n//# sourceMappingURL=concat.js.map","import { isArgmaxDef, isArgminDef } from '../../aggregate';\nimport { getPositionChannelFromLatLong, getSecondaryRangeChannel, isGeoPositionChannel, isScaleChannel } from '../../channel';\nimport { binRequiresRange, hasBand, isTypedFieldDef, vgField } from '../../channeldef';\nimport * as log from '../../log';\nimport { duplicate, hash, keys, replacePathInField, setEqual } from '../../util';\nimport { isUnitModel } from '../model';\nimport { DataFlowNode } from './dataflow';\nfunction addDimension(dims, channel, fieldDef, model) {\n    const channelDef2 = isUnitModel(model) ? model.encoding[getSecondaryRangeChannel(channel)] : undefined;\n    if (isTypedFieldDef(fieldDef) &&\n        isUnitModel(model) &&\n        hasBand(channel, fieldDef, channelDef2, model.stack, model.markDef, model.config)) {\n        dims.add(vgField(fieldDef, {}));\n        dims.add(vgField(fieldDef, { suffix: 'end' }));\n        if (fieldDef.bin && binRequiresRange(fieldDef, channel)) {\n            dims.add(vgField(fieldDef, { binSuffix: 'range' }));\n        }\n    }\n    else if (isGeoPositionChannel(channel)) {\n        const posChannel = getPositionChannelFromLatLong(channel);\n        dims.add(model.getName(posChannel));\n    }\n    else {\n        dims.add(vgField(fieldDef));\n    }\n    return dims;\n}\nfunction mergeMeasures(parentMeasures, childMeasures) {\n    var _a;\n    for (const field of keys(childMeasures)) {\n        // when we merge a measure, we either have to add an aggregation operator or even a new field\n        const ops = childMeasures[field];\n        for (const op of keys(ops)) {\n            if (field in parentMeasures) {\n                // add operator to existing measure field\n                parentMeasures[field][op] = new Set([...((_a = parentMeasures[field][op]) !== null && _a !== void 0 ? _a : []), ...ops[op]]);\n            }\n            else {\n                parentMeasures[field] = { [op]: ops[op] };\n            }\n        }\n    }\n}\nexport class AggregateNode extends DataFlowNode {\n    /**\n     * @param dimensions string set for dimensions\n     * @param measures dictionary mapping field name => dict of aggregation functions and names to use\n     */\n    constructor(parent, dimensions, measures) {\n        super(parent);\n        this.dimensions = dimensions;\n        this.measures = measures;\n    }\n    clone() {\n        return new AggregateNode(null, new Set(this.dimensions), duplicate(this.measures));\n    }\n    get groupBy() {\n        return this.dimensions;\n    }\n    static makeFromEncoding(parent, model) {\n        let isAggregate = false;\n        model.forEachFieldDef(fd => {\n            if (fd.aggregate) {\n                isAggregate = true;\n            }\n        });\n        const meas = {};\n        const dims = new Set();\n        if (!isAggregate) {\n            // no need to create this node if the model has no aggregation\n            return null;\n        }\n        model.forEachFieldDef((fieldDef, channel) => {\n            var _a, _b, _c, _d;\n            const { aggregate, field } = fieldDef;\n            if (aggregate) {\n                if (aggregate === 'count') {\n                    meas['*'] = (_a = meas['*']) !== null && _a !== void 0 ? _a : {};\n                    meas['*']['count'] = new Set([vgField(fieldDef, { forAs: true })]);\n                }\n                else {\n                    if (isArgminDef(aggregate) || isArgmaxDef(aggregate)) {\n                        const op = isArgminDef(aggregate) ? 'argmin' : 'argmax';\n                        const argField = aggregate[op];\n                        meas[argField] = (_b = meas[argField]) !== null && _b !== void 0 ? _b : {};\n                        meas[argField][op] = new Set([vgField({ op, field: argField }, { forAs: true })]);\n                    }\n                    else {\n                        meas[field] = (_c = meas[field]) !== null && _c !== void 0 ? _c : {};\n                        meas[field][aggregate] = new Set([vgField(fieldDef, { forAs: true })]);\n                    }\n                    // For scale channel with domain === 'unaggregated', add min/max so we can use their union as unaggregated domain\n                    if (isScaleChannel(channel) && model.scaleDomain(channel) === 'unaggregated') {\n                        meas[field] = (_d = meas[field]) !== null && _d !== void 0 ? _d : {};\n                        meas[field]['min'] = new Set([vgField({ field, aggregate: 'min' }, { forAs: true })]);\n                        meas[field]['max'] = new Set([vgField({ field, aggregate: 'max' }, { forAs: true })]);\n                    }\n                }\n            }\n            else {\n                addDimension(dims, channel, fieldDef, model);\n            }\n        });\n        if (dims.size + keys(meas).length === 0) {\n            return null;\n        }\n        return new AggregateNode(parent, dims, meas);\n    }\n    static makeFromTransform(parent, t) {\n        var _a, _b, _c;\n        const dims = new Set();\n        const meas = {};\n        for (const s of t.aggregate) {\n            const { op, field, as } = s;\n            if (op) {\n                if (op === 'count') {\n                    meas['*'] = (_a = meas['*']) !== null && _a !== void 0 ? _a : {};\n                    meas['*']['count'] = new Set([as ? as : vgField(s, { forAs: true })]);\n                }\n                else {\n                    meas[field] = (_b = meas[field]) !== null && _b !== void 0 ? _b : {};\n                    meas[field][op] = new Set([as ? as : vgField(s, { forAs: true })]);\n                }\n            }\n        }\n        for (const s of (_c = t.groupby) !== null && _c !== void 0 ? _c : []) {\n            dims.add(s);\n        }\n        if (dims.size + keys(meas).length === 0) {\n            return null;\n        }\n        return new AggregateNode(parent, dims, meas);\n    }\n    merge(other) {\n        if (setEqual(this.dimensions, other.dimensions)) {\n            mergeMeasures(this.measures, other.measures);\n            return true;\n        }\n        else {\n            log.debug('different dimensions, cannot merge');\n            return false;\n        }\n    }\n    addDimensions(fields) {\n        fields.forEach(this.dimensions.add, this.dimensions);\n    }\n    dependentFields() {\n        return new Set([...this.dimensions, ...keys(this.measures)]);\n    }\n    producedFields() {\n        const out = new Set();\n        for (const field of keys(this.measures)) {\n            for (const op of keys(this.measures[field])) {\n                const m = this.measures[field][op];\n                if (m.size === 0) {\n                    out.add(`${op}_${field}`);\n                }\n                else {\n                    m.forEach(out.add, out);\n                }\n            }\n        }\n        return out;\n    }\n    hash() {\n        return `Aggregate ${hash({ dimensions: this.dimensions, measures: this.measures })}`;\n    }\n    assemble() {\n        const ops = [];\n        const fields = [];\n        const as = [];\n        for (const field of keys(this.measures)) {\n            for (const op of keys(this.measures[field])) {\n                for (const alias of this.measures[field][op]) {\n                    as.push(alias);\n                    ops.push(op);\n                    fields.push(field === '*' ? null : replacePathInField(field));\n                }\n            }\n        }\n        const result = {\n            type: 'aggregate',\n            groupby: [...this.dimensions].map(replacePathInField),\n            ops,\n            fields,\n            as\n        };\n        return result;\n    }\n}\n//# sourceMappingURL=aggregate.js.map","import { isUrlData } from '../../data';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { CalculateNode } from './calculate';\nimport { OutputNode } from './dataflow';\nimport { DensityTransformNode } from './density';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { FilterInvalidNode } from './filterinvalid';\nimport { FlattenTransformNode } from './flatten';\nimport { FoldTransformNode } from './fold';\nimport { ParseNode } from './formatparse';\nimport { GeoJSONNode } from './geojson';\nimport { GeoPointNode } from './geopoint';\nimport { GraticuleNode } from './graticule';\nimport { IdentifierNode } from './identifier';\nimport { ImputeNode } from './impute';\nimport { JoinAggregateTransformNode } from './joinaggregate';\nimport { LoessTransformNode } from './loess';\nimport { LookupNode } from './lookup';\nimport { QuantileTransformNode } from './quantile';\nimport { RegressionTransformNode } from './regression';\nimport { PivotTransformNode } from './pivot';\nimport { SampleTransformNode } from './sample';\nimport { SequenceNode } from './sequence';\nimport { SourceNode } from './source';\nimport { StackNode } from './stack';\nimport { TimeUnitNode } from './timeunit';\nimport { WindowTransformNode } from './window';\nfunction makeWalkTree(data) {\n    // to name datasources\n    let datasetIndex = 0;\n    /**\n     * Recursively walk down the tree.\n     */\n    function walkTree(node, dataSource) {\n        var _a;\n        if (node instanceof SourceNode) {\n            // If the source is a named data source or a data source with values, we need\n            // to put it in a different data source. Otherwise, Vega may override the data.\n            if (!node.isGenerator && !isUrlData(node.data)) {\n                data.push(dataSource);\n                const newData = {\n                    name: null,\n                    source: dataSource.name,\n                    transform: []\n                };\n                dataSource = newData;\n            }\n        }\n        if (node instanceof ParseNode) {\n            if (node.parent instanceof SourceNode && !dataSource.source) {\n                // If node's parent is a root source and the data source does not refer to another data source, use normal format parse\n                dataSource.format = Object.assign(Object.assign({}, ((_a = dataSource.format) !== null && _a !== void 0 ? _a : {})), { parse: node.assembleFormatParse() });\n                // add calculates for all nested fields\n                dataSource.transform.push(...node.assembleTransforms(true));\n            }\n            else {\n                // Otherwise use Vega expression to parse\n                dataSource.transform.push(...node.assembleTransforms());\n            }\n        }\n        if (node instanceof FacetNode) {\n            if (!dataSource.name) {\n                dataSource.name = `data_${datasetIndex++}`;\n            }\n            if (!dataSource.source || dataSource.transform.length > 0) {\n                data.push(dataSource);\n                node.data = dataSource.name;\n            }\n            else {\n                node.data = dataSource.source;\n            }\n            for (const d of node.assemble()) {\n                data.push(d);\n            }\n            // break here because the rest of the tree has to be taken care of by the facet.\n            return;\n        }\n        if (node instanceof GraticuleNode ||\n            node instanceof SequenceNode ||\n            node instanceof FilterInvalidNode ||\n            node instanceof FilterNode ||\n            node instanceof CalculateNode ||\n            node instanceof GeoPointNode ||\n            node instanceof GeoJSONNode ||\n            node instanceof AggregateNode ||\n            node instanceof LookupNode ||\n            node instanceof WindowTransformNode ||\n            node instanceof JoinAggregateTransformNode ||\n            node instanceof FoldTransformNode ||\n            node instanceof FlattenTransformNode ||\n            node instanceof DensityTransformNode ||\n            node instanceof LoessTransformNode ||\n            node instanceof QuantileTransformNode ||\n            node instanceof RegressionTransformNode ||\n            node instanceof IdentifierNode ||\n            node instanceof SampleTransformNode ||\n            node instanceof PivotTransformNode) {\n            dataSource.transform.push(node.assemble());\n        }\n        if (node instanceof BinNode ||\n            node instanceof TimeUnitNode ||\n            node instanceof ImputeNode ||\n            node instanceof StackNode) {\n            dataSource.transform.push(...node.assemble());\n        }\n        if (node instanceof OutputNode) {\n            if (dataSource.source && dataSource.transform.length === 0) {\n                node.setSource(dataSource.source);\n            }\n            else if (node.parent instanceof OutputNode) {\n                // Note that an output node may be required but we still do not assemble a\n                // separate data source for it.\n                node.setSource(dataSource.name);\n            }\n            else {\n                if (!dataSource.name) {\n                    dataSource.name = `data_${datasetIndex++}`;\n                }\n                // Here we set the name of the datasource we generated. From now on\n                // other assemblers can use it.\n                node.setSource(dataSource.name);\n                // if this node has more than one child, we will add a datasource automatically\n                if (node.numChildren() === 1) {\n                    data.push(dataSource);\n                    const newData = {\n                        name: null,\n                        source: dataSource.name,\n                        transform: []\n                    };\n                    dataSource = newData;\n                }\n            }\n        }\n        switch (node.numChildren()) {\n            case 0:\n                // done\n                if (node instanceof OutputNode && (!dataSource.source || dataSource.transform.length > 0)) {\n                    // do not push empty datasources that are simply references\n                    data.push(dataSource);\n                }\n                break;\n            case 1:\n                walkTree(node.children[0], dataSource);\n                break;\n            default: {\n                if (!dataSource.name) {\n                    dataSource.name = `data_${datasetIndex++}`;\n                }\n                let source = dataSource.name;\n                if (!dataSource.source || dataSource.transform.length > 0) {\n                    data.push(dataSource);\n                }\n                else {\n                    source = dataSource.source;\n                }\n                for (const child of node.children) {\n                    const newData = {\n                        name: null,\n                        source: source,\n                        transform: []\n                    };\n                    walkTree(child, newData);\n                }\n                break;\n            }\n        }\n    }\n    return walkTree;\n}\n/**\n * Assemble data sources that are derived from faceted data.\n */\nexport function assembleFacetData(root) {\n    const data = [];\n    const walkTree = makeWalkTree(data);\n    for (const child of root.children) {\n        walkTree(child, {\n            source: root.name,\n            name: null,\n            transform: []\n        });\n    }\n    return data;\n}\n/**\n * Create Vega data array from a given compiled model and append all of them to the given array\n *\n * @param  model\n * @param  data array\n * @return modified data array\n */\nexport function assembleRootData(dataComponent, datasets) {\n    var _a, _b;\n    const data = [];\n    // dataComponent.sources.forEach(debug);\n    // draw(dataComponent.sources);\n    const walkTree = makeWalkTree(data);\n    let sourceIndex = 0;\n    for (const root of dataComponent.sources) {\n        // assign a name if the source does not have a name yet\n        if (!root.hasName()) {\n            root.dataName = `source_${sourceIndex++}`;\n        }\n        const newData = root.assemble();\n        walkTree(root, newData);\n    }\n    // remove empty transform arrays for cleaner output\n    for (const d of data) {\n        if (d.transform.length === 0) {\n            delete d.transform;\n        }\n    }\n    // move sources without transforms (the ones that are potentially used in lookups) to the beginning\n    let whereTo = 0;\n    for (const [i, d] of data.entries()) {\n        if (((_a = d.transform) !== null && _a !== void 0 ? _a : []).length === 0 && !d.source) {\n            data.splice(whereTo++, 0, data.splice(i, 1)[0]);\n        }\n    }\n    // now fix the from references in lookup transforms\n    for (const d of data) {\n        for (const t of (_b = d.transform) !== null && _b !== void 0 ? _b : []) {\n            if (t.type === 'lookup') {\n                t.from = dataComponent.outputNodes[t.from].getSource();\n            }\n        }\n    }\n    // inline values for datasets that are in the datastore\n    for (const d of data) {\n        if (d.name in datasets) {\n            d.values = datasets[d.name];\n        }\n    }\n    return data;\n}\n//# sourceMappingURL=assemble.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isString } from 'vega-util';\nimport { binToString, isBinning, isSelectionExtent } from '../../bin';\nimport { binRequiresRange, isTypedFieldDef, normalizeBin, vgField } from '../../channeldef';\nimport { duplicate, hash, isEmpty, keys, replacePathInField, unique, vals, varName } from '../../util';\nimport { binFormatExpression } from '../format';\nimport { isUnitModel } from '../model';\nimport { parseSelectionBinExtent } from '../selection/parse';\nimport { DataFlowNode } from './dataflow';\nfunction rangeFormula(model, fieldDef, channel, config) {\n    var _a, _b;\n    if (binRequiresRange(fieldDef, channel)) {\n        // read format from axis or legend, if there is no format then use config.numberFormat\n        const guide = isUnitModel(model)\n            ? (_b = (_a = model.axis(channel)) !== null && _a !== void 0 ? _a : model.legend(channel)) !== null && _b !== void 0 ? _b : {} : {};\n        const startField = vgField(fieldDef, { expr: 'datum' });\n        const endField = vgField(fieldDef, { expr: 'datum', binSuffix: 'end' });\n        return {\n            formulaAs: vgField(fieldDef, { binSuffix: 'range', forAs: true }),\n            formula: binFormatExpression(startField, endField, guide.format, guide.formatType, config)\n        };\n    }\n    return {};\n}\nfunction binKey(bin, field) {\n    return `${binToString(bin)}_${field}`;\n}\nfunction getSignalsFromModel(model, key) {\n    return {\n        signal: model.getName(`${key}_bins`),\n        extentSignal: model.getName(`${key}_extent`)\n    };\n}\nexport function getBinSignalName(model, field, bin) {\n    var _a;\n    const normalizedBin = (_a = normalizeBin(bin, undefined)) !== null && _a !== void 0 ? _a : {};\n    const key = binKey(normalizedBin, field);\n    return model.getName(`${key}_bins`);\n}\nfunction isBinTransform(t) {\n    return 'as' in t;\n}\nfunction createBinComponent(t, bin, model) {\n    let as;\n    let span;\n    if (isBinTransform(t)) {\n        as = isString(t.as) ? [t.as, `${t.as}_end`] : [t.as[0], t.as[1]];\n    }\n    else {\n        as = [vgField(t, { forAs: true }), vgField(t, { binSuffix: 'end', forAs: true })];\n    }\n    const normalizedBin = Object.assign({}, normalizeBin(bin, undefined));\n    const key = binKey(normalizedBin, t.field);\n    const { signal, extentSignal } = getSignalsFromModel(model, key);\n    if (isSelectionExtent(normalizedBin.extent)) {\n        const ext = normalizedBin.extent;\n        const selName = ext.selection;\n        span = parseSelectionBinExtent(model.getSelectionComponent(varName(selName), selName), ext);\n        delete normalizedBin.extent; // Vega-Lite selection extent map to Vega's span property.\n    }\n    const binComponent = Object.assign(Object.assign(Object.assign({ bin: normalizedBin, field: t.field, as: [as] }, (signal ? { signal } : {})), (extentSignal ? { extentSignal } : {})), (span ? { span } : {}));\n    return { key, binComponent };\n}\nexport class BinNode extends DataFlowNode {\n    constructor(parent, bins) {\n        super(parent);\n        this.bins = bins;\n    }\n    clone() {\n        return new BinNode(null, duplicate(this.bins));\n    }\n    static makeFromEncoding(parent, model) {\n        const bins = model.reduceFieldDef((binComponentIndex, fieldDef, channel) => {\n            if (isTypedFieldDef(fieldDef) && isBinning(fieldDef.bin)) {\n                const { key, binComponent } = createBinComponent(fieldDef, fieldDef.bin, model);\n                binComponentIndex[key] = Object.assign(Object.assign(Object.assign({}, binComponent), binComponentIndex[key]), rangeFormula(model, fieldDef, channel, model.config));\n            }\n            return binComponentIndex;\n        }, {});\n        if (isEmpty(bins)) {\n            return null;\n        }\n        return new BinNode(parent, bins);\n    }\n    /**\n     * Creates a bin node from BinTransform.\n     * The optional parameter should provide\n     */\n    static makeFromTransform(parent, t, model) {\n        const { key, binComponent } = createBinComponent(t, t.bin, model);\n        return new BinNode(parent, {\n            [key]: binComponent\n        });\n    }\n    /**\n     * Merge bin nodes. This method either integrates the bin config from the other node\n     * or if this node already has a bin config, renames the corresponding signal in the model.\n     */\n    merge(other, renameSignal) {\n        for (const key of keys(other.bins)) {\n            if (key in this.bins) {\n                renameSignal(other.bins[key].signal, this.bins[key].signal);\n                // Ensure that we don't have duplicate names for signal pairs\n                this.bins[key].as = unique([...this.bins[key].as, ...other.bins[key].as], hash);\n            }\n            else {\n                this.bins[key] = other.bins[key];\n            }\n        }\n        for (const child of other.children) {\n            other.removeChild(child);\n            child.parent = this;\n        }\n        other.remove();\n    }\n    producedFields() {\n        return new Set(vals(this.bins)\n            .map(c => c.as)\n            .flat(2));\n    }\n    dependentFields() {\n        return new Set(vals(this.bins).map(c => c.field));\n    }\n    hash() {\n        return `Bin ${hash(this.bins)}`;\n    }\n    assemble() {\n        return vals(this.bins).flatMap(bin => {\n            const transform = [];\n            const [binAs, ...remainingAs] = bin.as;\n            const _a = bin.bin, { extent } = _a, params = __rest(_a, [\"extent\"]);\n            const binTrans = Object.assign(Object.assign(Object.assign({ type: 'bin', field: replacePathInField(bin.field), as: binAs, signal: bin.signal }, (!isSelectionExtent(extent) ? { extent } : { extent: null })), (bin.span ? { span: { signal: `span(${bin.span})` } } : {})), params);\n            if (!extent && bin.extentSignal) {\n                transform.push({\n                    type: 'extent',\n                    field: replacePathInField(bin.field),\n                    signal: bin.extentSignal\n                });\n                binTrans.extent = { signal: bin.extentSignal };\n            }\n            transform.push(binTrans);\n            for (const as of remainingAs) {\n                for (let i = 0; i < 2; i++) {\n                    transform.push({\n                        type: 'formula',\n                        expr: vgField({ field: binAs[i] }, { expr: 'datum' }),\n                        as: as[i]\n                    });\n                }\n            }\n            if (bin.formula) {\n                transform.push({\n                    type: 'formula',\n                    expr: bin.formula,\n                    as: bin.formulaAs\n                });\n            }\n            return transform;\n        });\n    }\n}\n//# sourceMappingURL=bin.js.map","import { isScaleFieldDef, vgField } from '../../channeldef';\nimport { fieldFilterExpression } from '../../predicate';\nimport { isSortArray } from '../../sort';\nimport { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\nimport { getDependentFields } from './expressions';\nexport class CalculateNode extends DataFlowNode {\n    constructor(parent, transform) {\n        super(parent);\n        this.transform = transform;\n        this._dependentFields = getDependentFields(this.transform.calculate);\n    }\n    clone() {\n        return new CalculateNode(null, duplicate(this.transform));\n    }\n    static parseAllForSortIndex(parent, model) {\n        // get all the encoding with sort fields from model\n        model.forEachFieldDef((fieldDef, channel) => {\n            if (!isScaleFieldDef(fieldDef)) {\n                return;\n            }\n            if (isSortArray(fieldDef.sort)) {\n                const { field, timeUnit } = fieldDef;\n                const sort = fieldDef.sort;\n                // generate `datum[\"a\"] === val0 ? 0 : datum[\"a\"] === val1 ? 1 : ... : n` via FieldEqualPredicate\n                const calculate = sort\n                    .map((sortValue, i) => {\n                    return `${fieldFilterExpression({ field, timeUnit, equal: sortValue })} ? ${i} : `;\n                })\n                    .join('') + sort.length;\n                parent = new CalculateNode(parent, {\n                    calculate,\n                    as: sortArrayIndexField(fieldDef, channel, { forAs: true })\n                });\n            }\n        });\n        return parent;\n    }\n    producedFields() {\n        return new Set([this.transform.as]);\n    }\n    dependentFields() {\n        return this._dependentFields;\n    }\n    assemble() {\n        return {\n            type: 'formula',\n            expr: this.transform.calculate,\n            as: this.transform.as\n        };\n    }\n    hash() {\n        return `Calculate ${hash(this.transform)}`;\n    }\n}\nexport function sortArrayIndexField(fieldDef, channel, opt) {\n    return vgField(fieldDef, Object.assign({ prefix: channel, suffix: 'sort_index' }, (opt !== null && opt !== void 0 ? opt : {})));\n}\n//# sourceMappingURL=calculate.js.map","import * as log from '../../log';\nimport { uniqueId } from '../../util';\n/**\n * A node in the dataflow tree.\n */\nexport class DataFlowNode {\n    constructor(parent, debugName) {\n        this.debugName = debugName;\n        this._children = [];\n        this._parent = null;\n        if (parent) {\n            this.parent = parent;\n        }\n    }\n    /**\n     * Clone this node with a deep copy but don't clone links to children or parents.\n     */\n    clone() {\n        throw new Error('Cannot clone node');\n    }\n    get parent() {\n        return this._parent;\n    }\n    /**\n     * Set the parent of the node and also add this node to the parent's children.\n     */\n    set parent(parent) {\n        this._parent = parent;\n        if (parent) {\n            parent.addChild(this);\n        }\n    }\n    get children() {\n        return this._children;\n    }\n    numChildren() {\n        return this._children.length;\n    }\n    addChild(child, loc) {\n        // do not add the same child twice\n        if (this._children.indexOf(child) > -1) {\n            log.warn(log.message.ADD_SAME_CHILD_TWICE);\n            return;\n        }\n        if (loc !== undefined) {\n            this._children.splice(loc, 0, child);\n        }\n        else {\n            this._children.push(child);\n        }\n    }\n    removeChild(oldChild) {\n        const loc = this._children.indexOf(oldChild);\n        this._children.splice(loc, 1);\n        return loc;\n    }\n    /**\n     * Remove node from the dataflow.\n     */\n    remove() {\n        let loc = this._parent.removeChild(this);\n        for (const child of this._children) {\n            // do not use the set method because we want to insert at a particular location\n            child._parent = this._parent;\n            this._parent.addChild(child, loc++);\n        }\n    }\n    /**\n     * Insert another node as a parent of this node.\n     */\n    insertAsParentOf(other) {\n        const parent = other.parent;\n        parent.removeChild(this);\n        this.parent = parent;\n        other.parent = this;\n    }\n    swapWithParent() {\n        const parent = this._parent;\n        const newParent = parent.parent;\n        // reconnect the children\n        for (const child of this._children) {\n            child.parent = parent;\n        }\n        // remove old links\n        this._children = []; // equivalent to removing every child link one by one\n        parent.removeChild(this);\n        parent.parent.removeChild(parent);\n        // swap two nodes\n        this.parent = newParent;\n        parent.parent = this;\n    }\n}\nexport class OutputNode extends DataFlowNode {\n    /**\n     * @param source The name of the source. Will change in assemble.\n     * @param type The type of the output node.\n     * @param refCounts A global ref counter map.\n     */\n    constructor(parent, source, type, refCounts) {\n        super(parent, source);\n        this.type = type;\n        this.refCounts = refCounts;\n        this._source = this._name = source;\n        if (this.refCounts && !(this._name in this.refCounts)) {\n            this.refCounts[this._name] = 0;\n        }\n    }\n    clone() {\n        const cloneObj = new this.constructor();\n        cloneObj.debugName = 'clone_' + this.debugName;\n        cloneObj._source = this._source;\n        cloneObj._name = 'clone_' + this._name;\n        cloneObj.type = this.type;\n        cloneObj.refCounts = this.refCounts;\n        cloneObj.refCounts[cloneObj._name] = 0;\n        return cloneObj;\n    }\n    dependentFields() {\n        return new Set();\n    }\n    producedFields() {\n        return new Set();\n    }\n    hash() {\n        if (this._hash === undefined) {\n            this._hash = `Output ${uniqueId()}`;\n        }\n        return this._hash;\n    }\n    /**\n     * Request the datasource name and increase the ref counter.\n     *\n     * During the parsing phase, this will return the simple name such as 'main' or 'raw'.\n     * It is crucial to request the name from an output node to mark it as a required node.\n     * If nobody ever requests the name, this datasource will not be instantiated in the assemble phase.\n     *\n     * In the assemble phase, this will return the correct name.\n     */\n    getSource() {\n        this.refCounts[this._name]++;\n        return this._source;\n    }\n    isRequired() {\n        return !!this.refCounts[this._name];\n    }\n    setSource(source) {\n        this._source = source;\n    }\n}\n//# sourceMappingURL=dataflow.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for density transform nodes\n */\nexport class DensityTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        var _a, _b, _c;\n        super(parent);\n        this.transform = transform;\n        this.transform = duplicate(transform); // duplicate to prevent side effects\n        const specifiedAs = (_a = this.transform.as) !== null && _a !== void 0 ? _a : [undefined, undefined];\n        this.transform.as = [(_b = specifiedAs[0]) !== null && _b !== void 0 ? _b : 'value', (_c = specifiedAs[1]) !== null && _c !== void 0 ? _c : 'density'];\n    }\n    clone() {\n        return new DensityTransformNode(null, duplicate(this.transform));\n    }\n    dependentFields() {\n        var _a;\n        return new Set([this.transform.density, ...((_a = this.transform.groupby) !== null && _a !== void 0 ? _a : [])]);\n    }\n    producedFields() {\n        return new Set(this.transform.as);\n    }\n    hash() {\n        return `DensityTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        const _a = this.transform, { density } = _a, rest = __rest(_a, [\"density\"]);\n        const result = Object.assign({ type: 'kde', field: density }, rest);\n        return result;\n    }\n}\n//# sourceMappingURL=density.js.map","import { parse } from 'vega-expression';\nfunction getName(node) {\n    const name = [];\n    if (node.type === 'Identifier') {\n        return [node.name];\n    }\n    if (node.type === 'Literal') {\n        return [node.value];\n    }\n    if (node.type === 'MemberExpression') {\n        name.push(...getName(node.object));\n        name.push(...getName(node.property));\n    }\n    return name;\n}\nfunction startsWithDatum(node) {\n    if (node.object.type === 'MemberExpression') {\n        return startsWithDatum(node.object);\n    }\n    return node.object.name === 'datum';\n}\nexport function getDependentFields(expression) {\n    const ast = parse(expression);\n    const dependents = new Set();\n    ast.visit((node) => {\n        if (node.type === 'MemberExpression' && startsWithDatum(node)) {\n            dependents.add(getName(node).slice(1).join('.'));\n        }\n    });\n    return dependents;\n}\n//# sourceMappingURL=expressions.js.map","import { isArray } from 'vega-util';\nimport { isBinning } from '../../bin';\nimport { COLUMN, FACET_CHANNELS, POSITION_SCALE_CHANNELS, ROW } from '../../channel';\nimport { vgField } from '../../channeldef';\nimport * as log from '../../log';\nimport { hasDiscreteDomain } from '../../scale';\nimport { DEFAULT_SORT_OP, isSortField } from '../../sort';\nimport { hash } from '../../util';\nimport { isVgRangeStep } from '../../vega.schema';\nimport { HEADER_CHANNELS, HEADER_TYPES } from '../header/component';\nimport { assembleDomain, getFieldFromDomain } from '../scale/domain';\nimport { sortArrayIndexField } from './calculate';\nimport { DataFlowNode } from './dataflow';\n/**\n * A node that helps us track what fields we are faceting by.\n */\nexport class FacetNode extends DataFlowNode {\n    /**\n     * @param model The facet model.\n     * @param name The name that this facet source will have.\n     * @param data The source data for this facet data.\n     */\n    constructor(parent, model, name, data) {\n        super(parent);\n        this.model = model;\n        this.name = name;\n        this.data = data;\n        for (const channel of FACET_CHANNELS) {\n            const fieldDef = model.facet[channel];\n            if (fieldDef) {\n                const { bin, sort } = fieldDef;\n                this[channel] = Object.assign({ name: model.getName(`${channel}_domain`), fields: [vgField(fieldDef), ...(isBinning(bin) ? [vgField(fieldDef, { binSuffix: 'end' })] : [])] }, (isSortField(sort)\n                    ? { sortField: sort }\n                    : isArray(sort)\n                        ? { sortIndexField: sortArrayIndexField(fieldDef, channel) }\n                        : {}));\n            }\n        }\n        this.childModel = model.child;\n    }\n    hash() {\n        let out = `Facet`;\n        for (const channel of FACET_CHANNELS) {\n            if (this[channel]) {\n                out += ` ${channel.charAt(0)}:${hash(this[channel])}`;\n            }\n        }\n        return out;\n    }\n    get fields() {\n        var _a;\n        const f = [];\n        for (const channel of FACET_CHANNELS) {\n            if ((_a = this[channel]) === null || _a === void 0 ? void 0 : _a.fields) {\n                f.push(...this[channel].fields);\n            }\n        }\n        return f;\n    }\n    dependentFields() {\n        const depFields = new Set(this.fields);\n        for (const channel of FACET_CHANNELS) {\n            if (this[channel]) {\n                if (this[channel].sortField) {\n                    depFields.add(this[channel].sortField.field);\n                }\n                if (this[channel].sortIndexField) {\n                    depFields.add(this[channel].sortIndexField);\n                }\n            }\n        }\n        return depFields;\n    }\n    producedFields() {\n        return new Set(); // facet does not produce any new fields\n    }\n    /**\n     * The name to reference this source is its name.\n     */\n    getSource() {\n        return this.name;\n    }\n    getChildIndependentFieldsWithStep() {\n        const childIndependentFieldsWithStep = {};\n        for (const channel of POSITION_SCALE_CHANNELS) {\n            const childScaleComponent = this.childModel.component.scales[channel];\n            if (childScaleComponent && !childScaleComponent.merged) {\n                // independent scale\n                const type = childScaleComponent.get('type');\n                const range = childScaleComponent.get('range');\n                if (hasDiscreteDomain(type) && isVgRangeStep(range)) {\n                    const domain = assembleDomain(this.childModel, channel);\n                    const field = getFieldFromDomain(domain);\n                    if (field) {\n                        childIndependentFieldsWithStep[channel] = field;\n                    }\n                    else {\n                        log.warn(log.message.unknownField(channel));\n                    }\n                }\n            }\n        }\n        return childIndependentFieldsWithStep;\n    }\n    assembleRowColumnHeaderData(channel, crossedDataName, childIndependentFieldsWithStep) {\n        const childChannel = { row: 'y', column: 'x' }[channel];\n        const fields = [];\n        const ops = [];\n        const as = [];\n        if (childIndependentFieldsWithStep && childIndependentFieldsWithStep[childChannel]) {\n            if (crossedDataName) {\n                // If there is a crossed data, calculate max\n                fields.push(`distinct_${childIndependentFieldsWithStep[childChannel]}`);\n                ops.push('max');\n            }\n            else {\n                // If there is no crossed data, just calculate distinct\n                fields.push(childIndependentFieldsWithStep[childChannel]);\n                ops.push('distinct');\n            }\n            // Although it is technically a max, just name it distinct so it's easier to refer to it\n            as.push(`distinct_${childIndependentFieldsWithStep[childChannel]}`);\n        }\n        const { sortField, sortIndexField } = this[channel];\n        if (sortField) {\n            const { op = DEFAULT_SORT_OP, field } = sortField;\n            fields.push(field);\n            ops.push(op);\n            as.push(vgField(sortField, { forAs: true }));\n        }\n        else if (sortIndexField) {\n            fields.push(sortIndexField);\n            ops.push('max');\n            as.push(sortIndexField);\n        }\n        return {\n            name: this[channel].name,\n            // Use data from the crossed one if it exist\n            source: crossedDataName !== null && crossedDataName !== void 0 ? crossedDataName : this.data,\n            transform: [\n                Object.assign({ type: 'aggregate', groupby: this[channel].fields }, (fields.length\n                    ? {\n                        fields,\n                        ops,\n                        as\n                    }\n                    : {}))\n            ]\n        };\n    }\n    assembleFacetHeaderData(childIndependentFieldsWithStep) {\n        var _a, _b;\n        const { columns } = this.model.layout;\n        const { layoutHeaders } = this.model.component;\n        const data = [];\n        const hasSharedAxis = {};\n        for (const headerChannel of HEADER_CHANNELS) {\n            for (const headerType of HEADER_TYPES) {\n                const headers = (_a = (layoutHeaders[headerChannel] && layoutHeaders[headerChannel][headerType])) !== null && _a !== void 0 ? _a : [];\n                for (const header of headers) {\n                    if (((_b = header.axes) === null || _b === void 0 ? void 0 : _b.length) > 0) {\n                        hasSharedAxis[headerChannel] = true;\n                        break;\n                    }\n                }\n            }\n            if (hasSharedAxis[headerChannel]) {\n                const cardinality = `length(data(\"${this.facet.name}\"))`;\n                const stop = headerChannel === 'row'\n                    ? columns\n                        ? { signal: `ceil(${cardinality} / ${columns})` }\n                        : 1\n                    : columns\n                        ? { signal: `min(${cardinality}, ${columns})` }\n                        : { signal: cardinality };\n                data.push({\n                    name: `${this.facet.name}_${headerChannel}`,\n                    transform: [\n                        {\n                            type: 'sequence',\n                            start: 0,\n                            stop\n                        }\n                    ]\n                });\n            }\n        }\n        const { row, column } = hasSharedAxis;\n        if (row || column) {\n            data.unshift(this.assembleRowColumnHeaderData('facet', null, childIndependentFieldsWithStep));\n        }\n        return data;\n    }\n    assemble() {\n        var _a, _b;\n        const data = [];\n        let crossedDataName = null;\n        const childIndependentFieldsWithStep = this.getChildIndependentFieldsWithStep();\n        const { column, row, facet } = this;\n        if (column && row && (childIndependentFieldsWithStep.x || childIndependentFieldsWithStep.y)) {\n            // Need to create a cross dataset to correctly calculate cardinality\n            crossedDataName = `cross_${this.column.name}_${this.row.name}`;\n            const fields = [].concat((_a = childIndependentFieldsWithStep.x) !== null && _a !== void 0 ? _a : [], (_b = childIndependentFieldsWithStep.y) !== null && _b !== void 0 ? _b : []);\n            const ops = fields.map(() => 'distinct');\n            data.push({\n                name: crossedDataName,\n                source: this.data,\n                transform: [\n                    {\n                        type: 'aggregate',\n                        groupby: this.fields,\n                        fields,\n                        ops\n                    }\n                ]\n            });\n        }\n        for (const channel of [COLUMN, ROW]) {\n            if (this[channel]) {\n                data.push(this.assembleRowColumnHeaderData(channel, crossedDataName, childIndependentFieldsWithStep));\n            }\n        }\n        if (facet) {\n            const facetData = this.assembleFacetHeaderData(childIndependentFieldsWithStep);\n            if (facetData) {\n                data.push(...facetData);\n            }\n        }\n        return data;\n    }\n}\n//# sourceMappingURL=facet.js.map","import { duplicate } from '../../util';\nimport { expression } from '../predicate';\nimport { DataFlowNode } from './dataflow';\nimport { getDependentFields } from './expressions';\nexport class FilterNode extends DataFlowNode {\n    constructor(parent, model, filter) {\n        super(parent);\n        this.model = model;\n        this.filter = filter;\n        // TODO: refactor this to not take a node and\n        // then add a static function makeFromOperand and make the constructor take only an expression\n        this.expr = expression(this.model, this.filter, this);\n        this._dependentFields = getDependentFields(this.expr);\n    }\n    clone() {\n        return new FilterNode(null, this.model, duplicate(this.filter));\n    }\n    dependentFields() {\n        return this._dependentFields;\n    }\n    producedFields() {\n        return new Set(); // filter does not produce any new fields\n    }\n    assemble() {\n        return {\n            type: 'filter',\n            expr: this.expr\n        };\n    }\n    hash() {\n        return `Filter ${this.expr}`;\n    }\n}\n//# sourceMappingURL=filter.js.map","import { isScaleChannel } from '../../channel';\nimport { vgField as fieldRef } from '../../channeldef';\nimport { isPathMark } from '../../mark';\nimport { hasContinuousDomain } from '../../scale';\nimport { hash, keys } from '../../util';\nimport { getMarkPropOrConfig } from '../common';\nimport { DataFlowNode } from './dataflow';\nexport class FilterInvalidNode extends DataFlowNode {\n    constructor(parent, filter) {\n        super(parent);\n        this.filter = filter;\n    }\n    clone() {\n        return new FilterInvalidNode(null, Object.assign({}, this.filter));\n    }\n    static make(parent, model) {\n        const { config, mark, markDef } = model;\n        const invalid = getMarkPropOrConfig('invalid', markDef, config);\n        if (invalid !== 'filter') {\n            return null;\n        }\n        const filter = model.reduceFieldDef((aggregator, fieldDef, channel) => {\n            const scaleComponent = isScaleChannel(channel) && model.getScaleComponent(channel);\n            if (scaleComponent) {\n                const scaleType = scaleComponent.get('type');\n                // While discrete domain scales can handle invalid values, continuous scales can't.\n                // Thus, for non-path marks, we have to filter null for scales with continuous domains.\n                // (For path marks, we will use \"defined\" property and skip these values instead.)\n                if (hasContinuousDomain(scaleType) && fieldDef.aggregate !== 'count' && !isPathMark(mark)) {\n                    aggregator[fieldDef.field] = fieldDef; // we know that the fieldDef is a typed field def\n                }\n            }\n            return aggregator;\n        }, {});\n        if (!keys(filter).length) {\n            return null;\n        }\n        return new FilterInvalidNode(parent, filter);\n    }\n    dependentFields() {\n        return new Set(keys(this.filter));\n    }\n    producedFields() {\n        return new Set(); // filter does not produce any new fields\n    }\n    hash() {\n        return `FilterInvalid ${hash(this.filter)}`;\n    }\n    /**\n     * Create the VgTransforms for each of the filtered fields.\n     */\n    assemble() {\n        const filters = keys(this.filter).reduce((vegaFilters, field) => {\n            const fieldDef = this.filter[field];\n            const ref = fieldRef(fieldDef, { expr: 'datum' });\n            if (fieldDef !== null) {\n                if (fieldDef.type === 'temporal') {\n                    vegaFilters.push(`(isDate(${ref}) || (isValid(${ref}) && isFinite(+${ref})))`);\n                }\n                else if (fieldDef.type === 'quantitative') {\n                    vegaFilters.push(`isValid(${ref})`);\n                    vegaFilters.push(`isFinite(+${ref})`);\n                }\n                else {\n                    // should never get here\n                }\n            }\n            return vegaFilters;\n        }, []);\n        return filters.length > 0\n            ? {\n                type: 'filter',\n                expr: filters.join(' && ')\n            }\n            : null;\n    }\n}\n//# sourceMappingURL=filterinvalid.js.map","import { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for flatten transform nodes\n */\nexport class FlattenTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        super(parent);\n        this.transform = transform;\n        this.transform = duplicate(transform); // duplicate to prevent side effects\n        const { flatten, as = [] } = this.transform;\n        this.transform.as = flatten.map((f, i) => { var _a; return (_a = as[i]) !== null && _a !== void 0 ? _a : f; });\n    }\n    clone() {\n        return new FlattenTransformNode(this.parent, duplicate(this.transform));\n    }\n    dependentFields() {\n        return new Set(this.transform.flatten);\n    }\n    producedFields() {\n        return new Set(this.transform.as);\n    }\n    hash() {\n        return `FlattenTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        const { flatten: fields, as } = this.transform;\n        const result = {\n            type: 'flatten',\n            fields,\n            as\n        };\n        return result;\n    }\n}\n//# sourceMappingURL=flatten.js.map","import { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for flatten transform nodes\n */\nexport class FoldTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        var _a, _b, _c;\n        super(parent);\n        this.transform = transform;\n        this.transform = duplicate(transform); // duplicate to prevent side effects\n        const specifiedAs = (_a = this.transform.as) !== null && _a !== void 0 ? _a : [undefined, undefined];\n        this.transform.as = [(_b = specifiedAs[0]) !== null && _b !== void 0 ? _b : 'key', (_c = specifiedAs[1]) !== null && _c !== void 0 ? _c : 'value'];\n    }\n    clone() {\n        return new FoldTransformNode(null, duplicate(this.transform));\n    }\n    dependentFields() {\n        return new Set(this.transform.fold);\n    }\n    producedFields() {\n        return new Set(this.transform.as);\n    }\n    hash() {\n        return `FoldTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        const { fold, as } = this.transform;\n        const result = {\n            type: 'fold',\n            fields: fold,\n            as\n        };\n        return result;\n    }\n}\n//# sourceMappingURL=fold.js.map","import { isNumber, isString } from 'vega-util';\nimport { isMinMaxOp } from '../../aggregate';\nimport { getMainRangeChannel } from '../../channel';\nimport { isFieldDef, isFieldOrDatumDefForTimeFormat, isScaleFieldDef, isTypedFieldDef } from '../../channeldef';\nimport { isGenerator } from '../../data';\nimport { isDateTime } from '../../datetime';\nimport * as log from '../../log';\nimport { forEachLeaf } from '../../logical';\nimport { isPathMark } from '../../mark';\nimport { isFieldEqualPredicate, isFieldGTEPredicate, isFieldGTPredicate, isFieldLTEPredicate, isFieldLTPredicate, isFieldOneOfPredicate, isFieldPredicate, isFieldRangePredicate } from '../../predicate';\nimport { isSortField } from '../../sort';\nimport { accessPathDepth, accessPathWithDatum, duplicate, hash, keys, removePathFromField } from '../../util';\nimport { signalRefOrValue } from '../common';\nimport { isFacetModel, isUnitModel } from '../model';\nimport { Split } from '../split';\nimport { DataFlowNode } from './dataflow';\n/**\n * Remove quotes from a string.\n */\nfunction unquote(pattern) {\n    if ((pattern[0] === \"'\" && pattern[pattern.length - 1] === \"'\") ||\n        (pattern[0] === '\"' && pattern[pattern.length - 1] === '\"')) {\n        return pattern.slice(1, -1);\n    }\n    return pattern;\n}\n/**\n * @param field The field.\n * @param parse What to parse the field as.\n */\nfunction parseExpression(field, parse) {\n    const f = accessPathWithDatum(field);\n    if (parse === 'number') {\n        return `toNumber(${f})`;\n    }\n    else if (parse === 'boolean') {\n        return `toBoolean(${f})`;\n    }\n    else if (parse === 'string') {\n        return `toString(${f})`;\n    }\n    else if (parse === 'date') {\n        return `toDate(${f})`;\n    }\n    else if (parse === 'flatten') {\n        return f;\n    }\n    else if (parse.indexOf('date:') === 0) {\n        const specifier = unquote(parse.slice(5, parse.length));\n        return `timeParse(${f},'${specifier}')`;\n    }\n    else if (parse.indexOf('utc:') === 0) {\n        const specifier = unquote(parse.slice(4, parse.length));\n        return `utcParse(${f},'${specifier}')`;\n    }\n    else {\n        log.warn(log.message.unrecognizedParse(parse));\n        return null;\n    }\n}\nexport function getImplicitFromFilterTransform(transform) {\n    const implicit = {};\n    forEachLeaf(transform.filter, filter => {\n        var _a;\n        if (isFieldPredicate(filter)) {\n            // Automatically add a parse node for filters with filter objects\n            let val = null;\n            // For EqualFilter, just use the equal property.\n            // For RangeFilter and OneOfFilter, all array members should have\n            // the same type, so we only use the first one.\n            if (isFieldEqualPredicate(filter)) {\n                val = signalRefOrValue(filter.equal);\n            }\n            else if (isFieldLTEPredicate(filter)) {\n                val = signalRefOrValue(filter.lte);\n            }\n            else if (isFieldLTPredicate(filter)) {\n                val = signalRefOrValue(filter.lt);\n            }\n            else if (isFieldGTPredicate(filter)) {\n                val = signalRefOrValue(filter.gt);\n            }\n            else if (isFieldGTEPredicate(filter)) {\n                val = signalRefOrValue(filter.gte);\n            }\n            else if (isFieldRangePredicate(filter)) {\n                val = filter.range[0];\n            }\n            else if (isFieldOneOfPredicate(filter)) {\n                val = ((_a = filter.oneOf) !== null && _a !== void 0 ? _a : filter['in'])[0];\n            } // else -- for filter expression, we can't infer anything\n            if (val) {\n                if (isDateTime(val)) {\n                    implicit[filter.field] = 'date';\n                }\n                else if (isNumber(val)) {\n                    implicit[filter.field] = 'number';\n                }\n                else if (isString(val)) {\n                    implicit[filter.field] = 'string';\n                }\n            }\n            if (filter.timeUnit) {\n                implicit[filter.field] = 'date';\n            }\n        }\n    });\n    return implicit;\n}\n/**\n * Creates a parse node for implicit parsing from a model and updates ancestorParse.\n */\nexport function getImplicitFromEncoding(model) {\n    const implicit = {};\n    function add(fieldDef) {\n        if (isFieldOrDatumDefForTimeFormat(fieldDef)) {\n            implicit[fieldDef.field] = 'date';\n        }\n        else if (fieldDef.type === 'quantitative' &&\n            isMinMaxOp(fieldDef.aggregate) // we need to parse numbers to support correct min and max\n        ) {\n            implicit[fieldDef.field] = 'number';\n        }\n        else if (accessPathDepth(fieldDef.field) > 1) {\n            // For non-date/non-number (strings and booleans), derive a flattened field for a referenced nested field.\n            // (Parsing numbers / dates already flattens numeric and temporal fields.)\n            if (!(fieldDef.field in implicit)) {\n                implicit[fieldDef.field] = 'flatten';\n            }\n        }\n        else if (isScaleFieldDef(fieldDef) && isSortField(fieldDef.sort) && accessPathDepth(fieldDef.sort.field) > 1) {\n            // Flatten fields that we sort by but that are not otherwise flattened.\n            if (!(fieldDef.sort.field in implicit)) {\n                implicit[fieldDef.sort.field] = 'flatten';\n            }\n        }\n    }\n    if (isUnitModel(model) || isFacetModel(model)) {\n        // Parse encoded fields\n        model.forEachFieldDef((fieldDef, channel) => {\n            if (isTypedFieldDef(fieldDef)) {\n                add(fieldDef);\n            }\n            else {\n                const mainChannel = getMainRangeChannel(channel);\n                const mainFieldDef = model.fieldDef(mainChannel);\n                add(Object.assign(Object.assign({}, fieldDef), { type: mainFieldDef.type }));\n            }\n        });\n    }\n    // Parse quantitative dimension fields of path marks as numbers so that we sort them correctly.\n    if (isUnitModel(model)) {\n        const { mark, markDef, encoding } = model;\n        if (isPathMark(mark) &&\n            // No need to sort by dimension if we have a connected scatterplot (order channel is present)\n            !model.encoding.order) {\n            const dimensionChannel = markDef.orient === 'horizontal' ? 'y' : 'x';\n            const dimensionChannelDef = encoding[dimensionChannel];\n            if (isFieldDef(dimensionChannelDef) &&\n                dimensionChannelDef.type === 'quantitative' &&\n                !(dimensionChannelDef.field in implicit)) {\n                implicit[dimensionChannelDef.field] = 'number';\n            }\n        }\n    }\n    return implicit;\n}\n/**\n * Creates a parse node for implicit parsing from a model and updates ancestorParse.\n */\nexport function getImplicitFromSelection(model) {\n    const implicit = {};\n    if (isUnitModel(model) && model.component.selection) {\n        for (const name of keys(model.component.selection)) {\n            const selCmpt = model.component.selection[name];\n            for (const proj of selCmpt.project.items) {\n                if (!proj.channel && accessPathDepth(proj.field) > 1) {\n                    implicit[proj.field] = 'flatten';\n                }\n            }\n        }\n    }\n    return implicit;\n}\nexport class ParseNode extends DataFlowNode {\n    constructor(parent, parse) {\n        super(parent);\n        this._parse = parse;\n    }\n    clone() {\n        return new ParseNode(null, duplicate(this._parse));\n    }\n    hash() {\n        return `Parse ${hash(this._parse)}`;\n    }\n    /**\n     * Creates a parse node from a data.format.parse and updates ancestorParse.\n     */\n    static makeExplicit(parent, model, ancestorParse) {\n        // Custom parse\n        let explicit = {};\n        const data = model.data;\n        if (!isGenerator(data) && data && data.format && data.format.parse) {\n            explicit = data.format.parse;\n        }\n        return this.makeWithAncestors(parent, explicit, {}, ancestorParse);\n    }\n    /**\n     * Creates a parse node from \"explicit\" parse and \"implicit\" parse and updates ancestorParse.\n     */\n    static makeWithAncestors(parent, explicit, implicit, ancestorParse) {\n        // We should not parse what has already been parsed in a parent (explicitly or implicitly) or what has been derived (maked as \"derived\"). We also don't need to flatten a field that has already been parsed.\n        for (const field of keys(implicit)) {\n            const parsedAs = ancestorParse.getWithExplicit(field);\n            if (parsedAs.value !== undefined) {\n                // We always ignore derived fields even if they are implicitly defined because we expect users to create the right types.\n                if (parsedAs.explicit ||\n                    parsedAs.value === implicit[field] ||\n                    parsedAs.value === 'derived' ||\n                    implicit[field] === 'flatten') {\n                    delete implicit[field];\n                }\n                else {\n                    log.warn(log.message.differentParse(field, implicit[field], parsedAs.value));\n                }\n            }\n        }\n        for (const field of keys(explicit)) {\n            const parsedAs = ancestorParse.get(field);\n            if (parsedAs !== undefined) {\n                // Don't parse a field again if it has been parsed with the same type already.\n                if (parsedAs === explicit[field]) {\n                    delete explicit[field];\n                }\n                else {\n                    log.warn(log.message.differentParse(field, explicit[field], parsedAs));\n                }\n            }\n        }\n        const parse = new Split(explicit, implicit);\n        // add the format parse from this model so that children don't parse the same field again\n        ancestorParse.copyAll(parse);\n        // copy only non-null parses\n        const p = {};\n        for (const key of keys(parse.combine())) {\n            const val = parse.get(key);\n            if (val !== null) {\n                p[key] = val;\n            }\n        }\n        if (keys(p).length === 0 || ancestorParse.parseNothing) {\n            return null;\n        }\n        return new ParseNode(parent, p);\n    }\n    get parse() {\n        return this._parse;\n    }\n    merge(other) {\n        this._parse = Object.assign(Object.assign({}, this._parse), other.parse);\n        other.remove();\n    }\n    /**\n     * Assemble an object for Vega's format.parse property.\n     */\n    assembleFormatParse() {\n        const formatParse = {};\n        for (const field of keys(this._parse)) {\n            const p = this._parse[field];\n            if (accessPathDepth(field) === 1) {\n                formatParse[field] = p;\n            }\n        }\n        return formatParse;\n    }\n    // format parse depends and produces all fields in its parse\n    producedFields() {\n        return new Set(keys(this._parse));\n    }\n    dependentFields() {\n        return new Set(keys(this._parse));\n    }\n    assembleTransforms(onlyNested = false) {\n        return keys(this._parse)\n            .filter(field => (onlyNested ? accessPathDepth(field) > 1 : true))\n            .map(field => {\n            const expr = parseExpression(field, this._parse[field]);\n            if (!expr) {\n                return null;\n            }\n            const formula = {\n                type: 'formula',\n                expr,\n                as: removePathFromField(field) // Vega output is always flattened\n            };\n            return formula;\n        })\n            .filter(t => t !== null);\n    }\n}\n//# sourceMappingURL=formatparse.js.map","import { isString } from 'vega-util';\nimport { LATITUDE, LATITUDE2, LONGITUDE, LONGITUDE2, SHAPE } from '../../channel';\nimport { getFieldOrDatumDef, isDatumDef, isFieldDef, isValueDef } from '../../channeldef';\nimport { GEOJSON } from '../../type';\nimport { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\nexport class GeoJSONNode extends DataFlowNode {\n    constructor(parent, fields, geojson, signal) {\n        super(parent);\n        this.fields = fields;\n        this.geojson = geojson;\n        this.signal = signal;\n    }\n    clone() {\n        return new GeoJSONNode(null, duplicate(this.fields), this.geojson, this.signal);\n    }\n    static parseAll(parent, model) {\n        if (model.component.projection && !model.component.projection.isFit) {\n            return parent;\n        }\n        let geoJsonCounter = 0;\n        for (const coordinates of [\n            [LONGITUDE, LATITUDE],\n            [LONGITUDE2, LATITUDE2]\n        ]) {\n            const pair = coordinates.map(channel => {\n                const def = getFieldOrDatumDef(model.encoding[channel]);\n                return isFieldDef(def)\n                    ? def.field\n                    : isDatumDef(def)\n                        ? { expr: `${def.datum}` }\n                        : isValueDef(def)\n                            ? { expr: `${def['value']}` }\n                            : undefined;\n            });\n            if (pair[0] || pair[1]) {\n                parent = new GeoJSONNode(parent, pair, null, model.getName(`geojson_${geoJsonCounter++}`));\n            }\n        }\n        if (model.channelHasField(SHAPE)) {\n            const fieldDef = model.typedFieldDef(SHAPE);\n            if (fieldDef.type === GEOJSON) {\n                parent = new GeoJSONNode(parent, null, fieldDef.field, model.getName(`geojson_${geoJsonCounter++}`));\n            }\n        }\n        return parent;\n    }\n    dependentFields() {\n        var _a;\n        const fields = ((_a = this.fields) !== null && _a !== void 0 ? _a : []).filter(isString);\n        return new Set([...(this.geojson ? [this.geojson] : []), ...fields]);\n    }\n    producedFields() {\n        return new Set();\n    }\n    hash() {\n        return `GeoJSON ${this.geojson} ${this.signal} ${hash(this.fields)}`;\n    }\n    assemble() {\n        return Object.assign(Object.assign(Object.assign({ type: 'geojson' }, (this.fields ? { fields: this.fields } : {})), (this.geojson ? { geojson: this.geojson } : {})), { signal: this.signal });\n    }\n}\n//# sourceMappingURL=geojson.js.map","import { isString } from 'vega-util';\nimport { LATITUDE, LATITUDE2, LONGITUDE, LONGITUDE2 } from '../../channel';\nimport { getFieldOrDatumDef, isDatumDef, isFieldDef, isValueDef } from '../../channeldef';\nimport { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\nexport class GeoPointNode extends DataFlowNode {\n    constructor(parent, projection, fields, as) {\n        super(parent);\n        this.projection = projection;\n        this.fields = fields;\n        this.as = as;\n    }\n    clone() {\n        return new GeoPointNode(null, this.projection, duplicate(this.fields), duplicate(this.as));\n    }\n    static parseAll(parent, model) {\n        if (!model.projectionName()) {\n            return parent;\n        }\n        for (const coordinates of [\n            [LONGITUDE, LATITUDE],\n            [LONGITUDE2, LATITUDE2]\n        ]) {\n            const pair = coordinates.map(channel => {\n                const def = getFieldOrDatumDef(model.encoding[channel]);\n                return isFieldDef(def)\n                    ? def.field\n                    : isDatumDef(def)\n                        ? { expr: `${def.datum}` }\n                        : isValueDef(def)\n                            ? { expr: `${def['value']}` }\n                            : undefined;\n            });\n            const suffix = coordinates[0] === LONGITUDE2 ? '2' : '';\n            if (pair[0] || pair[1]) {\n                parent = new GeoPointNode(parent, model.projectionName(), pair, [\n                    model.getName('x' + suffix),\n                    model.getName('y' + suffix)\n                ]);\n            }\n        }\n        return parent;\n    }\n    dependentFields() {\n        return new Set(this.fields.filter(isString));\n    }\n    producedFields() {\n        return new Set(this.as);\n    }\n    hash() {\n        return `Geopoint ${this.projection} ${hash(this.fields)} ${hash(this.as)}`;\n    }\n    assemble() {\n        return {\n            type: 'geopoint',\n            projection: this.projection,\n            fields: this.fields,\n            as: this.as\n        };\n    }\n}\n//# sourceMappingURL=geopoint.js.map","import { hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\nexport class GraticuleNode extends DataFlowNode {\n    constructor(parent, params) {\n        super(parent);\n        this.params = params;\n    }\n    clone() {\n        return new GraticuleNode(null, this.params);\n    }\n    dependentFields() {\n        return new Set();\n    }\n    producedFields() {\n        return undefined; // there should never be a node before graticule\n    }\n    hash() {\n        return `Graticule ${hash(this.params)}`;\n    }\n    assemble() {\n        return Object.assign({ type: 'graticule' }, (this.params === true ? {} : this.params));\n    }\n}\n//# sourceMappingURL=graticule.js.map","import { SELECTION_ID } from '../../selection';\nimport { DataFlowNode } from './dataflow';\nexport class IdentifierNode extends DataFlowNode {\n    clone() {\n        return new IdentifierNode(null);\n    }\n    constructor(parent) {\n        super(parent);\n    }\n    dependentFields() {\n        return new Set();\n    }\n    producedFields() {\n        return new Set([SELECTION_ID]);\n    }\n    hash() {\n        return 'Identifier';\n    }\n    assemble() {\n        return { type: 'identifier', as: SELECTION_ID };\n    }\n}\n//# sourceMappingURL=identifier.js.map","import { isFieldDef } from '../../channeldef';\nimport { pathGroupingFields } from '../../encoding';\nimport { isImputeSequence } from '../../transform';\nimport { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\nexport class ImputeNode extends DataFlowNode {\n    constructor(parent, transform) {\n        super(parent);\n        this.transform = transform;\n    }\n    clone() {\n        return new ImputeNode(null, duplicate(this.transform));\n    }\n    dependentFields() {\n        var _a;\n        return new Set([this.transform.impute, this.transform.key, ...((_a = this.transform.groupby) !== null && _a !== void 0 ? _a : [])]);\n    }\n    producedFields() {\n        return new Set([this.transform.impute]);\n    }\n    processSequence(keyvals) {\n        const { start = 0, stop, step } = keyvals;\n        const result = [start, stop, ...(step ? [step] : [])].join(',');\n        return { signal: `sequence(${result})` };\n    }\n    static makeFromTransform(parent, imputeTransform) {\n        return new ImputeNode(parent, imputeTransform);\n    }\n    static makeFromEncoding(parent, model) {\n        const encoding = model.encoding;\n        const xDef = encoding.x;\n        const yDef = encoding.y;\n        if (isFieldDef(xDef) && isFieldDef(yDef)) {\n            const imputedChannel = xDef.impute ? xDef : yDef.impute ? yDef : undefined;\n            if (imputedChannel === undefined) {\n                return undefined;\n            }\n            const keyChannel = xDef.impute ? yDef : yDef.impute ? xDef : undefined;\n            const { method, value, frame, keyvals } = imputedChannel.impute;\n            const groupbyFields = pathGroupingFields(model.mark, encoding);\n            return new ImputeNode(parent, Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ impute: imputedChannel.field, key: keyChannel.field }, (method ? { method } : {})), (value !== undefined ? { value } : {})), (frame ? { frame } : {})), (keyvals !== undefined ? { keyvals } : {})), (groupbyFields.length ? { groupby: groupbyFields } : {})));\n        }\n        return null;\n    }\n    hash() {\n        return `Impute ${hash(this.transform)}`;\n    }\n    assemble() {\n        const { impute, key, keyvals, method, groupby, value, frame = [null, null] } = this.transform;\n        const imputeTransform = Object.assign(Object.assign(Object.assign(Object.assign({ type: 'impute', field: impute, key }, (keyvals ? { keyvals: isImputeSequence(keyvals) ? this.processSequence(keyvals) : keyvals } : {})), { method: 'value' }), (groupby ? { groupby } : {})), { value: !method || method === 'value' ? value : null });\n        if (method && method !== 'value') {\n            const deriveNewField = Object.assign({ type: 'window', as: [`imputed_${impute}_value`], ops: [method], fields: [impute], frame, ignorePeers: false }, (groupby ? { groupby } : {}));\n            const replaceOriginal = {\n                type: 'formula',\n                expr: `datum.${impute} === null ? datum.imputed_${impute}_value : datum.${impute}`,\n                as: impute\n            };\n            return [imputeTransform, deriveNewField, replaceOriginal];\n        }\n        else {\n            return [imputeTransform];\n        }\n    }\n}\n//# sourceMappingURL=impute.js.map","import { Split } from '../split';\n/**\n * Class to track interesting properties (see https://15721.courses.cs.cmu.edu/spring2016/papers/graefe-ieee1995.pdf)\n * about how fields have been parsed or whether they have been derived in a transform. We use this to not parse the\n * same field again (or differently).\n */\nexport class AncestorParse extends Split {\n    constructor(explicit = {}, implicit = {}, parseNothing = false) {\n        super(explicit, implicit);\n        this.explicit = explicit;\n        this.implicit = implicit;\n        this.parseNothing = parseNothing;\n    }\n    clone() {\n        const clone = super.clone();\n        clone.parseNothing = this.parseNothing;\n        return clone;\n    }\n}\n//# sourceMappingURL=index.js.map","import { vgField } from '../../channeldef';\nimport { duplicate, hash } from '../../util';\nimport { unique } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for the join aggregate transform nodes.\n */\nexport class JoinAggregateTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        super(parent);\n        this.transform = transform;\n    }\n    clone() {\n        return new JoinAggregateTransformNode(null, duplicate(this.transform));\n    }\n    addDimensions(fields) {\n        this.transform.groupby = unique(this.transform.groupby.concat(fields), d => d);\n    }\n    dependentFields() {\n        const out = new Set();\n        if (this.transform.groupby) {\n            this.transform.groupby.forEach(out.add, out);\n        }\n        this.transform.joinaggregate\n            .map(w => w.field)\n            .filter(f => f !== undefined)\n            .forEach(out.add, out);\n        return out;\n    }\n    producedFields() {\n        return new Set(this.transform.joinaggregate.map(this.getDefaultName));\n    }\n    getDefaultName(joinAggregateFieldDef) {\n        var _a;\n        return (_a = joinAggregateFieldDef.as) !== null && _a !== void 0 ? _a : vgField(joinAggregateFieldDef);\n    }\n    hash() {\n        return `JoinAggregateTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        const fields = [];\n        const ops = [];\n        const as = [];\n        for (const joinaggregate of this.transform.joinaggregate) {\n            ops.push(joinaggregate.op);\n            as.push(this.getDefaultName(joinaggregate));\n            fields.push(joinaggregate.field === undefined ? null : joinaggregate.field);\n        }\n        const groupby = this.transform.groupby;\n        return Object.assign({ type: 'joinaggregate', as,\n            ops,\n            fields }, (groupby !== undefined ? { groupby } : {}));\n    }\n}\n//# sourceMappingURL=joinaggregate.js.map","import { vgField } from '../../channeldef';\nimport { DEFAULT_SORT_OP, isSortField } from '../../sort';\nimport { facetSortFieldName } from '../facet';\nimport { JoinAggregateTransformNode } from './joinaggregate';\nexport function makeJoinAggregateFromFacet(parent, facet) {\n    const { row, column } = facet;\n    if (row && column) {\n        let newParent = null;\n        // only need to make one for crossed facet\n        for (const fieldDef of [row, column]) {\n            if (isSortField(fieldDef.sort)) {\n                const { field, op = DEFAULT_SORT_OP } = fieldDef.sort;\n                parent = newParent = new JoinAggregateTransformNode(parent, {\n                    joinaggregate: [\n                        {\n                            op,\n                            field,\n                            as: facetSortFieldName(fieldDef, fieldDef.sort, { forAs: true })\n                        }\n                    ],\n                    groupby: [vgField(fieldDef)]\n                });\n            }\n        }\n        return newParent;\n    }\n    return null;\n}\n//# sourceMappingURL=joinaggregatefacet.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for loess transform nodes\n */\nexport class LoessTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        var _a, _b, _c;\n        super(parent);\n        this.transform = transform;\n        this.transform = duplicate(transform); // duplicate to prevent side effects\n        const specifiedAs = (_a = this.transform.as) !== null && _a !== void 0 ? _a : [undefined, undefined];\n        this.transform.as = [(_b = specifiedAs[0]) !== null && _b !== void 0 ? _b : transform.on, (_c = specifiedAs[1]) !== null && _c !== void 0 ? _c : transform.loess];\n    }\n    clone() {\n        return new LoessTransformNode(null, duplicate(this.transform));\n    }\n    dependentFields() {\n        var _a;\n        return new Set([this.transform.loess, this.transform.on, ...((_a = this.transform.groupby) !== null && _a !== void 0 ? _a : [])]);\n    }\n    producedFields() {\n        return new Set(this.transform.as);\n    }\n    hash() {\n        return `LoessTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        const _a = this.transform, { loess, on } = _a, rest = __rest(_a, [\"loess\", \"on\"]);\n        const result = Object.assign({ type: 'loess', x: on, y: loess }, rest);\n        return result;\n    }\n}\n//# sourceMappingURL=loess.js.map","import { array, isString } from 'vega-util';\nimport * as log from '../../log';\nimport { isLookupData, isLookupSelection } from '../../transform';\nimport { duplicate, hash, varName } from '../../util';\nimport { DataFlowNode, OutputNode } from './dataflow';\nimport { findSource } from './parse';\nimport { SourceNode } from './source';\nimport { DataSourceType } from '../../data';\nexport class LookupNode extends DataFlowNode {\n    constructor(parent, transform, secondary) {\n        super(parent);\n        this.transform = transform;\n        this.secondary = secondary;\n    }\n    clone() {\n        return new LookupNode(null, duplicate(this.transform), this.secondary);\n    }\n    static make(parent, model, transform, counter) {\n        const sources = model.component.data.sources;\n        const { from } = transform;\n        let fromOutputNode = null;\n        if (isLookupData(from)) {\n            let fromSource = findSource(from.data, sources);\n            if (!fromSource) {\n                fromSource = new SourceNode(from.data);\n                sources.push(fromSource);\n            }\n            const fromOutputName = model.getName(`lookup_${counter}`);\n            fromOutputNode = new OutputNode(fromSource, fromOutputName, DataSourceType.Lookup, model.component.data.outputNodeRefCounts);\n            model.component.data.outputNodes[fromOutputName] = fromOutputNode;\n        }\n        else if (isLookupSelection(from)) {\n            const selName = from.selection;\n            transform = Object.assign({ as: selName }, transform);\n            fromOutputNode = model.getSelectionComponent(varName(selName), selName).materialized;\n            if (!fromOutputNode) {\n                throw new Error(log.message.noSameUnitLookup(selName));\n            }\n        }\n        return new LookupNode(parent, transform, fromOutputNode.getSource());\n    }\n    dependentFields() {\n        return new Set([this.transform.lookup]);\n    }\n    producedFields() {\n        return new Set(this.transform.as ? array(this.transform.as) : this.transform.from.fields);\n    }\n    hash() {\n        return `Lookup ${hash({ transform: this.transform, secondary: this.secondary })}`;\n    }\n    assemble() {\n        let foreign;\n        if (this.transform.from.fields) {\n            // lookup a few fields and add create a flat output\n            foreign = Object.assign({ values: this.transform.from.fields }, (this.transform.as ? { as: array(this.transform.as) } : {}));\n        }\n        else {\n            // lookup full record and nest it\n            let asName = this.transform.as;\n            if (!isString(asName)) {\n                log.warn(log.message.NO_FIELDS_NEEDS_AS);\n                asName = '_lookup';\n            }\n            foreign = {\n                as: [asName]\n            };\n        }\n        return Object.assign(Object.assign({ type: 'lookup', from: this.secondary, key: this.transform.from.key, fields: [this.transform.lookup] }, foreign), (this.transform.default ? { default: this.transform.default } : {}));\n    }\n}\n//# sourceMappingURL=lookup.js.map","import * as log from '../../log';\nimport * as optimizers from './optimizers';\nimport { moveFacetDown } from './subtree';\nexport const FACET_SCALE_PREFIX = 'scale_';\nexport const MAX_OPTIMIZATION_RUNS = 5;\n/**\n * Iterates over a dataflow graph and checks whether all links are consistent.\n */\nexport function checkLinks(nodes) {\n    for (const node of nodes) {\n        for (const child of node.children) {\n            if (child.parent !== node) {\n                // log.error('Dataflow graph is inconsistent.', node, child);\n                return false;\n            }\n        }\n        if (!checkLinks(node.children)) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * Run the specified optimizer on the provided nodes.\n *\n * @param optimizer The optimizer instance to run.\n * @param nodes A set of nodes to optimize.\n */\nfunction runOptimizer(optimizer, nodes) {\n    let modified = false;\n    for (const node of nodes) {\n        modified = optimizer.optimize(node) || modified;\n    }\n    return modified;\n}\nfunction optimizationDataflowHelper(dataComponent, model, firstPass) {\n    let roots = dataComponent.sources;\n    let modified = false;\n    modified = runOptimizer(new optimizers.RemoveUnnecessaryOutputNodes(), roots) || modified;\n    modified = runOptimizer(new optimizers.RemoveUnnecessaryIdentifierNodes(model), roots) || modified;\n    // remove source nodes that don't have any children because they also don't have output nodes\n    roots = roots.filter(r => r.numChildren() > 0);\n    modified = runOptimizer(new optimizers.RemoveUnusedSubtrees(), roots) || modified;\n    roots = roots.filter(r => r.numChildren() > 0);\n    if (!firstPass) {\n        // Only run these optimizations after the optimizer has moved down the facet node.\n        // With this change, we can be more aggressive in the optimizations.\n        modified = runOptimizer(new optimizers.MoveParseUp(), roots) || modified;\n        modified = runOptimizer(new optimizers.MergeBins(model), roots) || modified;\n        modified = runOptimizer(new optimizers.RemoveDuplicateTimeUnits(), roots) || modified;\n        modified = runOptimizer(new optimizers.MergeParse(), roots) || modified;\n        modified = runOptimizer(new optimizers.MergeAggregates(), roots) || modified;\n        modified = runOptimizer(new optimizers.MergeTimeUnits(), roots) || modified;\n        modified = runOptimizer(new optimizers.MergeIdenticalNodes(), roots) || modified;\n        modified = runOptimizer(new optimizers.MergeOutputs(), roots) || modified;\n    }\n    dataComponent.sources = roots;\n    return modified;\n}\n/**\n * Optimizes the dataflow of the passed in data component.\n */\nexport function optimizeDataflow(data, model) {\n    // check before optimizations\n    checkLinks(data.sources);\n    let firstPassCounter = 0;\n    let secondPassCounter = 0;\n    for (let i = 0; i < MAX_OPTIMIZATION_RUNS; i++) {\n        if (!optimizationDataflowHelper(data, model, true)) {\n            break;\n        }\n        firstPassCounter++;\n    }\n    // move facets down and make a copy of the subtree so that we can have scales at the top level\n    data.sources.map(moveFacetDown);\n    for (let i = 0; i < MAX_OPTIMIZATION_RUNS; i++) {\n        if (!optimizationDataflowHelper(data, model, false)) {\n            break;\n        }\n        secondPassCounter++;\n    }\n    // check after optimizations\n    checkLinks(data.sources);\n    if (Math.max(firstPassCounter, secondPassCounter) === MAX_OPTIMIZATION_RUNS) {\n        log.warn(`Maximum optimization runs(${MAX_OPTIMIZATION_RUNS}) reached.`);\n    }\n}\n//# sourceMappingURL=optimize.js.map","var __classPrivateFieldSet = (this && this.__classPrivateFieldSet) || function (receiver, privateMap, value) {\n    if (!privateMap.has(receiver)) {\n        throw new TypeError(\"attempted to set private field on non-instance\");\n    }\n    privateMap.set(receiver, value);\n    return value;\n};\nvar __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, privateMap) {\n    if (!privateMap.has(receiver)) {\n        throw new TypeError(\"attempted to get private field on non-instance\");\n    }\n    return privateMap.get(receiver);\n};\nvar _modified;\nimport { GraticuleNode } from './graticule';\nimport { SequenceNode } from './sequence';\nimport { SourceNode } from './source';\n/**\n * Whether this dataflow node is the source of the dataflow that produces data i.e. a source or a generator.\n */\nexport function isDataSourceNode(node) {\n    return node instanceof SourceNode || node instanceof GraticuleNode || node instanceof SequenceNode;\n}\n/**\n * Abstract base class for Dataflow optimizers.\n * Contains only mutation handling logic. Subclasses need to implement iteration logic.\n */\nexport class Optimizer {\n    constructor() {\n        _modified.set(this, void 0);\n        __classPrivateFieldSet(this, _modified, false);\n    }\n    // Once true, #modified is never set to false\n    setModified() {\n        __classPrivateFieldSet(this, _modified, true);\n    }\n    get modifiedFlag() {\n        return __classPrivateFieldGet(this, _modified);\n    }\n}\n_modified = new WeakMap();\n/**\n * Starts from a node and runs the optimization function (the \"run\" method) upwards to the root,\n * depending on the continue and modified flag values returned by the optimization function.\n */\nexport class BottomUpOptimizer extends Optimizer {\n    /**\n     * Compute a map of node depths that we can use to determine a topological sort order.\n     */\n    getNodeDepths(node, depth, depths) {\n        depths.set(node, depth);\n        for (const child of node.children) {\n            this.getNodeDepths(child, depth + 1, depths);\n        }\n        return depths;\n    }\n    /**\n     * Run the optimizer on all nodes starting from the leaves.\n     */\n    optimize(node) {\n        const depths = this.getNodeDepths(node, 0, new Map());\n        const topologicalSort = [...depths.entries()].sort((a, b) => b[1] - a[1]);\n        for (const tuple of topologicalSort) {\n            this.run(tuple[0]);\n        }\n        return this.modifiedFlag;\n    }\n}\n/**\n * The optimizer function (the \"run\" method), is invoked on the given node and then continues recursively.\n */\nexport class TopDownOptimizer extends Optimizer {\n    /**\n     * Run the optimizer depth first on all nodes starting from the roots.\n     */\n    optimize(node) {\n        this.run(node);\n        for (const child of node.children) {\n            this.optimize(child);\n        }\n        return this.modifiedFlag;\n    }\n}\n//# sourceMappingURL=optimizer.js.map","import { fieldIntersection, hash, hasIntersection, isEmpty, keys, some } from '../../util';\nimport { requiresSelectionId } from '../selection';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { OutputNode } from './dataflow';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { ParseNode } from './formatparse';\nimport { IdentifierNode } from './identifier';\nimport { BottomUpOptimizer, isDataSourceNode, Optimizer, TopDownOptimizer } from './optimizer';\nimport { SourceNode } from './source';\nimport { TimeUnitNode } from './timeunit';\n/**\n * Merge identical nodes at forks by comparing hashes.\n *\n * Does not need to iterate from leaves so we implement this with recursion as it's a bit simpler.\n */\nexport class MergeIdenticalNodes extends TopDownOptimizer {\n    mergeNodes(parent, nodes) {\n        const mergedNode = nodes.shift();\n        for (const node of nodes) {\n            parent.removeChild(node);\n            node.parent = mergedNode;\n            node.remove();\n        }\n    }\n    run(node) {\n        const hashes = node.children.map(x => x.hash());\n        const buckets = {};\n        for (let i = 0; i < hashes.length; i++) {\n            if (buckets[hashes[i]] === undefined) {\n                buckets[hashes[i]] = [node.children[i]];\n            }\n            else {\n                buckets[hashes[i]].push(node.children[i]);\n            }\n        }\n        for (const k of keys(buckets)) {\n            if (buckets[k].length > 1) {\n                this.setModified();\n                this.mergeNodes(node, buckets[k]);\n            }\n        }\n    }\n}\n/**\n * Optimizer that removes identifier nodes that are not needed for selections.\n */\nexport class RemoveUnnecessaryIdentifierNodes extends TopDownOptimizer {\n    constructor(model) {\n        super();\n        this.requiresSelectionId = model && requiresSelectionId(model);\n    }\n    run(node) {\n        if (node instanceof IdentifierNode) {\n            // Only preserve IdentifierNodes if we have default discrete selections\n            // in our model tree, and if the nodes come after tuple producing nodes.\n            if (!(this.requiresSelectionId &&\n                (isDataSourceNode(node.parent) || node.parent instanceof AggregateNode || node.parent instanceof ParseNode))) {\n                this.setModified();\n                node.remove();\n            }\n        }\n    }\n}\n/**\n * Removes duplicate time unit nodes (as determined by the name of the output field) that may be generated due to\n * selections projected over time units. Only keeps the first time unit in any branch.\n *\n * This optimizer is a custom top down optimizer that keep track of produced fields in a branch.\n */\nexport class RemoveDuplicateTimeUnits extends Optimizer {\n    optimize(node) {\n        this.run(node, new Set());\n        return this.modifiedFlag;\n    }\n    run(node, timeUnitFields) {\n        let producedFields = new Set();\n        if (node instanceof TimeUnitNode) {\n            producedFields = node.producedFields();\n            if (hasIntersection(producedFields, timeUnitFields)) {\n                this.setModified();\n                node.removeFormulas(timeUnitFields);\n                if (node.producedFields.length === 0) {\n                    node.remove();\n                }\n            }\n        }\n        for (const child of node.children) {\n            this.run(child, new Set([...timeUnitFields, ...producedFields]));\n        }\n    }\n}\n/**\n * Remove output nodes that are not required.\n */\nexport class RemoveUnnecessaryOutputNodes extends TopDownOptimizer {\n    constructor() {\n        super();\n    }\n    run(node) {\n        if (node instanceof OutputNode && !node.isRequired()) {\n            this.setModified();\n            node.remove();\n        }\n    }\n}\n/**\n * Move parse nodes up to forks and merges them if possible.\n */\nexport class MoveParseUp extends BottomUpOptimizer {\n    run(node) {\n        if (isDataSourceNode(node)) {\n            return;\n        }\n        if (node.numChildren() > 1) {\n            // Don't move parse further up but continue with parent.\n            return;\n        }\n        for (const child of node.children) {\n            if (child instanceof ParseNode) {\n                if (node instanceof ParseNode) {\n                    this.setModified();\n                    node.merge(child);\n                }\n                else {\n                    // Don't swap with nodes that produce something that the parse node depends on (e.g. lookup).\n                    if (fieldIntersection(node.producedFields(), child.dependentFields())) {\n                        continue;\n                    }\n                    this.setModified();\n                    child.swapWithParent();\n                }\n            }\n        }\n        return;\n    }\n}\n/**\n * Inserts an intermediate ParseNode containing all non-conflicting parse fields and removes the empty ParseNodes.\n *\n * We assume that dependent paths that do not have a parse node can be just merged.\n */\nexport class MergeParse extends BottomUpOptimizer {\n    run(node) {\n        const originalChildren = [...node.children];\n        const parseChildren = node.children.filter((child) => child instanceof ParseNode);\n        if (node.numChildren() > 1 && parseChildren.length >= 1) {\n            const commonParse = {};\n            const conflictingParse = new Set();\n            for (const parseNode of parseChildren) {\n                const parse = parseNode.parse;\n                for (const k of keys(parse)) {\n                    if (!(k in commonParse)) {\n                        commonParse[k] = parse[k];\n                    }\n                    else if (commonParse[k] !== parse[k]) {\n                        conflictingParse.add(k);\n                    }\n                }\n            }\n            for (const field of conflictingParse) {\n                delete commonParse[field];\n            }\n            if (!isEmpty(commonParse)) {\n                this.setModified();\n                const mergedParseNode = new ParseNode(node, commonParse);\n                for (const childNode of originalChildren) {\n                    if (childNode instanceof ParseNode) {\n                        for (const key of keys(commonParse)) {\n                            delete childNode.parse[key];\n                        }\n                    }\n                    node.removeChild(childNode);\n                    childNode.parent = mergedParseNode;\n                    // remove empty parse nodes\n                    if (childNode instanceof ParseNode && keys(childNode.parse).length === 0) {\n                        childNode.remove();\n                    }\n                }\n            }\n        }\n    }\n}\n/**\n * Repeatedly remove leaf nodes that are not output or facet nodes.\n * The reason is that we don't need subtrees that don't have any output nodes.\n * Facet nodes are needed for the row or column domains.\n */\nexport class RemoveUnusedSubtrees extends BottomUpOptimizer {\n    run(node) {\n        if (node instanceof OutputNode || node.numChildren() > 0 || node instanceof FacetNode) {\n            // no need to continue with parent because it is output node or will have children (there was a fork)\n        }\n        else if (node instanceof SourceNode) {\n            // ignore empty unused sources as they will be removed in optimizationDataflowHelper\n        }\n        else {\n            this.setModified();\n            node.remove();\n        }\n    }\n}\n/**\n * Merge adjacent time unit nodes.\n */\nexport class MergeTimeUnits extends BottomUpOptimizer {\n    run(node) {\n        const timeUnitChildren = node.children.filter((x) => x instanceof TimeUnitNode);\n        const combination = timeUnitChildren.pop();\n        for (const timeUnit of timeUnitChildren) {\n            this.setModified();\n            combination.merge(timeUnit);\n        }\n    }\n}\nexport class MergeAggregates extends BottomUpOptimizer {\n    run(node) {\n        const aggChildren = node.children.filter((child) => child instanceof AggregateNode);\n        // Object which we'll use to map the fields which an aggregate is grouped by to\n        // the set of aggregates with that grouping. This is useful as only aggregates\n        // with the same group by can be merged\n        const groupedAggregates = {};\n        // Build groupedAggregates\n        for (const agg of aggChildren) {\n            const groupBys = hash(agg.groupBy);\n            if (!(groupBys in groupedAggregates)) {\n                groupedAggregates[groupBys] = [];\n            }\n            groupedAggregates[groupBys].push(agg);\n        }\n        // Merge aggregateNodes with same key in groupedAggregates\n        for (const group of keys(groupedAggregates)) {\n            const mergeableAggs = groupedAggregates[group];\n            if (mergeableAggs.length > 1) {\n                const mergedAggs = mergeableAggs.pop();\n                for (const agg of mergeableAggs) {\n                    if (mergedAggs.merge(agg)) {\n                        node.removeChild(agg);\n                        agg.parent = mergedAggs;\n                        agg.remove();\n                        this.setModified();\n                    }\n                }\n            }\n        }\n    }\n}\n/**\n * Merge bin nodes and move them up through forks. Stop at filters, parse, identifier as we want them to stay before the bin node.\n */\nexport class MergeBins extends BottomUpOptimizer {\n    constructor(model) {\n        super();\n        this.model = model;\n    }\n    run(node) {\n        const moveBinsUp = !(isDataSourceNode(node) ||\n            node instanceof FilterNode ||\n            node instanceof ParseNode ||\n            node instanceof IdentifierNode);\n        const promotableBins = [];\n        const remainingBins = [];\n        for (const child of node.children) {\n            if (child instanceof BinNode) {\n                if (moveBinsUp && !fieldIntersection(node.producedFields(), child.dependentFields())) {\n                    promotableBins.push(child);\n                }\n                else {\n                    remainingBins.push(child);\n                }\n            }\n        }\n        if (promotableBins.length > 0) {\n            const promotedBin = promotableBins.pop();\n            for (const bin of promotableBins) {\n                promotedBin.merge(bin, this.model.renameSignal.bind(this.model));\n            }\n            this.setModified();\n            if (node instanceof BinNode) {\n                node.merge(promotedBin, this.model.renameSignal.bind(this.model));\n            }\n            else {\n                promotedBin.swapWithParent();\n            }\n        }\n        if (remainingBins.length > 1) {\n            const remainingBin = remainingBins.pop();\n            for (const bin of remainingBins) {\n                remainingBin.merge(bin, this.model.renameSignal.bind(this.model));\n            }\n            this.setModified();\n        }\n    }\n}\n/**\n * This optimizer takes output nodes that are at a fork and moves them before the fork.\n *\n * The algorithm iterates over the children and tries to find the last output node in a chain of output nodes.\n * It then moves all output nodes before that main output node. All other children (and the children of the output nodes)\n * are inserted after the main output node.\n */\nexport class MergeOutputs extends BottomUpOptimizer {\n    run(node) {\n        const children = [...node.children];\n        const hasOutputChild = some(children, child => child instanceof OutputNode);\n        if (!hasOutputChild || node.numChildren() <= 1) {\n            return;\n        }\n        const otherChildren = [];\n        // The output node we will connect all other nodes to.\n        // Output nodes will be added before the new node, other nodes after.\n        let mainOutput;\n        for (const child of children) {\n            if (child instanceof OutputNode) {\n                let lastOutput = child;\n                while (lastOutput.numChildren() === 1) {\n                    const [theChild] = lastOutput.children;\n                    if (theChild instanceof OutputNode) {\n                        lastOutput = theChild;\n                    }\n                    else {\n                        break;\n                    }\n                }\n                otherChildren.push(...lastOutput.children);\n                if (mainOutput) {\n                    // Move the output nodes before the mainOutput. We do this by setting\n                    // the parent of the first not to the parent of the main output and\n                    // the main output's parent to the last output.\n                    // note: the child is the first output\n                    node.removeChild(child);\n                    child.parent = mainOutput.parent;\n                    mainOutput.parent.removeChild(mainOutput);\n                    mainOutput.parent = lastOutput;\n                    this.setModified();\n                }\n                else {\n                    mainOutput = lastOutput;\n                }\n            }\n            else {\n                otherChildren.push(child);\n            }\n        }\n        if (otherChildren.length) {\n            this.setModified();\n            for (const child of otherChildren) {\n                child.parent.removeChild(child);\n                child.parent = mainOutput;\n            }\n        }\n    }\n}\n//# sourceMappingURL=optimizers.js.map","import { AncestorParse } from '.';\nimport { isGenerator, isGraticuleGenerator, isInlineData, isNamedData, isSequenceGenerator, isUrlData, DataSourceType } from '../../data';\nimport * as log from '../../log';\nimport { isAggregate, isBin, isCalculate, isDensity, isFilter, isFlatten, isFold, isImpute, isJoinAggregate, isLoess, isLookup, isPivot, isQuantile, isRegression, isSample, isStack, isTimeUnit, isWindow } from '../../transform';\nimport { deepEqual, mergeDeep } from '../../util';\nimport { isFacetModel, isLayerModel, isUnitModel } from '../model';\nimport { requiresSelectionId } from '../selection';\nimport { materializeSelections } from '../selection/parse';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { CalculateNode } from './calculate';\nimport { OutputNode } from './dataflow';\nimport { DensityTransformNode } from './density';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { FilterInvalidNode } from './filterinvalid';\nimport { FlattenTransformNode } from './flatten';\nimport { FoldTransformNode } from './fold';\nimport { getImplicitFromEncoding, getImplicitFromFilterTransform, getImplicitFromSelection, ParseNode } from './formatparse';\nimport { GeoJSONNode } from './geojson';\nimport { GeoPointNode } from './geopoint';\nimport { GraticuleNode } from './graticule';\nimport { IdentifierNode } from './identifier';\nimport { ImputeNode } from './impute';\nimport { JoinAggregateTransformNode } from './joinaggregate';\nimport { makeJoinAggregateFromFacet } from './joinaggregatefacet';\nimport { LoessTransformNode } from './loess';\nimport { LookupNode } from './lookup';\nimport { PivotTransformNode } from './pivot';\nimport { QuantileTransformNode } from './quantile';\nimport { RegressionTransformNode } from './regression';\nimport { SampleTransformNode } from './sample';\nimport { SequenceNode } from './sequence';\nimport { SourceNode } from './source';\nimport { StackNode } from './stack';\nimport { TimeUnitNode } from './timeunit';\nimport { WindowTransformNode } from './window';\nexport function findSource(data, sources) {\n    var _a, _b, _c, _d;\n    for (const other of sources) {\n        const otherData = other.data;\n        // if both datasets have a name defined, we cannot merge\n        if (data.name && other.hasName() && data.name !== other.dataName) {\n            continue;\n        }\n        const formatMesh = (_a = data['format']) === null || _a === void 0 ? void 0 : _a.mesh;\n        const otherFeature = (_b = otherData.format) === null || _b === void 0 ? void 0 : _b.feature;\n        // feature and mesh are mutually exclusive\n        if (formatMesh && otherFeature) {\n            continue;\n        }\n        // we have to extract the same feature or mesh\n        const formatFeature = (_c = data['format']) === null || _c === void 0 ? void 0 : _c.feature;\n        if ((formatFeature || otherFeature) && formatFeature !== otherFeature) {\n            continue;\n        }\n        const otherMesh = (_d = otherData.format) === null || _d === void 0 ? void 0 : _d.mesh;\n        if ((formatMesh || otherMesh) && formatMesh !== otherMesh) {\n            continue;\n        }\n        if (isInlineData(data) && isInlineData(otherData)) {\n            if (deepEqual(data.values, otherData.values)) {\n                return other;\n            }\n        }\n        else if (isUrlData(data) && isUrlData(otherData)) {\n            if (data.url === otherData.url) {\n                return other;\n            }\n        }\n        else if (isNamedData(data)) {\n            if (data.name === other.dataName) {\n                return other;\n            }\n        }\n    }\n    return null;\n}\nfunction parseRoot(model, sources) {\n    if (model.data || !model.parent) {\n        // if the model defines a data source or is the root, create a source node\n        if (model.data === null) {\n            // data: null means we should ignore the parent's data so we just create a new data source\n            const source = new SourceNode({ values: [] });\n            sources.push(source);\n            return source;\n        }\n        const existingSource = findSource(model.data, sources);\n        if (existingSource) {\n            if (!isGenerator(model.data)) {\n                existingSource.data.format = mergeDeep({}, model.data.format, existingSource.data.format);\n            }\n            // if the new source has a name but the existing one does not, we can set it\n            if (!existingSource.hasName() && model.data.name) {\n                existingSource.dataName = model.data.name;\n            }\n            return existingSource;\n        }\n        else {\n            const source = new SourceNode(model.data);\n            sources.push(source);\n            return source;\n        }\n    }\n    else {\n        // If we don't have a source defined (overriding parent's data), use the parent's facet root or main.\n        return model.parent.component.data.facetRoot\n            ? model.parent.component.data.facetRoot\n            : model.parent.component.data.main;\n    }\n}\n/**\n * Parses a transform array into a chain of connected dataflow nodes.\n */\nexport function parseTransformArray(head, model, ancestorParse) {\n    var _a, _b;\n    let lookupCounter = 0;\n    for (const t of model.transforms) {\n        let derivedType = undefined;\n        let transformNode;\n        if (isCalculate(t)) {\n            transformNode = head = new CalculateNode(head, t);\n            derivedType = 'derived';\n        }\n        else if (isFilter(t)) {\n            const implicit = getImplicitFromFilterTransform(t);\n            transformNode = head = (_a = ParseNode.makeWithAncestors(head, {}, implicit, ancestorParse)) !== null && _a !== void 0 ? _a : head;\n            head = new FilterNode(head, model, t.filter);\n        }\n        else if (isBin(t)) {\n            transformNode = head = BinNode.makeFromTransform(head, t, model);\n            derivedType = 'number';\n        }\n        else if (isTimeUnit(t)) {\n            derivedType = 'date';\n            const parsedAs = ancestorParse.getWithExplicit(t.field);\n            // Create parse node because the input to time unit is always date.\n            if (parsedAs.value === undefined) {\n                head = new ParseNode(head, { [t.field]: derivedType });\n                ancestorParse.set(t.field, derivedType, false);\n            }\n            transformNode = head = TimeUnitNode.makeFromTransform(head, t);\n        }\n        else if (isAggregate(t)) {\n            transformNode = head = AggregateNode.makeFromTransform(head, t);\n            derivedType = 'number';\n            if (requiresSelectionId(model)) {\n                head = new IdentifierNode(head);\n            }\n        }\n        else if (isLookup(t)) {\n            transformNode = head = LookupNode.make(head, model, t, lookupCounter++);\n            derivedType = 'derived';\n        }\n        else if (isWindow(t)) {\n            transformNode = head = new WindowTransformNode(head, t);\n            derivedType = 'number';\n        }\n        else if (isJoinAggregate(t)) {\n            transformNode = head = new JoinAggregateTransformNode(head, t);\n            derivedType = 'number';\n        }\n        else if (isStack(t)) {\n            transformNode = head = StackNode.makeFromTransform(head, t);\n            derivedType = 'derived';\n        }\n        else if (isFold(t)) {\n            transformNode = head = new FoldTransformNode(head, t);\n            derivedType = 'derived';\n        }\n        else if (isFlatten(t)) {\n            transformNode = head = new FlattenTransformNode(head, t);\n            derivedType = 'derived';\n        }\n        else if (isPivot(t)) {\n            transformNode = head = new PivotTransformNode(head, t);\n            derivedType = 'derived';\n        }\n        else if (isSample(t)) {\n            head = new SampleTransformNode(head, t);\n        }\n        else if (isImpute(t)) {\n            transformNode = head = ImputeNode.makeFromTransform(head, t);\n            derivedType = 'derived';\n        }\n        else if (isDensity(t)) {\n            transformNode = head = new DensityTransformNode(head, t);\n            derivedType = 'derived';\n        }\n        else if (isQuantile(t)) {\n            transformNode = head = new QuantileTransformNode(head, t);\n            derivedType = 'derived';\n        }\n        else if (isRegression(t)) {\n            transformNode = head = new RegressionTransformNode(head, t);\n            derivedType = 'derived';\n        }\n        else if (isLoess(t)) {\n            transformNode = head = new LoessTransformNode(head, t);\n            derivedType = 'derived';\n        }\n        else {\n            log.warn(log.message.invalidTransformIgnored(t));\n            continue;\n        }\n        if (transformNode && derivedType !== undefined) {\n            for (const field of (_b = transformNode.producedFields()) !== null && _b !== void 0 ? _b : []) {\n                ancestorParse.set(field, derivedType, false);\n            }\n        }\n    }\n    return head;\n}\n/*\nDescription of the dataflow (http://asciiflow.com/):\n     +--------+\n     | Source |\n     +---+----+\n         |\n         v\n     FormatParse\n     (explicit)\n         |\n         v\n     Transforms\n(Filter, Calculate, Binning, TimeUnit, Aggregate, Window, ...)\n         |\n         v\n     FormatParse\n     (implicit)\n         |\n         v\n Binning (in `encoding`)\n         |\n         v\n Timeunit (in `encoding`)\n         |\n         v\nFormula From Sort Array\n         |\n         v\n      +--+--+\n      | Raw |\n      +-----+\n         |\n         v\n  Aggregate (in `encoding`)\n         |\n         v\n  Stack (in `encoding`)\n         |\n         v\n  Invalid Filter\n         |\n         v\n   +----------+\n   |   Main   |\n   +----------+\n         |\n         v\n     +-------+\n     | Facet |----> \"column\", \"column-layout\", and \"row\"\n     +-------+\n         |\n         v\n  ...Child data...\n*/\nexport function parseData(model) {\n    var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k;\n    let head = parseRoot(model, model.component.data.sources);\n    const { outputNodes, outputNodeRefCounts } = model.component.data;\n    const ancestorParse = model.parent ? model.parent.component.data.ancestorParse.clone() : new AncestorParse();\n    const data = model.data;\n    if (isGenerator(data)) {\n        // insert generator transform\n        if (isSequenceGenerator(data)) {\n            head = new SequenceNode(head, data.sequence);\n        }\n        else if (isGraticuleGenerator(data)) {\n            head = new GraticuleNode(head, data.graticule);\n        }\n        // no parsing necessary for generator\n        ancestorParse.parseNothing = true;\n    }\n    else if (((_a = data === null || data === void 0 ? void 0 : data.format) === null || _a === void 0 ? void 0 : _a.parse) === null) {\n        // format.parse: null means disable parsing\n        ancestorParse.parseNothing = true;\n    }\n    head = (_b = ParseNode.makeExplicit(head, model, ancestorParse)) !== null && _b !== void 0 ? _b : head;\n    // Default discrete selections require an identifer transform to\n    // uniquely identify data points. Add this transform at the head of\n    // the pipeline such that the identifier field is available for all\n    // subsequent datasets. During optimization, we will remove this\n    // transform if it proves to be unnecessary. Additional identifier\n    // transforms will be necessary when new tuples are constructed\n    // (e.g., post-aggregation).\n    head = new IdentifierNode(head);\n    // HACK: This is equivalent for merging bin extent for union scale.\n    // FIXME(https://github.com/vega/vega-lite/issues/2270): Correctly merge extent / bin node for shared bin scale\n    const parentIsLayer = model.parent && isLayerModel(model.parent);\n    if (isUnitModel(model) || isFacetModel(model)) {\n        if (parentIsLayer) {\n            head = (_c = BinNode.makeFromEncoding(head, model)) !== null && _c !== void 0 ? _c : head;\n        }\n    }\n    if (model.transforms.length > 0) {\n        head = parseTransformArray(head, model, ancestorParse);\n    }\n    // create parse nodes for fields that need to be parsed (or flattened) implicitly\n    const implicitSelection = getImplicitFromSelection(model);\n    const implicitEncoding = getImplicitFromEncoding(model);\n    head = (_d = ParseNode.makeWithAncestors(head, {}, Object.assign(Object.assign({}, implicitSelection), implicitEncoding), ancestorParse)) !== null && _d !== void 0 ? _d : head;\n    if (isUnitModel(model)) {\n        head = GeoJSONNode.parseAll(head, model);\n        head = GeoPointNode.parseAll(head, model);\n    }\n    if (isUnitModel(model) || isFacetModel(model)) {\n        if (!parentIsLayer) {\n            head = (_e = BinNode.makeFromEncoding(head, model)) !== null && _e !== void 0 ? _e : head;\n        }\n        head = (_f = TimeUnitNode.makeFromEncoding(head, model)) !== null && _f !== void 0 ? _f : head;\n        head = CalculateNode.parseAllForSortIndex(head, model);\n    }\n    // add an output node pre aggregation\n    const rawName = model.getDataName(DataSourceType.Raw);\n    const raw = new OutputNode(head, rawName, DataSourceType.Raw, outputNodeRefCounts);\n    outputNodes[rawName] = raw;\n    head = raw;\n    if (isUnitModel(model)) {\n        const agg = AggregateNode.makeFromEncoding(head, model);\n        if (agg) {\n            head = agg;\n            if (requiresSelectionId(model)) {\n                head = new IdentifierNode(head);\n            }\n        }\n        head = (_g = ImputeNode.makeFromEncoding(head, model)) !== null && _g !== void 0 ? _g : head;\n        head = (_h = StackNode.makeFromEncoding(head, model)) !== null && _h !== void 0 ? _h : head;\n    }\n    if (isUnitModel(model)) {\n        head = (_j = FilterInvalidNode.make(head, model)) !== null && _j !== void 0 ? _j : head;\n    }\n    // output node for marks\n    const mainName = model.getDataName(DataSourceType.Main);\n    const main = new OutputNode(head, mainName, DataSourceType.Main, outputNodeRefCounts);\n    outputNodes[mainName] = main;\n    head = main;\n    if (isUnitModel(model)) {\n        materializeSelections(model, main);\n    }\n    // add facet marker\n    let facetRoot = null;\n    if (isFacetModel(model)) {\n        const facetName = model.getName('facet');\n        // Derive new aggregate for facet's sort field\n        // augment data source with new fields for crossed facet\n        head = (_k = makeJoinAggregateFromFacet(head, model.facet)) !== null && _k !== void 0 ? _k : head;\n        facetRoot = new FacetNode(head, model, facetName, main.getSource());\n        outputNodes[facetName] = facetRoot;\n    }\n    return Object.assign(Object.assign({}, model.component.data), { outputNodes,\n        outputNodeRefCounts,\n        raw,\n        main,\n        facetRoot,\n        ancestorParse });\n}\n//# sourceMappingURL=parse.js.map","import { duplicate, hash, unique } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for pivot transform nodes.\n */\nexport class PivotTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        super(parent);\n        this.transform = transform;\n    }\n    clone() {\n        return new PivotTransformNode(null, duplicate(this.transform));\n    }\n    addDimensions(fields) {\n        var _a;\n        this.transform.groupby = unique(((_a = this.transform.groupby) !== null && _a !== void 0 ? _a : []).concat(fields), d => d);\n    }\n    producedFields() {\n        return undefined; // return undefined so that potentially everything can depend on the pivot\n    }\n    dependentFields() {\n        var _a;\n        return new Set([this.transform.pivot, this.transform.value, ...((_a = this.transform.groupby) !== null && _a !== void 0 ? _a : [])]);\n    }\n    hash() {\n        return `PivotTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        const { pivot, value, groupby, limit, op } = this.transform;\n        return Object.assign(Object.assign(Object.assign({ type: 'pivot', field: pivot, value }, (limit !== undefined ? { limit } : {})), (op !== undefined ? { op } : {})), (groupby !== undefined ? { groupby } : {}));\n    }\n}\n//# sourceMappingURL=pivot.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for quantile transform nodes\n */\nexport class QuantileTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        var _a, _b, _c;\n        super(parent);\n        this.transform = transform;\n        this.transform = duplicate(transform); // duplicate to prevent side effects\n        const specifiedAs = (_a = this.transform.as) !== null && _a !== void 0 ? _a : [undefined, undefined];\n        this.transform.as = [(_b = specifiedAs[0]) !== null && _b !== void 0 ? _b : 'prob', (_c = specifiedAs[1]) !== null && _c !== void 0 ? _c : 'value'];\n    }\n    clone() {\n        return new QuantileTransformNode(null, duplicate(this.transform));\n    }\n    dependentFields() {\n        var _a;\n        return new Set([this.transform.quantile, ...((_a = this.transform.groupby) !== null && _a !== void 0 ? _a : [])]);\n    }\n    producedFields() {\n        return new Set(this.transform.as);\n    }\n    hash() {\n        return `QuantileTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        const _a = this.transform, { quantile } = _a, rest = __rest(_a, [\"quantile\"]);\n        const result = Object.assign({ type: 'quantile', field: quantile }, rest);\n        return result;\n    }\n}\n//# sourceMappingURL=quantile.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for regression transform nodes\n */\nexport class RegressionTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        var _a, _b, _c;\n        super(parent);\n        this.transform = transform;\n        this.transform = duplicate(transform); // duplicate to prevent side effects\n        const specifiedAs = (_a = this.transform.as) !== null && _a !== void 0 ? _a : [undefined, undefined];\n        this.transform.as = [(_b = specifiedAs[0]) !== null && _b !== void 0 ? _b : transform.on, (_c = specifiedAs[1]) !== null && _c !== void 0 ? _c : transform.regression];\n    }\n    clone() {\n        return new RegressionTransformNode(null, duplicate(this.transform));\n    }\n    dependentFields() {\n        var _a;\n        return new Set([this.transform.regression, this.transform.on, ...((_a = this.transform.groupby) !== null && _a !== void 0 ? _a : [])]);\n    }\n    producedFields() {\n        return new Set(this.transform.as);\n    }\n    hash() {\n        return `RegressionTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        const _a = this.transform, { regression, on } = _a, rest = __rest(_a, [\"regression\", \"on\"]);\n        const result = Object.assign({ type: 'regression', x: on, y: regression }, rest);\n        return result;\n    }\n}\n//# sourceMappingURL=regression.js.map","import { duplicate, hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for the sample transform nodes\n */\nexport class SampleTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        super(parent);\n        this.transform = transform;\n    }\n    clone() {\n        return new SampleTransformNode(null, duplicate(this.transform));\n    }\n    dependentFields() {\n        return new Set();\n    }\n    producedFields() {\n        return new Set();\n    }\n    hash() {\n        return `SampleTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        return {\n            type: 'sample',\n            size: this.transform.sample\n        };\n    }\n}\n//# sourceMappingURL=sample.js.map","import { hash } from '../../util';\nimport { DataFlowNode } from './dataflow';\nexport class SequenceNode extends DataFlowNode {\n    constructor(parent, params) {\n        super(parent);\n        this.params = params;\n    }\n    clone() {\n        return new SequenceNode(null, this.params);\n    }\n    dependentFields() {\n        return new Set();\n    }\n    producedFields() {\n        var _a;\n        return new Set([(_a = this.params.as) !== null && _a !== void 0 ? _a : 'data']);\n    }\n    hash() {\n        return `Hash ${hash(this.params)}`;\n    }\n    assemble() {\n        return Object.assign({ type: 'sequence' }, this.params);\n    }\n}\n//# sourceMappingURL=sequence.js.map","import { isGenerator, isInlineData, isNamedData, isSphereGenerator, isUrlData } from '../../data';\nimport { contains, isEmpty, omit } from '../../util';\nimport { DataFlowNode } from './dataflow';\nexport class SourceNode extends DataFlowNode {\n    constructor(data) {\n        super(null); // source cannot have parent\n        data = data !== null && data !== void 0 ? data : { name: 'source' };\n        let format;\n        if (!isGenerator(data)) {\n            format = data.format ? Object.assign({}, omit(data.format, ['parse'])) : {};\n        }\n        if (isInlineData(data)) {\n            this._data = { values: data.values };\n        }\n        else if (isUrlData(data)) {\n            this._data = { url: data.url };\n            if (!format.type) {\n                // Extract extension from URL using snippet from\n                // http://stackoverflow.com/questions/680929/how-to-extract-extension-from-filename-string-in-javascript\n                let defaultExtension = /(?:\\.([^.]+))?$/.exec(data.url)[1];\n                if (!contains(['json', 'csv', 'tsv', 'dsv', 'topojson'], defaultExtension)) {\n                    defaultExtension = 'json';\n                }\n                // defaultExtension has type string but we ensure that it is DataFormatType above\n                format.type = defaultExtension;\n            }\n        }\n        else if (isSphereGenerator(data)) {\n            // hardwire GeoJSON sphere data into output specification\n            this._data = { values: [{ type: 'Sphere' }] };\n        }\n        else if (isNamedData(data) || isGenerator(data)) {\n            this._data = {};\n        }\n        // set flag to check if generator\n        this._generator = isGenerator(data);\n        // any dataset can be named\n        if (data.name) {\n            this._name = data.name;\n        }\n        if (format && !isEmpty(format)) {\n            this._data.format = format;\n        }\n    }\n    dependentFields() {\n        return new Set();\n    }\n    producedFields() {\n        return undefined; // we don't know what this source produces\n    }\n    get data() {\n        return this._data;\n    }\n    hasName() {\n        return !!this._name;\n    }\n    get isGenerator() {\n        return this._generator;\n    }\n    get dataName() {\n        return this._name;\n    }\n    set dataName(name) {\n        this._name = name;\n    }\n    set parent(parent) {\n        throw new Error('Source nodes have to be roots.');\n    }\n    remove() {\n        throw new Error('Source nodes are roots and cannot be removed.');\n    }\n    hash() {\n        throw new Error('Cannot hash sources');\n    }\n    assemble() {\n        return Object.assign(Object.assign({ name: this._name }, this._data), { transform: [] });\n    }\n}\n//# sourceMappingURL=source.js.map","import { isArray, isString } from 'vega-util';\nimport { getFieldDef, isFieldDef, vgField } from '../../channeldef';\nimport { duplicate, getFirstDefined, hash } from '../../util';\nimport { sortParams } from '../common';\nimport { DataFlowNode } from './dataflow';\nfunction getStackByFields(model) {\n    return model.stack.stackBy.reduce((fields, by) => {\n        const fieldDef = by.fieldDef;\n        const _field = vgField(fieldDef);\n        if (_field) {\n            fields.push(_field);\n        }\n        return fields;\n    }, []);\n}\nfunction isValidAsArray(as) {\n    return isArray(as) && as.every(s => isString(s)) && as.length > 1;\n}\nexport class StackNode extends DataFlowNode {\n    constructor(parent, stack) {\n        super(parent);\n        this._stack = stack;\n    }\n    clone() {\n        return new StackNode(null, duplicate(this._stack));\n    }\n    static makeFromTransform(parent, stackTransform) {\n        const { stack, groupby, as, offset = 'zero' } = stackTransform;\n        const sortFields = [];\n        const sortOrder = [];\n        if (stackTransform.sort !== undefined) {\n            for (const sortField of stackTransform.sort) {\n                sortFields.push(sortField.field);\n                sortOrder.push(getFirstDefined(sortField.order, 'ascending'));\n            }\n        }\n        const sort = {\n            field: sortFields,\n            order: sortOrder\n        };\n        let normalizedAs;\n        if (isValidAsArray(as)) {\n            normalizedAs = as;\n        }\n        else if (isString(as)) {\n            normalizedAs = [as, as + '_end'];\n        }\n        else {\n            normalizedAs = [stackTransform.stack + '_start', stackTransform.stack + '_end'];\n        }\n        return new StackNode(parent, {\n            stackField: stack,\n            groupby,\n            offset,\n            sort,\n            facetby: [],\n            as: normalizedAs\n        });\n    }\n    static makeFromEncoding(parent, model) {\n        const stackProperties = model.stack;\n        const { encoding } = model;\n        if (!stackProperties) {\n            return null;\n        }\n        const { groupbyChannel, fieldChannel, offset, impute } = stackProperties;\n        let dimensionFieldDef;\n        if (groupbyChannel) {\n            const cDef = encoding[groupbyChannel];\n            dimensionFieldDef = getFieldDef(cDef); // Fair to cast as groupByChannel is always either x or y\n        }\n        const stackby = getStackByFields(model);\n        const orderDef = model.encoding.order;\n        let sort;\n        if (isArray(orderDef) || isFieldDef(orderDef)) {\n            sort = sortParams(orderDef);\n        }\n        else {\n            // default = descending by stackFields\n            // FIXME is the default here correct for binned fields?\n            sort = stackby.reduce((s, field) => {\n                s.field.push(field);\n                s.order.push(fieldChannel === 'y' ? 'descending' : 'ascending');\n                return s;\n            }, { field: [], order: [] });\n        }\n        return new StackNode(parent, {\n            dimensionFieldDef,\n            stackField: model.vgField(fieldChannel),\n            facetby: [],\n            stackby,\n            sort,\n            offset,\n            impute,\n            as: [\n                model.vgField(fieldChannel, { suffix: 'start', forAs: true }),\n                model.vgField(fieldChannel, { suffix: 'end', forAs: true })\n            ]\n        });\n    }\n    get stack() {\n        return this._stack;\n    }\n    addDimensions(fields) {\n        this._stack.facetby.push(...fields);\n    }\n    dependentFields() {\n        const out = new Set();\n        out.add(this._stack.stackField);\n        this.getGroupbyFields().forEach(out.add, out);\n        this._stack.facetby.forEach(out.add, out);\n        this._stack.sort.field.forEach(out.add, out);\n        return out;\n    }\n    producedFields() {\n        return new Set(this._stack.as);\n    }\n    hash() {\n        return `Stack ${hash(this._stack)}`;\n    }\n    getGroupbyFields() {\n        const { dimensionFieldDef, impute, groupby } = this._stack;\n        if (dimensionFieldDef) {\n            if (dimensionFieldDef.bin) {\n                if (impute) {\n                    // For binned group by field with impute, we calculate bin_mid\n                    // as we cannot impute two fields simultaneously\n                    return [vgField(dimensionFieldDef, { binSuffix: 'mid' })];\n                }\n                return [\n                    // For binned group by field without impute, we need both bin (start) and bin_end\n                    vgField(dimensionFieldDef, {}),\n                    vgField(dimensionFieldDef, { binSuffix: 'end' })\n                ];\n            }\n            return [vgField(dimensionFieldDef)];\n        }\n        return groupby !== null && groupby !== void 0 ? groupby : [];\n    }\n    assemble() {\n        const transform = [];\n        const { facetby, dimensionFieldDef, stackField: field, stackby, sort, offset, impute, as } = this._stack;\n        // Impute\n        if (impute && dimensionFieldDef) {\n            const { band = 0.5, bin } = dimensionFieldDef;\n            if (bin) {\n                // As we can only impute one field at a time, we need to calculate\n                // mid point for a binned field\n                transform.push({\n                    type: 'formula',\n                    expr: `${band}*` +\n                        vgField(dimensionFieldDef, { expr: 'datum' }) +\n                        `+${1 - band}*` +\n                        vgField(dimensionFieldDef, { expr: 'datum', binSuffix: 'end' }),\n                    as: vgField(dimensionFieldDef, { binSuffix: 'mid', forAs: true })\n                });\n            }\n            transform.push({\n                type: 'impute',\n                field,\n                groupby: [...stackby, ...facetby],\n                key: vgField(dimensionFieldDef, { binSuffix: 'mid' }),\n                method: 'value',\n                value: 0\n            });\n        }\n        // Stack\n        transform.push({\n            type: 'stack',\n            groupby: [...this.getGroupbyFields(), ...facetby],\n            field,\n            sort,\n            as,\n            offset\n        });\n        return transform;\n    }\n}\n//# sourceMappingURL=stack.js.map","import { DataSourceType } from '../../data';\nimport { AggregateNode } from './aggregate';\nimport { OutputNode } from './dataflow';\nimport { FacetNode } from './facet';\nimport { JoinAggregateTransformNode } from './joinaggregate';\nimport { FACET_SCALE_PREFIX } from './optimize';\nimport { StackNode } from './stack';\nimport { WindowTransformNode } from './window';\n/**\n * Clones the subtree and ignores output nodes except for the leaves, which are renamed.\n */\nfunction cloneSubtree(facet) {\n    function clone(node) {\n        if (!(node instanceof FacetNode)) {\n            const copy = node.clone();\n            if (copy instanceof OutputNode) {\n                const newName = FACET_SCALE_PREFIX + copy.getSource();\n                copy.setSource(newName);\n                facet.model.component.data.outputNodes[newName] = copy;\n            }\n            else if (copy instanceof AggregateNode ||\n                copy instanceof StackNode ||\n                copy instanceof WindowTransformNode ||\n                copy instanceof JoinAggregateTransformNode) {\n                copy.addDimensions(facet.fields);\n            }\n            for (const n of node.children.flatMap(clone)) {\n                n.parent = copy;\n            }\n            return [copy];\n        }\n        return node.children.flatMap(clone);\n    }\n    return clone;\n}\n/**\n * Move facet nodes down to the next fork or output node. Also pull the main output with the facet node.\n * After moving down the facet node, make a copy of the subtree and make it a child of the main output.\n */\nexport function moveFacetDown(node) {\n    if (node instanceof FacetNode) {\n        if (node.numChildren() === 1 && !(node.children[0] instanceof OutputNode)) {\n            // move down until we hit a fork or output node\n            const child = node.children[0];\n            if (child instanceof AggregateNode ||\n                child instanceof StackNode ||\n                child instanceof WindowTransformNode ||\n                child instanceof JoinAggregateTransformNode) {\n                child.addDimensions(node.fields);\n            }\n            child.swapWithParent();\n            moveFacetDown(node);\n        }\n        else {\n            // move main to facet\n            const facetMain = node.model.component.data.main;\n            moveMainDownToFacet(facetMain);\n            // replicate the subtree and place it before the facet's main node\n            const cloner = cloneSubtree(node);\n            const copy = node.children.map(cloner).flat();\n            for (const c of copy) {\n                c.parent = facetMain;\n            }\n        }\n    }\n    else {\n        node.children.map(moveFacetDown);\n    }\n}\nfunction moveMainDownToFacet(node) {\n    if (node instanceof OutputNode && node.type === DataSourceType.Main) {\n        if (node.numChildren() === 1) {\n            const child = node.children[0];\n            if (!(child instanceof FacetNode)) {\n                child.swapWithParent();\n                moveMainDownToFacet(node);\n            }\n        }\n    }\n}\n//# sourceMappingURL=subtree.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { getSecondaryRangeChannel } from '../../channel';\nimport { hasBand, vgField } from '../../channeldef';\nimport { getTimeUnitParts, normalizeTimeUnit } from '../../timeunit';\nimport { duplicate, hash, isEmpty, replacePathInField, vals, entries } from '../../util';\nimport { isUnitModel } from '../model';\nimport { DataFlowNode } from './dataflow';\nexport class TimeUnitNode extends DataFlowNode {\n    constructor(parent, formula) {\n        super(parent);\n        this.formula = formula;\n    }\n    clone() {\n        return new TimeUnitNode(null, duplicate(this.formula));\n    }\n    static makeFromEncoding(parent, model) {\n        const formula = model.reduceFieldDef((timeUnitComponent, fieldDef, channel) => {\n            const { field, timeUnit } = fieldDef;\n            const channelDef2 = isUnitModel(model) ? model.encoding[getSecondaryRangeChannel(channel)] : undefined;\n            const band = isUnitModel(model) && hasBand(channel, fieldDef, channelDef2, model.stack, model.markDef, model.config);\n            if (timeUnit) {\n                const as = vgField(fieldDef, { forAs: true });\n                timeUnitComponent[hash({\n                    as,\n                    field,\n                    timeUnit\n                })] = Object.assign({ as,\n                    field,\n                    timeUnit }, (band ? { band: true } : {}));\n            }\n            return timeUnitComponent;\n        }, {});\n        if (isEmpty(formula)) {\n            return null;\n        }\n        return new TimeUnitNode(parent, formula);\n    }\n    static makeFromTransform(parent, t) {\n        const _a = Object.assign({}, t), { timeUnit } = _a, other = __rest(_a, [\"timeUnit\"]);\n        const normalizedTimeUnit = normalizeTimeUnit(timeUnit);\n        const component = Object.assign(Object.assign({}, other), { timeUnit: normalizedTimeUnit });\n        return new TimeUnitNode(parent, {\n            [hash(component)]: component\n        });\n    }\n    /**\n     * Merge together TimeUnitNodes assigning the children of `other` to `this`\n     * and removing `other`.\n     */\n    merge(other) {\n        this.formula = Object.assign({}, this.formula);\n        // if the same hash happen twice, merge \"band\"\n        for (const key in other.formula) {\n            if (!this.formula[key] || other.formula[key].band) {\n                // copy if it's not a duplicate or if we need to copy band over\n                this.formula[key] = other.formula[key];\n            }\n        }\n        for (const child of other.children) {\n            other.removeChild(child);\n            child.parent = this;\n        }\n        other.remove();\n    }\n    /**\n     * Remove time units coming from the other node.\n     */\n    removeFormulas(fields) {\n        const newFormula = {};\n        for (const [key, timeUnit] of entries(this.formula)) {\n            if (!fields.has(timeUnit.as)) {\n                newFormula[key] = timeUnit;\n            }\n        }\n        this.formula = newFormula;\n    }\n    producedFields() {\n        return new Set(vals(this.formula).map(f => f.as));\n    }\n    dependentFields() {\n        return new Set(vals(this.formula).map(f => f.field));\n    }\n    hash() {\n        return `TimeUnit ${hash(this.formula)}`;\n    }\n    assemble() {\n        const transforms = [];\n        for (const f of vals(this.formula)) {\n            const { field, as, timeUnit } = f;\n            const _a = normalizeTimeUnit(timeUnit), { unit, utc } = _a, params = __rest(_a, [\"unit\", \"utc\"]);\n            transforms.push(Object.assign(Object.assign(Object.assign(Object.assign({ field: replacePathInField(field), type: 'timeunit' }, (unit ? { units: getTimeUnitParts(unit) } : {})), (utc ? { timezone: 'utc' } : {})), params), { as: [as, `${as}_end`] }));\n        }\n        return transforms;\n    }\n}\n//# sourceMappingURL=timeunit.js.map","import { isAggregateOp } from '../../aggregate';\nimport { vgField } from '../../channeldef';\nimport { duplicate, hash } from '../../util';\nimport { unique } from '../../util';\nimport { DataFlowNode } from './dataflow';\n/**\n * A class for the window transform nodes\n */\nexport class WindowTransformNode extends DataFlowNode {\n    constructor(parent, transform) {\n        super(parent);\n        this.transform = transform;\n    }\n    clone() {\n        return new WindowTransformNode(null, duplicate(this.transform));\n    }\n    addDimensions(fields) {\n        this.transform.groupby = unique(this.transform.groupby.concat(fields), d => d);\n    }\n    dependentFields() {\n        var _a, _b;\n        const out = new Set();\n        ((_a = this.transform.groupby) !== null && _a !== void 0 ? _a : []).forEach(out.add, out);\n        ((_b = this.transform.sort) !== null && _b !== void 0 ? _b : []).forEach(m => out.add(m.field));\n        this.transform.window\n            .map(w => w.field)\n            .filter(f => f !== undefined)\n            .forEach(out.add, out);\n        return out;\n    }\n    producedFields() {\n        return new Set(this.transform.window.map(this.getDefaultName));\n    }\n    getDefaultName(windowFieldDef) {\n        var _a;\n        return (_a = windowFieldDef.as) !== null && _a !== void 0 ? _a : vgField(windowFieldDef);\n    }\n    hash() {\n        return `WindowTransform ${hash(this.transform)}`;\n    }\n    assemble() {\n        var _a;\n        const fields = [];\n        const ops = [];\n        const as = [];\n        const params = [];\n        for (const window of this.transform.window) {\n            ops.push(window.op);\n            as.push(this.getDefaultName(window));\n            params.push(window.param === undefined ? null : window.param);\n            fields.push(window.field === undefined ? null : window.field);\n        }\n        const frame = this.transform.frame;\n        const groupby = this.transform.groupby;\n        if (frame && frame[0] === null && frame[1] === null && ops.every(o => isAggregateOp(o))) {\n            // when the window does not rely on any particular window ops or frame, switch to a simpler and more efficient joinaggregate\n            return Object.assign({ type: 'joinaggregate', as, ops: ops, fields }, (groupby !== undefined ? { groupby } : {}));\n        }\n        const sortFields = [];\n        const sortOrder = [];\n        if (this.transform.sort !== undefined) {\n            for (const sortField of this.transform.sort) {\n                sortFields.push(sortField.field);\n                sortOrder.push((_a = sortField.order) !== null && _a !== void 0 ? _a : 'ascending');\n            }\n        }\n        const sort = {\n            field: sortFields,\n            order: sortOrder\n        };\n        const ignorePeers = this.transform.ignorePeers;\n        return Object.assign(Object.assign(Object.assign({ type: 'window', params,\n            as,\n            ops,\n            fields,\n            sort }, (ignorePeers !== undefined ? { ignorePeers } : {})), (groupby !== undefined ? { groupby } : {})), (frame !== undefined ? { frame } : {}));\n    }\n}\n//# sourceMappingURL=window.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isArray } from 'vega-util';\nimport { isBinning } from '../bin';\nimport { COLUMN, FACET_CHANNELS, POSITION_SCALE_CHANNELS, ROW } from '../channel';\nimport { initFieldDef, vgField } from '../channeldef';\nimport { replaceExprRefInIndex } from '../expr';\nimport * as log from '../log';\nimport { hasDiscreteDomain } from '../scale';\nimport { DEFAULT_SORT_OP, isSortField } from '../sort';\nimport { isFacetMapping } from '../spec/facet';\nimport { contains, keys } from '../util';\nimport { isVgRangeStep } from '../vega.schema';\nimport { buildModel } from './buildmodel';\nimport { assembleFacetData } from './data/assemble';\nimport { sortArrayIndexField } from './data/calculate';\nimport { parseData } from './data/parse';\nimport { assembleLabelTitle } from './header/assemble';\nimport { getHeaderChannel, getHeaderProperty } from './header/common';\nimport { HEADER_CHANNELS, HEADER_TYPES } from './header/component';\nimport { parseFacetHeaders } from './header/parse';\nimport { parseChildrenLayoutSize } from './layoutsize/parse';\nimport { ModelWithField } from './model';\nimport { assembleDomain, getFieldFromDomain } from './scale/domain';\nimport { assembleFacetSignals } from './selection/assemble';\nexport function facetSortFieldName(fieldDef, sort, opt) {\n    return vgField(sort, Object.assign({ suffix: `by_${vgField(fieldDef)}` }, (opt !== null && opt !== void 0 ? opt : {})));\n}\nexport class FacetModel extends ModelWithField {\n    constructor(spec, parent, parentGivenName, config) {\n        super(spec, 'facet', parent, parentGivenName, config, spec.resolve);\n        this.child = buildModel(spec.spec, this, this.getName('child'), undefined, config);\n        this.children = [this.child];\n        this.facet = this.initFacet(spec.facet);\n    }\n    initFacet(facet) {\n        // clone to prevent side effect to the original spec\n        if (!isFacetMapping(facet)) {\n            return { facet: this.initFacetFieldDef(facet, 'facet') };\n        }\n        const channels = keys(facet);\n        const normalizedFacet = {};\n        for (const channel of channels) {\n            if (!contains([ROW, COLUMN], channel)) {\n                // Drop unsupported channel\n                log.warn(log.message.incompatibleChannel(channel, 'facet'));\n                break;\n            }\n            const fieldDef = facet[channel];\n            if (fieldDef.field === undefined) {\n                log.warn(log.message.emptyFieldDef(fieldDef, channel));\n                break;\n            }\n            normalizedFacet[channel] = this.initFacetFieldDef(fieldDef, channel);\n        }\n        return normalizedFacet;\n    }\n    initFacetFieldDef(fieldDef, channel) {\n        const { header } = fieldDef, rest = __rest(fieldDef, [\"header\"]);\n        // Cast because we call initFieldDef, which assumes general FieldDef.\n        // However, FacetFieldDef is a bit more constrained than the general FieldDef\n        const facetFieldDef = initFieldDef(rest, channel);\n        if (header) {\n            facetFieldDef.header = replaceExprRefInIndex(header);\n        }\n        return facetFieldDef;\n    }\n    channelHasField(channel) {\n        return !!this.facet[channel];\n    }\n    fieldDef(channel) {\n        return this.facet[channel];\n    }\n    parseData() {\n        this.component.data = parseData(this);\n        this.child.parseData();\n    }\n    parseLayoutSize() {\n        parseChildrenLayoutSize(this);\n    }\n    parseSelections() {\n        // As a facet has a single child, the selection components are the same.\n        // The child maintains its selections to assemble signals, which remain\n        // within its unit.\n        this.child.parseSelections();\n        this.component.selection = this.child.component.selection;\n    }\n    parseMarkGroup() {\n        this.child.parseMarkGroup();\n    }\n    parseAxesAndHeaders() {\n        this.child.parseAxesAndHeaders();\n        parseFacetHeaders(this);\n    }\n    assembleSelectionTopLevelSignals(signals) {\n        return this.child.assembleSelectionTopLevelSignals(signals);\n    }\n    assembleSignals() {\n        this.child.assembleSignals();\n        return [];\n    }\n    assembleSelectionData(data) {\n        return this.child.assembleSelectionData(data);\n    }\n    getHeaderLayoutMixins() {\n        var _a, _b, _c;\n        const layoutMixins = {};\n        for (const channel of FACET_CHANNELS) {\n            for (const headerType of HEADER_TYPES) {\n                const layoutHeaderComponent = this.component.layoutHeaders[channel];\n                const headerComponent = layoutHeaderComponent[headerType];\n                const { facetFieldDef } = layoutHeaderComponent;\n                if (facetFieldDef) {\n                    const titleOrient = getHeaderProperty('titleOrient', facetFieldDef.header, this.config, channel);\n                    if (contains(['right', 'bottom'], titleOrient)) {\n                        const headerChannel = getHeaderChannel(channel, titleOrient);\n                        layoutMixins.titleAnchor = (_a = layoutMixins.titleAnchor) !== null && _a !== void 0 ? _a : {};\n                        layoutMixins.titleAnchor[headerChannel] = 'end';\n                    }\n                }\n                if (headerComponent === null || headerComponent === void 0 ? void 0 : headerComponent[0]) {\n                    // set header/footerBand\n                    const sizeType = channel === 'row' ? 'height' : 'width';\n                    const bandType = headerType === 'header' ? 'headerBand' : 'footerBand';\n                    if (channel !== 'facet' && !this.child.component.layoutSize.get(sizeType)) {\n                        // If facet child does not have size signal, then apply headerBand\n                        layoutMixins[bandType] = (_b = layoutMixins[bandType]) !== null && _b !== void 0 ? _b : {};\n                        layoutMixins[bandType][channel] = 0.5;\n                    }\n                    if (layoutHeaderComponent.title) {\n                        layoutMixins.offset = (_c = layoutMixins.offset) !== null && _c !== void 0 ? _c : {};\n                        layoutMixins.offset[channel === 'row' ? 'rowTitle' : 'columnTitle'] = 10;\n                    }\n                }\n            }\n        }\n        return layoutMixins;\n    }\n    assembleDefaultLayout() {\n        const { column, row } = this.facet;\n        const columns = column ? this.columnDistinctSignal() : row ? 1 : undefined;\n        let align = 'all';\n        // Do not align the cells if the scale corresponding to the direction is indepent.\n        // We always align when we facet into both row and column.\n        if (!row && this.component.resolve.scale.x === 'independent') {\n            align = 'none';\n        }\n        else if (!column && this.component.resolve.scale.y === 'independent') {\n            align = 'none';\n        }\n        return Object.assign(Object.assign(Object.assign({}, this.getHeaderLayoutMixins()), (columns ? { columns } : {})), { bounds: 'full', align });\n    }\n    assembleLayoutSignals() {\n        // FIXME(https://github.com/vega/vega-lite/issues/1193): this can be incorrect if we have independent scales.\n        return this.child.assembleLayoutSignals();\n    }\n    columnDistinctSignal() {\n        if (this.parent && this.parent instanceof FacetModel) {\n            // For nested facet, we will add columns to group mark instead\n            // See discussion in https://github.com/vega/vega/issues/952\n            // and https://github.com/vega/vega-view/releases/tag/v1.2.6\n            return undefined;\n        }\n        else {\n            // In facetNode.assemble(), the name is always this.getName('column') + '_layout'.\n            const facetLayoutDataName = this.getName('column_domain');\n            return { signal: `length(data('${facetLayoutDataName}'))` };\n        }\n    }\n    assembleGroup(signals) {\n        if (this.parent && this.parent instanceof FacetModel) {\n            // Provide number of columns for layout.\n            // See discussion in https://github.com/vega/vega/issues/952\n            // and https://github.com/vega/vega-view/releases/tag/v1.2.6\n            return Object.assign(Object.assign({}, (this.channelHasField('column')\n                ? {\n                    encode: {\n                        update: {\n                            // TODO(https://github.com/vega/vega-lite/issues/2759):\n                            // Correct the signal for facet of concat of facet_column\n                            columns: { field: vgField(this.facet.column, { prefix: 'distinct' }) }\n                        }\n                    }\n                }\n                : {})), super.assembleGroup(signals));\n        }\n        return super.assembleGroup(signals);\n    }\n    /**\n     * Aggregate cardinality for calculating size\n     */\n    getCardinalityAggregateForChild() {\n        const fields = [];\n        const ops = [];\n        const as = [];\n        if (this.child instanceof FacetModel) {\n            if (this.child.channelHasField('column')) {\n                const field = vgField(this.child.facet.column);\n                fields.push(field);\n                ops.push('distinct');\n                as.push(`distinct_${field}`);\n            }\n        }\n        else {\n            for (const channel of POSITION_SCALE_CHANNELS) {\n                const childScaleComponent = this.child.component.scales[channel];\n                if (childScaleComponent && !childScaleComponent.merged) {\n                    const type = childScaleComponent.get('type');\n                    const range = childScaleComponent.get('range');\n                    if (hasDiscreteDomain(type) && isVgRangeStep(range)) {\n                        const domain = assembleDomain(this.child, channel);\n                        const field = getFieldFromDomain(domain);\n                        if (field) {\n                            fields.push(field);\n                            ops.push('distinct');\n                            as.push(`distinct_${field}`);\n                        }\n                        else {\n                            log.warn(log.message.unknownField(channel));\n                        }\n                    }\n                }\n            }\n        }\n        return { fields, ops, as };\n    }\n    assembleFacet() {\n        const { name, data } = this.component.data.facetRoot;\n        const { row, column } = this.facet;\n        const { fields, ops, as } = this.getCardinalityAggregateForChild();\n        const groupby = [];\n        for (const channel of FACET_CHANNELS) {\n            const fieldDef = this.facet[channel];\n            if (fieldDef) {\n                groupby.push(vgField(fieldDef));\n                const { bin, sort } = fieldDef;\n                if (isBinning(bin)) {\n                    groupby.push(vgField(fieldDef, { binSuffix: 'end' }));\n                }\n                if (isSortField(sort)) {\n                    const { field, op = DEFAULT_SORT_OP } = sort;\n                    const outputName = facetSortFieldName(fieldDef, sort);\n                    if (row && column) {\n                        // For crossed facet, use pre-calculate field as it requires a different groupby\n                        // For each calculated field, apply max and assign them to the same name as\n                        // all values of the same group should be the same anyway.\n                        fields.push(outputName);\n                        ops.push('max');\n                        as.push(outputName);\n                    }\n                    else {\n                        fields.push(field);\n                        ops.push(op);\n                        as.push(outputName);\n                    }\n                }\n                else if (isArray(sort)) {\n                    const outputName = sortArrayIndexField(fieldDef, channel);\n                    fields.push(outputName);\n                    ops.push('max');\n                    as.push(outputName);\n                }\n            }\n        }\n        const cross = !!row && !!column;\n        return Object.assign({ name,\n            data,\n            groupby }, (cross || fields.length > 0\n            ? {\n                aggregate: Object.assign(Object.assign({}, (cross ? { cross } : {})), (fields.length ? { fields, ops, as } : {}))\n            }\n            : {}));\n    }\n    facetSortFields(channel) {\n        const { facet } = this;\n        const fieldDef = facet[channel];\n        if (fieldDef) {\n            if (isSortField(fieldDef.sort)) {\n                return [facetSortFieldName(fieldDef, fieldDef.sort, { expr: 'datum' })];\n            }\n            else if (isArray(fieldDef.sort)) {\n                return [sortArrayIndexField(fieldDef, channel, { expr: 'datum' })];\n            }\n            return [vgField(fieldDef, { expr: 'datum' })];\n        }\n        return [];\n    }\n    facetSortOrder(channel) {\n        const { facet } = this;\n        const fieldDef = facet[channel];\n        if (fieldDef) {\n            const { sort } = fieldDef;\n            const order = (isSortField(sort) ? sort.order : !isArray(sort) && sort) || 'ascending';\n            return [order];\n        }\n        return [];\n    }\n    assembleLabelTitle() {\n        var _a;\n        const { facet, config } = this;\n        if (facet.facet) {\n            // Facet always uses title to display labels\n            return assembleLabelTitle(facet.facet, 'facet', config);\n        }\n        const ORTHOGONAL_ORIENT = {\n            row: ['top', 'bottom'],\n            column: ['left', 'right']\n        };\n        for (const channel of HEADER_CHANNELS) {\n            if (facet[channel]) {\n                const labelOrient = getHeaderProperty('labelOrient', (_a = facet[channel]) === null || _a === void 0 ? void 0 : _a.header, config, channel);\n                if (contains(ORTHOGONAL_ORIENT[channel], labelOrient)) {\n                    // Row/Column with orthogonal labelOrient must use title to display labels\n                    return assembleLabelTitle(facet[channel], channel, config);\n                }\n            }\n        }\n        return undefined;\n    }\n    assembleMarks() {\n        const { child } = this;\n        // If we facet by two dimensions, we need to add a cross operator to the aggregation\n        // so that we create all groups\n        const facetRoot = this.component.data.facetRoot;\n        const data = assembleFacetData(facetRoot);\n        const encodeEntry = child.assembleGroupEncodeEntry(false);\n        const title = this.assembleLabelTitle() || child.assembleTitle();\n        const style = child.assembleGroupStyle();\n        const markGroup = Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ name: this.getName('cell'), type: 'group' }, (title ? { title } : {})), (style ? { style } : {})), { from: {\n                facet: this.assembleFacet()\n            }, \n            // TODO: move this to after data\n            sort: {\n                field: FACET_CHANNELS.map(c => this.facetSortFields(c)).flat(),\n                order: FACET_CHANNELS.map(c => this.facetSortOrder(c)).flat()\n            } }), (data.length > 0 ? { data: data } : {})), (encodeEntry ? { encode: { update: encodeEntry } } : {})), child.assembleGroup(assembleFacetSignals(this, [])));\n        return [markGroup];\n    }\n    getMapping() {\n        return this.facet;\n    }\n}\n//# sourceMappingURL=facet.js.map","import { isString } from 'vega-util';\nimport { isBinning } from '../bin';\nimport { channelDefType, isFieldDef, isFieldOrDatumDefForTimeFormat, isScaleFieldDef, vgField } from '../channeldef';\nimport { fieldValidPredicate } from '../predicate';\nimport { ScaleType } from '../scale';\nimport { formatExpression, normalizeTimeUnit, timeUnitSpecifierExpression } from '../timeunit';\nimport { QUANTITATIVE } from '../type';\nimport { isSignalRef } from '../vega.schema';\nimport { datumDefToExpr } from './mark/encode/valueref';\nexport function isCustomFormatType(formatType) {\n    return formatType && formatType !== 'number' && formatType !== 'time';\n}\nfunction customFormatExpr(formatType, field, format) {\n    return `${formatType}(${field}${format ? `, ${JSON.stringify(format)}` : ''})`;\n}\nexport const BIN_RANGE_DELIMITER = ' \\u2013 ';\nexport function formatSignalRef({ fieldOrDatumDef, format, formatType, expr, normalizeStack, config }) {\n    var _a, _b;\n    if (isCustomFormatType(formatType)) {\n        return formatCustomType({\n            fieldOrDatumDef,\n            format,\n            formatType,\n            expr,\n            config\n        });\n    }\n    const field = fieldToFormat(fieldOrDatumDef, expr, normalizeStack);\n    if (isFieldOrDatumDefForTimeFormat(fieldOrDatumDef)) {\n        const signal = timeFormatExpression(field, isFieldDef(fieldOrDatumDef) ? (_a = normalizeTimeUnit(fieldOrDatumDef.timeUnit)) === null || _a === void 0 ? void 0 : _a.unit : undefined, format, config.timeFormat, isScaleFieldDef(fieldOrDatumDef) && ((_b = fieldOrDatumDef.scale) === null || _b === void 0 ? void 0 : _b.type) === ScaleType.UTC);\n        return signal ? { signal } : undefined;\n    }\n    format = numberFormat(channelDefType(fieldOrDatumDef), format, config);\n    if (isFieldDef(fieldOrDatumDef) && isBinning(fieldOrDatumDef.bin)) {\n        const endField = vgField(fieldOrDatumDef, { expr, binSuffix: 'end' });\n        return {\n            signal: binFormatExpression(field, endField, format, formatType, config)\n        };\n    }\n    else if (format || channelDefType(fieldOrDatumDef) === 'quantitative') {\n        return {\n            signal: `${formatExpr(field, format)}`\n        };\n    }\n    else {\n        return { signal: `isValid(${field}) ? ${field} : \"\"+${field}` };\n    }\n}\nfunction fieldToFormat(fieldOrDatumDef, expr, normalizeStack) {\n    if (isFieldDef(fieldOrDatumDef)) {\n        if (normalizeStack) {\n            return `${vgField(fieldOrDatumDef, { expr, suffix: 'end' })}-${vgField(fieldOrDatumDef, {\n                expr,\n                suffix: 'start'\n            })}`;\n        }\n        else {\n            return vgField(fieldOrDatumDef, { expr });\n        }\n    }\n    else {\n        return datumDefToExpr(fieldOrDatumDef);\n    }\n}\nexport function formatCustomType({ fieldOrDatumDef, format, formatType, expr, normalizeStack, config, field }) {\n    field = field !== null && field !== void 0 ? field : fieldToFormat(fieldOrDatumDef, expr, normalizeStack);\n    if (isFieldDef(fieldOrDatumDef) && isBinning(fieldOrDatumDef.bin)) {\n        const endField = vgField(fieldOrDatumDef, { expr, binSuffix: 'end' });\n        return {\n            signal: binFormatExpression(field, endField, format, formatType, config)\n        };\n    }\n    return { signal: customFormatExpr(formatType, field, format) };\n}\nexport function guideFormat(fieldOrDatumDef, type, format, formatType, config, omitTimeFormatConfig // axis doesn't use config.timeFormat\n) {\n    var _a;\n    if (isCustomFormatType(formatType)) {\n        return undefined; // handled in encode block\n    }\n    if (isFieldOrDatumDefForTimeFormat(fieldOrDatumDef)) {\n        const timeUnit = isFieldDef(fieldOrDatumDef) ? (_a = normalizeTimeUnit(fieldOrDatumDef.timeUnit)) === null || _a === void 0 ? void 0 : _a.unit : undefined;\n        return timeFormat(format, timeUnit, config, omitTimeFormatConfig);\n    }\n    return numberFormat(type, format, config);\n}\nexport function guideFormatType(formatType, fieldOrDatumDef, scaleType) {\n    if (formatType && (isSignalRef(formatType) || formatType === 'number' || formatType === 'time')) {\n        return formatType;\n    }\n    if (isFieldOrDatumDefForTimeFormat(fieldOrDatumDef) && scaleType !== 'time' && scaleType !== 'utc') {\n        return 'time';\n    }\n    return undefined;\n}\n/**\n * Returns number format for a fieldDef.\n */\nexport function numberFormat(type, specifiedFormat, config) {\n    // Specified format in axis/legend has higher precedence than fieldDef.format\n    if (isString(specifiedFormat)) {\n        return specifiedFormat;\n    }\n    if (type === QUANTITATIVE) {\n        // we only apply the default if the field is quantitative\n        return config.numberFormat;\n    }\n    return undefined;\n}\n/**\n * Returns time format for a fieldDef for use in guides.\n */\nexport function timeFormat(specifiedFormat, timeUnit, config, omitTimeFormatConfig) {\n    if (specifiedFormat) {\n        return specifiedFormat;\n    }\n    if (timeUnit) {\n        return {\n            signal: timeUnitSpecifierExpression(timeUnit)\n        };\n    }\n    return omitTimeFormatConfig ? undefined : config.timeFormat;\n}\nfunction formatExpr(field, format) {\n    return `format(${field}, \"${format || ''}\")`;\n}\nfunction binNumberFormatExpr(field, format, formatType, config) {\n    var _a;\n    if (isCustomFormatType(formatType)) {\n        return customFormatExpr(formatType, field, format);\n    }\n    return formatExpr(field, (_a = (isString(format) ? format : undefined)) !== null && _a !== void 0 ? _a : config.numberFormat);\n}\nexport function binFormatExpression(startField, endField, format, formatType, config) {\n    const start = binNumberFormatExpr(startField, format, formatType, config);\n    const end = binNumberFormatExpr(endField, format, formatType, config);\n    return `${fieldValidPredicate(startField, false)} ? \"null\" : ${start} + \"${BIN_RANGE_DELIMITER}\" + ${end}`;\n}\n/**\n * Returns the time expression used for axis/legend labels or text mark for a temporal field\n */\nexport function timeFormatExpression(field, timeUnit, format, rawTimeFormat, // should be provided only for actual text and headers, not axis/legend labels\nisUTCScale) {\n    if (!timeUnit || format) {\n        // If there is no time unit, or if user explicitly specifies format for axis/legend/text.\n        format = isString(format) ? format : rawTimeFormat; // only use provided timeFormat if there is no timeUnit.\n        return `${isUTCScale ? 'utc' : 'time'}Format(${field}, '${format}')`;\n    }\n    else {\n        return formatExpression(timeUnit, field, isUTCScale);\n    }\n}\n//# sourceMappingURL=format.js.map","import { keys } from '../util';\nimport { signalOrValueRef } from './common';\nimport { wrapCondition } from './mark/encode';\nexport function guideEncodeEntry(encoding, model) {\n    return keys(encoding).reduce((encode, channel) => {\n        const valueDef = encoding[channel];\n        return Object.assign(Object.assign({}, encode), wrapCondition(model, valueDef, channel, def => signalOrValueRef(def.value)));\n    }, {});\n}\n//# sourceMappingURL=guide.js.map","/**\n * Utility for generating row / column headers\n */\nimport { isArray } from 'vega-util';\nimport { FACET_CHANNELS } from '../../channel';\nimport { vgField } from '../../channeldef';\nimport { HEADER_LABEL_PROPERTIES, HEADER_LABEL_PROPERTIES_MAP, HEADER_TITLE_PROPERTIES, HEADER_TITLE_PROPERTIES_MAP } from '../../header';\nimport { isSortField } from '../../sort';\nimport { isFacetMapping } from '../../spec/facet';\nimport { contains, isEmpty, normalizeAngle, replaceAll } from '../../util';\nimport { defaultLabelAlign, defaultLabelBaseline } from '../axis/properties';\nimport { sortArrayIndexField } from '../data/calculate';\nimport { formatSignalRef } from '../format';\nimport { isFacetModel } from '../model';\nimport { getHeaderChannel, getHeaderProperties, getHeaderProperty } from './common';\nimport { HEADER_TYPES } from './component';\n// TODO: rename to assembleHeaderTitleGroup\nexport function assembleTitleGroup(model, channel) {\n    const title = model.component.layoutHeaders[channel].title;\n    const config = model.config ? model.config : undefined;\n    const facetFieldDef = model.component.layoutHeaders[channel].facetFieldDef\n        ? model.component.layoutHeaders[channel].facetFieldDef\n        : undefined;\n    const { titleAnchor, titleAngle: ta, titleOrient } = getHeaderProperties(['titleAnchor', 'titleAngle', 'titleOrient'], facetFieldDef.header, config, channel);\n    const headerChannel = getHeaderChannel(channel, titleOrient);\n    const titleAngle = normalizeAngle(ta);\n    return {\n        name: `${channel}-title`,\n        type: 'group',\n        role: `${headerChannel}-title`,\n        title: Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ text: title }, (channel === 'row' ? { orient: 'left' } : {})), { style: 'guide-title' }), defaultHeaderGuideBaseline(titleAngle, headerChannel)), defaultHeaderGuideAlign(headerChannel, titleAngle, titleAnchor)), assembleHeaderProperties(config, facetFieldDef, channel, HEADER_TITLE_PROPERTIES, HEADER_TITLE_PROPERTIES_MAP))\n    };\n}\nexport function defaultHeaderGuideAlign(headerChannel, angle, anchor = 'middle') {\n    switch (anchor) {\n        case 'start':\n            return { align: 'left' };\n        case 'end':\n            return { align: 'right' };\n    }\n    const align = defaultLabelAlign(angle, headerChannel === 'row' ? 'left' : 'top', headerChannel === 'row' ? 'y' : 'x');\n    return align ? { align } : {};\n}\nexport function defaultHeaderGuideBaseline(angle, channel) {\n    const baseline = defaultLabelBaseline(angle, channel === 'row' ? 'left' : 'top', channel === 'row' ? 'y' : 'x', true);\n    return baseline ? { baseline } : {};\n}\nexport function assembleHeaderGroups(model, channel) {\n    const layoutHeader = model.component.layoutHeaders[channel];\n    const groups = [];\n    for (const headerType of HEADER_TYPES) {\n        if (layoutHeader[headerType]) {\n            for (const headerComponent of layoutHeader[headerType]) {\n                const group = assembleHeaderGroup(model, channel, headerType, layoutHeader, headerComponent);\n                if (group != null) {\n                    groups.push(group);\n                }\n            }\n        }\n    }\n    return groups;\n}\nfunction getSort(facetFieldDef, channel) {\n    var _a;\n    const { sort } = facetFieldDef;\n    if (isSortField(sort)) {\n        return {\n            field: vgField(sort, { expr: 'datum' }),\n            order: (_a = sort.order) !== null && _a !== void 0 ? _a : 'ascending'\n        };\n    }\n    else if (isArray(sort)) {\n        return {\n            field: sortArrayIndexField(facetFieldDef, channel, { expr: 'datum' }),\n            order: 'ascending'\n        };\n    }\n    else {\n        return {\n            field: vgField(facetFieldDef, { expr: 'datum' }),\n            order: sort !== null && sort !== void 0 ? sort : 'ascending'\n        };\n    }\n}\nexport function assembleLabelTitle(facetFieldDef, channel, config) {\n    const { format, formatType, labelAngle, labelAnchor, labelOrient, labelExpr } = getHeaderProperties(['format', 'formatType', 'labelAngle', 'labelAnchor', 'labelOrient', 'labelExpr'], facetFieldDef.header, config, channel);\n    const titleTextExpr = formatSignalRef({ fieldOrDatumDef: facetFieldDef, format, formatType, expr: 'parent', config })\n        .signal;\n    const headerChannel = getHeaderChannel(channel, labelOrient);\n    return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ text: {\n            signal: labelExpr\n                ? replaceAll(replaceAll(labelExpr, 'datum.label', titleTextExpr), 'datum.value', vgField(facetFieldDef, { expr: 'parent' }))\n                : titleTextExpr\n        } }, (channel === 'row' ? { orient: 'left' } : {})), { style: 'guide-label', frame: 'group' }), defaultHeaderGuideBaseline(labelAngle, headerChannel)), defaultHeaderGuideAlign(headerChannel, labelAngle, labelAnchor)), assembleHeaderProperties(config, facetFieldDef, channel, HEADER_LABEL_PROPERTIES, HEADER_LABEL_PROPERTIES_MAP));\n}\nexport function assembleHeaderGroup(model, channel, headerType, layoutHeader, headerComponent) {\n    if (headerComponent) {\n        let title = null;\n        const { facetFieldDef } = layoutHeader;\n        const config = model.config ? model.config : undefined;\n        if (facetFieldDef && headerComponent.labels) {\n            const { labelOrient } = getHeaderProperties(['labelOrient'], facetFieldDef.header, config, channel);\n            // Include label title in the header if orient aligns with the channel\n            if ((channel === 'row' && !contains(['top', 'bottom'], labelOrient)) ||\n                (channel === 'column' && !contains(['left', 'right'], labelOrient))) {\n                title = assembleLabelTitle(facetFieldDef, channel, config);\n            }\n        }\n        const isFacetWithoutRowCol = isFacetModel(model) && !isFacetMapping(model.facet);\n        const axes = headerComponent.axes;\n        const hasAxes = (axes === null || axes === void 0 ? void 0 : axes.length) > 0;\n        if (title || hasAxes) {\n            const sizeChannel = channel === 'row' ? 'height' : 'width';\n            return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ name: model.getName(`${channel}_${headerType}`), type: 'group', role: `${channel}-${headerType}` }, (layoutHeader.facetFieldDef\n                ? {\n                    from: { data: model.getName(channel + '_domain') },\n                    sort: getSort(facetFieldDef, channel)\n                }\n                : {})), (hasAxes && isFacetWithoutRowCol\n                ? {\n                    from: { data: model.getName(`facet_domain_${channel}`) }\n                }\n                : {})), (title ? { title } : {})), (headerComponent.sizeSignal\n                ? {\n                    encode: {\n                        update: {\n                            [sizeChannel]: headerComponent.sizeSignal\n                        }\n                    }\n                }\n                : {})), (hasAxes ? { axes } : {}));\n        }\n    }\n    return null;\n}\nconst LAYOUT_TITLE_BAND = {\n    column: {\n        start: 0,\n        end: 1\n    },\n    row: {\n        start: 1,\n        end: 0\n    }\n};\nexport function getLayoutTitleBand(titleAnchor, headerChannel) {\n    return LAYOUT_TITLE_BAND[headerChannel][titleAnchor];\n}\nexport function assembleLayoutTitleBand(headerComponentIndex, config) {\n    const titleBand = {};\n    for (const channel of FACET_CHANNELS) {\n        const headerComponent = headerComponentIndex[channel];\n        if (headerComponent === null || headerComponent === void 0 ? void 0 : headerComponent.facetFieldDef) {\n            const { titleAnchor, titleOrient } = getHeaderProperties(['titleAnchor', 'titleOrient'], headerComponent.facetFieldDef.header, config, channel);\n            const headerChannel = getHeaderChannel(channel, titleOrient);\n            const band = getLayoutTitleBand(titleAnchor, headerChannel);\n            if (band !== undefined) {\n                titleBand[headerChannel] = band;\n            }\n        }\n    }\n    return isEmpty(titleBand) ? undefined : titleBand;\n}\nexport function assembleHeaderProperties(config, facetFieldDef, channel, properties, propertiesMap) {\n    const props = {};\n    for (const prop of properties) {\n        if (!propertiesMap[prop]) {\n            continue;\n        }\n        const value = getHeaderProperty(prop, facetFieldDef === null || facetFieldDef === void 0 ? void 0 : facetFieldDef.header, config, channel);\n        if (value !== undefined) {\n            props[propertiesMap[prop]] = value;\n        }\n    }\n    return props;\n}\n//# sourceMappingURL=assemble.js.map","import { contains, getFirstDefined } from '../../util';\n/**\n * Get header channel, which can be different from facet channel when orient is specified or when the facet channel is facet.\n */\nexport function getHeaderChannel(channel, orient) {\n    if (contains(['top', 'bottom'], orient)) {\n        return 'column';\n    }\n    else if (contains(['left', 'right'], orient)) {\n        return 'row';\n    }\n    return channel === 'row' ? 'row' : 'column';\n}\nexport function getHeaderProperty(prop, header, config, channel) {\n    const headerSpecificConfig = channel === 'row' ? config.headerRow : channel === 'column' ? config.headerColumn : config.headerFacet;\n    return getFirstDefined((header || {})[prop], headerSpecificConfig[prop], config.header[prop]);\n}\nexport function getHeaderProperties(properties, header, config, channel) {\n    const props = {};\n    for (const prop of properties) {\n        const value = getHeaderProperty(prop, header || {}, config, channel);\n        if (value !== undefined) {\n            props[prop] = value;\n        }\n    }\n    return props;\n}\n//# sourceMappingURL=common.js.map","export const HEADER_CHANNELS = ['row', 'column'];\nexport const HEADER_TYPES = ['header', 'footer'];\n//# sourceMappingURL=component.js.map","import { isArray } from 'vega-util';\nimport { FACET_CHANNELS } from '../../channel';\nimport { title as fieldDefTitle } from '../../channeldef';\nimport { contains, getFirstDefined } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { assembleAxis } from '../axis/assemble';\nimport { parseGuideResolve } from '../resolve';\nimport { getHeaderProperty } from './common';\nexport function getHeaderType(orient) {\n    if (orient === 'top' || orient === 'left' || isSignalRef(orient)) {\n        // we always use header for orient signal since we can't dynamically make header becomes footer\n        return 'header';\n    }\n    return 'footer';\n}\nexport function parseFacetHeaders(model) {\n    for (const channel of FACET_CHANNELS) {\n        parseFacetHeader(model, channel);\n    }\n    mergeChildAxis(model, 'x');\n    mergeChildAxis(model, 'y');\n}\nfunction parseFacetHeader(model, channel) {\n    var _a;\n    const { facet, config, child, component } = model;\n    if (model.channelHasField(channel)) {\n        const fieldDef = facet[channel];\n        const titleConfig = getHeaderProperty('title', null, config, channel);\n        let title = fieldDefTitle(fieldDef, config, {\n            allowDisabling: true,\n            includeDefault: titleConfig === undefined || !!titleConfig\n        });\n        if (child.component.layoutHeaders[channel].title) {\n            // TODO: better handle multiline titles\n            title = isArray(title) ? title.join(', ') : title;\n            // merge title with child to produce \"Title / Subtitle / Sub-subtitle\"\n            title += ' / ' + child.component.layoutHeaders[channel].title;\n            child.component.layoutHeaders[channel].title = null;\n        }\n        const labelOrient = getHeaderProperty('labelOrient', fieldDef, config, channel);\n        const header = (_a = fieldDef.header) !== null && _a !== void 0 ? _a : {};\n        const labels = getFirstDefined(header.labels, config.header.labels, true);\n        const headerType = contains(['bottom', 'right'], labelOrient) ? 'footer' : 'header';\n        component.layoutHeaders[channel] = {\n            title,\n            facetFieldDef: fieldDef,\n            [headerType]: channel === 'facet' ? [] : [makeHeaderComponent(model, channel, labels)]\n        };\n    }\n}\nfunction makeHeaderComponent(model, channel, labels) {\n    const sizeType = channel === 'row' ? 'height' : 'width';\n    return {\n        labels,\n        sizeSignal: model.child.component.layoutSize.get(sizeType) ? model.child.getSizeSignalRef(sizeType) : undefined,\n        axes: []\n    };\n}\nfunction mergeChildAxis(model, channel) {\n    var _a;\n    const { child } = model;\n    if (child.component.axes[channel]) {\n        const { layoutHeaders, resolve } = model.component;\n        resolve.axis[channel] = parseGuideResolve(resolve, channel);\n        if (resolve.axis[channel] === 'shared') {\n            // For shared axis, move the axes to facet's header or footer\n            const headerChannel = channel === 'x' ? 'column' : 'row';\n            const layoutHeader = layoutHeaders[headerChannel];\n            for (const axisComponent of child.component.axes[channel]) {\n                const headerType = getHeaderType(axisComponent.get('orient'));\n                layoutHeader[headerType] = (_a = layoutHeader[headerType]) !== null && _a !== void 0 ? _a : [makeHeaderComponent(model, headerChannel, false)];\n                // FIXME: assemble shouldn't be called here, but we do it this way so we only extract the main part of the axes\n                const mainAxis = assembleAxis(axisComponent, 'main', model.config, { header: true });\n                if (mainAxis) {\n                    // LayoutHeader no longer keep track of property precedence, thus let's combine.\n                    layoutHeader[headerType][0].axes.push(mainAxis);\n                }\n                axisComponent.mainExtracted = true;\n            }\n        }\n        else {\n            // Otherwise do nothing for independent axes\n        }\n    }\n}\n//# sourceMappingURL=parse.js.map","import * as log from '../log';\nimport { isLayerSpec, isUnitSpec } from '../spec';\nimport { keys } from '../util';\nimport { assembleAxisSignals } from './axis/assemble';\nimport { parseLayerAxes } from './axis/parse';\nimport { parseData } from './data/parse';\nimport { assembleLayoutSignals } from './layoutsize/assemble';\nimport { parseLayerLayoutSize } from './layoutsize/parse';\nimport { assembleLegends } from './legend/assemble';\nimport { Model } from './model';\nimport { assembleLayerSelectionMarks } from './selection/assemble';\nimport { UnitModel } from './unit';\nexport class LayerModel extends Model {\n    constructor(spec, parent, parentGivenName, parentGivenSize, config) {\n        super(spec, 'layer', parent, parentGivenName, config, spec.resolve, spec.view);\n        const layoutSize = Object.assign(Object.assign(Object.assign({}, parentGivenSize), (spec.width ? { width: spec.width } : {})), (spec.height ? { height: spec.height } : {}));\n        this.children = spec.layer.map((layer, i) => {\n            if (isLayerSpec(layer)) {\n                return new LayerModel(layer, this, this.getName('layer_' + i), layoutSize, config);\n            }\n            else if (isUnitSpec(layer)) {\n                return new UnitModel(layer, this, this.getName('layer_' + i), layoutSize, config);\n            }\n            throw new Error(log.message.invalidSpec(layer));\n        });\n    }\n    parseData() {\n        this.component.data = parseData(this);\n        for (const child of this.children) {\n            child.parseData();\n        }\n    }\n    parseLayoutSize() {\n        parseLayerLayoutSize(this);\n    }\n    parseSelections() {\n        // Merge selections up the hierarchy so that they may be referenced\n        // across unit specs. Persist their definitions within each child\n        // to assemble signals which remain within output Vega unit groups.\n        this.component.selection = {};\n        for (const child of this.children) {\n            child.parseSelections();\n            for (const key of keys(child.component.selection)) {\n                this.component.selection[key] = child.component.selection[key];\n            }\n        }\n    }\n    parseMarkGroup() {\n        for (const child of this.children) {\n            child.parseMarkGroup();\n        }\n    }\n    parseAxesAndHeaders() {\n        parseLayerAxes(this);\n    }\n    assembleSelectionTopLevelSignals(signals) {\n        return this.children.reduce((sg, child) => child.assembleSelectionTopLevelSignals(sg), signals);\n    }\n    // TODO: Support same named selections across children.\n    assembleSignals() {\n        return this.children.reduce((signals, child) => {\n            return signals.concat(child.assembleSignals());\n        }, assembleAxisSignals(this));\n    }\n    assembleLayoutSignals() {\n        return this.children.reduce((signals, child) => {\n            return signals.concat(child.assembleLayoutSignals());\n        }, assembleLayoutSignals(this));\n    }\n    assembleSelectionData(data) {\n        return this.children.reduce((db, child) => child.assembleSelectionData(db), data);\n    }\n    assembleTitle() {\n        let title = super.assembleTitle();\n        if (title) {\n            return title;\n        }\n        // If title does not provide layer, look into children\n        for (const child of this.children) {\n            title = child.assembleTitle();\n            if (title) {\n                return title;\n            }\n        }\n        return undefined;\n    }\n    assembleLayout() {\n        return null;\n    }\n    assembleMarks() {\n        return assembleLayerSelectionMarks(this, this.children.flatMap(child => {\n            return child.assembleMarks();\n        }));\n    }\n    assembleLegends() {\n        return this.children.reduce((legends, child) => {\n            return legends.concat(child.assembleLegends());\n        }, assembleLegends(this));\n    }\n}\n//# sourceMappingURL=layer.js.map","import { getViewConfigContinuousSize } from '../../config';\nimport { hasDiscreteDomain } from '../../scale';\nimport { getFirstDefined } from '../../util';\nimport { isVgRangeStep } from '../../vega.schema';\nimport { signalOrStringValue } from '../common';\nimport { isFacetModel } from '../model';\nexport function assembleLayoutSignals(model) {\n    return [\n        ...sizeSignals(model, 'width'),\n        ...sizeSignals(model, 'height'),\n        ...sizeSignals(model, 'childWidth'),\n        ...sizeSignals(model, 'childHeight')\n    ];\n}\nexport function sizeSignals(model, sizeType) {\n    const channel = sizeType === 'width' ? 'x' : 'y';\n    const size = model.component.layoutSize.get(sizeType);\n    if (!size || size === 'merged') {\n        return [];\n    }\n    // Read size signal name from name map, just in case it is the top-level size signal that got renamed.\n    const name = model.getSizeSignalRef(sizeType).signal;\n    if (size === 'step') {\n        const scaleComponent = model.getScaleComponent(channel);\n        if (scaleComponent) {\n            const type = scaleComponent.get('type');\n            const range = scaleComponent.get('range');\n            if (hasDiscreteDomain(type) && isVgRangeStep(range)) {\n                const scaleName = model.scaleName(channel);\n                if (isFacetModel(model.parent)) {\n                    // If parent is facet and this is an independent scale, return only signal signal\n                    // as the width/height will be calculated using the cardinality from\n                    // facet's aggregate rather than reading from scale domain\n                    const parentResolve = model.parent.component.resolve;\n                    if (parentResolve.scale[channel] === 'independent') {\n                        return [stepSignal(scaleName, range)];\n                    }\n                }\n                return [\n                    stepSignal(scaleName, range),\n                    {\n                        name,\n                        update: sizeExpr(scaleName, scaleComponent, `domain('${scaleName}').length`)\n                    }\n                ];\n            }\n        }\n        /* istanbul ignore next: Condition should not happen -- only for warning in development. */\n        throw new Error('layout size is step although width/height is not step.');\n    }\n    else if (size == 'container') {\n        const isWidth = name.endsWith('width');\n        const expr = isWidth ? 'containerSize()[0]' : 'containerSize()[1]';\n        const defaultValue = getViewConfigContinuousSize(model.config.view, isWidth ? 'width' : 'height');\n        const safeExpr = `isFinite(${expr}) ? ${expr} : ${defaultValue}`;\n        return [{ name, init: safeExpr, on: [{ update: safeExpr, events: 'window:resize' }] }];\n    }\n    else {\n        return [\n            {\n                name,\n                value: size\n            }\n        ];\n    }\n}\nfunction stepSignal(scaleName, range) {\n    return {\n        name: scaleName + '_step',\n        value: range.step\n    };\n}\nexport function sizeExpr(scaleName, scaleComponent, cardinality) {\n    const type = scaleComponent.get('type');\n    const padding = scaleComponent.get('padding');\n    const paddingOuter = getFirstDefined(scaleComponent.get('paddingOuter'), padding);\n    let paddingInner = scaleComponent.get('paddingInner');\n    paddingInner =\n        type === 'band'\n            ? // only band has real paddingInner\n                paddingInner !== undefined\n                    ? paddingInner\n                    : padding\n            : // For point, as calculated in https://github.com/vega/vega-scale/blob/master/src/band.js#L128,\n                // it's equivalent to have paddingInner = 1 since there is only n-1 steps between n points.\n                1;\n    return `bandspace(${cardinality}, ${signalOrStringValue(paddingInner)}, ${signalOrStringValue(paddingOuter)}) * ${scaleName}_step`;\n}\n//# sourceMappingURL=assemble.js.map","export function getSizeTypeFromLayoutSizeType(layoutSizeType) {\n    return layoutSizeType === 'childWidth' ? 'width' : layoutSizeType === 'childHeight' ? 'height' : layoutSizeType;\n}\n//# sourceMappingURL=component.js.map","import { getSizeChannel, POSITION_SCALE_CHANNELS } from '../../channel';\nimport { isContinuousFieldOrDatumDef } from '../../channeldef';\nimport * as log from '../../log';\nimport { isStep } from '../../spec/base';\nexport function initLayoutSize({ encoding, size }) {\n    for (const channel of POSITION_SCALE_CHANNELS) {\n        const sizeType = getSizeChannel(channel);\n        if (isStep(size[sizeType])) {\n            if (isContinuousFieldOrDatumDef(encoding[channel])) {\n                delete size[sizeType];\n                log.warn(log.message.stepDropped(sizeType));\n            }\n        }\n    }\n    return size;\n}\n//# sourceMappingURL=init.js.map","import { getPositionScaleChannel, getSizeChannel, POSITION_SCALE_CHANNELS } from '../../channel';\nimport { getViewConfigContinuousSize, getViewConfigDiscreteSize } from '../../config';\nimport { hasDiscreteDomain } from '../../scale';\nimport { isStep } from '../../spec/base';\nimport { isVgRangeStep } from '../../vega.schema';\nimport { mergeValuesWithExplicit } from '../split';\nimport { getSizeTypeFromLayoutSizeType } from './component';\nexport function parseLayerLayoutSize(model) {\n    parseChildrenLayoutSize(model);\n    parseNonUnitLayoutSizeForChannel(model, 'width');\n    parseNonUnitLayoutSizeForChannel(model, 'height');\n}\nexport const parseRepeatLayoutSize = parseConcatLayoutSize;\nexport function parseConcatLayoutSize(model) {\n    parseChildrenLayoutSize(model);\n    // for columns === 1 (vconcat), we can completely merge width. Otherwise, we can treat merged width as childWidth.\n    const widthType = model.layout.columns === 1 ? 'width' : 'childWidth';\n    // for columns === undefined (hconcat), we can completely merge height. Otherwise, we can treat merged height as childHeight.\n    const heightType = model.layout.columns === undefined ? 'height' : 'childHeight';\n    parseNonUnitLayoutSizeForChannel(model, widthType);\n    parseNonUnitLayoutSizeForChannel(model, heightType);\n}\nexport function parseChildrenLayoutSize(model) {\n    for (const child of model.children) {\n        child.parseLayoutSize();\n    }\n}\n/**\n * Merge child layout size (width or height).\n */\nfunction parseNonUnitLayoutSizeForChannel(model, layoutSizeType) {\n    /*\n     * For concat, the parent width or height might not be the same as the children's shared height.\n     * For example, hconcat's subviews may share width, but the shared width is not the hconcat view's width.\n     *\n     * layoutSizeType represents the output of the view (could be childWidth/childHeight/width/height)\n     * while the sizeType represents the properties of the child.\n     */\n    const sizeType = getSizeTypeFromLayoutSizeType(layoutSizeType);\n    const channel = getPositionScaleChannel(sizeType);\n    const resolve = model.component.resolve;\n    const layoutSizeCmpt = model.component.layoutSize;\n    let mergedSize;\n    // Try to merge layout size\n    for (const child of model.children) {\n        const childSize = child.component.layoutSize.getWithExplicit(sizeType);\n        const scaleResolve = resolve.scale[channel];\n        if (scaleResolve === 'independent' && childSize.value === 'step') {\n            // Do not merge independent scales with range-step as their size depends\n            // on the scale domains, which can be different between scales.\n            mergedSize = undefined;\n            break;\n        }\n        if (mergedSize) {\n            if (scaleResolve === 'independent' && mergedSize.value !== childSize.value) {\n                // For independent scale, only merge if all the sizes are the same.\n                // If the values are different, abandon the merge!\n                mergedSize = undefined;\n                break;\n            }\n            mergedSize = mergeValuesWithExplicit(mergedSize, childSize, sizeType, '');\n        }\n        else {\n            mergedSize = childSize;\n        }\n    }\n    if (mergedSize) {\n        // If merged, rename size and set size of all children.\n        for (const child of model.children) {\n            model.renameSignal(child.getName(sizeType), model.getName(layoutSizeType));\n            child.component.layoutSize.set(sizeType, 'merged', false);\n        }\n        layoutSizeCmpt.setWithExplicit(layoutSizeType, mergedSize);\n    }\n    else {\n        layoutSizeCmpt.setWithExplicit(layoutSizeType, {\n            explicit: false,\n            value: undefined\n        });\n    }\n}\nexport function parseUnitLayoutSize(model) {\n    const { size, component } = model;\n    for (const channel of POSITION_SCALE_CHANNELS) {\n        const sizeType = getSizeChannel(channel);\n        if (size[sizeType]) {\n            const specifiedSize = size[sizeType];\n            component.layoutSize.set(sizeType, isStep(specifiedSize) ? 'step' : specifiedSize, true);\n        }\n        else {\n            const defaultSize = defaultUnitSize(model, sizeType);\n            component.layoutSize.set(sizeType, defaultSize, false);\n        }\n    }\n}\nfunction defaultUnitSize(model, sizeType) {\n    const channel = sizeType === 'width' ? 'x' : 'y';\n    const config = model.config;\n    const scaleComponent = model.getScaleComponent(channel);\n    if (scaleComponent) {\n        const scaleType = scaleComponent.get('type');\n        const range = scaleComponent.get('range');\n        if (hasDiscreteDomain(scaleType)) {\n            const size = getViewConfigDiscreteSize(config.view, sizeType);\n            if (isVgRangeStep(range) || isStep(size)) {\n                // For discrete domain with range.step, use dynamic width/height\n                return 'step';\n            }\n            else {\n                return size;\n            }\n        }\n        else {\n            return getViewConfigContinuousSize(config.view, sizeType);\n        }\n    }\n    else if (model.hasProjection || model.mark === 'arc') {\n        // arc should use continuous size by default otherwise the pie is extremely small\n        return getViewConfigContinuousSize(config.view, sizeType);\n    }\n    else {\n        const size = getViewConfigDiscreteSize(config.view, sizeType);\n        return isStep(size) ? size.step : size;\n    }\n}\n//# sourceMappingURL=parse.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { LEGEND_SCALE_CHANNELS } from '../../legend';\nimport { keys, replaceAll, stringify, vals } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { mergeLegendComponent } from './parse';\nfunction setLegendEncode(legend, part, vgProp, vgRef) {\n    var _a, _b, _c;\n    legend.encode = (_a = legend.encode) !== null && _a !== void 0 ? _a : {};\n    legend.encode[part] = (_b = legend.encode[part]) !== null && _b !== void 0 ? _b : {};\n    legend.encode[part].update = (_c = legend.encode[part].update) !== null && _c !== void 0 ? _c : {};\n    // TODO: remove as any after https://github.com/prisma/nexus-prisma/issues/291\n    legend.encode[part].update[vgProp] = vgRef;\n}\nexport function assembleLegends(model) {\n    const legendComponentIndex = model.component.legends;\n    const legendByDomain = {};\n    for (const channel of keys(legendComponentIndex)) {\n        const scaleComponent = model.getScaleComponent(channel);\n        const domainHash = stringify(scaleComponent.get('domains'));\n        if (legendByDomain[domainHash]) {\n            for (const mergedLegendComponent of legendByDomain[domainHash]) {\n                const merged = mergeLegendComponent(mergedLegendComponent, legendComponentIndex[channel]);\n                if (!merged) {\n                    // If cannot merge, need to add this legend separately\n                    legendByDomain[domainHash].push(legendComponentIndex[channel]);\n                }\n            }\n        }\n        else {\n            legendByDomain[domainHash] = [legendComponentIndex[channel].clone()];\n        }\n    }\n    const legends = vals(legendByDomain)\n        .flat()\n        .map(l => assembleLegend(l, model.config))\n        .filter(l => l !== undefined);\n    return legends;\n}\nexport function assembleLegend(legendCmpt, config) {\n    var _a, _b, _c;\n    const _d = legendCmpt.combine(), { disable, labelExpr, selections } = _d, legend = __rest(_d, [\"disable\", \"labelExpr\", \"selections\"]);\n    if (disable) {\n        return undefined;\n    }\n    if (config.aria === false && legend.aria == undefined) {\n        legend.aria = false;\n    }\n    if ((_a = legend.encode) === null || _a === void 0 ? void 0 : _a.symbols) {\n        const out = legend.encode.symbols.update;\n        if (out.fill && out.fill['value'] !== 'transparent' && !out.stroke && !legend.stroke) {\n            // For non color channel's legend, we need to override symbol stroke config from Vega config if stroke channel is not used.\n            out.stroke = { value: 'transparent' };\n        }\n        // Remove properties that the legend is encoding.\n        for (const property of LEGEND_SCALE_CHANNELS) {\n            if (legend[property]) {\n                delete out[property];\n            }\n        }\n    }\n    if (!legend.title) {\n        // title schema doesn't include null, ''\n        delete legend.title;\n    }\n    if (labelExpr !== undefined) {\n        let expr = labelExpr;\n        if (((_c = (_b = legend.encode) === null || _b === void 0 ? void 0 : _b.labels) === null || _c === void 0 ? void 0 : _c.update) && isSignalRef(legend.encode.labels.update.text)) {\n            expr = replaceAll(labelExpr, 'datum.label', legend.encode.labels.update.text.signal);\n        }\n        setLegendEncode(legend, 'labels', 'text', { signal: expr });\n    }\n    return legend;\n}\n//# sourceMappingURL=assemble.js.map","import { COMMON_LEGEND_PROPERTY_INDEX } from '../../legend';\nimport { keys } from '../../util';\nimport { Split } from '../split';\nconst LEGEND_COMPONENT_PROPERTY_INDEX = Object.assign(Object.assign({}, COMMON_LEGEND_PROPERTY_INDEX), { disable: 1, labelExpr: 1, selections: 1, \n    // channel scales\n    opacity: 1, shape: 1, stroke: 1, fill: 1, size: 1, strokeWidth: 1, strokeDash: 1, \n    // encode\n    encode: 1 });\nexport const LEGEND_COMPONENT_PROPERTIES = keys(LEGEND_COMPONENT_PROPERTY_INDEX);\nexport class LegendComponent extends Split {\n}\n//# sourceMappingURL=component.js.map","import { array, isArray, stringValue } from 'vega-util';\nimport { COLOR, OPACITY } from '../../channel';\nimport { hasConditionalValueDef, isFieldDef, isValueDef } from '../../channeldef';\nimport { FILL_STROKE_CONFIG } from '../../mark';\nimport { getFirstDefined, isEmpty, varName } from '../../util';\nimport { applyMarkConfig, signalOrValueRef } from '../common';\nimport { formatCustomType, isCustomFormatType } from '../format';\nimport * as mixins from '../mark/encode';\nimport { STORE } from '../selection';\nexport const legendEncodeRules = {\n    symbols,\n    gradient,\n    labels,\n    entries\n};\nexport function symbols(symbolsSpec, { fieldOrDatumDef, model, channel, legendCmpt, legendType }) {\n    var _a, _b, _c, _d, _e, _f, _g, _h;\n    if (legendType !== 'symbol') {\n        return undefined;\n    }\n    const { markDef, encoding, config, mark } = model;\n    const filled = markDef.filled && mark !== 'trail';\n    let out = Object.assign(Object.assign({}, applyMarkConfig({}, model, FILL_STROKE_CONFIG)), mixins.color(model, { filled })); // FIXME: remove this when VgEncodeEntry is compatible with SymbolEncodeEntry\n    const symbolOpacity = (_a = legendCmpt.get('symbolOpacity')) !== null && _a !== void 0 ? _a : config.legend.symbolOpacity;\n    const symbolFillColor = (_b = legendCmpt.get('symbolFillColor')) !== null && _b !== void 0 ? _b : config.legend.symbolFillColor;\n    const symbolStrokeColor = (_c = legendCmpt.get('symbolStrokeColor')) !== null && _c !== void 0 ? _c : config.legend.symbolStrokeColor;\n    const opacity = symbolOpacity === undefined ? (_d = getMaxValue(encoding.opacity)) !== null && _d !== void 0 ? _d : markDef.opacity : undefined;\n    if (out.fill) {\n        // for fill legend, we don't want any fill in symbol\n        if (channel === 'fill' || (filled && channel === COLOR)) {\n            delete out.fill;\n        }\n        else {\n            if (out.fill['field']) {\n                // For others, set fill to some opaque value (or nothing if a color is already set)\n                if (symbolFillColor) {\n                    delete out.fill;\n                }\n                else {\n                    out.fill = signalOrValueRef((_e = config.legend.symbolBaseFillColor) !== null && _e !== void 0 ? _e : 'black');\n                    out.fillOpacity = signalOrValueRef(opacity !== null && opacity !== void 0 ? opacity : 1);\n                }\n            }\n            else if (isArray(out.fill)) {\n                const fill = (_h = (_g = getFirstConditionValue((_f = encoding.fill) !== null && _f !== void 0 ? _f : encoding.color)) !== null && _g !== void 0 ? _g : markDef.fill) !== null && _h !== void 0 ? _h : (filled && markDef.color);\n                if (fill) {\n                    out.fill = signalOrValueRef(fill);\n                }\n            }\n        }\n    }\n    if (out.stroke) {\n        if (channel === 'stroke' || (!filled && channel === COLOR)) {\n            delete out.stroke;\n        }\n        else {\n            if (out.stroke['field'] || symbolStrokeColor) {\n                // For others, remove stroke field\n                delete out.stroke;\n            }\n            else if (isArray(out.stroke)) {\n                const stroke = getFirstDefined(getFirstConditionValue(encoding.stroke || encoding.color), markDef.stroke, filled ? markDef.color : undefined);\n                if (stroke) {\n                    out.stroke = { value: stroke };\n                }\n            }\n        }\n    }\n    if (channel !== OPACITY) {\n        const condition = isFieldDef(fieldOrDatumDef) && selectedCondition(model, legendCmpt, fieldOrDatumDef);\n        if (condition) {\n            out.opacity = [\n                Object.assign({ test: condition }, signalOrValueRef(opacity !== null && opacity !== void 0 ? opacity : 1)),\n                signalOrValueRef(config.legend.unselectedOpacity)\n            ];\n        }\n        else if (opacity) {\n            out.opacity = signalOrValueRef(opacity);\n        }\n    }\n    out = Object.assign(Object.assign({}, out), symbolsSpec);\n    return isEmpty(out) ? undefined : out;\n}\nexport function gradient(gradientSpec, { model, legendType, legendCmpt }) {\n    var _a;\n    if (legendType !== 'gradient') {\n        return undefined;\n    }\n    const { config, markDef, encoding } = model;\n    let out = {};\n    const gradientOpacity = (_a = legendCmpt.get('gradientOpacity')) !== null && _a !== void 0 ? _a : config.legend.gradientOpacity;\n    const opacity = gradientOpacity === undefined ? getMaxValue(encoding.opacity) || markDef.opacity : undefined;\n    if (opacity) {\n        // only apply opacity if it is neither zero or undefined\n        out.opacity = signalOrValueRef(opacity);\n    }\n    out = Object.assign(Object.assign({}, out), gradientSpec);\n    return isEmpty(out) ? undefined : out;\n}\nexport function labels(specifiedlabelsSpec, { fieldOrDatumDef, model, channel, legendCmpt }) {\n    const legend = model.legend(channel) || {};\n    const config = model.config;\n    const condition = isFieldDef(fieldOrDatumDef) ? selectedCondition(model, legendCmpt, fieldOrDatumDef) : undefined;\n    const opacity = condition ? [{ test: condition, value: 1 }, { value: config.legend.unselectedOpacity }] : undefined;\n    const { format, formatType } = legend;\n    const text = isCustomFormatType(formatType)\n        ? formatCustomType({\n            fieldOrDatumDef,\n            field: 'datum.value',\n            format,\n            formatType,\n            config\n        })\n        : undefined;\n    const labelsSpec = Object.assign(Object.assign(Object.assign({}, (opacity ? { opacity } : {})), (text ? { text } : {})), specifiedlabelsSpec);\n    return isEmpty(labelsSpec) ? undefined : labelsSpec;\n}\nexport function entries(entriesSpec, { legendCmpt }) {\n    const selections = legendCmpt.get('selections');\n    return (selections === null || selections === void 0 ? void 0 : selections.length) ? Object.assign(Object.assign({}, entriesSpec), { fill: { value: 'transparent' } }) : entriesSpec;\n}\nfunction getMaxValue(channelDef) {\n    return getConditionValue(channelDef, (v, conditionalDef) => Math.max(v, conditionalDef.value));\n}\nexport function getFirstConditionValue(channelDef) {\n    return getConditionValue(channelDef, (v, conditionalDef) => {\n        return getFirstDefined(v, conditionalDef.value);\n    });\n}\nfunction getConditionValue(channelDef, reducer) {\n    if (hasConditionalValueDef(channelDef)) {\n        return array(channelDef.condition).reduce(reducer, channelDef.value);\n    }\n    else if (isValueDef(channelDef)) {\n        return channelDef.value;\n    }\n    return undefined;\n}\nfunction selectedCondition(model, legendCmpt, fieldDef) {\n    const selections = legendCmpt.get('selections');\n    if (!(selections === null || selections === void 0 ? void 0 : selections.length))\n        return undefined;\n    const field = stringValue(fieldDef.field);\n    return selections\n        .map(name => {\n        const store = stringValue(varName(name) + STORE);\n        return `(!length(data(${store})) || (${name}[${field}] && indexof(${name}[${field}], datum.value) >= 0))`;\n    })\n        .join(' || ');\n}\n//# sourceMappingURL=encode.js.map","import { COLOR, SHAPE } from '../../channel';\nimport { getFieldOrDatumDef, isFieldDef } from '../../channeldef';\nimport { LEGEND_SCALE_CHANNELS } from '../../legend';\nimport { normalizeTimeUnit } from '../../timeunit';\nimport { GEOJSON } from '../../type';\nimport { deleteNestedProperty, isEmpty, keys, varName } from '../../util';\nimport { mergeTitleComponent } from '../common';\nimport { guideEncodeEntry } from '../guide';\nimport { isUnitModel } from '../model';\nimport { parseGuideResolve } from '../resolve';\nimport { parseInteractiveLegend } from '../selection/transforms/legends';\nimport { defaultTieBreaker, makeImplicit, mergeValuesWithExplicit } from '../split';\nimport { LegendComponent, LEGEND_COMPONENT_PROPERTIES } from './component';\nimport { legendEncodeRules } from './encode';\nimport { getDirection, getLegendType, legendRules } from './properties';\nexport function parseLegend(model) {\n    const legendComponent = isUnitModel(model) ? parseUnitLegend(model) : parseNonUnitLegend(model);\n    model.component.legends = legendComponent;\n    return legendComponent;\n}\nfunction parseUnitLegend(model) {\n    const { encoding } = model;\n    const legendComponent = {};\n    for (const channel of [COLOR, ...LEGEND_SCALE_CHANNELS]) {\n        const def = getFieldOrDatumDef(encoding[channel]);\n        if (!def || !model.getScaleComponent(channel)) {\n            continue;\n        }\n        if (channel === SHAPE && isFieldDef(def) && def.type === GEOJSON) {\n            continue;\n        }\n        legendComponent[channel] = parseLegendForChannel(model, channel);\n    }\n    return legendComponent;\n}\nfunction getLegendDefWithScale(model, channel) {\n    const scale = model.scaleName(channel);\n    if (model.mark === 'trail') {\n        if (channel === 'color') {\n            // trail is a filled mark, but its default symbolType (\"stroke\") should use \"stroke\"\n            return { stroke: scale };\n        }\n        else if (channel === 'size') {\n            return { strokeWidth: scale };\n        }\n    }\n    if (channel === 'color') {\n        return model.markDef.filled ? { fill: scale } : { stroke: scale };\n    }\n    return { [channel]: scale };\n}\n// eslint-disable-next-line @typescript-eslint/ban-types\nfunction isExplicit(value, property, legend, fieldDef) {\n    switch (property) {\n        case 'disable':\n            return legend !== undefined; // if axis is specified or null/false, then it's enable/disable state is explicit\n        case 'values':\n            // specified legend.values is already respected, but may get transformed.\n            return !!(legend === null || legend === void 0 ? void 0 : legend.values);\n        case 'title':\n            // title can be explicit if fieldDef.title is set\n            if (property === 'title' && value === (fieldDef === null || fieldDef === void 0 ? void 0 : fieldDef.title)) {\n                return true;\n            }\n    }\n    // Otherwise, things are explicit if the returned value matches the specified property\n    return value === (legend || {})[property];\n}\nexport function parseLegendForChannel(model, channel) {\n    var _a, _b, _c;\n    let legend = model.legend(channel);\n    const { markDef, encoding, config } = model;\n    const legendConfig = config.legend;\n    const legendCmpt = new LegendComponent({}, getLegendDefWithScale(model, channel));\n    parseInteractiveLegend(model, channel, legendCmpt);\n    const disable = legend !== undefined ? !legend : legendConfig.disable;\n    legendCmpt.set('disable', disable, legend !== undefined);\n    if (disable) {\n        return legendCmpt;\n    }\n    legend = legend || {};\n    const scaleType = model.getScaleComponent(channel).get('type');\n    const fieldOrDatumDef = getFieldOrDatumDef(encoding[channel]);\n    const timeUnit = isFieldDef(fieldOrDatumDef) ? (_a = normalizeTimeUnit(fieldOrDatumDef.timeUnit)) === null || _a === void 0 ? void 0 : _a.unit : undefined;\n    const orient = legend.orient || config.legend.orient || 'right';\n    const legendType = getLegendType({ legend, channel, timeUnit, scaleType });\n    const direction = getDirection({ legend, legendType, orient, legendConfig });\n    const ruleParams = {\n        legend,\n        channel,\n        model,\n        markDef,\n        encoding,\n        fieldOrDatumDef,\n        legendConfig,\n        config,\n        scaleType,\n        orient,\n        legendType,\n        direction\n    };\n    for (const property of LEGEND_COMPONENT_PROPERTIES) {\n        if ((legendType === 'gradient' && property.startsWith('symbol')) ||\n            (legendType === 'symbol' && property.startsWith('gradient'))) {\n            continue;\n        }\n        const value = property in legendRules ? legendRules[property](ruleParams) : legend[property];\n        if (value !== undefined) {\n            const explicit = isExplicit(value, property, legend, model.fieldDef(channel));\n            if (explicit || config.legend[property] === undefined) {\n                legendCmpt.set(property, value, explicit);\n            }\n        }\n    }\n    const legendEncoding = (_b = legend === null || legend === void 0 ? void 0 : legend.encoding) !== null && _b !== void 0 ? _b : {};\n    const selections = legendCmpt.get('selections');\n    const legendEncode = {};\n    const legendEncodeParams = { fieldOrDatumDef, model, channel, legendCmpt, legendType };\n    for (const part of ['labels', 'legend', 'title', 'symbols', 'gradient', 'entries']) {\n        const legendEncodingPart = guideEncodeEntry((_c = legendEncoding[part]) !== null && _c !== void 0 ? _c : {}, model);\n        const value = part in legendEncodeRules\n            ? legendEncodeRules[part](legendEncodingPart, legendEncodeParams) // apply rule\n            : legendEncodingPart; // no rule -- just default values\n        if (value !== undefined && !isEmpty(value)) {\n            legendEncode[part] = Object.assign(Object.assign(Object.assign({}, ((selections === null || selections === void 0 ? void 0 : selections.length) && isFieldDef(fieldOrDatumDef)\n                ? { name: `${varName(fieldOrDatumDef.field)}_legend_${part}` }\n                : {})), ((selections === null || selections === void 0 ? void 0 : selections.length) ? { interactive: !!selections } : {})), { update: value });\n        }\n    }\n    if (!isEmpty(legendEncode)) {\n        legendCmpt.set('encode', legendEncode, !!(legend === null || legend === void 0 ? void 0 : legend.encoding));\n    }\n    return legendCmpt;\n}\nfunction parseNonUnitLegend(model) {\n    const { legends, resolve } = model.component;\n    for (const child of model.children) {\n        parseLegend(child);\n        for (const channel of keys(child.component.legends)) {\n            resolve.legend[channel] = parseGuideResolve(model.component.resolve, channel);\n            if (resolve.legend[channel] === 'shared') {\n                // If the resolve says shared (and has not been overridden)\n                // We will try to merge and see if there is a conflict\n                legends[channel] = mergeLegendComponent(legends[channel], child.component.legends[channel]);\n                if (!legends[channel]) {\n                    // If merge returns nothing, there is a conflict so we cannot make the legend shared.\n                    // Thus, mark legend as independent and remove the legend component.\n                    resolve.legend[channel] = 'independent';\n                    delete legends[channel];\n                }\n            }\n        }\n    }\n    for (const channel of keys(legends)) {\n        for (const child of model.children) {\n            if (!child.component.legends[channel]) {\n                // skip if the child does not have a particular legend\n                continue;\n            }\n            if (resolve.legend[channel] === 'shared') {\n                // After merging shared legend, make sure to remove legend from child\n                delete child.component.legends[channel];\n            }\n        }\n    }\n    return legends;\n}\nexport function mergeLegendComponent(mergedLegend, childLegend) {\n    var _a, _b, _c, _d;\n    if (!mergedLegend) {\n        return childLegend.clone();\n    }\n    const mergedOrient = mergedLegend.getWithExplicit('orient');\n    const childOrient = childLegend.getWithExplicit('orient');\n    if (mergedOrient.explicit && childOrient.explicit && mergedOrient.value !== childOrient.value) {\n        // TODO: throw warning if resolve is explicit (We don't have info about explicit/implicit resolve yet.)\n        // Cannot merge due to inconsistent orient\n        return undefined;\n    }\n    let typeMerged = false;\n    // Otherwise, let's merge\n    for (const prop of LEGEND_COMPONENT_PROPERTIES) {\n        const mergedValueWithExplicit = mergeValuesWithExplicit(mergedLegend.getWithExplicit(prop), childLegend.getWithExplicit(prop), prop, 'legend', \n        // Tie breaker function\n        (v1, v2) => {\n            switch (prop) {\n                case 'symbolType':\n                    return mergeSymbolType(v1, v2);\n                case 'title':\n                    return mergeTitleComponent(v1, v2);\n                case 'type':\n                    // There are only two types. If we have different types, then prefer symbol over gradient.\n                    typeMerged = true;\n                    return makeImplicit('symbol');\n            }\n            return defaultTieBreaker(v1, v2, prop, 'legend');\n        });\n        mergedLegend.setWithExplicit(prop, mergedValueWithExplicit);\n    }\n    if (typeMerged) {\n        if ((_b = (_a = mergedLegend.implicit) === null || _a === void 0 ? void 0 : _a.encode) === null || _b === void 0 ? void 0 : _b.gradient) {\n            deleteNestedProperty(mergedLegend.implicit, ['encode', 'gradient']);\n        }\n        if ((_d = (_c = mergedLegend.explicit) === null || _c === void 0 ? void 0 : _c.encode) === null || _d === void 0 ? void 0 : _d.gradient) {\n            deleteNestedProperty(mergedLegend.explicit, ['encode', 'gradient']);\n        }\n    }\n    return mergedLegend;\n}\nfunction mergeSymbolType(st1, st2) {\n    if (st2.value === 'circle') {\n        // prefer \"circle\" over \"stroke\"\n        return st2;\n    }\n    return st1;\n}\n//# sourceMappingURL=parse.js.map","import { isArray } from 'vega-util';\nimport { isColorChannel } from '../../channel';\nimport { title as fieldDefTitle, valueArray } from '../../channeldef';\nimport { isContinuousToContinuous } from '../../scale';\nimport { contains, getFirstDefined } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { guideFormat, guideFormatType } from '../format';\nimport { getFirstConditionValue } from './encode';\nexport const legendRules = {\n    direction: ({ direction }) => direction,\n    format: ({ fieldOrDatumDef, legend, config }) => {\n        const { format, formatType } = legend;\n        return guideFormat(fieldOrDatumDef, fieldOrDatumDef.type, format, formatType, config, false);\n    },\n    formatType: ({ legend, fieldOrDatumDef, scaleType }) => {\n        const { formatType } = legend;\n        return guideFormatType(formatType, fieldOrDatumDef, scaleType);\n    },\n    gradientLength: params => {\n        var _a, _b;\n        const { legend, legendConfig } = params;\n        return (_b = (_a = legend.gradientLength) !== null && _a !== void 0 ? _a : legendConfig.gradientLength) !== null && _b !== void 0 ? _b : defaultGradientLength(params);\n    },\n    labelOverlap: ({ legend, legendConfig, scaleType }) => { var _a, _b; return (_b = (_a = legend.labelOverlap) !== null && _a !== void 0 ? _a : legendConfig.labelOverlap) !== null && _b !== void 0 ? _b : defaultLabelOverlap(scaleType); },\n    symbolType: ({ legend, markDef, channel, encoding }) => { var _a; return (_a = legend.symbolType) !== null && _a !== void 0 ? _a : defaultSymbolType(markDef.type, channel, encoding.shape, markDef.shape); },\n    title: ({ fieldOrDatumDef, config }) => fieldDefTitle(fieldOrDatumDef, config, { allowDisabling: true }),\n    type: ({ legendType, scaleType, channel }) => {\n        if (isColorChannel(channel) && isContinuousToContinuous(scaleType)) {\n            if (legendType === 'gradient') {\n                return undefined;\n            }\n        }\n        else if (legendType === 'symbol') {\n            return undefined;\n        }\n        return legendType;\n    },\n    values: ({ fieldOrDatumDef, legend }) => values(legend, fieldOrDatumDef)\n};\nexport function values(legend, fieldOrDatumDef) {\n    const vals = legend.values;\n    if (isArray(vals)) {\n        return valueArray(fieldOrDatumDef, vals);\n    }\n    else if (isSignalRef(vals)) {\n        return vals;\n    }\n    return undefined;\n}\nexport function defaultSymbolType(mark, channel, shapeChannelDef, markShape) {\n    var _a;\n    if (channel !== 'shape') {\n        // use the value from the shape encoding or the mark config if they exist\n        const shape = (_a = getFirstConditionValue(shapeChannelDef)) !== null && _a !== void 0 ? _a : markShape;\n        if (shape) {\n            return shape;\n        }\n    }\n    switch (mark) {\n        case 'bar':\n        case 'rect':\n        case 'image':\n        case 'square':\n            return 'square';\n        case 'line':\n        case 'trail':\n        case 'rule':\n            return 'stroke';\n        case 'arc':\n        case 'point':\n        case 'circle':\n        case 'tick':\n        case 'geoshape':\n        case 'area':\n        case 'text':\n            return 'circle';\n    }\n}\nexport function clipHeight(legendType) {\n    if (legendType === 'gradient') {\n        return 20;\n    }\n    return undefined;\n}\nexport function getLegendType(params) {\n    const { legend } = params;\n    return getFirstDefined(legend.type, defaultType(params));\n}\nexport function defaultType({ channel, timeUnit, scaleType }) {\n    // Following the logic in https://github.com/vega/vega-parser/blob/master/src/parsers/legend.js\n    if (isColorChannel(channel)) {\n        if (contains(['quarter', 'month', 'day'], timeUnit)) {\n            return 'symbol';\n        }\n        if (isContinuousToContinuous(scaleType)) {\n            return 'gradient';\n        }\n    }\n    return 'symbol';\n}\nexport function getDirection({ legendConfig, legendType, orient, legend }) {\n    var _a, _b;\n    return ((_b = (_a = legend.direction) !== null && _a !== void 0 ? _a : legendConfig[legendType ? 'gradientDirection' : 'symbolDirection']) !== null && _b !== void 0 ? _b : defaultDirection(orient, legendType));\n}\nexport function defaultDirection(orient, legendType) {\n    switch (orient) {\n        case 'top':\n        case 'bottom':\n            return 'horizontal';\n        case 'left':\n        case 'right':\n        case 'none':\n        case undefined: // undefined = \"right\" in Vega\n            return undefined; // vertical is Vega's default\n        default:\n            // top-left / ...\n            // For inner legend, uses compact layout like Tableau\n            return legendType === 'gradient' ? 'horizontal' : undefined;\n    }\n}\nexport function defaultGradientLength({ legendConfig, model, direction, orient, scaleType }) {\n    const { gradientHorizontalMaxLength, gradientHorizontalMinLength, gradientVerticalMaxLength, gradientVerticalMinLength } = legendConfig;\n    if (isContinuousToContinuous(scaleType)) {\n        if (direction === 'horizontal') {\n            if (orient === 'top' || orient === 'bottom') {\n                return gradientLengthSignal(model, 'width', gradientHorizontalMinLength, gradientHorizontalMaxLength);\n            }\n            else {\n                return gradientHorizontalMinLength;\n            }\n        }\n        else {\n            // vertical / undefined (Vega uses vertical by default)\n            return gradientLengthSignal(model, 'height', gradientVerticalMinLength, gradientVerticalMaxLength);\n        }\n    }\n    return undefined;\n}\nfunction gradientLengthSignal(model, sizeType, min, max) {\n    const sizeSignal = model.getSizeSignalRef(sizeType).signal;\n    return { signal: `clamp(${sizeSignal}, ${min}, ${max})` };\n}\nexport function defaultLabelOverlap(scaleType) {\n    if (contains(['quantile', 'threshold', 'log', 'symlog'], scaleType)) {\n        return 'greedy';\n    }\n    return undefined;\n}\n//# sourceMappingURL=properties.js.map","import * as encode from './encode';\nexport const arc = {\n    vgMark: 'arc',\n    encodeEntry: (model) => {\n        return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            size: 'ignore',\n            orient: 'ignore',\n            theta: 'ignore'\n        })), encode.pointPosition('x', model, { defaultPos: 'mid' })), encode.pointPosition('y', model, { defaultPos: 'mid' })), encode.rectPosition(model, 'radius', 'arc')), encode.rectPosition(model, 'theta', 'arc'));\n    }\n};\n//# sourceMappingURL=arc.js.map","import * as encode from './encode';\nexport const area = {\n    vgMark: 'area',\n    encodeEntry: (model) => {\n        return Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            orient: 'include',\n            size: 'ignore',\n            theta: 'ignore'\n        })), encode.pointOrRangePosition('x', model, {\n            defaultPos: 'zeroOrMin',\n            defaultPos2: 'zeroOrMin',\n            range: model.markDef.orient === 'horizontal'\n        })), encode.pointOrRangePosition('y', model, {\n            defaultPos: 'zeroOrMin',\n            defaultPos2: 'zeroOrMin',\n            range: model.markDef.orient === 'vertical'\n        })), encode.defined(model));\n    }\n};\n//# sourceMappingURL=area.js.map","import * as encode from './encode';\nexport const bar = {\n    vgMark: 'rect',\n    encodeEntry: (model) => {\n        return Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            orient: 'ignore',\n            size: 'ignore',\n            theta: 'ignore'\n        })), encode.rectPosition(model, 'x', 'bar')), encode.rectPosition(model, 'y', 'bar'));\n    }\n};\n//# sourceMappingURL=bar.js.map","import { entries, isEmpty } from '../../../util';\nimport { getMarkPropOrConfig, signalOrValueRef } from '../../common';\nimport { VG_MARK_INDEX } from './../../../vega.schema';\nimport { wrapCondition } from './conditional';\nimport { textRef } from './text';\nimport { tooltipData } from './tooltip';\nexport function aria(model) {\n    const { markDef, config } = model;\n    const enableAria = getMarkPropOrConfig('aria', markDef, config);\n    // We can ignore other aria properties if ariaHidden is true.\n    if (enableAria === false) {\n        // getMarkGroups sets aria to false already so we don't have to set it in the encode block\n        return {};\n    }\n    return Object.assign(Object.assign(Object.assign({}, (enableAria ? { aria: enableAria } : {})), ariaRoleDescription(model)), description(model));\n}\nfunction ariaRoleDescription(model) {\n    const { mark, markDef, config } = model;\n    if (config.aria === false) {\n        return {};\n    }\n    const ariaRoleDesc = getMarkPropOrConfig('ariaRoleDescription', markDef, config);\n    if (ariaRoleDesc != null) {\n        return { ariaRoleDescription: { value: ariaRoleDesc } };\n    }\n    return mark in VG_MARK_INDEX ? {} : { ariaRoleDescription: { value: mark } };\n}\nexport function description(model) {\n    const { encoding, markDef, config, stack } = model;\n    const channelDef = encoding.description;\n    if (channelDef) {\n        return wrapCondition(model, channelDef, 'description', cDef => textRef(cDef, model.config));\n    }\n    // Use default from mark def or config if defined.\n    // Functions in encode usually just return undefined but since we are defining a default below, we need to check the default here.\n    const descriptionValue = getMarkPropOrConfig('description', markDef, config);\n    if (descriptionValue != null) {\n        return {\n            description: signalOrValueRef(descriptionValue)\n        };\n    }\n    if (config.aria === false) {\n        return {};\n    }\n    const data = tooltipData(encoding, stack, config);\n    if (isEmpty(data)) {\n        return undefined;\n    }\n    return {\n        description: {\n            signal: entries(data)\n                .map(([key, value], index) => `\"${index > 0 ? '; ' : ''}${key}: \" + (${value})`)\n                .join(' + ')\n        }\n    };\n}\n//# sourceMappingURL=aria.js.map","import { array } from 'vega-util';\nimport { SCALE_CHANNELS } from '../../../channel';\nimport { isPathMark } from '../../../mark';\nimport { hasContinuousDomain } from '../../../scale';\nimport { keys } from '../../../util';\nimport { VG_MARK_CONFIGS } from '../../../vega.schema';\nimport { getMarkPropOrConfig, signalOrValueRef } from '../../common';\nimport { aria } from './aria';\nimport { color } from './color';\nimport { nonPosition } from './nonposition';\nimport { text } from './text';\nimport { tooltip } from './tooltip';\nimport { fieldInvalidPredicate } from './valueref';\nimport { zindex } from './zindex';\nexport { color } from './color';\nexport { wrapCondition } from './conditional';\nexport { nonPosition } from './nonposition';\nexport { pointPosition } from './position-point';\nexport { pointOrRangePosition, rangePosition } from './position-range';\nexport { rectPosition } from './position-rect';\nexport { text } from './text';\nexport { tooltip } from './tooltip';\nconst ALWAYS_IGNORE = new Set(['aria']);\nexport function baseEncodeEntry(model, ignore) {\n    const { fill = undefined, stroke = undefined } = ignore.color === 'include' ? color(model) : {};\n    return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, markDefProperties(model.markDef, ignore)), wrapAllFieldsInvalid(model, 'fill', fill)), wrapAllFieldsInvalid(model, 'stroke', stroke)), nonPosition('opacity', model)), nonPosition('fillOpacity', model)), nonPosition('strokeOpacity', model)), nonPosition('strokeWidth', model)), nonPosition('strokeDash', model)), zindex(model)), tooltip(model)), text(model, 'href')), aria(model));\n}\n// TODO: mark VgValueRef[] as readonly after https://github.com/vega/vega/pull/1987\nfunction wrapAllFieldsInvalid(model, channel, valueRef) {\n    const { config, mark, markDef } = model;\n    const invalid = getMarkPropOrConfig('invalid', markDef, config);\n    if (invalid === 'hide' && valueRef && !isPathMark(mark)) {\n        // For non-path marks, we have to exclude invalid values (null and NaN) for scales with continuous domains.\n        // For path marks, we will use \"defined\" property and skip these values instead.\n        const test = allFieldsInvalidPredicate(model, { invalid: true, channels: SCALE_CHANNELS });\n        if (test) {\n            return {\n                [channel]: [\n                    // prepend the invalid case\n                    // TODO: support custom value\n                    { test, value: null },\n                    ...array(valueRef)\n                ]\n            };\n        }\n    }\n    return valueRef ? { [channel]: valueRef } : {};\n}\nfunction markDefProperties(mark, ignore) {\n    return VG_MARK_CONFIGS.reduce((m, prop) => {\n        if (!ALWAYS_IGNORE.has(prop) && mark[prop] !== undefined && ignore[prop] !== 'ignore') {\n            m[prop] = signalOrValueRef(mark[prop]);\n        }\n        return m;\n    }, {});\n}\nfunction allFieldsInvalidPredicate(model, { invalid = false, channels }) {\n    const filterIndex = channels.reduce((aggregator, channel) => {\n        const scaleComponent = model.getScaleComponent(channel);\n        if (scaleComponent) {\n            const scaleType = scaleComponent.get('type');\n            const field = model.vgField(channel, { expr: 'datum' });\n            // While discrete domain scales can handle invalid values, continuous scales can't.\n            if (field && hasContinuousDomain(scaleType)) {\n                aggregator[field] = true;\n            }\n        }\n        return aggregator;\n    }, {});\n    const fields = keys(filterIndex);\n    if (fields.length > 0) {\n        const op = invalid ? '||' : '&&';\n        return fields.map(field => fieldInvalidPredicate(field, invalid)).join(` ${op} `);\n    }\n    return undefined;\n}\n//# sourceMappingURL=base.js.map","import * as log from '../../../log';\nimport { contains } from '../../../util';\nimport { getMarkPropOrConfig, signalOrValueRef } from '../../common';\nimport { nonPosition } from './nonposition';\nexport function color(model, opt = { filled: undefined }) {\n    var _a, _b, _c, _d;\n    const { markDef, encoding, config } = model;\n    const { type: markType } = markDef;\n    // Allow filled to be overridden (for trail's \"filled\")\n    const filled = (_a = opt.filled) !== null && _a !== void 0 ? _a : getMarkPropOrConfig('filled', markDef, config);\n    const transparentIfNeeded = contains(['bar', 'point', 'circle', 'square', 'geoshape'], markType)\n        ? 'transparent'\n        : undefined;\n    const defaultFill = (_c = (_b = getMarkPropOrConfig(filled === true ? 'color' : undefined, markDef, config, { vgChannel: 'fill' })) !== null && _b !== void 0 ? _b : \n    // need to add this manually as getMarkConfig normally drops config.mark[channel] if vgChannel is specified\n    config.mark[filled === true && 'color']) !== null && _c !== void 0 ? _c : \n    // If there is no fill, always fill symbols, bar, geoshape\n    // with transparent fills https://github.com/vega/vega-lite/issues/1316\n    transparentIfNeeded;\n    const defaultStroke = (_d = getMarkPropOrConfig(filled === false ? 'color' : undefined, markDef, config, { vgChannel: 'stroke' })) !== null && _d !== void 0 ? _d : \n    // need to add this manually as getMarkConfig normally drops config.mark[channel] if vgChannel is specified\n    config.mark[filled === false && 'color'];\n    const colorVgChannel = filled ? 'fill' : 'stroke';\n    const fillStrokeMarkDefAndConfig = Object.assign(Object.assign({}, (defaultFill ? { fill: signalOrValueRef(defaultFill) } : {})), (defaultStroke ? { stroke: signalOrValueRef(defaultStroke) } : {}));\n    if (markDef.color && (filled ? markDef.fill : markDef.stroke)) {\n        log.warn(log.message.droppingColor('property', { fill: 'fill' in markDef, stroke: 'stroke' in markDef }));\n    }\n    return Object.assign(Object.assign(Object.assign(Object.assign({}, fillStrokeMarkDefAndConfig), nonPosition('color', model, {\n        vgChannel: colorVgChannel,\n        defaultValue: filled ? defaultFill : defaultStroke\n    })), nonPosition('fill', model, {\n        // if there is encoding.fill, include default fill just in case we have conditional-only fill encoding\n        defaultValue: encoding.fill ? defaultFill : undefined\n    })), nonPosition('stroke', model, {\n        // if there is encoding.stroke, include default fill just in case we have conditional-only stroke encoding\n        defaultValue: encoding.stroke ? defaultStroke : undefined\n    }));\n}\n//# sourceMappingURL=color.js.map","import { array } from 'vega-util';\nimport { isConditionalDef, isConditionalSelection } from '../../../channeldef';\nimport { expression } from '../../predicate';\nimport { parseSelectionPredicate } from '../../selection/parse';\n/**\n * Return a mixin that includes a Vega production rule for a Vega-Lite conditional channel definition\n * or a simple mixin if channel def has no condition.\n */\nexport function wrapCondition(model, channelDef, vgChannel, refFn) {\n    const condition = isConditionalDef(channelDef) && channelDef.condition;\n    const valueRef = refFn(channelDef);\n    if (condition) {\n        const conditions = array(condition);\n        const vgConditions = conditions.map(c => {\n            const conditionValueRef = refFn(c);\n            const test = isConditionalSelection(c)\n                ? parseSelectionPredicate(model, c.selection) // FIXME: remove casting once TS is no longer dumb about it\n                : expression(model, c.test); // FIXME: remove casting once TS is no longer dumb about it\n            return Object.assign({ test }, conditionValueRef);\n        });\n        return {\n            [vgChannel]: [...vgConditions, ...(valueRef !== undefined ? [valueRef] : [])]\n        };\n    }\n    else {\n        return valueRef !== undefined ? { [vgChannel]: valueRef } : {};\n    }\n}\n//# sourceMappingURL=conditional.js.map","import { POSITION_SCALE_CHANNELS } from '../../../channel';\nimport { hasContinuousDomain } from '../../../scale';\nimport { keys } from '../../../util';\nimport { getMarkPropOrConfig, signalOrValueRef } from '../../common';\nimport { fieldInvalidPredicate } from './valueref';\nexport function defined(model) {\n    const { config, markDef } = model;\n    const invalid = getMarkPropOrConfig('invalid', markDef, config);\n    if (invalid) {\n        const signal = allFieldsInvalidPredicate(model, { channels: POSITION_SCALE_CHANNELS });\n        if (signal) {\n            return { defined: { signal } };\n        }\n    }\n    return {};\n}\nfunction allFieldsInvalidPredicate(model, { invalid = false, channels }) {\n    const filterIndex = channels.reduce((aggregator, channel) => {\n        const scaleComponent = model.getScaleComponent(channel);\n        if (scaleComponent) {\n            const scaleType = scaleComponent.get('type');\n            const field = model.vgField(channel, { expr: 'datum' });\n            // While discrete domain scales can handle invalid values, continuous scales can't.\n            if (field && hasContinuousDomain(scaleType)) {\n                aggregator[field] = true;\n            }\n        }\n        return aggregator;\n    }, {});\n    const fields = keys(filterIndex);\n    if (fields.length > 0) {\n        const op = invalid ? '||' : '&&';\n        return fields.map(field => fieldInvalidPredicate(field, invalid)).join(` ${op} `);\n    }\n    return undefined;\n}\nexport function valueIfDefined(prop, value) {\n    if (value !== undefined) {\n        return { [prop]: signalOrValueRef(value) };\n    }\n    return undefined;\n}\n//# sourceMappingURL=defined.js.map","export { baseEncodeEntry } from './base';\nexport { color } from './color';\nexport { wrapCondition } from './conditional';\nexport { defined, valueIfDefined } from './defined';\nexport { nonPosition } from './nonposition';\nexport { pointPosition } from './position-point';\nexport { pointOrRangePosition, rangePosition } from './position-range';\nexport { rectBinPosition, rectPosition } from './position-rect';\nexport { text } from './text';\nexport { tooltip, tooltipRefForEncoding } from './tooltip';\nexport { aria } from './aria';\n//# sourceMappingURL=index.js.map","import { getMarkPropOrConfig, signalOrValueRef } from '../../common';\nimport { wrapCondition } from './conditional';\nimport * as ref from './valueref';\n/**\n * Return encode for non-positional channels with scales. (Text doesn't have scale.)\n */\nexport function nonPosition(channel, model, opt = {}) {\n    const { markDef, encoding, config } = model;\n    const { vgChannel } = opt;\n    let { defaultRef, defaultValue } = opt;\n    if (defaultRef === undefined) {\n        // prettier-ignore\n        defaultValue = defaultValue !== null && defaultValue !== void 0 ? defaultValue : getMarkPropOrConfig(channel, markDef, config, { vgChannel, ignoreVgConfig: true });\n        if (defaultValue !== undefined) {\n            defaultRef = signalOrValueRef(defaultValue);\n        }\n    }\n    const channelDef = encoding[channel];\n    return wrapCondition(model, channelDef, vgChannel !== null && vgChannel !== void 0 ? vgChannel : channel, cDef => {\n        return ref.midPoint({\n            channel,\n            channelDef: cDef,\n            markDef,\n            config,\n            scaleName: model.scaleName(channel),\n            scale: model.getScaleComponent(channel),\n            stack: null,\n            defaultRef\n        });\n    });\n}\n//# sourceMappingURL=nonposition.js.map","import { getOffsetChannel } from '../../../channel';\nexport function getOffset(channel, markDef) {\n    const offsetChannel = getOffsetChannel(channel);\n    // TODO: in the future read from encoding channel too\n    const markDefOffsetValue = markDef[offsetChannel];\n    if (markDefOffsetValue) {\n        return markDefOffsetValue;\n    }\n    return undefined;\n}\n//# sourceMappingURL=offset.js.map","import { getVgPositionChannel } from '../../../channel';\nimport * as log from '../../../log';\nimport { isSignalRef } from '../../../vega.schema';\nimport { getMarkPropOrConfig } from '../../common';\nconst ALIGNED_X_CHANNEL = {\n    left: 'x',\n    center: 'xc',\n    right: 'x2'\n};\nconst BASELINED_Y_CHANNEL = {\n    top: 'y',\n    middle: 'yc',\n    bottom: 'y2'\n};\nexport function vgAlignedPositionChannel(channel, markDef, config, defaultAlign = 'middle') {\n    if (channel === 'radius' || channel === 'theta') {\n        return getVgPositionChannel(channel);\n    }\n    const alignChannel = channel === 'x' ? 'align' : 'baseline';\n    const align = getMarkPropOrConfig(alignChannel, markDef, config);\n    let alignExcludingSignal;\n    if (isSignalRef(align)) {\n        log.warn(log.message.rangeMarkAlignmentCannotBeExpression(alignChannel));\n        alignExcludingSignal = undefined;\n    }\n    else {\n        alignExcludingSignal = align;\n    }\n    if (channel === 'x') {\n        return ALIGNED_X_CHANNEL[alignExcludingSignal || (defaultAlign === 'top' ? 'left' : 'center')];\n    }\n    else {\n        return BASELINED_Y_CHANNEL[alignExcludingSignal || defaultAlign];\n    }\n}\n//# sourceMappingURL=position-align.js.map","import { getMainRangeChannel, getSecondaryRangeChannel, getSizeChannel, getVgPositionChannel, isXorY } from '../../../channel';\nimport { getBand, isFieldDef, isFieldOrDatumDef } from '../../../channeldef';\nimport { ScaleType } from '../../../scale';\nimport { contains } from '../../../util';\nimport { getMarkPropOrConfig } from '../../common';\nimport { getOffset } from './offset';\nimport * as ref from './valueref';\n/**\n * Return encode for point (non-band) position channels.\n */\nexport function pointPosition(channel, model, { defaultPos, vgChannel, isMidPoint }) {\n    const { encoding, markDef, config, stack } = model;\n    const channelDef = encoding[channel];\n    const channel2Def = encoding[getSecondaryRangeChannel(channel)];\n    const scaleName = model.scaleName(channel);\n    const scale = model.getScaleComponent(channel);\n    const offset = getOffset(channel, markDef);\n    // Get default position or position from mark def\n    const defaultRef = pointPositionDefaultRef({\n        model,\n        defaultPos,\n        channel,\n        scaleName,\n        scale\n    });\n    const valueRef = !channelDef && isXorY(channel) && (encoding.latitude || encoding.longitude)\n        ? // use geopoint output if there are lat/long and there is no point position overriding lat/long.\n            { field: model.getName(channel) }\n        : positionRef({\n            channel,\n            channelDef,\n            channel2Def,\n            markDef,\n            config,\n            isMidPoint,\n            scaleName,\n            scale,\n            stack,\n            offset,\n            defaultRef\n        });\n    return valueRef ? { [vgChannel || channel]: valueRef } : undefined;\n}\n// TODO: we need to find a way to refactor these so that scaleName is a part of scale\n// but that's complicated. For now, this is a huge step moving forward.\n/**\n * @return Vega ValueRef for normal x- or y-position without projection\n */\nexport function positionRef(params) {\n    const { channel, channelDef, isMidPoint, scaleName, stack, offset, markDef, config } = params;\n    // This isn't a part of midPoint because we use midPoint for non-position too\n    if (isFieldOrDatumDef(channelDef) && stack && channel === stack.fieldChannel) {\n        if (isFieldDef(channelDef)) {\n            const band = getBand({\n                channel,\n                fieldDef: channelDef,\n                isMidPoint,\n                markDef,\n                stack,\n                config\n            });\n            if (band !== undefined) {\n                return ref.interpolatedSignalRef({\n                    scaleName,\n                    fieldOrDatumDef: channelDef,\n                    startSuffix: 'start',\n                    band,\n                    offset\n                });\n            }\n        }\n        // x or y use stack_end so that stacked line's point mark use stack_end too.\n        return ref.valueRefForFieldOrDatumDef(channelDef, scaleName, { suffix: 'end' }, { offset });\n    }\n    return ref.midPointRefWithPositionInvalidTest(params);\n}\nexport function pointPositionDefaultRef({ model, defaultPos, channel, scaleName, scale }) {\n    const { markDef, config } = model;\n    return () => {\n        const mainChannel = getMainRangeChannel(channel);\n        const vgChannel = getVgPositionChannel(channel);\n        const definedValueOrConfig = getMarkPropOrConfig(channel, markDef, config, { vgChannel });\n        if (definedValueOrConfig !== undefined) {\n            return ref.widthHeightValueOrSignalRef(channel, definedValueOrConfig);\n        }\n        switch (defaultPos) {\n            case 'zeroOrMin':\n            case 'zeroOrMax':\n                if (scaleName) {\n                    const scaleType = scale.get('type');\n                    if (contains([ScaleType.LOG, ScaleType.TIME, ScaleType.UTC], scaleType)) {\n                        // Log scales cannot have zero.\n                        // Zero in time scale is arbitrary, and does not affect ratio.\n                        // (Time is an interval level of measurement, not ratio).\n                        // See https://en.wikipedia.org/wiki/Level_of_measurement for more info.\n                    }\n                    else {\n                        if (scale.domainDefinitelyIncludesZero()) {\n                            return {\n                                scale: scaleName,\n                                value: 0\n                            };\n                        }\n                    }\n                }\n                if (defaultPos === 'zeroOrMin') {\n                    return mainChannel === 'y' ? { field: { group: 'height' } } : { value: 0 };\n                }\n                else {\n                    // zeroOrMax\n                    switch (mainChannel) {\n                        case 'radius':\n                            // max of radius is min(width, height) / 2\n                            return {\n                                signal: `min(${model.width.signal},${model.height.signal})/2`\n                            };\n                        case 'theta':\n                            return { signal: '2*PI' };\n                        case 'x':\n                            return { field: { group: 'width' } };\n                        case 'y':\n                            return { value: 0 };\n                    }\n                }\n                break;\n            case 'mid': {\n                const sizeRef = model[getSizeChannel(channel)];\n                return Object.assign(Object.assign({}, sizeRef), { mult: 0.5 });\n            }\n        }\n        // defaultPos === null\n        return undefined;\n    };\n}\n//# sourceMappingURL=position-point.js.map","import { getMainRangeChannel, getSecondaryRangeChannel, getSizeChannel, getVgPositionChannel } from '../../../channel';\nimport { isFieldOrDatumDef } from '../../../channeldef';\nimport { getMarkStyleConfig } from '../../common';\nimport { getOffset } from './offset';\nimport { vgAlignedPositionChannel } from './position-align';\nimport { pointPosition, pointPositionDefaultRef } from './position-point';\nimport * as ref from './valueref';\n/**\n * Utility for area/rule position, which can be either point or range. (One of the axes should be point and the other should be range.)\n */\nexport function pointOrRangePosition(channel, model, { defaultPos, defaultPos2, range }) {\n    if (range) {\n        return rangePosition(channel, model, { defaultPos, defaultPos2 });\n    }\n    return pointPosition(channel, model, { defaultPos });\n}\nexport function rangePosition(channel, model, { defaultPos, defaultPos2 }) {\n    const { markDef, config } = model;\n    const channel2 = getSecondaryRangeChannel(channel);\n    const sizeChannel = getSizeChannel(channel);\n    const pos2Mixins = pointPosition2OrSize(model, defaultPos2, channel2);\n    const vgChannel = pos2Mixins[sizeChannel]\n        ? // If there is width/height, we need to position the marks based on the alignment.\n            vgAlignedPositionChannel(channel, markDef, config)\n        : // Otherwise, make sure to apply to the right Vg Channel (for arc mark)\n            getVgPositionChannel(channel);\n    return Object.assign(Object.assign({}, pointPosition(channel, model, { defaultPos, vgChannel })), pos2Mixins);\n}\n/**\n * Return encode for x2, y2.\n * If channel is not specified, return one channel based on orientation.\n */\nfunction pointPosition2OrSize(model, defaultPos, channel) {\n    const { encoding, mark, markDef, stack, config } = model;\n    const baseChannel = getMainRangeChannel(channel);\n    const sizeChannel = getSizeChannel(channel);\n    const vgChannel = getVgPositionChannel(channel);\n    const channelDef = encoding[baseChannel];\n    const scaleName = model.scaleName(baseChannel);\n    const scale = model.getScaleComponent(baseChannel);\n    const offset = channel in encoding || channel in markDef\n        ? getOffset(channel, model.markDef)\n        : getOffset(baseChannel, model.markDef);\n    if (!channelDef && (channel === 'x2' || channel === 'y2') && (encoding.latitude || encoding.longitude)) {\n        // use geopoint output if there are lat2/long2 and there is no point position2 overriding lat2/long2.\n        return { [vgChannel]: { field: model.getName(channel) } };\n    }\n    const valueRef = position2Ref({\n        channel,\n        channelDef,\n        channel2Def: encoding[channel],\n        markDef,\n        config,\n        scaleName,\n        scale,\n        stack,\n        offset,\n        defaultRef: undefined\n    });\n    if (valueRef !== undefined) {\n        return { [vgChannel]: valueRef };\n    }\n    // TODO: check width/height encoding here once we add them\n    // no x2/y2 encoding, then try to read x2/y2 or width/height based on precedence:\n    // markDef > config.style > mark-specific config (config[mark]) > general mark config (config.mark)\n    return (position2orSize(channel, markDef) ||\n        position2orSize(channel, {\n            [channel]: getMarkStyleConfig(channel, markDef, config.style),\n            [sizeChannel]: getMarkStyleConfig(sizeChannel, markDef, config.style)\n        }) ||\n        position2orSize(channel, config[mark]) ||\n        position2orSize(channel, config.mark) || {\n        [vgChannel]: pointPositionDefaultRef({\n            model,\n            defaultPos,\n            channel,\n            scaleName,\n            scale\n        })()\n    });\n}\nexport function position2Ref({ channel, channelDef, channel2Def, markDef, config, scaleName, scale, stack, offset, defaultRef }) {\n    if (isFieldOrDatumDef(channelDef) &&\n        stack &&\n        // If fieldChannel is X and channel is X2 (or Y and Y2)\n        channel.charAt(0) === stack.fieldChannel.charAt(0)) {\n        return ref.valueRefForFieldOrDatumDef(channelDef, scaleName, { suffix: 'start' }, { offset });\n    }\n    return ref.midPointRefWithPositionInvalidTest({\n        channel,\n        channelDef: channel2Def,\n        scaleName,\n        scale,\n        stack,\n        markDef,\n        config,\n        offset,\n        defaultRef\n    });\n}\nfunction position2orSize(channel, markDef) {\n    const sizeChannel = getSizeChannel(channel);\n    const vgChannel = getVgPositionChannel(channel);\n    if (markDef[vgChannel] !== undefined) {\n        return { [vgChannel]: ref.widthHeightValueOrSignalRef(channel, markDef[vgChannel]) };\n    }\n    else if (markDef[channel] !== undefined) {\n        return { [vgChannel]: ref.widthHeightValueOrSignalRef(channel, markDef[channel]) };\n    }\n    else if (markDef[sizeChannel]) {\n        return { [sizeChannel]: ref.widthHeightValueOrSignalRef(channel, markDef[sizeChannel]) };\n    }\n    return undefined;\n}\n//# sourceMappingURL=position-range.js.map","import { isArray, isNumber } from 'vega-util';\nimport { isBinned, isBinning, isBinParams } from '../../../bin';\nimport { getSecondaryRangeChannel, getSizeChannel, getVgPositionChannel, isPolarPositionChannel, isXorY } from '../../../channel';\nimport { getBand, isFieldDef, isFieldOrDatumDef, vgField } from '../../../channeldef';\nimport { DEFAULT_STEP, getViewConfigDiscreteStep } from '../../../config';\nimport * as log from '../../../log';\nimport { hasDiscreteDomain, ScaleType } from '../../../scale';\nimport { getFirstDefined } from '../../../util';\nimport { isSignalRef, isVgRangeStep } from '../../../vega.schema';\nimport { getMarkPropOrConfig, signalOrStringValue } from '../../common';\nimport { nonPosition } from './nonposition';\nimport { getOffset } from './offset';\nimport { vgAlignedPositionChannel } from './position-align';\nimport { pointPositionDefaultRef } from './position-point';\nimport { rangePosition } from './position-range';\nimport * as ref from './valueref';\nexport function rectPosition(model, channel, mark) {\n    var _a, _b, _c, _d;\n    const { config, encoding, markDef, stack } = model;\n    const channel2 = getSecondaryRangeChannel(channel);\n    const sizeChannel = getSizeChannel(channel);\n    const channelDef = encoding[channel];\n    const channelDef2 = encoding[channel2];\n    const scale = model.getScaleComponent(channel);\n    const scaleType = scale ? scale.get('type') : undefined;\n    const scaleName = model.scaleName(channel);\n    const orient = markDef.orient;\n    const hasSizeDef = (_b = (_a = encoding[sizeChannel]) !== null && _a !== void 0 ? _a : encoding.size) !== null && _b !== void 0 ? _b : getMarkPropOrConfig('size', markDef, config, { vgChannel: sizeChannel });\n    const isBarBand = mark === 'bar' && (channel === 'x' ? orient === 'vertical' : orient === 'horizontal');\n    // x, x2, and width -- we must specify two of these in all conditions\n    if (isFieldDef(channelDef) &&\n        (isBinning(channelDef.bin) || isBinned(channelDef.bin) || (channelDef.timeUnit && !channelDef2)) &&\n        !hasSizeDef &&\n        !hasDiscreteDomain(scaleType)) {\n        const band = getBand({ channel, fieldDef: channelDef, stack, markDef, config });\n        const axis = (_c = model.component.axes[channel]) === null || _c === void 0 ? void 0 : _c[0];\n        const axisTranslate = (_d = axis === null || axis === void 0 ? void 0 : axis.get('translate')) !== null && _d !== void 0 ? _d : 0.5; // vega default is 0.5\n        return rectBinPosition({\n            fieldDef: channelDef,\n            fieldDef2: channelDef2,\n            channel,\n            markDef,\n            scaleName,\n            band,\n            axisTranslate,\n            spacing: isXorY(channel) ? getMarkPropOrConfig('binSpacing', markDef, config) : undefined,\n            reverse: scale.get('reverse'),\n            config\n        });\n    }\n    else if (((isFieldOrDatumDef(channelDef) && hasDiscreteDomain(scaleType)) || isBarBand) && !channelDef2) {\n        return positionAndSize(mark, channelDef, channel, model);\n    }\n    else {\n        return rangePosition(channel, model, { defaultPos: 'zeroOrMax', defaultPos2: 'zeroOrMin' });\n    }\n}\nfunction defaultSizeRef(mark, sizeChannel, scaleName, scale, config, band) {\n    if (scale) {\n        const scaleType = scale.get('type');\n        if (scaleType === 'point' || scaleType === 'band') {\n            if (config[mark].discreteBandSize !== undefined) {\n                return { value: config[mark].discreteBandSize };\n            }\n            if (scaleType === ScaleType.POINT) {\n                const scaleRange = scale.get('range');\n                if (isVgRangeStep(scaleRange) && isNumber(scaleRange.step)) {\n                    return { value: scaleRange.step - 2 };\n                }\n                return { value: DEFAULT_STEP - 2 };\n            }\n            else {\n                // BAND\n                return { scale: scaleName, band };\n            }\n        }\n        else {\n            // continuous scale\n            return { value: config[mark].continuousBandSize };\n        }\n    }\n    // No Scale\n    const step = getViewConfigDiscreteStep(config.view, sizeChannel);\n    const value = getFirstDefined(\n    // No scale is like discrete bar (with one item)\n    config[mark].discreteBandSize, step - 2);\n    return value !== undefined ? { value } : undefined;\n}\n/**\n * Output position encoding and its size encoding for continuous, point, and band scales.\n */\nfunction positionAndSize(mark, fieldDef, channel, model) {\n    var _a;\n    const { markDef, encoding, config, stack } = model;\n    const orient = markDef.orient;\n    const scaleName = model.scaleName(channel);\n    const scale = model.getScaleComponent(channel);\n    const vgSizeChannel = getSizeChannel(channel);\n    const channel2 = getSecondaryRangeChannel(channel);\n    // use \"size\" channel for bars, if there is orient and the channel matches the right orientation\n    const useVlSizeChannel = (orient === 'horizontal' && channel === 'y') || (orient === 'vertical' && channel === 'x');\n    const sizeFromMarkOrConfig = getMarkPropOrConfig(useVlSizeChannel ? 'size' : vgSizeChannel, markDef, config, {\n        vgChannel: vgSizeChannel\n    });\n    // Use size encoding / mark property / config if it exists\n    let sizeMixins;\n    if (encoding.size || sizeFromMarkOrConfig !== undefined) {\n        if (useVlSizeChannel) {\n            sizeMixins = nonPosition('size', model, { vgChannel: vgSizeChannel, defaultValue: sizeFromMarkOrConfig });\n        }\n        else {\n            log.warn(log.message.cannotApplySizeToNonOrientedMark(markDef.type));\n        }\n    }\n    // Otherwise, apply default value\n    const band = (_a = (isFieldOrDatumDef(fieldDef) ? getBand({ channel, fieldDef, markDef, stack, config }) : undefined)) !== null && _a !== void 0 ? _a : 1;\n    sizeMixins = sizeMixins || { [vgSizeChannel]: defaultSizeRef(mark, vgSizeChannel, scaleName, scale, config, band) };\n    /*\n      Band scales with size value and all point scales, use xc/yc + band=0.5\n  \n      Otherwise (band scales that has size based on a band ref), use x/y with position band = (1 - size_band) / 2.\n      In this case, size_band is the band specified in the x/y-encoding.\n      By default band is 1, so `(1 - band) / 2` = 0.\n      If band is 0.6, the the x/y position in such case should be `(1 - band) / 2` = 0.2\n     */\n    const center = (scale === null || scale === void 0 ? void 0 : scale.get('type')) !== 'band' || !('band' in sizeMixins[vgSizeChannel]);\n    const vgChannel = vgAlignedPositionChannel(channel, markDef, config, center ? 'middle' : 'top');\n    const offset = getOffset(channel, markDef);\n    const posRef = ref.midPointRefWithPositionInvalidTest({\n        channel,\n        channelDef: fieldDef,\n        markDef,\n        config,\n        scaleName,\n        scale,\n        stack,\n        offset,\n        defaultRef: pointPositionDefaultRef({ model, defaultPos: 'mid', channel, scaleName, scale }),\n        band: center ? 0.5 : (1 - band) / 2\n    });\n    if (vgSizeChannel) {\n        return Object.assign({ [vgChannel]: posRef }, sizeMixins);\n    }\n    else {\n        // otherwise, we must simulate size by setting position2 = position + size\n        // (for theta/radius since Vega doesn't have thetaWidth/radiusWidth)\n        const vgChannel2 = getVgPositionChannel(channel2);\n        const sizeRef = sizeMixins[vgSizeChannel];\n        const sizeOffset = offset ? Object.assign(Object.assign({}, sizeRef), { offset }) : sizeRef;\n        return {\n            [vgChannel]: posRef,\n            // posRef might be an array that wraps position invalid test\n            [vgChannel2]: isArray(posRef)\n                ? [posRef[0], Object.assign(Object.assign({}, posRef[1]), { offset: sizeOffset })]\n                : Object.assign(Object.assign({}, posRef), { offset: sizeOffset })\n        };\n    }\n}\nfunction getBinSpacing(channel, spacing, reverse, translate, offset) {\n    if (isPolarPositionChannel(channel)) {\n        return 0;\n    }\n    const spacingOffset = channel === 'x' || channel === 'y2' ? -spacing / 2 : spacing / 2;\n    if (isSignalRef(reverse) || isSignalRef(offset) || isSignalRef(translate)) {\n        const reverseExpr = signalOrStringValue(reverse);\n        const offsetExpr = signalOrStringValue(offset);\n        const translateExpr = signalOrStringValue(translate);\n        const t = translateExpr ? `${translateExpr} + ` : '';\n        const r = reverseExpr ? `(${reverseExpr} ? -1 : 1) * ` : '';\n        const o = offsetExpr ? `(${offsetExpr} + ${spacingOffset})` : spacingOffset;\n        return {\n            signal: t + r + o\n        };\n    }\n    else {\n        offset = offset || 0;\n        return translate + (reverse ? -offset - spacingOffset : +offset + spacingOffset);\n    }\n}\nexport function rectBinPosition({ fieldDef, fieldDef2, channel, band, scaleName, markDef, spacing = 0, axisTranslate, reverse, config }) {\n    const channel2 = getSecondaryRangeChannel(channel);\n    const vgChannel = getVgPositionChannel(channel);\n    const vgChannel2 = getVgPositionChannel(channel2);\n    const offset = getOffset(channel, markDef);\n    if (isBinning(fieldDef.bin) || fieldDef.timeUnit) {\n        return {\n            [vgChannel2]: rectBinRef({\n                channel,\n                fieldDef,\n                scaleName,\n                markDef,\n                band: (1 - band) / 2,\n                offset: getBinSpacing(channel2, spacing, reverse, axisTranslate, offset),\n                config\n            }),\n            [vgChannel]: rectBinRef({\n                channel,\n                fieldDef,\n                scaleName,\n                markDef,\n                band: 1 - (1 - band) / 2,\n                offset: getBinSpacing(channel, spacing, reverse, axisTranslate, offset),\n                config\n            })\n        };\n    }\n    else if (isBinned(fieldDef.bin)) {\n        const startRef = ref.valueRefForFieldOrDatumDef(fieldDef, scaleName, {}, { offset: getBinSpacing(channel2, spacing, reverse, axisTranslate, offset) });\n        if (isFieldDef(fieldDef2)) {\n            return {\n                [vgChannel2]: startRef,\n                [vgChannel]: ref.valueRefForFieldOrDatumDef(fieldDef2, scaleName, {}, { offset: getBinSpacing(channel, spacing, reverse, axisTranslate, offset) })\n            };\n        }\n        else if (isBinParams(fieldDef.bin) && fieldDef.bin.step) {\n            return {\n                [vgChannel2]: startRef,\n                [vgChannel]: {\n                    signal: `scale(\"${scaleName}\", ${vgField(fieldDef, { expr: 'datum' })} + ${fieldDef.bin.step})`,\n                    offset: getBinSpacing(channel, spacing, reverse, axisTranslate, offset)\n                }\n            };\n        }\n    }\n    log.warn(log.message.channelRequiredForBinned(channel2));\n    return undefined;\n}\n/**\n * Value Ref for binned fields\n */\nexport function rectBinRef({ channel, fieldDef, scaleName, markDef, band, offset, config }) {\n    const r = ref.interpolatedSignalRef({\n        scaleName,\n        fieldOrDatumDef: fieldDef,\n        band,\n        offset\n    });\n    return ref.wrapPositionInvalidTest({\n        fieldDef,\n        channel,\n        markDef,\n        ref: r,\n        config\n    });\n}\n//# sourceMappingURL=position-rect.js.map","import { getFormatMixins, isFieldOrDatumDef, isValueDef } from '../../../channeldef';\nimport { signalOrValueRef } from '../../common';\nimport { formatSignalRef } from '../../format';\nimport { wrapCondition } from './conditional';\nexport function text(model, channel = 'text') {\n    const channelDef = model.encoding[channel];\n    return wrapCondition(model, channelDef, channel, cDef => textRef(cDef, model.config));\n}\nexport function textRef(channelDef, config, expr = 'datum') {\n    // text\n    if (channelDef) {\n        if (isValueDef(channelDef)) {\n            return signalOrValueRef(channelDef.value);\n        }\n        if (isFieldOrDatumDef(channelDef)) {\n            const { format, formatType } = getFormatMixins(channelDef);\n            return formatSignalRef({ fieldOrDatumDef: channelDef, format, formatType, expr, config });\n        }\n    }\n    return undefined;\n}\n//# sourceMappingURL=text.js.map","import { array, isArray, isObject, isString } from 'vega-util';\nimport { isBinned } from '../../../bin';\nimport { getMainRangeChannel, isXorY } from '../../../channel';\nimport { defaultTitle, getFieldDef, getFormatMixins, hasConditionalFieldDef, isFieldDef, isTypedFieldDef, vgField } from '../../../channeldef';\nimport { forEach } from '../../../encoding';\nimport { entries } from '../../../util';\nimport { isSignalRef } from '../../../vega.schema';\nimport { getMarkPropOrConfig } from '../../common';\nimport { binFormatExpression, formatSignalRef } from '../../format';\nimport { wrapCondition } from './conditional';\nimport { textRef } from './text';\nexport function tooltip(model, opt = {}) {\n    const { encoding, markDef, config, stack } = model;\n    const channelDef = encoding.tooltip;\n    if (isArray(channelDef)) {\n        return { tooltip: tooltipRefForEncoding({ tooltip: channelDef }, stack, config, opt) };\n    }\n    else {\n        const datum = opt.reactiveGeom ? 'datum.datum' : 'datum';\n        return wrapCondition(model, channelDef, 'tooltip', cDef => {\n            // use valueRef based on channelDef first\n            const tooltipRefFromChannelDef = textRef(cDef, config, datum);\n            if (tooltipRefFromChannelDef) {\n                return tooltipRefFromChannelDef;\n            }\n            if (cDef === null) {\n                // Allow using encoding.tooltip = null to disable tooltip\n                return undefined;\n            }\n            let markTooltip = getMarkPropOrConfig('tooltip', markDef, config);\n            if (markTooltip === true) {\n                markTooltip = { content: 'encoding' };\n            }\n            if (isString(markTooltip)) {\n                return { value: markTooltip };\n            }\n            else if (isObject(markTooltip)) {\n                // `tooltip` is `{fields: 'encodings' | 'fields'}`\n                if (isSignalRef(markTooltip)) {\n                    return markTooltip;\n                }\n                else if (markTooltip.content === 'encoding') {\n                    return tooltipRefForEncoding(encoding, stack, config, opt);\n                }\n                else {\n                    return { signal: datum };\n                }\n            }\n            return undefined;\n        });\n    }\n}\nexport function tooltipData(encoding, stack, config, { reactiveGeom } = {}) {\n    const toSkip = {};\n    const expr = reactiveGeom ? 'datum.datum' : 'datum';\n    const tuples = [];\n    function add(fDef, channel) {\n        const mainChannel = getMainRangeChannel(channel);\n        const fieldDef = isTypedFieldDef(fDef)\n            ? fDef\n            : Object.assign(Object.assign({}, fDef), { type: encoding[mainChannel].type // for secondary field def, copy type from main channel\n             });\n        const title = fieldDef.title || defaultTitle(fieldDef, config);\n        const key = array(title).join(', ');\n        let value;\n        if (isXorY(channel)) {\n            const channel2 = channel === 'x' ? 'x2' : 'y2';\n            const fieldDef2 = getFieldDef(encoding[channel2]);\n            if (isBinned(fieldDef.bin) && fieldDef2) {\n                const startField = vgField(fieldDef, { expr });\n                const endField = vgField(fieldDef2, { expr });\n                const { format, formatType } = getFormatMixins(fieldDef);\n                value = binFormatExpression(startField, endField, format, formatType, config);\n                toSkip[channel2] = true;\n            }\n            else if (stack && stack.fieldChannel === channel && stack.offset === 'normalize') {\n                const { format, formatType } = getFormatMixins(fieldDef);\n                value = formatSignalRef({ fieldOrDatumDef: fieldDef, format, formatType, expr, config, normalizeStack: true })\n                    .signal;\n            }\n        }\n        value = value !== null && value !== void 0 ? value : textRef(fieldDef, config, expr).signal;\n        tuples.push({ channel, key, value });\n    }\n    forEach(encoding, (channelDef, channel) => {\n        if (isFieldDef(channelDef)) {\n            add(channelDef, channel);\n        }\n        else if (hasConditionalFieldDef(channelDef)) {\n            add(channelDef.condition, channel);\n        }\n    });\n    const out = {};\n    for (const { channel, key, value } of tuples) {\n        if (!toSkip[channel] && !out[key]) {\n            out[key] = value;\n        }\n    }\n    return out;\n}\nexport function tooltipRefForEncoding(encoding, stack, config, { reactiveGeom } = {}) {\n    const data = tooltipData(encoding, stack, config, { reactiveGeom });\n    const keyValues = entries(data).map(([key, value]) => `\"${key}\": ${value}`);\n    return keyValues.length > 0 ? { signal: `{${keyValues.join(', ')}}` } : undefined;\n}\n//# sourceMappingURL=tooltip.js.map","import { isFunction, isString } from 'vega-util';\nimport { isCountingAggregateOp } from '../../../aggregate';\nimport { isBinned, isBinning } from '../../../bin';\nimport { getMainRangeChannel, X, X2, Y2 } from '../../../channel';\nimport { binRequiresRange, getBand, isDatumDef, isFieldDef, isFieldOrDatumDef, isTypedFieldDef, isValueDef, vgField } from '../../../channeldef';\nimport { dateTimeToExpr, isDateTime } from '../../../datetime';\nimport { isExprRef } from '../../../expr';\nimport * as log from '../../../log';\nimport { isPathMark } from '../../../mark';\nimport { fieldValidPredicate } from '../../../predicate';\nimport { hasDiscreteDomain, isContinuousToContinuous } from '../../../scale';\nimport { TEMPORAL } from '../../../type';\nimport { contains } from '../../../util';\nimport { isSignalRef } from '../../../vega.schema';\nimport { getMarkPropOrConfig, signalOrValueRef } from '../../common';\nexport function midPointRefWithPositionInvalidTest(params) {\n    const { channel, channelDef, markDef, scale, config } = params;\n    const ref = midPoint(params);\n    // Wrap to check if the positional value is invalid, if so, plot the point on the min value\n    if (\n    // Only this for field def without counting aggregate (as count wouldn't be null)\n    isFieldDef(channelDef) &&\n        !isCountingAggregateOp(channelDef.aggregate) &&\n        // and only for continuous scale without zero (otherwise, null / invalid will be interpreted as zero, which doesn't cause layout problem)\n        scale &&\n        isContinuousToContinuous(scale.get('type')) &&\n        scale.get('zero') === false) {\n        return wrapPositionInvalidTest({\n            fieldDef: channelDef,\n            channel,\n            markDef,\n            ref,\n            config\n        });\n    }\n    return ref;\n}\nexport function wrapPositionInvalidTest({ fieldDef, channel, markDef, ref, config }) {\n    if (isPathMark(markDef.type)) {\n        // path mark already use defined to skip points, no need to do it here.\n        return ref;\n    }\n    const invalid = getMarkPropOrConfig('invalid', markDef, config);\n    if (invalid === null) {\n        // if there is no invalid filter, don't do the invalid test\n        return ref;\n    }\n    return [fieldInvalidTestValueRef(fieldDef, channel), ref];\n}\nexport function fieldInvalidTestValueRef(fieldDef, channel) {\n    const test = fieldInvalidPredicate(fieldDef, true);\n    const mainChannel = getMainRangeChannel(channel); // we can cast here as the output can't be other things.\n    const zeroValueRef = mainChannel === 'y'\n        ? { field: { group: 'height' } }\n        : // x / angle / radius can all use 0\n            { value: 0 };\n    return Object.assign({ test }, zeroValueRef);\n}\nexport function fieldInvalidPredicate(field, invalid = true) {\n    return fieldValidPredicate(isString(field) ? field : vgField(field, { expr: 'datum' }), !invalid);\n}\nexport function datumDefToExpr(datumDef) {\n    const { datum } = datumDef;\n    if (isDateTime(datum)) {\n        return dateTimeToExpr(datum);\n    }\n    return `${JSON.stringify(datum)}`;\n}\nexport function valueRefForFieldOrDatumDef(fieldDef, scaleName, opt, encode) {\n    const ref = {};\n    if (scaleName) {\n        ref.scale = scaleName;\n    }\n    if (isDatumDef(fieldDef)) {\n        const { datum } = fieldDef;\n        if (isDateTime(datum)) {\n            ref.signal = dateTimeToExpr(datum);\n        }\n        else if (isSignalRef(datum)) {\n            ref.signal = datum.signal;\n        }\n        else if (isExprRef(datum)) {\n            ref.signal = datum.expr;\n        }\n        else {\n            ref.value = datum;\n        }\n    }\n    else {\n        ref.field = vgField(fieldDef, opt);\n    }\n    if (encode) {\n        const { offset, band } = encode;\n        if (offset) {\n            ref.offset = offset;\n        }\n        if (band) {\n            ref.band = band;\n        }\n    }\n    return ref;\n}\n/**\n * Signal that returns the middle of a bin from start and end field. Should only be used with x and y.\n */\nexport function interpolatedSignalRef({ scaleName, fieldOrDatumDef, fieldOrDatumDef2, offset, startSuffix, band = 0.5 }) {\n    const expr = 0 < band && band < 1 ? 'datum' : undefined;\n    const start = vgField(fieldOrDatumDef, { expr, suffix: startSuffix });\n    const end = fieldOrDatumDef2 !== undefined\n        ? vgField(fieldOrDatumDef2, { expr })\n        : vgField(fieldOrDatumDef, { suffix: 'end', expr });\n    const ref = {};\n    if (band === 0 || band === 1) {\n        ref.scale = scaleName;\n        const val = band === 0 ? start : end;\n        ref.field = val;\n    }\n    else {\n        const datum = `${band} * ${start} + ${1 - band} * ${end}`;\n        ref.signal = `scale(\"${scaleName}\", ${datum})`;\n    }\n    if (offset) {\n        ref.offset = offset;\n    }\n    return ref;\n}\n/**\n * @returns {VgValueRef} Value Ref for xc / yc or mid point for other channels.\n */\nexport function midPoint({ channel, channelDef, channel2Def, markDef, config, scaleName, scale, stack, offset, defaultRef, band }) {\n    var _a;\n    // TODO: datum support\n    if (channelDef) {\n        /* istanbul ignore else */\n        if (isFieldOrDatumDef(channelDef)) {\n            if (isTypedFieldDef(channelDef)) {\n                band = band !== null && band !== void 0 ? band : getBand({\n                    channel,\n                    fieldDef: channelDef,\n                    fieldDef2: channel2Def,\n                    markDef,\n                    stack,\n                    config,\n                    isMidPoint: true\n                });\n                const { bin, timeUnit, type } = channelDef;\n                if (isBinning(bin) || (band && timeUnit && type === TEMPORAL)) {\n                    // Use middle only for x an y to place marks in the center between start and end of the bin range.\n                    // We do not use the mid point for other channels (e.g. size) so that properties of legends and marks match.\n                    if (stack && stack.impute) {\n                        // For stack, we computed bin_mid so we can impute.\n                        return valueRefForFieldOrDatumDef(channelDef, scaleName, { binSuffix: 'mid' }, { offset });\n                    }\n                    if (band) {\n                        // if band = 0, no need to call interpolation\n                        // For non-stack, we can just calculate bin mid on the fly using signal.\n                        return interpolatedSignalRef({ scaleName, fieldOrDatumDef: channelDef, band, offset });\n                    }\n                    return valueRefForFieldOrDatumDef(channelDef, scaleName, binRequiresRange(channelDef, channel) ? { binSuffix: 'range' } : {}, {\n                        offset\n                    });\n                }\n                else if (isBinned(bin)) {\n                    if (isFieldDef(channel2Def)) {\n                        return interpolatedSignalRef({\n                            scaleName,\n                            fieldOrDatumDef: channelDef,\n                            fieldOrDatumDef2: channel2Def,\n                            band,\n                            offset\n                        });\n                    }\n                    else {\n                        const channel2 = channel === X ? X2 : Y2;\n                        log.warn(log.message.channelRequiredForBinned(channel2));\n                    }\n                }\n            }\n            const scaleType = scale === null || scale === void 0 ? void 0 : scale.get('type');\n            return valueRefForFieldOrDatumDef(channelDef, scaleName, hasDiscreteDomain(scaleType) ? { binSuffix: 'range' } : {}, // no need for bin suffix if there is no scale\n            {\n                offset,\n                // For band, to get mid point, need to offset by half of the band\n                band: scaleType === 'band' ? (_a = band !== null && band !== void 0 ? band : channelDef.band) !== null && _a !== void 0 ? _a : 0.5 : undefined\n            });\n        }\n        else if (isValueDef(channelDef)) {\n            const value = channelDef.value;\n            const offsetMixins = offset ? { offset } : {};\n            return Object.assign(Object.assign({}, widthHeightValueOrSignalRef(channel, value)), offsetMixins);\n        }\n        // If channelDef is neither field def or value def, it's a condition-only def.\n        // In such case, we will use default ref.\n    }\n    if (isFunction(defaultRef)) {\n        defaultRef = defaultRef();\n    }\n    if (defaultRef) {\n        // for non-position, ref could be undefined.\n        return Object.assign(Object.assign({}, defaultRef), (offset ? { offset } : {}));\n    }\n    return defaultRef;\n}\n/**\n * Convert special \"width\" and \"height\" values in Vega-Lite into Vega value ref.\n */\nexport function widthHeightValueOrSignalRef(channel, value) {\n    if (contains(['x', 'x2'], channel) && value === 'width') {\n        return { field: { group: 'width' } };\n    }\n    else if (contains(['y', 'y2'], channel) && value === 'height') {\n        return { field: { group: 'height' } };\n    }\n    return signalOrValueRef(value);\n}\n//# sourceMappingURL=valueref.js.map","import { isValueDef } from '../../../channeldef';\nimport { isPathMark } from '../../../mark';\nimport { signalOrValueRef } from '../../common';\nimport { wrapCondition } from './conditional';\nexport function zindex(model) {\n    const { encoding, mark } = model;\n    const order = encoding.order;\n    if (!isPathMark(mark) && isValueDef(order)) {\n        return wrapCondition(model, order, 'zindex', cd => signalOrValueRef(cd.value));\n    }\n    return {};\n}\n//# sourceMappingURL=zindex.js.map","import { isFieldDef, vgField } from '../../channeldef';\nimport { GEOJSON } from '../../type';\nimport * as encode from './encode';\nexport const geoshape = {\n    vgMark: 'shape',\n    encodeEntry: (model) => {\n        return Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            size: 'ignore',\n            orient: 'ignore',\n            theta: 'ignore'\n        }));\n    },\n    postEncodingTransform: (model) => {\n        const { encoding } = model;\n        const shapeDef = encoding.shape;\n        const transform = Object.assign({ type: 'geoshape', projection: model.projectionName() }, (shapeDef && isFieldDef(shapeDef) && shapeDef.type === GEOJSON\n            ? { field: vgField(shapeDef, { expr: 'datum' }) }\n            : {}));\n        return [transform];\n    }\n};\n//# sourceMappingURL=geoshape.js.map","import * as encode from './encode';\nexport const image = {\n    vgMark: 'image',\n    encodeEntry: (model) => {\n        return Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'ignore',\n            orient: 'ignore',\n            size: 'ignore',\n            theta: 'ignore'\n        })), encode.rectPosition(model, 'x', 'image')), encode.rectPosition(model, 'y', 'image')), encode.text(model, 'url'));\n    }\n};\n//# sourceMappingURL=image.js.map","import { isBinned, isBinning } from '../../bin';\nimport { isContinuousFieldOrDatumDef, isFieldDef, isNumericDataDef } from '../../channeldef';\nimport { isAggregate } from '../../encoding';\nimport { replaceExprRefInIndex } from '../../expr';\nimport * as log from '../../log';\nimport { AREA, BAR, BAR_CORNER_RADIUS_INDEX as BAR_CORNER_RADIUS_END_INDEX, CIRCLE, IMAGE, LINE, POINT, RECT, RULE, SQUARE, TEXT, TICK } from '../../mark';\nimport { QUANTITATIVE, TEMPORAL } from '../../type';\nimport { contains, getFirstDefined } from '../../util';\nimport { getMarkConfig, getMarkPropOrConfig } from '../common';\nexport function initMarkdef(originalMarkDef, encoding, config) {\n    const markDef = replaceExprRefInIndex(originalMarkDef);\n    // set orient, which can be overridden by rules as sometimes the specified orient is invalid.\n    const specifiedOrient = getMarkPropOrConfig('orient', markDef, config);\n    markDef.orient = orient(markDef.type, encoding, specifiedOrient);\n    if (specifiedOrient !== undefined && specifiedOrient !== markDef.orient) {\n        log.warn(log.message.orientOverridden(markDef.orient, specifiedOrient));\n    }\n    if (markDef.type === 'bar' && markDef.orient) {\n        const cornerRadiusEnd = getMarkPropOrConfig('cornerRadiusEnd', markDef, config);\n        if (cornerRadiusEnd !== undefined) {\n            const newProps = (markDef.orient === 'horizontal' && encoding.x2) || (markDef.orient === 'vertical' && encoding.y2)\n                ? ['cornerRadius']\n                : BAR_CORNER_RADIUS_END_INDEX[markDef.orient];\n            for (const newProp of newProps) {\n                markDef[newProp] = cornerRadiusEnd;\n            }\n            if (markDef.cornerRadiusEnd !== undefined) {\n                delete markDef.cornerRadiusEnd; // no need to keep the original cap cornerRadius\n            }\n        }\n    }\n    // set opacity and filled if not specified in mark config\n    const specifiedOpacity = getMarkPropOrConfig('opacity', markDef, config);\n    if (specifiedOpacity === undefined) {\n        markDef.opacity = opacity(markDef.type, encoding);\n    }\n    // set cursor, which should be pointer if href channel is present unless otherwise specified\n    const specifiedCursor = getMarkPropOrConfig('cursor', markDef, config);\n    if (specifiedCursor === undefined) {\n        markDef.cursor = cursor(markDef, encoding, config);\n    }\n    return markDef;\n}\nfunction cursor(markDef, encoding, config) {\n    if (encoding.href || markDef.href || getMarkPropOrConfig('href', markDef, config)) {\n        return 'pointer';\n    }\n    return markDef.cursor;\n}\nfunction opacity(mark, encoding) {\n    if (contains([POINT, TICK, CIRCLE, SQUARE], mark)) {\n        // point-based marks\n        if (!isAggregate(encoding)) {\n            return 0.7;\n        }\n    }\n    return undefined;\n}\nexport function defaultFilled(markDef, config, { graticule }) {\n    if (graticule) {\n        return false;\n    }\n    const filledConfig = getMarkConfig('filled', markDef, config);\n    const mark = markDef.type;\n    return getFirstDefined(filledConfig, mark !== POINT && mark !== LINE && mark !== RULE);\n}\nfunction orient(mark, encoding, specifiedOrient) {\n    switch (mark) {\n        case POINT:\n        case CIRCLE:\n        case SQUARE:\n        case TEXT:\n        case RECT:\n        case IMAGE:\n            // orient is meaningless for these marks.\n            return undefined;\n    }\n    const { x, y, x2, y2 } = encoding;\n    switch (mark) {\n        case BAR:\n            if (isFieldDef(x) && (isBinned(x.bin) || (isFieldDef(y) && y.aggregate && !x.aggregate))) {\n                return 'vertical';\n            }\n            if (isFieldDef(y) && (isBinned(y.bin) || (isFieldDef(x) && x.aggregate && !y.aggregate))) {\n                return 'horizontal';\n            }\n            if (y2 || x2) {\n                // Ranged bar does not always have clear orientation, so we allow overriding\n                if (specifiedOrient) {\n                    return specifiedOrient;\n                }\n                // If y is range and x is non-range, non-bin Q, y is likely a prebinned field\n                if (!x2) {\n                    if ((isFieldDef(x) && x.type === QUANTITATIVE && !isBinning(x.bin)) || isNumericDataDef(x)) {\n                        return 'horizontal';\n                    }\n                }\n                // If x is range and y is non-range, non-bin Q, x is likely a prebinned field\n                if (!y2) {\n                    if ((isFieldDef(y) && y.type === QUANTITATIVE && !isBinning(y.bin)) || isNumericDataDef(y)) {\n                        return 'vertical';\n                    }\n                }\n            }\n        // falls through\n        case RULE:\n            // return undefined for line segment rule and bar with both axis ranged\n            // we have to ignore the case that the data are already binned\n            if (x2 && !(isFieldDef(x) && isBinned(x.bin)) && y2 && !(isFieldDef(y) && isBinned(y.bin))) {\n                return undefined;\n            }\n        // falls through\n        case AREA:\n            // If there are range for both x and y, y (vertical) has higher precedence.\n            if (y2) {\n                if (isFieldDef(y) && isBinned(y.bin)) {\n                    return 'horizontal';\n                }\n                else {\n                    return 'vertical';\n                }\n            }\n            else if (x2) {\n                if (isFieldDef(x) && isBinned(x.bin)) {\n                    return 'vertical';\n                }\n                else {\n                    return 'horizontal';\n                }\n            }\n            else if (mark === RULE) {\n                if (x && !y) {\n                    return 'vertical';\n                }\n                else if (y && !x) {\n                    return 'horizontal';\n                }\n            }\n        // falls through\n        case LINE:\n        case TICK: {\n            // Tick is opposite to bar, line, area and never have ranged mark.\n            const xIsContinuous = isContinuousFieldOrDatumDef(x);\n            const yIsContinuous = isContinuousFieldOrDatumDef(y);\n            if (xIsContinuous && !yIsContinuous) {\n                return mark !== 'tick' ? 'horizontal' : 'vertical';\n            }\n            else if (!xIsContinuous && yIsContinuous) {\n                return mark !== 'tick' ? 'vertical' : 'horizontal';\n            }\n            else if (xIsContinuous && yIsContinuous) {\n                const xDef = x; // we can cast here since they are surely fieldDef\n                const yDef = y;\n                const xIsTemporal = xDef.type === TEMPORAL;\n                const yIsTemporal = yDef.type === TEMPORAL;\n                // temporal without timeUnit is considered continuous, but better serves as dimension\n                if (xIsTemporal && !yIsTemporal) {\n                    return mark !== 'tick' ? 'vertical' : 'horizontal';\n                }\n                else if (!xIsTemporal && yIsTemporal) {\n                    return mark !== 'tick' ? 'horizontal' : 'vertical';\n                }\n                if (!xDef.aggregate && yDef.aggregate) {\n                    return mark !== 'tick' ? 'vertical' : 'horizontal';\n                }\n                else if (xDef.aggregate && !yDef.aggregate) {\n                    return mark !== 'tick' ? 'horizontal' : 'vertical';\n                }\n                if (specifiedOrient) {\n                    // When ambiguous, use user specified one.\n                    return specifiedOrient;\n                }\n                return 'vertical';\n            }\n            else {\n                // Discrete x Discrete case\n                if (specifiedOrient) {\n                    // When ambiguous, use user specified one.\n                    return specifiedOrient;\n                }\n                return undefined;\n            }\n        }\n    }\n    return 'vertical';\n}\n//# sourceMappingURL=init.js.map","import * as encode from './encode';\nexport const line = {\n    vgMark: 'line',\n    encodeEntry: (model) => {\n        return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            size: 'ignore',\n            orient: 'ignore',\n            theta: 'ignore'\n        })), encode.pointPosition('x', model, { defaultPos: 'mid' })), encode.pointPosition('y', model, { defaultPos: 'mid' })), encode.nonPosition('size', model, {\n            vgChannel: 'strokeWidth' // VL's line size is strokeWidth\n        })), encode.defined(model));\n    }\n};\nexport const trail = {\n    vgMark: 'trail',\n    encodeEntry: (model) => {\n        return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            size: 'include',\n            orient: 'ignore',\n            theta: 'ignore'\n        })), encode.pointPosition('x', model, { defaultPos: 'mid' })), encode.pointPosition('y', model, { defaultPos: 'mid' })), encode.nonPosition('size', model)), encode.defined(model));\n    }\n};\n//# sourceMappingURL=line.js.map","import { isArray } from 'vega-util';\nimport { isFieldDef, isValueDef, vgField } from '../../channeldef';\nimport { DataSourceType } from '../../data';\nimport { isAggregate, pathGroupingFields } from '../../encoding';\nimport { AREA, BAR, isPathMark, LINE, TRAIL } from '../../mark';\nimport { isSortByEncoding, isSortField } from '../../sort';\nimport { contains, getFirstDefined, isNullOrFalse, keys, omit, pick } from '../../util';\nimport { VG_CORNERRADIUS_CHANNELS } from '../../vega.schema';\nimport { getMarkConfig, getMarkPropOrConfig, getStyles, signalOrValueRef, sortParams } from '../common';\nimport { arc } from './arc';\nimport { area } from './area';\nimport { bar } from './bar';\nimport { geoshape } from './geoshape';\nimport { image } from './image';\nimport { line, trail } from './line';\nimport { circle, point, square } from './point';\nimport { rect } from './rect';\nimport { rule } from './rule';\nimport { text } from './text';\nimport { tick } from './tick';\nconst markCompiler = {\n    arc,\n    area,\n    bar,\n    circle,\n    geoshape,\n    image,\n    line,\n    point,\n    rect,\n    rule,\n    square,\n    text,\n    tick,\n    trail\n};\nexport function parseMarkGroups(model) {\n    if (contains([LINE, AREA, TRAIL], model.mark)) {\n        const details = pathGroupingFields(model.mark, model.encoding);\n        if (details.length > 0) {\n            return getPathGroups(model, details);\n        }\n        // otherwise use standard mark groups\n    }\n    else if (contains([BAR], model.mark)) {\n        const hasCornerRadius = VG_CORNERRADIUS_CHANNELS.some(prop => getMarkPropOrConfig(prop, model.markDef, model.config));\n        if (model.stack && !model.fieldDef('size') && hasCornerRadius) {\n            return getGroupsForStackedBarWithCornerRadius(model);\n        }\n    }\n    return getMarkGroup(model);\n}\nconst FACETED_PATH_PREFIX = 'faceted_path_';\nfunction getPathGroups(model, details) {\n    // TODO: for non-stacked plot, map order to zindex. (Maybe rename order for layer to zindex?)\n    return [\n        {\n            name: model.getName('pathgroup'),\n            type: 'group',\n            from: {\n                facet: {\n                    name: FACETED_PATH_PREFIX + model.requestDataName(DataSourceType.Main),\n                    data: model.requestDataName(DataSourceType.Main),\n                    groupby: details\n                }\n            },\n            encode: {\n                update: {\n                    width: { field: { group: 'width' } },\n                    height: { field: { group: 'height' } }\n                }\n            },\n            // With subfacet for line/area group, need to use faceted data from above.\n            marks: getMarkGroup(model, { fromPrefix: FACETED_PATH_PREFIX })\n        }\n    ];\n}\nconst STACK_GROUP_PREFIX = 'stack_group_';\n/**\n * We need to put stacked bars into groups in order to enable cornerRadius for stacks.\n * If stack is used and the model doesn't have size encoding, we put the mark into groups,\n * and apply cornerRadius properties at the group.\n */\nfunction getGroupsForStackedBarWithCornerRadius(model) {\n    // Generate the mark\n    const [mark] = getMarkGroup(model, { fromPrefix: STACK_GROUP_PREFIX });\n    // Get the scale for the stacked field\n    const fieldScale = model.scaleName(model.stack.fieldChannel);\n    const stackField = (opt = {}) => model.vgField(model.stack.fieldChannel, opt);\n    // Find the min/max of the pixel value on the stacked direction\n    const stackFieldGroup = (func, expr) => {\n        const vgFieldMinMax = [\n            stackField({ prefix: 'min', suffix: 'start', expr }),\n            stackField({ prefix: 'max', suffix: 'start', expr }),\n            stackField({ prefix: 'min', suffix: 'end', expr }),\n            stackField({ prefix: 'max', suffix: 'end', expr })\n        ];\n        return `${func}(${vgFieldMinMax.map(field => `scale('${fieldScale}',${field})`).join(',')})`;\n    };\n    let groupUpdate;\n    let innerGroupUpdate;\n    // Build the encoding for group and an inner group\n    if (model.stack.fieldChannel === 'x') {\n        // Move cornerRadius, y/yc/y2/height properties to group\n        // Group x/x2 should be the min/max of the marks within\n        groupUpdate = Object.assign(Object.assign({}, pick(mark.encode.update, ['y', 'yc', 'y2', 'height', ...VG_CORNERRADIUS_CHANNELS])), { x: { signal: stackFieldGroup('min', 'datum') }, x2: { signal: stackFieldGroup('max', 'datum') }, clip: { value: true } });\n        // Inner group should revert the x translation, and pass height through\n        innerGroupUpdate = {\n            x: { field: { group: 'x' }, mult: -1 },\n            height: { field: { group: 'height' } }\n        };\n        // The marks should use the same height as group, without y/yc/y2 properties (because it's already done by group)\n        // This is why size encoding is not supported yet\n        mark.encode.update = Object.assign(Object.assign({}, omit(mark.encode.update, ['y', 'yc', 'y2'])), { height: { field: { group: 'height' } } });\n    }\n    else {\n        groupUpdate = Object.assign(Object.assign({}, pick(mark.encode.update, ['x', 'xc', 'x2', 'width'])), { y: { signal: stackFieldGroup('min', 'datum') }, y2: { signal: stackFieldGroup('max', 'datum') }, clip: { value: true } });\n        innerGroupUpdate = {\n            y: { field: { group: 'y' }, mult: -1 },\n            width: { field: { group: 'width' } }\n        };\n        mark.encode.update = Object.assign(Object.assign({}, omit(mark.encode.update, ['x', 'xc', 'x2'])), { width: { field: { group: 'width' } } });\n    }\n    // Deal with cornerRadius properties\n    for (const key of VG_CORNERRADIUS_CHANNELS) {\n        const configValue = getMarkConfig(key, model.markDef, model.config);\n        // Move from mark to group\n        if (mark.encode.update[key]) {\n            groupUpdate[key] = mark.encode.update[key];\n            delete mark.encode.update[key];\n        }\n        else if (configValue) {\n            groupUpdate[key] = signalOrValueRef(configValue);\n        }\n        // Overwrite any cornerRadius on mark set by config --- they are already moved to the group\n        if (configValue) {\n            mark.encode.update[key] = { value: 0 };\n        }\n    }\n    // For bin and time unit, we have to add bin/timeunit -end channels.\n    const groupByField = model.fieldDef(model.stack.groupbyChannel);\n    const groupby = vgField(groupByField) ? [vgField(groupByField)] : [];\n    if ((groupByField === null || groupByField === void 0 ? void 0 : groupByField.bin) || (groupByField === null || groupByField === void 0 ? void 0 : groupByField.timeUnit)) {\n        groupby.push(vgField(groupByField, { binSuffix: 'end' }));\n    }\n    const strokeProperties = [\n        'stroke',\n        'strokeWidth',\n        'strokeJoin',\n        'strokeCap',\n        'strokeDash',\n        'strokeDashOffset',\n        'strokeMiterLimit',\n        'strokeOpacity'\n    ];\n    // Generate stroke properties for the group\n    groupUpdate = strokeProperties.reduce((encode, prop) => {\n        if (mark.encode.update[prop]) {\n            return Object.assign(Object.assign({}, encode), { [prop]: mark.encode.update[prop] });\n        }\n        else {\n            const configValue = getMarkConfig(prop, model.markDef, model.config);\n            if (configValue !== undefined) {\n                return Object.assign(Object.assign({}, encode), { [prop]: signalOrValueRef(configValue) });\n            }\n            else {\n                return encode;\n            }\n        }\n    }, groupUpdate);\n    // Apply strokeForeground and strokeOffset if stroke is used\n    if (groupUpdate.stroke) {\n        groupUpdate.strokeForeground = { value: true };\n        groupUpdate.strokeOffset = { value: 0 };\n    }\n    return [\n        {\n            type: 'group',\n            from: {\n                facet: {\n                    data: model.requestDataName(DataSourceType.Main),\n                    name: STACK_GROUP_PREFIX + model.requestDataName(DataSourceType.Main),\n                    groupby,\n                    aggregate: {\n                        fields: [\n                            stackField({ suffix: 'start' }),\n                            stackField({ suffix: 'start' }),\n                            stackField({ suffix: 'end' }),\n                            stackField({ suffix: 'end' })\n                        ],\n                        ops: ['min', 'max', 'min', 'max']\n                    }\n                }\n            },\n            encode: {\n                update: groupUpdate\n            },\n            marks: [\n                {\n                    type: 'group',\n                    encode: { update: innerGroupUpdate },\n                    marks: [mark]\n                }\n            ]\n        }\n    ];\n}\nexport function getSort(model) {\n    const { encoding, stack, mark, markDef, config } = model;\n    const order = encoding.order;\n    if ((!isArray(order) && isValueDef(order) && isNullOrFalse(order.value)) ||\n        (!order && isNullOrFalse(getMarkPropOrConfig('order', markDef, config)))) {\n        return undefined;\n    }\n    else if ((isArray(order) || isFieldDef(order)) && !stack) {\n        // Sort by the order field if it is specified and the field is not stacked. (For stacked field, order specify stack order.)\n        return sortParams(order, { expr: 'datum' });\n    }\n    else if (isPathMark(mark)) {\n        // For both line and area, we sort values based on dimension by default\n        const dimensionChannel = markDef.orient === 'horizontal' ? 'y' : 'x';\n        const dimensionChannelDef = encoding[dimensionChannel];\n        if (isFieldDef(dimensionChannelDef)) {\n            const s = dimensionChannelDef.sort;\n            if (isArray(s)) {\n                return {\n                    field: vgField(dimensionChannelDef, { prefix: dimensionChannel, suffix: 'sort_index', expr: 'datum' })\n                };\n            }\n            else if (isSortField(s)) {\n                return {\n                    field: vgField({\n                        // FIXME: this op might not already exist?\n                        // FIXME: what if dimensionChannel (x or y) contains custom domain?\n                        aggregate: isAggregate(model.encoding) ? s.op : undefined,\n                        field: s.field\n                    }, { expr: 'datum' })\n                };\n            }\n            else if (isSortByEncoding(s)) {\n                const fieldDefToSort = model.fieldDef(s.encoding);\n                return {\n                    field: vgField(fieldDefToSort, { expr: 'datum' }),\n                    order: s.order\n                };\n            }\n            else if (s === null) {\n                return undefined;\n            }\n            else {\n                return {\n                    field: vgField(dimensionChannelDef, {\n                        // For stack with imputation, we only have bin_mid\n                        binSuffix: model.stack && model.stack.impute ? 'mid' : undefined,\n                        expr: 'datum'\n                    })\n                };\n            }\n        }\n        return undefined;\n    }\n    return undefined;\n}\nfunction getMarkGroup(model, opt = { fromPrefix: '' }) {\n    const { mark, markDef, encoding, config } = model;\n    const clip = getFirstDefined(markDef.clip, scaleClip(model), projectionClip(model));\n    const style = getStyles(markDef);\n    const key = encoding.key;\n    const sort = getSort(model);\n    const interactive = interactiveFlag(model);\n    const aria = getMarkPropOrConfig('aria', markDef, config);\n    const postEncodingTransform = markCompiler[mark].postEncodingTransform\n        ? markCompiler[mark].postEncodingTransform(model)\n        : null;\n    return [\n        Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ name: model.getName('marks'), type: markCompiler[mark].vgMark }, (clip ? { clip: true } : {})), (style ? { style } : {})), (key ? { key: key.field } : {})), (sort ? { sort } : {})), (interactive ? interactive : {})), (aria === false ? { aria } : {})), { from: { data: opt.fromPrefix + model.requestDataName(DataSourceType.Main) }, encode: {\n                update: markCompiler[mark].encodeEntry(model)\n            } }), (postEncodingTransform\n            ? {\n                transform: postEncodingTransform\n            }\n            : {}))\n    ];\n}\n/**\n * If scales are bound to interval selections, we want to automatically clip\n * marks to account for panning/zooming interactions. We identify bound scales\n * by the selectionExtent property, which gets added during scale parsing.\n */\nfunction scaleClip(model) {\n    const xScale = model.getScaleComponent('x');\n    const yScale = model.getScaleComponent('y');\n    return (xScale && xScale.get('selectionExtent')) || (yScale && yScale.get('selectionExtent')) ? true : undefined;\n}\n/**\n * If we use a custom projection with auto-fitting to the geodata extent,\n * we need to clip to ensure the chart size doesn't explode.\n */\nfunction projectionClip(model) {\n    const projection = model.component.projection;\n    return projection && !projection.isFit ? true : undefined;\n}\n/**\n * Only output interactive flags if we have selections defined somewhere in our model hierarchy.\n */\nfunction interactiveFlag(model) {\n    if (!model.component.selection)\n        return null;\n    const unitCount = keys(model.component.selection).length;\n    let parentCount = unitCount;\n    let parent = model.parent;\n    while (parent && parentCount === 0) {\n        parentCount = keys(parent.component.selection).length;\n        parent = parent.parent;\n    }\n    return parentCount\n        ? {\n            interactive: unitCount > 0 || !!model.encoding.tooltip\n        }\n        : null;\n}\n//# sourceMappingURL=mark.js.map","import * as encode from './encode';\nfunction encodeEntry(model, fixedShape) {\n    const { config } = model;\n    return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n        align: 'ignore',\n        baseline: 'ignore',\n        color: 'include',\n        size: 'include',\n        orient: 'ignore',\n        theta: 'ignore'\n    })), encode.pointPosition('x', model, { defaultPos: 'mid' })), encode.pointPosition('y', model, { defaultPos: 'mid' })), encode.nonPosition('size', model)), encode.nonPosition('angle', model)), shapeMixins(model, config, fixedShape));\n}\nexport function shapeMixins(model, config, fixedShape) {\n    if (fixedShape) {\n        return { shape: { value: fixedShape } };\n    }\n    return encode.nonPosition('shape', model);\n}\nexport const point = {\n    vgMark: 'symbol',\n    encodeEntry: (model) => {\n        return encodeEntry(model);\n    }\n};\nexport const circle = {\n    vgMark: 'symbol',\n    encodeEntry: (model) => {\n        return encodeEntry(model, 'circle');\n    }\n};\nexport const square = {\n    vgMark: 'symbol',\n    encodeEntry: (model) => {\n        return encodeEntry(model, 'square');\n    }\n};\n//# sourceMappingURL=point.js.map","import * as encode from './encode';\nexport const rect = {\n    vgMark: 'rect',\n    encodeEntry: (model) => {\n        return Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            orient: 'ignore',\n            size: 'ignore',\n            theta: 'ignore'\n        })), encode.rectPosition(model, 'x', 'rect')), encode.rectPosition(model, 'y', 'rect'));\n    }\n};\n//# sourceMappingURL=rect.js.map","import * as encode from './encode';\nexport const rule = {\n    vgMark: 'rule',\n    encodeEntry: (model) => {\n        const { markDef } = model;\n        const orient = markDef.orient;\n        if (!model.encoding.x && !model.encoding.y && !model.encoding.latitude && !model.encoding.longitude) {\n            // Show nothing if we have none of x, y, lat, and long.\n            return {};\n        }\n        return Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            orient: 'ignore',\n            size: 'ignore',\n            theta: 'ignore'\n        })), encode.pointOrRangePosition('x', model, {\n            defaultPos: orient === 'horizontal' ? 'zeroOrMax' : 'mid',\n            defaultPos2: 'zeroOrMin',\n            range: orient !== 'vertical' // include x2 for horizontal or line segment rule\n        })), encode.pointOrRangePosition('y', model, {\n            defaultPos: orient === 'vertical' ? 'zeroOrMax' : 'mid',\n            defaultPos2: 'zeroOrMin',\n            range: orient !== 'horizontal' // include y2 for vertical or line segment rule\n        })), encode.nonPosition('size', model, {\n            vgChannel: 'strokeWidth' // VL's rule size is strokeWidth\n        }));\n    }\n};\n//# sourceMappingURL=rule.js.map","import { getMarkPropOrConfig } from '../common';\nimport * as encode from './encode';\nexport const text = {\n    vgMark: 'text',\n    encodeEntry: (model) => {\n        const { config, encoding } = model;\n        return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'include',\n            baseline: 'include',\n            color: 'include',\n            size: 'ignore',\n            orient: 'ignore',\n            theta: 'include'\n        })), encode.pointPosition('x', model, { defaultPos: 'mid' })), encode.pointPosition('y', model, { defaultPos: 'mid' })), encode.text(model)), encode.nonPosition('size', model, {\n            vgChannel: 'fontSize' // VL's text size is fontSize\n        })), encode.nonPosition('angle', model)), encode.valueIfDefined('align', align(model.markDef, encoding, config))), encode.valueIfDefined('baseline', baseline(model.markDef, encoding, config))), encode.pointPosition('radius', model, { defaultPos: null, isMidPoint: true })), encode.pointPosition('theta', model, { defaultPos: null, isMidPoint: true }));\n    }\n};\nfunction align(markDef, encoding, config) {\n    const a = getMarkPropOrConfig('align', markDef, config);\n    if (a === undefined) {\n        return 'center';\n    }\n    // If there is a config, Vega-parser will process this already.\n    return undefined;\n}\nfunction baseline(markDef, encoding, config) {\n    const b = getMarkPropOrConfig('baseline', markDef, config);\n    if (b === undefined) {\n        return 'middle';\n    }\n    // If there is a config, Vega-parser will process this already.\n    return undefined;\n}\n//# sourceMappingURL=text.js.map","import { isNumber } from 'vega-util';\nimport { getViewConfigDiscreteStep } from '../../config';\nimport { isVgRangeStep } from '../../vega.schema';\nimport { getMarkPropOrConfig, signalOrValueRef } from '../common';\nimport * as encode from './encode';\nexport const tick = {\n    vgMark: 'rect',\n    encodeEntry: (model) => {\n        const { config, markDef } = model;\n        const orient = markDef.orient;\n        const vgSizeChannel = orient === 'horizontal' ? 'width' : 'height';\n        const vgThicknessChannel = orient === 'horizontal' ? 'height' : 'width';\n        return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, encode.baseEncodeEntry(model, {\n            align: 'ignore',\n            baseline: 'ignore',\n            color: 'include',\n            orient: 'ignore',\n            size: 'ignore',\n            theta: 'ignore'\n        })), encode.pointPosition('x', model, { defaultPos: 'mid', vgChannel: 'xc' })), encode.pointPosition('y', model, { defaultPos: 'mid', vgChannel: 'yc' })), encode.nonPosition('size', model, {\n            defaultValue: defaultSize(model),\n            vgChannel: vgSizeChannel\n        })), { [vgThicknessChannel]: signalOrValueRef(getMarkPropOrConfig('thickness', markDef, config)) });\n    }\n};\nfunction defaultSize(model) {\n    var _a;\n    const { config, markDef } = model;\n    const { orient } = markDef;\n    const vgSizeChannel = orient === 'horizontal' ? 'width' : 'height';\n    const scale = model.getScaleComponent(orient === 'horizontal' ? 'x' : 'y');\n    const markPropOrConfig = (_a = getMarkPropOrConfig('size', markDef, config, { vgChannel: vgSizeChannel })) !== null && _a !== void 0 ? _a : config.tick.bandSize;\n    if (markPropOrConfig !== undefined) {\n        return markPropOrConfig;\n    }\n    else {\n        const scaleRange = scale ? scale.get('range') : undefined;\n        if (scaleRange && isVgRangeStep(scaleRange) && isNumber(scaleRange.step)) {\n            return (scaleRange.step * 3) / 4;\n        }\n        const defaultViewStep = getViewConfigDiscreteStep(config.view, vgSizeChannel);\n        return (defaultViewStep * 3) / 4;\n    }\n}\n//# sourceMappingURL=tick.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { FACET_CHANNELS, getPositionScaleChannel, isChannel, isScaleChannel } from '../channel';\nimport { getFieldDef, vgField } from '../channeldef';\nimport { DataSourceType } from '../data';\nimport { forEach, reduce } from '../encoding';\nimport { replaceExprRefInIndex } from '../expr';\nimport * as log from '../log';\nimport { hasDiscreteDomain } from '../scale';\nimport { isFacetSpec } from '../spec';\nimport { extractCompositionLayout } from '../spec/base';\nimport { extractTitleConfig, isText } from '../title';\nimport { normalizeTransform } from '../transform';\nimport { contains, duplicate, isEmpty, keys, varName } from '../util';\nimport { isVgRangeStep } from '../vega.schema';\nimport { assembleAxes } from './axis/assemble';\nimport { signalOrValueRef, signalRefOrValue } from './common';\nimport { assembleHeaderGroups, assembleLayoutTitleBand, assembleTitleGroup } from './header/assemble';\nimport { HEADER_CHANNELS } from './header/component';\nimport { sizeExpr } from './layoutsize/assemble';\nimport { getSizeTypeFromLayoutSizeType } from './layoutsize/component';\nimport { assembleLegends } from './legend/assemble';\nimport { parseLegend } from './legend/parse';\nimport { assembleProjections } from './projection/assemble';\nimport { parseProjection } from './projection/parse';\nimport { assembleScales } from './scale/assemble';\nimport { assembleDomain, getFieldFromDomain } from './scale/domain';\nimport { parseScales } from './scale/parse';\nimport { Split } from './split';\nexport class NameMap {\n    constructor() {\n        this.nameMap = {};\n    }\n    rename(oldName, newName) {\n        this.nameMap[oldName] = newName;\n    }\n    has(name) {\n        return this.nameMap[name] !== undefined;\n    }\n    get(name) {\n        // If the name appears in the _nameMap, we need to read its new name.\n        // We have to loop over the dict just in case the new name also gets renamed.\n        while (this.nameMap[name] && name !== this.nameMap[name]) {\n            name = this.nameMap[name];\n        }\n        return name;\n    }\n}\n/*\n  We use type guards instead of `instanceof` as `instanceof` makes\n  different parts of the compiler depend on the actual implementation of\n  the model classes, which in turn depend on different parts of the compiler.\n  Thus, `instanceof` leads to circular dependency problems.\n\n  On the other hand, type guards only make different parts of the compiler\n  depend on the type of the model classes, but not the actual implementation.\n*/\nexport function isUnitModel(model) {\n    return (model === null || model === void 0 ? void 0 : model.type) === 'unit';\n}\nexport function isFacetModel(model) {\n    return (model === null || model === void 0 ? void 0 : model.type) === 'facet';\n}\nexport function isConcatModel(model) {\n    return (model === null || model === void 0 ? void 0 : model.type) === 'concat';\n}\nexport function isLayerModel(model) {\n    return (model === null || model === void 0 ? void 0 : model.type) === 'layer';\n}\nexport class Model {\n    constructor(spec, type, parent, parentGivenName, config, resolve, view) {\n        var _a, _b;\n        this.type = type;\n        this.parent = parent;\n        this.config = config;\n        this.children = [];\n        /**\n         * Corrects the data references in marks after assemble.\n         */\n        this.correctDataNames = (mark) => {\n            // TODO: make this correct\n            // for normal data references\n            if (mark.from && mark.from.data) {\n                mark.from.data = this.lookupDataSource(mark.from.data);\n            }\n            // for access to facet data\n            if (mark.from && mark.from.facet && mark.from.facet.data) {\n                mark.from.facet.data = this.lookupDataSource(mark.from.facet.data);\n            }\n            return mark;\n        };\n        this.parent = parent;\n        this.config = config;\n        this.view = replaceExprRefInIndex(view);\n        // If name is not provided, always use parent's givenName to avoid name conflicts.\n        this.name = (_a = spec.name) !== null && _a !== void 0 ? _a : parentGivenName;\n        this.title = isText(spec.title) ? { text: spec.title } : spec.title ? this.initTitle(spec.title) : undefined;\n        // Shared name maps\n        this.scaleNameMap = parent ? parent.scaleNameMap : new NameMap();\n        this.projectionNameMap = parent ? parent.projectionNameMap : new NameMap();\n        this.signalNameMap = parent ? parent.signalNameMap : new NameMap();\n        this.data = spec.data;\n        this.description = spec.description;\n        this.transforms = normalizeTransform((_b = spec.transform) !== null && _b !== void 0 ? _b : []);\n        this.layout = type === 'layer' || type === 'unit' ? {} : extractCompositionLayout(spec, type, config);\n        this.component = {\n            data: {\n                sources: parent ? parent.component.data.sources : [],\n                outputNodes: parent ? parent.component.data.outputNodes : {},\n                outputNodeRefCounts: parent ? parent.component.data.outputNodeRefCounts : {},\n                // data is faceted if the spec is a facet spec or the parent has faceted data and data is undefined\n                isFaceted: isFacetSpec(spec) || (parent && parent.component.data.isFaceted && spec.data === undefined)\n            },\n            layoutSize: new Split(),\n            layoutHeaders: { row: {}, column: {}, facet: {} },\n            mark: null,\n            resolve: Object.assign({ scale: {}, axis: {}, legend: {} }, (resolve ? duplicate(resolve) : {})),\n            selection: null,\n            scales: null,\n            projection: null,\n            axes: {},\n            legends: {}\n        };\n    }\n    initTitle(title) {\n        const props = keys(title);\n        const titleInternal = {\n            text: signalRefOrValue(title.text)\n        };\n        for (const prop of props) {\n            titleInternal[prop] = signalRefOrValue(title[prop]);\n        }\n        return titleInternal;\n    }\n    get width() {\n        return this.getSizeSignalRef('width');\n    }\n    get height() {\n        return this.getSizeSignalRef('height');\n    }\n    parse() {\n        this.parseScale();\n        this.parseLayoutSize(); // depends on scale\n        this.renameTopLevelLayoutSizeSignal();\n        this.parseSelections();\n        this.parseProjection();\n        this.parseData(); // (pathorder) depends on markDef; selection filters depend on parsed selections; depends on projection because some transforms require the finalized projection name.\n        this.parseAxesAndHeaders(); // depends on scale and layout size\n        this.parseLegends(); // depends on scale, markDef\n        this.parseMarkGroup(); // depends on data name, scale, layout size, axisGroup, and children's scale, axis, legend and mark.\n    }\n    parseScale() {\n        parseScales(this);\n    }\n    parseProjection() {\n        parseProjection(this);\n    }\n    /**\n     * Rename top-level spec's size to be just width / height, ignoring model name.\n     * This essentially merges the top-level spec's width/height signals with the width/height signals\n     * to help us reduce redundant signals declaration.\n     */\n    renameTopLevelLayoutSizeSignal() {\n        if (this.getName('width') !== 'width') {\n            this.renameSignal(this.getName('width'), 'width');\n        }\n        if (this.getName('height') !== 'height') {\n            this.renameSignal(this.getName('height'), 'height');\n        }\n    }\n    parseLegends() {\n        parseLegend(this);\n    }\n    assembleGroupStyle() {\n        var _a, _b;\n        if (this.type === 'unit' || this.type === 'layer') {\n            return (_b = (_a = this.view) === null || _a === void 0 ? void 0 : _a.style) !== null && _b !== void 0 ? _b : 'cell';\n        }\n        return undefined;\n    }\n    assembleEncodeFromView(view) {\n        // Exclude \"style\"\n        const { style: _ } = view, baseView = __rest(view, [\"style\"]);\n        const e = {};\n        for (const property of keys(baseView)) {\n            const value = baseView[property];\n            if (value !== undefined) {\n                e[property] = signalOrValueRef(value);\n            }\n        }\n        return e;\n    }\n    assembleGroupEncodeEntry(isTopLevel) {\n        let encodeEntry = {};\n        if (this.view) {\n            encodeEntry = this.assembleEncodeFromView(this.view);\n        }\n        if (!isTopLevel) {\n            // Descriptions are already added to the top-level description so we only need to add them to the inner views.\n            if (this.description) {\n                encodeEntry['description'] = signalOrValueRef(this.description);\n            }\n            // For top-level spec, we can set the global width and height signal to adjust the group size.\n            // For other child specs, we have to manually set width and height in the encode entry.\n            if (this.type === 'unit' || this.type === 'layer') {\n                return Object.assign({ width: this.getSizeSignalRef('width'), height: this.getSizeSignalRef('height') }, (encodeEntry !== null && encodeEntry !== void 0 ? encodeEntry : {}));\n            }\n        }\n        return isEmpty(encodeEntry) ? undefined : encodeEntry;\n    }\n    assembleLayout() {\n        if (!this.layout) {\n            return undefined;\n        }\n        const _a = this.layout, { spacing } = _a, layout = __rest(_a, [\"spacing\"]);\n        const { component, config } = this;\n        const titleBand = assembleLayoutTitleBand(component.layoutHeaders, config);\n        return Object.assign(Object.assign(Object.assign({ padding: spacing }, this.assembleDefaultLayout()), layout), (titleBand ? { titleBand } : {}));\n    }\n    assembleDefaultLayout() {\n        return {};\n    }\n    assembleHeaderMarks() {\n        const { layoutHeaders } = this.component;\n        let headerMarks = [];\n        for (const channel of FACET_CHANNELS) {\n            if (layoutHeaders[channel].title) {\n                headerMarks.push(assembleTitleGroup(this, channel));\n            }\n        }\n        for (const channel of HEADER_CHANNELS) {\n            headerMarks = headerMarks.concat(assembleHeaderGroups(this, channel));\n        }\n        return headerMarks;\n    }\n    assembleAxes() {\n        return assembleAxes(this.component.axes, this.config);\n    }\n    assembleLegends() {\n        return assembleLegends(this);\n    }\n    assembleProjections() {\n        return assembleProjections(this);\n    }\n    assembleTitle() {\n        var _a, _b, _c;\n        const _d = (_a = this.title) !== null && _a !== void 0 ? _a : {}, { encoding } = _d, titleNoEncoding = __rest(_d, [\"encoding\"]);\n        const title = Object.assign(Object.assign(Object.assign({}, extractTitleConfig(this.config.title).nonMark), titleNoEncoding), (encoding ? { encode: { update: encoding } } : {}));\n        if (title.text) {\n            if (contains(['unit', 'layer'], this.type)) {\n                // Unit/Layer\n                if (contains(['middle', undefined], title.anchor)) {\n                    title.frame = (_b = title.frame) !== null && _b !== void 0 ? _b : 'group';\n                }\n            }\n            else {\n                // composition with Vega layout\n                // Set title = \"start\" by default for composition as \"middle\" does not look nice\n                // https://github.com/vega/vega/issues/960#issuecomment-471360328\n                title.anchor = (_c = title.anchor) !== null && _c !== void 0 ? _c : 'start';\n            }\n            return isEmpty(title) ? undefined : title;\n        }\n        return undefined;\n    }\n    /**\n     * Assemble the mark group for this model. We accept optional `signals` so that we can include concat top-level signals with the top-level model's local signals.\n     */\n    assembleGroup(signals = []) {\n        const group = {};\n        signals = signals.concat(this.assembleSignals());\n        if (signals.length > 0) {\n            group.signals = signals;\n        }\n        const layout = this.assembleLayout();\n        if (layout) {\n            group.layout = layout;\n        }\n        group.marks = [].concat(this.assembleHeaderMarks(), this.assembleMarks());\n        // Only include scales if this spec is top-level or if parent is facet.\n        // (Otherwise, it will be merged with upper-level's scope.)\n        const scales = !this.parent || isFacetModel(this.parent) ? assembleScales(this) : [];\n        if (scales.length > 0) {\n            group.scales = scales;\n        }\n        const axes = this.assembleAxes();\n        if (axes.length > 0) {\n            group.axes = axes;\n        }\n        const legends = this.assembleLegends();\n        if (legends.length > 0) {\n            group.legends = legends;\n        }\n        return group;\n    }\n    getName(text) {\n        return varName((this.name ? this.name + '_' : '') + text);\n    }\n    getDataName(type) {\n        return this.getName(DataSourceType[type].toLowerCase());\n    }\n    /**\n     * Request a data source name for the given data source type and mark that data source as required.\n     * This method should be called in parse, so that all used data source can be correctly instantiated in assembleData().\n     * You can lookup the correct dataset name in assemble with `lookupDataSource`.\n     */\n    requestDataName(name) {\n        const fullName = this.getDataName(name);\n        // Increase ref count. This is critical because otherwise we won't create a data source.\n        // We also increase the ref counts on OutputNode.getSource() calls.\n        const refCounts = this.component.data.outputNodeRefCounts;\n        refCounts[fullName] = (refCounts[fullName] || 0) + 1;\n        return fullName;\n    }\n    getSizeSignalRef(layoutSizeType) {\n        if (isFacetModel(this.parent)) {\n            const sizeType = getSizeTypeFromLayoutSizeType(layoutSizeType);\n            const channel = getPositionScaleChannel(sizeType);\n            const scaleComponent = this.component.scales[channel];\n            if (scaleComponent && !scaleComponent.merged) {\n                // independent scale\n                const type = scaleComponent.get('type');\n                const range = scaleComponent.get('range');\n                if (hasDiscreteDomain(type) && isVgRangeStep(range)) {\n                    const scaleName = scaleComponent.get('name');\n                    const domain = assembleDomain(this, channel);\n                    const field = getFieldFromDomain(domain);\n                    if (field) {\n                        const fieldRef = vgField({ aggregate: 'distinct', field }, { expr: 'datum' });\n                        return {\n                            signal: sizeExpr(scaleName, scaleComponent, fieldRef)\n                        };\n                    }\n                    else {\n                        log.warn(log.message.unknownField(channel));\n                        return null;\n                    }\n                }\n            }\n        }\n        return {\n            signal: this.signalNameMap.get(this.getName(layoutSizeType))\n        };\n    }\n    /**\n     * Lookup the name of the datasource for an output node. You probably want to call this in assemble.\n     */\n    lookupDataSource(name) {\n        const node = this.component.data.outputNodes[name];\n        if (!node) {\n            // Name not found in map so let's just return what we got.\n            // This can happen if we already have the correct name.\n            return name;\n        }\n        return node.getSource();\n    }\n    getSignalName(oldSignalName) {\n        return this.signalNameMap.get(oldSignalName);\n    }\n    renameSignal(oldName, newName) {\n        this.signalNameMap.rename(oldName, newName);\n    }\n    renameScale(oldName, newName) {\n        this.scaleNameMap.rename(oldName, newName);\n    }\n    renameProjection(oldName, newName) {\n        this.projectionNameMap.rename(oldName, newName);\n    }\n    /**\n     * @return scale name for a given channel after the scale has been parsed and named.\n     */\n    scaleName(originalScaleName, parse) {\n        if (parse) {\n            // During the parse phase always return a value\n            // No need to refer to rename map because a scale can't be renamed\n            // before it has the original name.\n            return this.getName(originalScaleName);\n        }\n        // If there is a scale for the channel, it should either\n        // be in the scale component or exist in the name map\n        if (\n        // If there is a scale for the channel, there should be a local scale component for it\n        (isChannel(originalScaleName) && isScaleChannel(originalScaleName) && this.component.scales[originalScaleName]) ||\n            // in the scale name map (the scale get merged by its parent)\n            this.scaleNameMap.has(this.getName(originalScaleName))) {\n            return this.scaleNameMap.get(this.getName(originalScaleName));\n        }\n        return undefined;\n    }\n    /**\n     * @return projection name after the projection has been parsed and named.\n     */\n    projectionName(parse) {\n        if (parse) {\n            // During the parse phase always return a value\n            // No need to refer to rename map because a projection can't be renamed\n            // before it has the original name.\n            return this.getName('projection');\n        }\n        if ((this.component.projection && !this.component.projection.merged) ||\n            this.projectionNameMap.has(this.getName('projection'))) {\n            return this.projectionNameMap.get(this.getName('projection'));\n        }\n        return undefined;\n    }\n    /**\n     * Traverse a model's hierarchy to get the scale component for a particular channel.\n     */\n    getScaleComponent(channel) {\n        /* istanbul ignore next: This is warning for debugging test */\n        if (!this.component.scales) {\n            throw new Error('getScaleComponent cannot be called before parseScale(). Make sure you have called parseScale or use parseUnitModelWithScale().');\n        }\n        const localScaleComponent = this.component.scales[channel];\n        if (localScaleComponent && !localScaleComponent.merged) {\n            return localScaleComponent;\n        }\n        return this.parent ? this.parent.getScaleComponent(channel) : undefined;\n    }\n    /**\n     * Traverse a model's hierarchy to get a particular selection component.\n     */\n    getSelectionComponent(variableName, origName) {\n        let sel = this.component.selection[variableName];\n        if (!sel && this.parent) {\n            sel = this.parent.getSelectionComponent(variableName, origName);\n        }\n        if (!sel) {\n            throw new Error(log.message.selectionNotFound(origName));\n        }\n        return sel;\n    }\n    /**\n     * Returns true if the model has a signalRef for an axis orient.\n     */\n    hasAxisOrientSignalRef() {\n        var _a, _b;\n        return (((_a = this.component.axes.x) === null || _a === void 0 ? void 0 : _a.some(a => a.hasOrientSignalRef())) || ((_b = this.component.axes.y) === null || _b === void 0 ? void 0 : _b.some(a => a.hasOrientSignalRef())));\n    }\n}\n/** Abstract class for UnitModel and FacetModel. Both of which can contain fieldDefs as a part of its own specification. */\nexport class ModelWithField extends Model {\n    /** Get \"field\" reference for Vega */\n    vgField(channel, opt = {}) {\n        const fieldDef = this.fieldDef(channel);\n        if (!fieldDef) {\n            return undefined;\n        }\n        return vgField(fieldDef, opt);\n    }\n    reduceFieldDef(f, init) {\n        return reduce(this.getMapping(), (acc, cd, c) => {\n            const fieldDef = getFieldDef(cd);\n            if (fieldDef) {\n                return f(acc, fieldDef, c);\n            }\n            return acc;\n        }, init);\n    }\n    forEachFieldDef(f, t) {\n        forEach(this.getMapping(), (cd, c) => {\n            const fieldDef = getFieldDef(cd);\n            if (fieldDef) {\n                f(fieldDef, c);\n            }\n        }, t);\n    }\n}\n//# sourceMappingURL=model.js.map","import { isString } from 'vega-util';\nimport { fieldFilterExpression, isSelectionPredicate } from '../predicate';\nimport { logicalExpr } from '../util';\nimport { parseSelectionPredicate } from './selection/parse';\n/**\n * Converts a predicate into an expression.\n */\n// model is only used for selection filters.\nexport function expression(model, filterOp, node) {\n    return logicalExpr(filterOp, (predicate) => {\n        if (isString(predicate)) {\n            return predicate;\n        }\n        else if (isSelectionPredicate(predicate)) {\n            return parseSelectionPredicate(model, predicate.selection, node);\n        }\n        else {\n            // Filter Object\n            return fieldFilterExpression(predicate);\n        }\n    });\n}\n//# sourceMappingURL=predicate.js.map","import { contains } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { isConcatModel, isLayerModel } from '../model';\nexport function assembleProjections(model) {\n    if (isLayerModel(model) || isConcatModel(model)) {\n        return assembleProjectionsForModelAndChildren(model);\n    }\n    else {\n        return assembleProjectionForModel(model);\n    }\n}\nexport function assembleProjectionsForModelAndChildren(model) {\n    return model.children.reduce((projections, child) => {\n        return projections.concat(child.assembleProjections());\n    }, assembleProjectionForModel(model));\n}\nexport function assembleProjectionForModel(model) {\n    const component = model.component.projection;\n    if (!component || component.merged) {\n        return [];\n    }\n    const projection = component.combine();\n    const { name } = projection; // we need to extract name so that it is always present in the output and pass TS type validation\n    if (!component.data) {\n        // generate custom projection, no automatic fitting\n        return [\n            Object.assign(Object.assign({ name }, { translate: { signal: '[width / 2, height / 2]' } }), projection)\n        ];\n    }\n    else {\n        // generate projection that uses extent fitting\n        const size = {\n            signal: `[${component.size.map(ref => ref.signal).join(', ')}]`\n        };\n        const fits = component.data.reduce((sources, data) => {\n            const source = isSignalRef(data) ? data.signal : `data('${model.lookupDataSource(data)}')`;\n            if (!contains(sources, source)) {\n                // build a unique list of sources\n                sources.push(source);\n            }\n            return sources;\n        }, []);\n        if (fits.length <= 0) {\n            throw new Error(\"Projection's fit didn't find any data sources\");\n        }\n        return [\n            Object.assign({ name,\n                size, fit: {\n                    signal: fits.length > 1 ? `[${fits.join(', ')}]` : fits[0]\n                } }, projection)\n        ];\n    }\n}\n//# sourceMappingURL=assemble.js.map","import { Split } from '../split';\nexport class ProjectionComponent extends Split {\n    constructor(name, specifiedProjection, size, data) {\n        super(Object.assign({}, specifiedProjection), // all explicit properties of projection\n        { name } // name as initial implicit property\n        );\n        this.specifiedProjection = specifiedProjection;\n        this.size = size;\n        this.data = data;\n        this.merged = false;\n    }\n    /**\n     * Whether the projection parameters should fit provided data.\n     */\n    get isFit() {\n        return !!this.data;\n    }\n}\n//# sourceMappingURL=component.js.map","import { hasOwnProperty } from 'vega-util';\nimport { LATITUDE, LATITUDE2, LONGITUDE, LONGITUDE2, SHAPE } from '../../channel';\nimport { getFieldOrDatumDef } from '../../channeldef';\nimport { DataSourceType } from '../../data';\nimport { PROJECTION_PROPERTIES } from '../../projection';\nimport { GEOJSON } from '../../type';\nimport { duplicate, every, stringify } from '../../util';\nimport { isUnitModel } from '../model';\nimport { ProjectionComponent } from './component';\nexport function parseProjection(model) {\n    model.component.projection = isUnitModel(model) ? parseUnitProjection(model) : parseNonUnitProjections(model);\n}\nfunction parseUnitProjection(model) {\n    var _a;\n    if (model.hasProjection) {\n        const proj = model.specifiedProjection;\n        const fit = !(proj && (proj.scale != null || proj.translate != null));\n        const size = fit ? [model.getSizeSignalRef('width'), model.getSizeSignalRef('height')] : undefined;\n        const data = fit ? gatherFitData(model) : undefined;\n        return new ProjectionComponent(model.projectionName(true), Object.assign(Object.assign({}, ((_a = model.config.projection) !== null && _a !== void 0 ? _a : {})), (proj !== null && proj !== void 0 ? proj : {})), size, data);\n    }\n    return undefined;\n}\nfunction gatherFitData(model) {\n    const data = [];\n    const { encoding } = model;\n    for (const posssiblePair of [\n        [LONGITUDE, LATITUDE],\n        [LONGITUDE2, LATITUDE2]\n    ]) {\n        if (getFieldOrDatumDef(encoding[posssiblePair[0]]) || getFieldOrDatumDef(encoding[posssiblePair[1]])) {\n            data.push({\n                signal: model.getName(`geojson_${data.length}`)\n            });\n        }\n    }\n    if (model.channelHasField(SHAPE) && model.typedFieldDef(SHAPE).type === GEOJSON) {\n        data.push({\n            signal: model.getName(`geojson_${data.length}`)\n        });\n    }\n    if (data.length === 0) {\n        // main source is geojson, so we can just use that\n        data.push(model.requestDataName(DataSourceType.Main));\n    }\n    return data;\n}\nfunction mergeIfNoConflict(first, second) {\n    const allPropertiesShared = every(PROJECTION_PROPERTIES, prop => {\n        // neither has the property\n        if (!hasOwnProperty(first.explicit, prop) && !hasOwnProperty(second.explicit, prop)) {\n            return true;\n        }\n        // both have property and an equal value for property\n        if (hasOwnProperty(first.explicit, prop) &&\n            hasOwnProperty(second.explicit, prop) &&\n            // some properties might be signals or objects and require hashing for comparison\n            stringify(first.get(prop)) === stringify(second.get(prop))) {\n            return true;\n        }\n        return false;\n    });\n    const size = stringify(first.size) === stringify(second.size);\n    if (size) {\n        if (allPropertiesShared) {\n            return first;\n        }\n        else if (stringify(first.explicit) === stringify({})) {\n            return second;\n        }\n        else if (stringify(second.explicit) === stringify({})) {\n            return first;\n        }\n    }\n    // if all properties don't match, let each unit spec have its own projection\n    return null;\n}\nfunction parseNonUnitProjections(model) {\n    if (model.children.length === 0) {\n        return undefined;\n    }\n    let nonUnitProjection;\n    // parse all children first\n    for (const child of model.children) {\n        parseProjection(child);\n    }\n    // analyze parsed projections, attempt to merge\n    const mergable = every(model.children, child => {\n        const projection = child.component.projection;\n        if (!projection) {\n            // child layer does not use a projection\n            return true;\n        }\n        else if (!nonUnitProjection) {\n            // cached 'projection' is null, cache this one\n            nonUnitProjection = projection;\n            return true;\n        }\n        else {\n            const merge = mergeIfNoConflict(nonUnitProjection, projection);\n            if (merge) {\n                nonUnitProjection = merge;\n            }\n            return !!merge;\n        }\n    });\n    // if cached one and all other children share the same projection,\n    if (nonUnitProjection && mergable) {\n        // so we can elevate it to the layer level\n        const name = model.projectionName(true);\n        const modelProjection = new ProjectionComponent(name, nonUnitProjection.specifiedProjection, nonUnitProjection.size, duplicate(nonUnitProjection.data));\n        // rename and assign all others as merged\n        for (const child of model.children) {\n            const projection = child.component.projection;\n            if (projection) {\n                if (projection.isFit) {\n                    modelProjection.data.push(...child.component.projection.data);\n                }\n                child.renameProjection(projection.get('name'), name);\n                projection.merged = true;\n            }\n        }\n        return modelProjection;\n    }\n    return undefined;\n}\n//# sourceMappingURL=parse.js.map","import { isXorY } from '../channel';\nimport * as log from '../log';\nimport { isConcatModel, isFacetModel, isLayerModel } from './model';\nexport function defaultScaleResolve(channel, model) {\n    if (isLayerModel(model) || isFacetModel(model)) {\n        return 'shared';\n    }\n    else if (isConcatModel(model)) {\n        return isXorY(channel) ? 'independent' : 'shared';\n    }\n    /* istanbul ignore next: should never reach here. */\n    throw new Error('invalid model type for resolve');\n}\nexport function parseGuideResolve(resolve, channel) {\n    const channelScaleResolve = resolve.scale[channel];\n    const guide = isXorY(channel) ? 'axis' : 'legend';\n    if (channelScaleResolve === 'independent') {\n        if (resolve[guide][channel] === 'shared') {\n            log.warn(log.message.independentScaleMeansIndependentGuide(channel));\n        }\n        return 'independent';\n    }\n    return resolve[guide][channel] || 'shared';\n}\n//# sourceMappingURL=resolve.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isObject } from 'vega-util';\nimport { isXorY } from '../../channel';\nimport { keys } from '../../util';\nimport { isDataRefDomain, isVgRangeStep } from '../../vega.schema';\nimport { isConcatModel, isLayerModel } from '../model';\nimport { assembleSelectionScaleDomain } from '../selection/assemble';\nimport { assembleDomain } from './domain';\nexport function assembleScales(model) {\n    if (isLayerModel(model) || isConcatModel(model)) {\n        // For concat and layer, include scales of children too\n        return model.children.reduce((scales, child) => {\n            return scales.concat(assembleScales(child));\n        }, assembleScalesForModel(model));\n    }\n    else {\n        // For facet, child scales would not be included in the parent's scope.\n        // For unit, there is no child.\n        return assembleScalesForModel(model);\n    }\n}\nexport function assembleScalesForModel(model) {\n    return keys(model.component.scales).reduce((scales, channel) => {\n        const scaleComponent = model.component.scales[channel];\n        if (scaleComponent.merged) {\n            // Skipped merged scales\n            return scales;\n        }\n        const scale = scaleComponent.combine();\n        const { name, type, selectionExtent, domains: _d, range: _r, reverse } = scale, otherScaleProps = __rest(scale, [\"name\", \"type\", \"selectionExtent\", \"domains\", \"range\", \"reverse\"]);\n        const range = assembleScaleRange(scale.range, name, channel, model);\n        let domainRaw;\n        if (selectionExtent) {\n            domainRaw = assembleSelectionScaleDomain(model, selectionExtent);\n        }\n        const domain = assembleDomain(model, channel);\n        scales.push(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({ name,\n            type }, (domain ? { domain } : {})), (domainRaw ? { domainRaw } : {})), { range }), (reverse !== undefined ? { reverse: reverse } : {})), otherScaleProps));\n        return scales;\n    }, []);\n}\nexport function assembleScaleRange(scaleRange, scaleName, channel, model) {\n    // add signals to x/y range\n    if (isXorY(channel)) {\n        if (isVgRangeStep(scaleRange)) {\n            // For width/height step, use a signal created in layout assemble instead of a constant step.\n            return {\n                step: { signal: scaleName + '_step' }\n            };\n        }\n    }\n    else if (isObject(scaleRange) && isDataRefDomain(scaleRange)) {\n        return Object.assign(Object.assign({}, scaleRange), { data: model.lookupDataSource(scaleRange.data) });\n    }\n    return scaleRange;\n}\n//# sourceMappingURL=assemble.js.map","import { isArray } from 'vega-util';\nimport { some } from '../../util';\nimport { Split } from '../split';\nexport class ScaleComponent extends Split {\n    constructor(name, typeWithExplicit) {\n        super({}, // no initial explicit property\n        { name } // name as initial implicit property\n        );\n        this.merged = false;\n        this.setWithExplicit('type', typeWithExplicit);\n    }\n    /**\n     * Whether the scale definitely includes zero in the domain\n     */\n    domainDefinitelyIncludesZero() {\n        if (this.get('zero') !== false) {\n            return true;\n        }\n        return some(this.get('domains'), d => isArray(d) && d.length === 2 && d[0] <= 0 && d[1] >= 0);\n    }\n}\n//# sourceMappingURL=component.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isObject, isString } from 'vega-util';\nimport { isAggregateOp, isArgmaxDef, isArgminDef, MULTIDOMAIN_SORT_OP_INDEX as UNIONDOMAIN_SORT_OP_INDEX, SHARED_DOMAIN_OP_INDEX } from '../../aggregate';\nimport { isBinning, isBinParams, isSelectionExtent } from '../../bin';\nimport { getSecondaryRangeChannel, isScaleChannel } from '../../channel';\nimport { binRequiresRange, getFieldOrDatumDef, hasBand, isDatumDef, isFieldDef, valueExpr, vgField } from '../../channeldef';\nimport { DataSourceType } from '../../data';\nimport * as log from '../../log';\nimport { hasDiscreteDomain, isDomainUnionWith, isSelectionDomain } from '../../scale';\nimport { DEFAULT_SORT_OP, isSortArray, isSortByEncoding, isSortField } from '../../sort';\nimport { normalizeTimeUnit } from '../../timeunit';\nimport * as util from '../../util';\nimport { isDataRefDomain, isDataRefUnionedDomain, isFieldRefUnionDomain, isSignalRef } from '../../vega.schema';\nimport { getBinSignalName } from '../data/bin';\nimport { sortArrayIndexField } from '../data/calculate';\nimport { FACET_SCALE_PREFIX } from '../data/optimize';\nimport { isFacetModel, isUnitModel } from '../model';\nimport { SignalRefWrapper } from '../signal';\nimport { makeExplicit, makeImplicit, mergeValuesWithExplicit } from '../split';\nexport function parseScaleDomain(model) {\n    if (isUnitModel(model)) {\n        parseUnitScaleDomain(model);\n    }\n    else {\n        parseNonUnitScaleDomain(model);\n    }\n}\nfunction parseUnitScaleDomain(model) {\n    const localScaleComponents = model.component.scales;\n    for (const channel of util.keys(localScaleComponents)) {\n        const domains = parseDomainForChannel(model, channel);\n        const localScaleCmpt = localScaleComponents[channel];\n        localScaleCmpt.setWithExplicit('domains', domains);\n        parseSelectionDomain(model, channel);\n        if (model.component.data.isFaceted) {\n            // get resolve from closest facet parent as this decides whether we need to refer to cloned subtree or not\n            let facetParent = model;\n            while (!isFacetModel(facetParent) && facetParent.parent) {\n                facetParent = facetParent.parent;\n            }\n            const resolve = facetParent.component.resolve.scale[channel];\n            if (resolve === 'shared') {\n                for (const domain of domains.value) {\n                    // Replace the scale domain with data output from a cloned subtree after the facet.\n                    if (isDataRefDomain(domain)) {\n                        // use data from cloned subtree (which is the same as data but with a prefix added once)\n                        domain.data = FACET_SCALE_PREFIX + domain.data.replace(FACET_SCALE_PREFIX, '');\n                    }\n                }\n            }\n        }\n    }\n}\nfunction parseNonUnitScaleDomain(model) {\n    for (const child of model.children) {\n        parseScaleDomain(child);\n    }\n    const localScaleComponents = model.component.scales;\n    for (const channel of util.keys(localScaleComponents)) {\n        let domains;\n        let selectionExtent = null;\n        for (const child of model.children) {\n            const childComponent = child.component.scales[channel];\n            if (childComponent) {\n                if (domains === undefined) {\n                    domains = childComponent.getWithExplicit('domains');\n                }\n                else {\n                    domains = mergeValuesWithExplicit(domains, childComponent.getWithExplicit('domains'), 'domains', 'scale', domainsTieBreaker);\n                }\n                const se = childComponent.get('selectionExtent');\n                if (selectionExtent && se && selectionExtent.selection !== se.selection) {\n                    log.warn(log.message.NEEDS_SAME_SELECTION);\n                }\n                selectionExtent = se;\n            }\n        }\n        localScaleComponents[channel].setWithExplicit('domains', domains);\n        if (selectionExtent) {\n            localScaleComponents[channel].set('selectionExtent', selectionExtent, true);\n        }\n    }\n}\n/**\n * Remove unaggregated domain if it is not applicable\n * Add unaggregated domain if domain is not specified and config.scale.useUnaggregatedDomain is true.\n */\nfunction normalizeUnaggregatedDomain(domain, fieldDef, scaleType, scaleConfig) {\n    if (domain === 'unaggregated') {\n        const { valid, reason } = canUseUnaggregatedDomain(fieldDef, scaleType);\n        if (!valid) {\n            log.warn(reason);\n            return undefined;\n        }\n    }\n    else if (domain === undefined && scaleConfig.useUnaggregatedDomain) {\n        // Apply config if domain is not specified.\n        const { valid } = canUseUnaggregatedDomain(fieldDef, scaleType);\n        if (valid) {\n            return 'unaggregated';\n        }\n    }\n    return domain;\n}\nexport function parseDomainForChannel(model, channel) {\n    const scaleType = model.getScaleComponent(channel).get('type');\n    const { encoding } = model;\n    const domain = normalizeUnaggregatedDomain(model.scaleDomain(channel), model.typedFieldDef(channel), scaleType, model.config.scale);\n    if (domain !== model.scaleDomain(channel)) {\n        model.specifiedScales[channel] = Object.assign(Object.assign({}, model.specifiedScales[channel]), { domain });\n    }\n    // If channel is either X or Y then union them with X2 & Y2 if they exist\n    if (channel === 'x' && getFieldOrDatumDef(encoding.x2)) {\n        if (getFieldOrDatumDef(encoding.x)) {\n            return mergeValuesWithExplicit(parseSingleChannelDomain(scaleType, domain, model, 'x'), parseSingleChannelDomain(scaleType, domain, model, 'x2'), 'domain', 'scale', domainsTieBreaker);\n        }\n        else {\n            return parseSingleChannelDomain(scaleType, domain, model, 'x2');\n        }\n    }\n    else if (channel === 'y' && getFieldOrDatumDef(encoding.y2)) {\n        if (getFieldOrDatumDef(encoding.y)) {\n            return mergeValuesWithExplicit(parseSingleChannelDomain(scaleType, domain, model, 'y'), parseSingleChannelDomain(scaleType, domain, model, 'y2'), 'domain', 'scale', domainsTieBreaker);\n        }\n        else {\n            return parseSingleChannelDomain(scaleType, domain, model, 'y2');\n        }\n    }\n    return parseSingleChannelDomain(scaleType, domain, model, channel);\n}\nfunction mapDomainToDataSignal(domain, type, timeUnit) {\n    return domain.map(v => {\n        const data = valueExpr(v, { timeUnit, type });\n        return { signal: `{data: ${data}}` };\n    });\n}\nfunction convertDomainIfItIsDateTime(domain, type, timeUnit) {\n    var _a;\n    // explicit value\n    const normalizedTimeUnit = (_a = normalizeTimeUnit(timeUnit)) === null || _a === void 0 ? void 0 : _a.unit;\n    if (type === 'temporal' || normalizedTimeUnit) {\n        return mapDomainToDataSignal(domain, type, normalizedTimeUnit);\n    }\n    return [domain]; // Date time won't make sense\n}\nfunction parseSingleChannelDomain(scaleType, domain, model, channel) {\n    const { encoding } = model;\n    const fieldOrDatumDef = getFieldOrDatumDef(encoding[channel]);\n    const { type } = fieldOrDatumDef;\n    const timeUnit = fieldOrDatumDef['timeUnit'];\n    if (isDomainUnionWith(domain)) {\n        const defaultDomain = parseSingleChannelDomain(scaleType, undefined, model, channel);\n        const unionWith = convertDomainIfItIsDateTime(domain.unionWith, type, timeUnit);\n        return makeExplicit([...defaultDomain.value, ...unionWith]);\n    }\n    else if (isSignalRef(domain)) {\n        return makeExplicit([domain]);\n    }\n    else if (domain && domain !== 'unaggregated' && !isSelectionDomain(domain)) {\n        return makeExplicit(convertDomainIfItIsDateTime(domain, type, timeUnit));\n    }\n    const stack = model.stack;\n    if (stack && channel === stack.fieldChannel) {\n        if (stack.offset === 'normalize') {\n            return makeImplicit([[0, 1]]);\n        }\n        const data = model.requestDataName(DataSourceType.Main);\n        return makeImplicit([\n            {\n                data,\n                field: model.vgField(channel, { suffix: 'start' })\n            },\n            {\n                data,\n                field: model.vgField(channel, { suffix: 'end' })\n            }\n        ]);\n    }\n    const sort = isScaleChannel(channel) && isFieldDef(fieldOrDatumDef) ? domainSort(model, channel, scaleType) : undefined;\n    if (isDatumDef(fieldOrDatumDef)) {\n        const d = convertDomainIfItIsDateTime([fieldOrDatumDef.datum], type, timeUnit);\n        return makeImplicit(d);\n    }\n    const fieldDef = fieldOrDatumDef; // now we can be sure it's a fieldDef\n    if (domain === 'unaggregated') {\n        const data = model.requestDataName(DataSourceType.Main);\n        const { field } = fieldOrDatumDef;\n        return makeImplicit([\n            {\n                data,\n                field: vgField({ field, aggregate: 'min' })\n            },\n            {\n                data,\n                field: vgField({ field, aggregate: 'max' })\n            }\n        ]);\n    }\n    else if (isBinning(fieldDef.bin)) {\n        if (hasDiscreteDomain(scaleType)) {\n            if (scaleType === 'bin-ordinal') {\n                // we can omit the domain as it is inferred from the `bins` property\n                return makeImplicit([]);\n            }\n            // ordinal bin scale takes domain from bin_range, ordered by bin start\n            // This is useful for both axis-based scale (x/y) and legend-based scale (other channels).\n            return makeImplicit([\n                {\n                    // If sort by aggregation of a specified sort field, we need to use RAW table,\n                    // so we can aggregate values for the scale independently from the main aggregation.\n                    data: util.isBoolean(sort)\n                        ? model.requestDataName(DataSourceType.Main)\n                        : model.requestDataName(DataSourceType.Raw),\n                    // Use range if we added it and the scale does not support computing a range as a signal.\n                    field: model.vgField(channel, binRequiresRange(fieldDef, channel) ? { binSuffix: 'range' } : {}),\n                    // we have to use a sort object if sort = true to make the sort correct by bin start\n                    sort: sort === true || !isObject(sort)\n                        ? {\n                            field: model.vgField(channel, {}),\n                            op: 'min' // min or max doesn't matter since we sort by the start of the bin range\n                        }\n                        : sort\n                }\n            ]);\n        }\n        else {\n            // continuous scales\n            const { bin } = fieldDef;\n            if (isBinning(bin)) {\n                const binSignal = getBinSignalName(model, fieldDef.field, bin);\n                return makeImplicit([\n                    new SignalRefWrapper(() => {\n                        const signal = model.getSignalName(binSignal);\n                        return `[${signal}.start, ${signal}.stop]`;\n                    })\n                ]);\n            }\n            else {\n                return makeImplicit([\n                    {\n                        data: model.requestDataName(DataSourceType.Main),\n                        field: model.vgField(channel, {})\n                    }\n                ]);\n            }\n        }\n    }\n    else if (fieldDef.timeUnit &&\n        util.contains(['time', 'utc'], scaleType) &&\n        hasBand(channel, fieldDef, isUnitModel(model) ? model.encoding[getSecondaryRangeChannel(channel)] : undefined, model.stack, model.markDef, model.config)) {\n        const data = model.requestDataName(DataSourceType.Main);\n        return makeImplicit([\n            {\n                data,\n                field: model.vgField(channel)\n            },\n            {\n                data,\n                field: model.vgField(channel, { suffix: 'end' })\n            }\n        ]);\n    }\n    else if (sort) {\n        return makeImplicit([\n            {\n                // If sort by aggregation of a specified sort field, we need to use RAW table,\n                // so we can aggregate values for the scale independently from the main aggregation.\n                data: util.isBoolean(sort)\n                    ? model.requestDataName(DataSourceType.Main)\n                    : model.requestDataName(DataSourceType.Raw),\n                field: model.vgField(channel),\n                sort: sort\n            }\n        ]);\n    }\n    else {\n        return makeImplicit([\n            {\n                data: model.requestDataName(DataSourceType.Main),\n                field: model.vgField(channel)\n            }\n        ]);\n    }\n}\nfunction normalizeSortField(sort, isStackedMeasure) {\n    const { op, field, order } = sort;\n    return Object.assign(Object.assign({ \n        // Apply default op\n        op: op !== null && op !== void 0 ? op : (isStackedMeasure ? 'sum' : DEFAULT_SORT_OP) }, (field ? { field: util.replacePathInField(field) } : {})), (order ? { order } : {}));\n}\nfunction parseSelectionDomain(model, channel) {\n    var _a;\n    const scale = model.component.scales[channel];\n    const spec = model.specifiedScales[channel].domain;\n    const bin = (_a = model.fieldDef(channel)) === null || _a === void 0 ? void 0 : _a.bin;\n    const domain = isSelectionDomain(spec) && spec;\n    const extent = isBinParams(bin) && isSelectionExtent(bin.extent) && bin.extent;\n    if (domain || extent) {\n        // As scale parsing occurs before selection parsing, we cannot set\n        // domainRaw directly. So instead, we store the selectionExtent on\n        // the scale component, and then add domainRaw during scale assembly.\n        scale.set('selectionExtent', domain !== null && domain !== void 0 ? domain : extent, true);\n    }\n}\nexport function domainSort(model, channel, scaleType) {\n    if (!hasDiscreteDomain(scaleType)) {\n        return undefined;\n    }\n    // save to cast as the only exception is the geojson type for shape, which would not generate a scale\n    const fieldDef = model.fieldDef(channel);\n    const sort = fieldDef.sort;\n    // if the sort is specified with array, use the derived sort index field\n    if (isSortArray(sort)) {\n        return {\n            op: 'min',\n            field: sortArrayIndexField(fieldDef, channel),\n            order: 'ascending'\n        };\n    }\n    const { stack } = model;\n    const stackDimensions = stack\n        ? [...(stack.groupbyField ? [stack.groupbyField] : []), ...stack.stackBy.map(s => s.fieldDef.field)]\n        : undefined;\n    // Sorted based on an aggregate calculation over a specified sort field (only for ordinal scale)\n    if (isSortField(sort)) {\n        const isStackedMeasure = stack && !util.contains(stackDimensions, sort.field);\n        return normalizeSortField(sort, isStackedMeasure);\n    }\n    else if (isSortByEncoding(sort)) {\n        const { encoding, order } = sort;\n        const fieldDefToSortBy = model.fieldDef(encoding);\n        const { aggregate, field } = fieldDefToSortBy;\n        const isStackedMeasure = stack && !util.contains(stackDimensions, field);\n        if (isArgminDef(aggregate) || isArgmaxDef(aggregate)) {\n            return normalizeSortField({\n                field: vgField(fieldDefToSortBy),\n                order\n            }, isStackedMeasure);\n        }\n        else if (isAggregateOp(aggregate) || !aggregate) {\n            return normalizeSortField({\n                op: aggregate,\n                field,\n                order\n            }, isStackedMeasure);\n        }\n    }\n    else if (sort === 'descending') {\n        return {\n            op: 'min',\n            field: model.vgField(channel),\n            order: 'descending'\n        };\n    }\n    else if (util.contains(['ascending', undefined /* default =ascending*/], sort)) {\n        return true;\n    }\n    // sort == null\n    return undefined;\n}\n/**\n * Determine if a scale can use unaggregated domain.\n * @return {Boolean} Returns true if all of the following conditions apply:\n * 1. `scale.domain` is `unaggregated`\n * 2. Aggregation function is not `count` or `sum`\n * 3. The scale is quantitative or time scale.\n */\nexport function canUseUnaggregatedDomain(fieldDef, scaleType) {\n    const { aggregate, type } = fieldDef;\n    if (!aggregate) {\n        return {\n            valid: false,\n            reason: log.message.unaggregateDomainHasNoEffectForRawField(fieldDef)\n        };\n    }\n    if (isString(aggregate) && !SHARED_DOMAIN_OP_INDEX[aggregate]) {\n        return {\n            valid: false,\n            reason: log.message.unaggregateDomainWithNonSharedDomainOp(aggregate)\n        };\n    }\n    if (type === 'quantitative') {\n        if (scaleType === 'log') {\n            return {\n                valid: false,\n                reason: log.message.unaggregatedDomainWithLogScale(fieldDef)\n            };\n        }\n    }\n    return { valid: true };\n}\n/**\n * Tie breaker for mergeValuesWithExplicit for domains. We concat the specified values.\n */\nfunction domainsTieBreaker(v1, v2, property, propertyOf) {\n    if (v1.explicit && v2.explicit) {\n        log.warn(log.message.mergeConflictingDomainProperty(property, propertyOf, v1.value, v2.value));\n    }\n    // If equal score, concat the domains so that we union them later.\n    return { explicit: v1.explicit, value: [...v1.value, ...v2.value] };\n}\n/**\n * Converts an array of domains to a single Vega scale domain.\n */\nexport function mergeDomains(domains) {\n    const uniqueDomains = util.unique(domains.map(domain => {\n        // ignore sort property when computing the unique domains\n        if (isDataRefDomain(domain)) {\n            const { sort: _s } = domain, domainWithoutSort = __rest(domain, [\"sort\"]);\n            return domainWithoutSort;\n        }\n        return domain;\n    }), util.hash);\n    const sorts = util.unique(domains\n        .map(d => {\n        if (isDataRefDomain(d)) {\n            const s = d.sort;\n            if (s !== undefined && !util.isBoolean(s)) {\n                if ('op' in s && s.op === 'count') {\n                    // let's make sure that if op is count, we don't use a field\n                    delete s.field;\n                }\n                if (s.order === 'ascending') {\n                    // drop order: ascending as it is the default\n                    delete s.order;\n                }\n            }\n            return s;\n        }\n        return undefined;\n    })\n        .filter(s => s !== undefined), util.hash);\n    if (uniqueDomains.length === 0) {\n        return undefined;\n    }\n    else if (uniqueDomains.length === 1) {\n        const domain = domains[0];\n        if (isDataRefDomain(domain) && sorts.length > 0) {\n            let sort = sorts[0];\n            if (sorts.length > 1) {\n                log.warn(log.message.MORE_THAN_ONE_SORT);\n                sort = true;\n            }\n            else {\n                // Simplify domain sort by removing field and op when the field is the same as the domain field.\n                if (isObject(sort) && 'field' in sort) {\n                    const sortField = sort.field;\n                    if (domain.field === sortField) {\n                        sort = sort.order ? { order: sort.order } : true;\n                    }\n                }\n            }\n            return Object.assign(Object.assign({}, domain), { sort });\n        }\n        return domain;\n    }\n    // only keep sort properties that work with unioned domains\n    const unionDomainSorts = util.unique(sorts.map(s => {\n        if (util.isBoolean(s) || !('op' in s) || (isString(s.op) && s.op in UNIONDOMAIN_SORT_OP_INDEX)) {\n            return s;\n        }\n        log.warn(log.message.domainSortDropped(s));\n        return true;\n    }), util.hash);\n    let sort;\n    if (unionDomainSorts.length === 1) {\n        sort = unionDomainSorts[0];\n    }\n    else if (unionDomainSorts.length > 1) {\n        log.warn(log.message.MORE_THAN_ONE_SORT);\n        sort = true;\n    }\n    const allData = util.unique(domains.map(d => {\n        if (isDataRefDomain(d)) {\n            return d.data;\n        }\n        return null;\n    }), x => x);\n    if (allData.length === 1 && allData[0] !== null) {\n        // create a union domain of different fields with a single data source\n        const domain = Object.assign({ data: allData[0], fields: uniqueDomains.map(d => d.field) }, (sort ? { sort } : {}));\n        return domain;\n    }\n    return Object.assign({ fields: uniqueDomains }, (sort ? { sort } : {}));\n}\n/**\n * Return a field if a scale uses a single field.\n * Return `undefined` otherwise.\n */\nexport function getFieldFromDomain(domain) {\n    if (isDataRefDomain(domain) && isString(domain.field)) {\n        return domain.field;\n    }\n    else if (isDataRefUnionedDomain(domain)) {\n        let field;\n        for (const nonUnionDomain of domain.fields) {\n            if (isDataRefDomain(nonUnionDomain) && isString(nonUnionDomain.field)) {\n                if (!field) {\n                    field = nonUnionDomain.field;\n                }\n                else if (field !== nonUnionDomain.field) {\n                    log.warn(log.message.FACETED_INDEPENDENT_DIFFERENT_SOURCES);\n                    return field;\n                }\n            }\n        }\n        log.warn(log.message.FACETED_INDEPENDENT_SAME_FIELDS_DIFFERENT_SOURCES);\n        return field;\n    }\n    else if (isFieldRefUnionDomain(domain)) {\n        log.warn(log.message.FACETED_INDEPENDENT_SAME_SOURCE);\n        const field = domain.fields[0];\n        return isString(field) ? field : undefined;\n    }\n    return undefined;\n}\nexport function assembleDomain(model, channel) {\n    const scaleComponent = model.component.scales[channel];\n    const domains = scaleComponent.get('domains').map((domain) => {\n        // Correct references to data as the original domain's data was determined\n        // in parseScale, which happens before parseData. Thus the original data\n        // reference can be incorrect.\n        if (isDataRefDomain(domain)) {\n            domain.data = model.lookupDataSource(domain.data);\n        }\n        return domain;\n    });\n    // domains is an array that has to be merged into a single vega domain\n    return mergeDomains(domains);\n}\n//# sourceMappingURL=domain.js.map","import { SCALE_CHANNELS, SHAPE } from '../../channel';\nimport { getFieldOrDatumDef } from '../../channeldef';\nimport { GEOSHAPE } from '../../mark';\nimport { NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTIES, scaleCompatible, scaleTypePrecedence } from '../../scale';\nimport { GEOJSON } from '../../type';\nimport { keys } from '../../util';\nimport { isUnitModel } from '../model';\nimport { defaultScaleResolve } from '../resolve';\nimport { mergeValuesWithExplicit, tieBreakByComparing } from '../split';\nimport { ScaleComponent } from './component';\nimport { parseScaleDomain } from './domain';\nimport { parseScaleProperty, parseScaleRange } from './properties';\nimport { scaleType } from './type';\nexport function parseScales(model, { ignoreRange } = {}) {\n    parseScaleCore(model);\n    parseScaleDomain(model);\n    for (const prop of NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTIES) {\n        parseScaleProperty(model, prop);\n    }\n    if (!ignoreRange) {\n        // range depends on zero\n        parseScaleRange(model);\n    }\n}\nexport function parseScaleCore(model) {\n    if (isUnitModel(model)) {\n        model.component.scales = parseUnitScaleCore(model);\n    }\n    else {\n        model.component.scales = parseNonUnitScaleCore(model);\n    }\n}\n/**\n * Parse scales for all channels of a model.\n */\nfunction parseUnitScaleCore(model) {\n    const { encoding, mark } = model;\n    return SCALE_CHANNELS.reduce((scaleComponents, channel) => {\n        const fieldOrDatumDef = getFieldOrDatumDef(encoding[channel]); // must be typed def to have scale\n        // Don't generate scale for shape of geoshape\n        if (fieldOrDatumDef && mark === GEOSHAPE && channel === SHAPE && fieldOrDatumDef.type === GEOJSON) {\n            return scaleComponents;\n        }\n        let specifiedScale = fieldOrDatumDef && fieldOrDatumDef['scale'];\n        if (fieldOrDatumDef && specifiedScale !== null && specifiedScale !== false) {\n            specifiedScale = specifiedScale !== null && specifiedScale !== void 0 ? specifiedScale : {};\n            const sType = scaleType(specifiedScale, channel, fieldOrDatumDef, mark);\n            scaleComponents[channel] = new ScaleComponent(model.scaleName(channel + '', true), {\n                value: sType,\n                explicit: specifiedScale.type === sType\n            });\n        }\n        return scaleComponents;\n    }, {});\n}\nconst scaleTypeTieBreaker = tieBreakByComparing((st1, st2) => scaleTypePrecedence(st1) - scaleTypePrecedence(st2));\nfunction parseNonUnitScaleCore(model) {\n    var _a;\n    const scaleComponents = (model.component.scales = {});\n    const scaleTypeWithExplicitIndex = {};\n    const resolve = model.component.resolve;\n    // Parse each child scale and determine if a particular channel can be merged.\n    for (const child of model.children) {\n        parseScaleCore(child);\n        // Instead of always merging right away -- check if it is compatible to merge first!\n        for (const channel of keys(child.component.scales)) {\n            // if resolve is undefined, set default first\n            resolve.scale[channel] = (_a = resolve.scale[channel]) !== null && _a !== void 0 ? _a : defaultScaleResolve(channel, model);\n            if (resolve.scale[channel] === 'shared') {\n                const explicitScaleType = scaleTypeWithExplicitIndex[channel];\n                const childScaleType = child.component.scales[channel].getWithExplicit('type');\n                if (explicitScaleType) {\n                    if (scaleCompatible(explicitScaleType.value, childScaleType.value)) {\n                        // merge scale component if type are compatible\n                        scaleTypeWithExplicitIndex[channel] = mergeValuesWithExplicit(explicitScaleType, childScaleType, 'type', 'scale', scaleTypeTieBreaker);\n                    }\n                    else {\n                        // Otherwise, update conflicting channel to be independent\n                        resolve.scale[channel] = 'independent';\n                        // Remove from the index so they don't get merged\n                        delete scaleTypeWithExplicitIndex[channel];\n                    }\n                }\n                else {\n                    scaleTypeWithExplicitIndex[channel] = childScaleType;\n                }\n            }\n        }\n    }\n    // Merge each channel listed in the index\n    for (const channel of keys(scaleTypeWithExplicitIndex)) {\n        // Create new merged scale component\n        const name = model.scaleName(channel, true);\n        const typeWithExplicit = scaleTypeWithExplicitIndex[channel];\n        scaleComponents[channel] = new ScaleComponent(name, typeWithExplicit);\n        // rename each child and mark them as merged\n        for (const child of model.children) {\n            const childScale = child.component.scales[channel];\n            if (childScale) {\n                child.renameScale(childScale.get('name'), name);\n                childScale.merged = true;\n            }\n        }\n    }\n    return scaleComponents;\n}\n//# sourceMappingURL=parse.js.map","import { isArray } from 'vega-util';\nimport { isBinned, isBinning, isBinParams } from '../../bin';\nimport { COLOR, FILL, POLAR_POSITION_SCALE_CHANNELS, POSITION_SCALE_CHANNELS, POSITION_SCALE_CHANNEL_INDEX, STROKE } from '../../channel';\nimport { getFieldDef, getFieldOrDatumDef, isFieldDef, valueExpr } from '../../channeldef';\nimport { isDateTime } from '../../datetime';\nimport * as log from '../../log';\nimport { channelScalePropertyIncompatability, hasContinuousDomain, isContinuousToContinuous, isContinuousToDiscrete, ScaleType, scaleTypeSupportProperty } from '../../scale';\nimport * as util from '../../util';\nimport { contains, getFirstDefined, keys } from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { getBinSignalName } from '../data/bin';\nimport { isUnitModel } from '../model';\nimport { SignalRefWrapper } from '../signal';\nimport { mergeValuesWithExplicit, tieBreakByComparing } from '../split';\nimport { parseUnitScaleRange } from './range';\nexport function parseScaleProperty(model, property) {\n    if (isUnitModel(model)) {\n        parseUnitScaleProperty(model, property);\n    }\n    else {\n        parseNonUnitScaleProperty(model, property);\n    }\n}\nfunction parseUnitScaleProperty(model, property) {\n    const localScaleComponents = model.component.scales;\n    const { config, encoding, markDef, specifiedScales } = model;\n    for (const channel of keys(localScaleComponents)) {\n        const specifiedScale = specifiedScales[channel];\n        const localScaleCmpt = localScaleComponents[channel];\n        const mergedScaleCmpt = model.getScaleComponent(channel);\n        const fieldOrDatumDef = getFieldOrDatumDef(encoding[channel]);\n        const specifiedValue = specifiedScale[property];\n        const scaleType = mergedScaleCmpt.get('type');\n        const scalePadding = mergedScaleCmpt.get('padding');\n        const scalePaddingInner = mergedScaleCmpt.get('paddingInner');\n        const supportedByScaleType = scaleTypeSupportProperty(scaleType, property);\n        const channelIncompatability = channelScalePropertyIncompatability(channel, property);\n        if (specifiedValue !== undefined) {\n            // If there is a specified value, check if it is compatible with scale type and channel\n            if (!supportedByScaleType) {\n                log.warn(log.message.scalePropertyNotWorkWithScaleType(scaleType, property, channel));\n            }\n            else if (channelIncompatability) {\n                // channel\n                log.warn(channelIncompatability);\n            }\n        }\n        if (supportedByScaleType && channelIncompatability === undefined) {\n            if (specifiedValue !== undefined) {\n                const timeUnit = fieldOrDatumDef['timeUnit'];\n                const type = fieldOrDatumDef.type;\n                switch (property) {\n                    // domainMax/Min to signal if the value is a datetime object\n                    case 'domainMax':\n                    case 'domainMin':\n                        if (isDateTime(specifiedScale[property]) || type === 'temporal' || timeUnit) {\n                            localScaleCmpt.set(property, { signal: valueExpr(specifiedScale[property], { type, timeUnit }) }, true);\n                        }\n                        else {\n                            localScaleCmpt.set(property, specifiedScale[property], true);\n                        }\n                        break;\n                    default:\n                        localScaleCmpt.copyKeyFromObject(property, specifiedScale);\n                }\n            }\n            else {\n                const value = property in scaleRules\n                    ? scaleRules[property]({\n                        model,\n                        channel,\n                        fieldOrDatumDef,\n                        scaleType,\n                        scalePadding,\n                        scalePaddingInner,\n                        domain: specifiedScale.domain,\n                        markDef,\n                        config\n                    })\n                    : config.scale[property];\n                if (value !== undefined) {\n                    localScaleCmpt.set(property, value, false);\n                }\n            }\n        }\n    }\n}\nexport const scaleRules = {\n    bins: ({ model, fieldOrDatumDef }) => (isFieldDef(fieldOrDatumDef) ? bins(model, fieldOrDatumDef) : undefined),\n    interpolate: ({ channel, fieldOrDatumDef }) => interpolate(channel, fieldOrDatumDef.type),\n    nice: ({ scaleType, channel, fieldOrDatumDef }) => nice(scaleType, channel, fieldOrDatumDef),\n    padding: ({ channel, scaleType, fieldOrDatumDef, markDef, config }) => padding(channel, scaleType, config.scale, fieldOrDatumDef, markDef, config.bar),\n    paddingInner: ({ scalePadding, channel, markDef, config }) => paddingInner(scalePadding, channel, markDef.type, config.scale),\n    paddingOuter: ({ scalePadding, channel, scaleType, markDef, scalePaddingInner, config }) => paddingOuter(scalePadding, channel, scaleType, markDef.type, scalePaddingInner, config.scale),\n    reverse: ({ fieldOrDatumDef, scaleType, channel, config }) => {\n        const sort = isFieldDef(fieldOrDatumDef) ? fieldOrDatumDef.sort : undefined;\n        return reverse(scaleType, sort, channel, config.scale);\n    },\n    zero: ({ channel, fieldOrDatumDef, domain, markDef, scaleType }) => zero(channel, fieldOrDatumDef, domain, markDef, scaleType)\n};\n// This method is here rather than in range.ts to avoid circular dependency.\nexport function parseScaleRange(model) {\n    if (isUnitModel(model)) {\n        parseUnitScaleRange(model);\n    }\n    else {\n        parseNonUnitScaleProperty(model, 'range');\n    }\n}\nexport function parseNonUnitScaleProperty(model, property) {\n    const localScaleComponents = model.component.scales;\n    for (const child of model.children) {\n        if (property === 'range') {\n            parseScaleRange(child);\n        }\n        else {\n            parseScaleProperty(child, property);\n        }\n    }\n    for (const channel of keys(localScaleComponents)) {\n        let valueWithExplicit;\n        for (const child of model.children) {\n            const childComponent = child.component.scales[channel];\n            if (childComponent) {\n                const childValueWithExplicit = childComponent.getWithExplicit(property);\n                valueWithExplicit = mergeValuesWithExplicit(valueWithExplicit, childValueWithExplicit, property, 'scale', tieBreakByComparing((v1, v2) => {\n                    switch (property) {\n                        case 'range':\n                            // For step, prefer larger step\n                            if (v1.step && v2.step) {\n                                return v1.step - v2.step;\n                            }\n                            return 0;\n                        // TODO: precedence rule for other properties\n                    }\n                    return 0;\n                }));\n            }\n        }\n        localScaleComponents[channel].setWithExplicit(property, valueWithExplicit);\n    }\n}\nexport function bins(model, fieldDef) {\n    const bin = fieldDef.bin;\n    if (isBinning(bin)) {\n        const binSignal = getBinSignalName(model, fieldDef.field, bin);\n        return new SignalRefWrapper(() => {\n            return model.getSignalName(binSignal);\n        });\n    }\n    else if (isBinned(bin) && isBinParams(bin) && bin.step !== undefined) {\n        // start and stop will be determined from the scale domain\n        return {\n            step: bin.step\n        };\n    }\n    return undefined;\n}\nexport function interpolate(channel, type) {\n    if (contains([COLOR, FILL, STROKE], channel) && type !== 'nominal') {\n        return 'hcl';\n    }\n    return undefined;\n}\nexport function nice(scaleType, channel, fieldOrDatumDef) {\n    var _a;\n    if (((_a = getFieldDef(fieldOrDatumDef)) === null || _a === void 0 ? void 0 : _a.bin) || util.contains([ScaleType.TIME, ScaleType.UTC], scaleType)) {\n        return undefined;\n    }\n    return channel in POSITION_SCALE_CHANNEL_INDEX ? true : undefined;\n}\nexport function padding(channel, scaleType, scaleConfig, fieldOrDatumDef, markDef, barConfig) {\n    if (channel in POSITION_SCALE_CHANNEL_INDEX) {\n        if (isContinuousToContinuous(scaleType)) {\n            if (scaleConfig.continuousPadding !== undefined) {\n                return scaleConfig.continuousPadding;\n            }\n            const { type, orient } = markDef;\n            if (type === 'bar' && !(isFieldDef(fieldOrDatumDef) && (fieldOrDatumDef.bin || fieldOrDatumDef.timeUnit))) {\n                if ((orient === 'vertical' && channel === 'x') || (orient === 'horizontal' && channel === 'y')) {\n                    return barConfig.continuousBandSize;\n                }\n            }\n        }\n        if (scaleType === ScaleType.POINT) {\n            return scaleConfig.pointPadding;\n        }\n    }\n    return undefined;\n}\nexport function paddingInner(paddingValue, channel, mark, scaleConfig) {\n    if (paddingValue !== undefined) {\n        // If user has already manually specified \"padding\", no need to add default paddingInner.\n        return undefined;\n    }\n    if (channel in POSITION_SCALE_CHANNEL_INDEX) {\n        // Padding is only set for X and Y by default.\n        // Basically it doesn't make sense to add padding for color and size.\n        // paddingOuter would only be called if it's a band scale, just return the default for bandScale.\n        const { bandPaddingInner, barBandPaddingInner, rectBandPaddingInner } = scaleConfig;\n        return getFirstDefined(bandPaddingInner, mark === 'bar' ? barBandPaddingInner : rectBandPaddingInner);\n    }\n    return undefined;\n}\nexport function paddingOuter(paddingValue, channel, scaleType, mark, paddingInnerValue, scaleConfig) {\n    if (paddingValue !== undefined) {\n        // If user has already manually specified \"padding\", no need to add default paddingOuter.\n        return undefined;\n    }\n    if (channel in POSITION_SCALE_CHANNEL_INDEX) {\n        // Padding is only set for X and Y by default.\n        // Basically it doesn't make sense to add padding for color and size.\n        if (scaleType === ScaleType.BAND) {\n            const { bandPaddingOuter } = scaleConfig;\n            return getFirstDefined(bandPaddingOuter, \n            /* By default, paddingOuter is paddingInner / 2. The reason is that\n              size (width/height) = step * (cardinality - paddingInner + 2 * paddingOuter).\n              and we want the width/height to be integer by default.\n              Note that step (by default) and cardinality are integers.) */\n            isSignalRef(paddingInnerValue) ? { signal: `${paddingInnerValue.signal}/2` } : paddingInnerValue / 2);\n        }\n    }\n    return undefined;\n}\nexport function reverse(scaleType, sort, channel, scaleConfig) {\n    if (channel === 'x' && scaleConfig.xReverse !== undefined) {\n        if (hasContinuousDomain(scaleType) && sort === 'descending') {\n            if (isSignalRef(scaleConfig.xReverse)) {\n                return { signal: `!${scaleConfig.xReverse.signal}` };\n            }\n            else {\n                return !scaleConfig.xReverse;\n            }\n        }\n        return scaleConfig.xReverse;\n    }\n    if (hasContinuousDomain(scaleType) && sort === 'descending') {\n        // For continuous domain scales, Vega does not support domain sort.\n        // Thus, we reverse range instead if sort is descending\n        return true;\n    }\n    return undefined;\n}\nexport function zero(channel, fieldDef, specifiedDomain, markDef, scaleType) {\n    // If users explicitly provide a domain range, we should not augment zero as that will be unexpected.\n    const hasCustomDomain = !!specifiedDomain && specifiedDomain !== 'unaggregated';\n    if (hasCustomDomain) {\n        if (hasContinuousDomain(scaleType)) {\n            if (isArray(specifiedDomain)) {\n                const first = specifiedDomain[0];\n                const last = specifiedDomain[specifiedDomain.length - 1];\n                if (first <= 0 && last >= 0) {\n                    // if the domain includes zero, make zero remains true\n                    return true;\n                }\n            }\n            return false;\n        }\n    }\n    // If there is no custom domain, return true only for the following cases:\n    // 1) using quantitative field with size\n    // While this can be either ratio or interval fields, our assumption is that\n    // ratio are more common. However, if the scaleType is discretizing scale, we want to return\n    // false so that range doesn't start at zero\n    if (channel === 'size' && fieldDef.type === 'quantitative' && !isContinuousToDiscrete(scaleType)) {\n        return true;\n    }\n    // 2) non-binned, quantitative x-scale or y-scale\n    // (For binning, we should not include zero by default because binning are calculated without zero.)\n    if (!(isFieldDef(fieldDef) && fieldDef.bin) &&\n        util.contains([...POSITION_SCALE_CHANNELS, ...POLAR_POSITION_SCALE_CHANNELS], channel)) {\n        const { orient, type } = markDef;\n        if (contains(['bar', 'area', 'line', 'trail'], type)) {\n            if ((orient === 'horizontal' && channel === 'y') || (orient === 'vertical' && channel === 'x')) {\n                return false;\n            }\n        }\n        return true;\n    }\n    return false;\n}\n//# sourceMappingURL=properties.js.map","import { isArray, isNumber, isObject } from 'vega-util';\nimport { isBinning } from '../../bin';\nimport { ANGLE, COLOR, FILL, FILLOPACITY, isXorY, OPACITY, RADIUS, SCALE_CHANNELS, SHAPE, SIZE, STROKE, STROKEDASH, STROKEOPACITY, STROKEWIDTH, THETA, X, Y } from '../../channel';\nimport { getFieldOrDatumDef } from '../../channeldef';\nimport { getViewConfigDiscreteSize, getViewConfigDiscreteStep } from '../../config';\nimport { DataSourceType } from '../../data';\nimport * as log from '../../log';\nimport { channelScalePropertyIncompatability, hasContinuousDomain, hasDiscreteDomain, isContinuousToDiscrete, isExtendedScheme, scaleTypeSupportProperty } from '../../scale';\nimport { isStep } from '../../spec/base';\nimport * as util from '../../util';\nimport { isSignalRef } from '../../vega.schema';\nimport { signalOrStringValue } from '../common';\nimport { getBinSignalName } from '../data/bin';\nimport { SignalRefWrapper } from '../signal';\nimport { makeExplicit, makeImplicit } from '../split';\nexport const RANGE_PROPERTIES = ['range', 'scheme'];\nfunction getSizeChannel(channel) {\n    return channel === 'x' ? 'width' : channel === 'y' ? 'height' : undefined;\n}\nexport function parseUnitScaleRange(model) {\n    const localScaleComponents = model.component.scales;\n    // use SCALE_CHANNELS instead of scales[channel] to ensure that x, y come first!\n    for (const channel of SCALE_CHANNELS) {\n        const localScaleCmpt = localScaleComponents[channel];\n        if (!localScaleCmpt) {\n            continue;\n        }\n        const rangeWithExplicit = parseRangeForChannel(channel, model);\n        localScaleCmpt.setWithExplicit('range', rangeWithExplicit);\n    }\n}\nfunction getBinStepSignal(model, channel) {\n    const fieldDef = model.fieldDef(channel);\n    if (fieldDef && fieldDef.bin && isBinning(fieldDef.bin)) {\n        const binSignal = getBinSignalName(model, fieldDef.field, fieldDef.bin);\n        // TODO: extract this to be range step signal\n        const sizeType = getSizeChannel(channel);\n        const sizeSignal = model.getName(sizeType);\n        return new SignalRefWrapper(() => {\n            const updatedName = model.getSignalName(binSignal);\n            const binCount = `(${updatedName}.stop - ${updatedName}.start) / ${updatedName}.step`;\n            return `${model.getSignalName(sizeSignal)} / (${binCount})`;\n        });\n    }\n    return undefined;\n}\n/**\n * Return mixins that includes one of the Vega range types (explicit range, range.step, range.scheme).\n */\nexport function parseRangeForChannel(channel, model) {\n    const specifiedScale = model.specifiedScales[channel];\n    const { size } = model;\n    const mergedScaleCmpt = model.getScaleComponent(channel);\n    const scaleType = mergedScaleCmpt.get('type');\n    // Check if any of the range properties is specified.\n    // If so, check if it is compatible and make sure that we only output one of the properties\n    for (const property of RANGE_PROPERTIES) {\n        if (specifiedScale[property] !== undefined) {\n            const supportedByScaleType = scaleTypeSupportProperty(scaleType, property);\n            const channelIncompatability = channelScalePropertyIncompatability(channel, property);\n            if (!supportedByScaleType) {\n                log.warn(log.message.scalePropertyNotWorkWithScaleType(scaleType, property, channel));\n            }\n            else if (channelIncompatability) {\n                // channel\n                log.warn(channelIncompatability);\n            }\n            else {\n                switch (property) {\n                    case 'range': {\n                        const range = specifiedScale.range;\n                        if (isArray(range)) {\n                            if (isXorY(channel)) {\n                                return makeExplicit(range.map(v => {\n                                    if (v === 'width' || v === 'height') {\n                                        // get signal for width/height\n                                        // Just like default range logic below, we use SignalRefWrapper to account for potential merges and renames.\n                                        const sizeSignal = model.getName(v);\n                                        const getSignalName = model.getSignalName.bind(model);\n                                        return SignalRefWrapper.fromName(getSignalName, sizeSignal);\n                                    }\n                                    return v;\n                                }));\n                            }\n                        }\n                        else if (isObject(range)) {\n                            return makeExplicit({\n                                data: model.requestDataName(DataSourceType.Main),\n                                field: range.field,\n                                sort: { op: 'min', field: model.vgField(channel) }\n                            });\n                        }\n                        return makeExplicit(range);\n                    }\n                    case 'scheme':\n                        return makeExplicit(parseScheme(specifiedScale[property]));\n                }\n            }\n        }\n    }\n    if (channel === X || channel === Y) {\n        const sizeChannel = channel === X ? 'width' : 'height';\n        const sizeValue = size[sizeChannel];\n        if (isStep(sizeValue)) {\n            if (hasDiscreteDomain(scaleType)) {\n                return makeExplicit({ step: sizeValue.step });\n            }\n            else {\n                log.warn(log.message.stepDropped(sizeChannel));\n            }\n        }\n    }\n    const { rangeMin, rangeMax } = specifiedScale;\n    const d = defaultRange(channel, model);\n    if ((rangeMin !== undefined || rangeMax !== undefined) &&\n        // it's ok to check just rangeMin's compatibility since rangeMin/rangeMax are the same\n        scaleTypeSupportProperty(scaleType, 'rangeMin') &&\n        isArray(d) &&\n        d.length === 2) {\n        return makeExplicit([rangeMin !== null && rangeMin !== void 0 ? rangeMin : d[0], rangeMax !== null && rangeMax !== void 0 ? rangeMax : d[1]]);\n    }\n    return makeImplicit(d);\n}\nfunction parseScheme(scheme) {\n    if (isExtendedScheme(scheme)) {\n        return Object.assign({ scheme: scheme.name }, util.omit(scheme, ['name']));\n    }\n    return { scheme: scheme };\n}\nfunction defaultRange(channel, model) {\n    const { size, config, mark, encoding } = model;\n    const getSignalName = model.getSignalName.bind(model);\n    const { type } = getFieldOrDatumDef(encoding[channel]);\n    const mergedScaleCmpt = model.getScaleComponent(channel);\n    const scaleType = mergedScaleCmpt.get('type');\n    const { domain, domainMid } = model.specifiedScales[channel];\n    switch (channel) {\n        case X:\n        case Y: {\n            // If there is no explicit width/height for discrete x/y scales\n            if (util.contains(['point', 'band'], scaleType)) {\n                if (channel === X && !size.width) {\n                    const w = getViewConfigDiscreteSize(config.view, 'width');\n                    if (isStep(w)) {\n                        return w;\n                    }\n                }\n                else if (channel === Y && !size.height) {\n                    const h = getViewConfigDiscreteSize(config.view, 'height');\n                    if (isStep(h)) {\n                        return h;\n                    }\n                }\n            }\n            // If step is null, use zero to width or height.\n            // Note that we use SignalRefWrapper to account for potential merges and renames.\n            const sizeType = getSizeChannel(channel);\n            const sizeSignal = model.getName(sizeType);\n            if (channel === Y && hasContinuousDomain(scaleType)) {\n                // For y continuous scale, we have to start from the height as the bottom part has the max value.\n                return [SignalRefWrapper.fromName(getSignalName, sizeSignal), 0];\n            }\n            else {\n                return [0, SignalRefWrapper.fromName(getSignalName, sizeSignal)];\n            }\n        }\n        case SIZE: {\n            // TODO: support custom rangeMin, rangeMax\n            const zero = model.component.scales[channel].get('zero');\n            const rangeMin = sizeRangeMin(mark, zero, config);\n            const rangeMax = sizeRangeMax(mark, size, model, config);\n            if (isContinuousToDiscrete(scaleType)) {\n                return interpolateRange(rangeMin, rangeMax, defaultContinuousToDiscreteCount(scaleType, config, domain, channel));\n            }\n            else {\n                return [rangeMin, rangeMax];\n            }\n        }\n        case THETA:\n            return [0, Math.PI * 2];\n        case ANGLE:\n            // TODO: add config.scale.min/maxAngleDegree (for point and text) and config.scale.min/maxAngleRadian (for arc) once we add arc marks.\n            // (It's weird to add just config.scale.min/maxAngleDegree for now)\n            return [0, 360];\n        case RADIUS: {\n            // max radius = half od min(width,height)\n            return [\n                0,\n                new SignalRefWrapper(() => {\n                    const w = model.getSignalName('width');\n                    const h = model.getSignalName('height');\n                    return `min(${w},${h})/2`;\n                })\n            ];\n        }\n        case STROKEWIDTH:\n            // TODO: support custom rangeMin, rangeMax\n            return [config.scale.minStrokeWidth, config.scale.maxStrokeWidth];\n        case STROKEDASH:\n            return [\n                // TODO: add this to Vega's config.range?\n                [1, 0],\n                [4, 2],\n                [2, 1],\n                [1, 1],\n                [1, 2, 4, 2]\n            ];\n        case SHAPE:\n            return 'symbol';\n        case COLOR:\n        case FILL:\n        case STROKE:\n            if (scaleType === 'ordinal') {\n                // Only nominal data uses ordinal scale by default\n                return type === 'nominal' ? 'category' : 'ordinal';\n            }\n            else {\n                if (domainMid !== undefined) {\n                    return 'diverging';\n                }\n                else {\n                    return mark === 'rect' || mark === 'geoshape' ? 'heatmap' : 'ramp';\n                }\n            }\n        case OPACITY:\n        case FILLOPACITY:\n        case STROKEOPACITY:\n            // TODO: support custom rangeMin, rangeMax\n            return [config.scale.minOpacity, config.scale.maxOpacity];\n    }\n    /* istanbul ignore next: should never reach here */\n    throw new Error(`Scale range undefined for channel ${channel}`);\n}\nexport function defaultContinuousToDiscreteCount(scaleType, config, domain, channel) {\n    switch (scaleType) {\n        case 'quantile':\n            return config.scale.quantileCount;\n        case 'quantize':\n            return config.scale.quantizeCount;\n        case 'threshold':\n            if (domain !== undefined && isArray(domain)) {\n                return domain.length + 1;\n            }\n            else {\n                log.warn(log.message.domainRequiredForThresholdScale(channel));\n                // default threshold boundaries for threshold scale since domain has cardinality of 2\n                return 3;\n            }\n    }\n}\n/**\n * Returns the linear interpolation of the range according to the cardinality\n *\n * @param rangeMin start of the range\n * @param rangeMax end of the range\n * @param cardinality number of values in the output range\n */\nexport function interpolateRange(rangeMin, rangeMax, cardinality) {\n    // always return a signal since it's better to compute the sequence in Vega later\n    const f = () => {\n        const rMax = signalOrStringValue(rangeMax);\n        const rMin = signalOrStringValue(rangeMin);\n        const step = `(${rMax} - ${rMin}) / (${cardinality} - 1)`;\n        return `sequence(${rMin}, ${rMax} + ${step}, ${step})`;\n    };\n    if (isSignalRef(rangeMax)) {\n        return new SignalRefWrapper(f);\n    }\n    else {\n        return { signal: f() };\n    }\n}\nfunction sizeRangeMin(mark, zero, config) {\n    if (zero) {\n        if (isSignalRef(zero)) {\n            return { signal: `${zero.signal} ? 0 : ${sizeRangeMin(mark, false, config)}` };\n        }\n        else {\n            return 0;\n        }\n    }\n    switch (mark) {\n        case 'bar':\n        case 'tick':\n            return config.scale.minBandSize;\n        case 'line':\n        case 'trail':\n        case 'rule':\n            return config.scale.minStrokeWidth;\n        case 'text':\n            return config.scale.minFontSize;\n        case 'point':\n        case 'square':\n        case 'circle':\n            return config.scale.minSize;\n    }\n    /* istanbul ignore next: should never reach here */\n    // sizeRangeMin not implemented for the mark\n    throw new Error(log.message.incompatibleChannel('size', mark));\n}\nexport const MAX_SIZE_RANGE_STEP_RATIO = 0.95;\nfunction sizeRangeMax(mark, size, model, config) {\n    const xyStepSignals = {\n        x: getBinStepSignal(model, 'x'),\n        y: getBinStepSignal(model, 'y')\n    };\n    switch (mark) {\n        case 'bar':\n        case 'tick': {\n            if (config.scale.maxBandSize !== undefined) {\n                return config.scale.maxBandSize;\n            }\n            const min = minXYStep(size, xyStepSignals, config.view);\n            if (isNumber(min)) {\n                return min - 1;\n            }\n            else {\n                return new SignalRefWrapper(() => `${min.signal} - 1`);\n            }\n        }\n        case 'line':\n        case 'trail':\n        case 'rule':\n            return config.scale.maxStrokeWidth;\n        case 'text':\n            return config.scale.maxFontSize;\n        case 'point':\n        case 'square':\n        case 'circle': {\n            if (config.scale.maxSize) {\n                return config.scale.maxSize;\n            }\n            const pointStep = minXYStep(size, xyStepSignals, config.view);\n            if (isNumber(pointStep)) {\n                return Math.pow(MAX_SIZE_RANGE_STEP_RATIO * pointStep, 2);\n            }\n            else {\n                return new SignalRefWrapper(() => `pow(${MAX_SIZE_RANGE_STEP_RATIO} * ${pointStep.signal}, 2)`);\n            }\n        }\n    }\n    /* istanbul ignore next: should never reach here */\n    // sizeRangeMax not implemented for the mark\n    throw new Error(log.message.incompatibleChannel('size', mark));\n}\n/**\n * @returns {number} Range step of x or y or minimum between the two if both are ordinal scale.\n */\nfunction minXYStep(size, xyStepSignals, viewConfig) {\n    const widthStep = isStep(size.width) ? size.width.step : getViewConfigDiscreteStep(viewConfig, 'width');\n    const heightStep = isStep(size.height) ? size.height.step : getViewConfigDiscreteStep(viewConfig, 'height');\n    if (xyStepSignals.x || xyStepSignals.y) {\n        return new SignalRefWrapper(() => {\n            const exprs = [\n                xyStepSignals.x ? xyStepSignals.x.signal : widthStep,\n                xyStepSignals.y ? xyStepSignals.y.signal : heightStep\n            ];\n            return `min(${exprs.join(', ')})`;\n        });\n    }\n    return Math.min(widthStep, heightStep);\n}\n//# sourceMappingURL=range.js.map","import { isBinning } from '../../bin';\nimport { isColorChannel, isScaleChannel, rangeType } from '../../channel';\nimport { isFieldDef, isPositionFieldOrDatumDef } from '../../channeldef';\nimport * as log from '../../log';\nimport { channelSupportScaleType, scaleTypeSupportDataType } from '../../scale';\nimport { normalizeTimeUnit } from '../../timeunit';\nimport * as util from '../../util';\nimport { POLAR_POSITION_SCALE_CHANNEL_INDEX, POSITION_SCALE_CHANNEL_INDEX } from './../../channel';\n/**\n * Determine if there is a specified scale type and if it is appropriate,\n * or determine default type if type is unspecified or inappropriate.\n */\n// NOTE: CompassQL uses this method.\nexport function scaleType(specifiedScale, channel, fieldDef, mark) {\n    const defaultScaleType = defaultType(channel, fieldDef, mark);\n    const { type } = specifiedScale;\n    if (!isScaleChannel(channel)) {\n        // There is no scale for these channels\n        return null;\n    }\n    if (type !== undefined) {\n        // Check if explicitly specified scale type is supported by the channel\n        if (!channelSupportScaleType(channel, type)) {\n            log.warn(log.message.scaleTypeNotWorkWithChannel(channel, type, defaultScaleType));\n            return defaultScaleType;\n        }\n        // Check if explicitly specified scale type is supported by the data type\n        if (isFieldDef(fieldDef) && !scaleTypeSupportDataType(type, fieldDef.type)) {\n            log.warn(log.message.scaleTypeNotWorkWithFieldDef(type, defaultScaleType));\n            return defaultScaleType;\n        }\n        return type;\n    }\n    return defaultScaleType;\n}\n/**\n * Determine appropriate default scale type.\n */\n// NOTE: Voyager uses this method.\nfunction defaultType(channel, fieldDef, mark) {\n    var _a;\n    switch (fieldDef.type) {\n        case 'nominal':\n        case 'ordinal':\n            if (isColorChannel(channel) || rangeType(channel) === 'discrete') {\n                if (channel === 'shape' && fieldDef.type === 'ordinal') {\n                    log.warn(log.message.discreteChannelCannotEncode(channel, 'ordinal'));\n                }\n                return 'ordinal';\n            }\n            if (channel in POSITION_SCALE_CHANNEL_INDEX) {\n                if (util.contains(['rect', 'bar', 'image', 'rule'], mark)) {\n                    // The rect/bar mark should fit into a band.\n                    // For rule, using band scale to make rule align with axis ticks better https://github.com/vega/vega-lite/issues/3429\n                    return 'band';\n                }\n            }\n            else if (mark === 'arc' && channel in POLAR_POSITION_SCALE_CHANNEL_INDEX) {\n                return 'band';\n            }\n            if (fieldDef.band !== undefined || (isPositionFieldOrDatumDef(fieldDef) && ((_a = fieldDef.axis) === null || _a === void 0 ? void 0 : _a.tickBand))) {\n                return 'band';\n            }\n            // Otherwise, use ordinal point scale so we can easily get center positions of the marks.\n            return 'point';\n        case 'temporal':\n            if (isColorChannel(channel)) {\n                return 'time';\n            }\n            else if (rangeType(channel) === 'discrete') {\n                log.warn(log.message.discreteChannelCannotEncode(channel, 'temporal'));\n                // TODO: consider using quantize (equivalent to binning) once we have it\n                return 'ordinal';\n            }\n            else if (isFieldDef(fieldDef) && fieldDef.timeUnit && normalizeTimeUnit(fieldDef.timeUnit).utc) {\n                return 'utc';\n            }\n            return 'time';\n        case 'quantitative':\n            if (isColorChannel(channel)) {\n                if (isFieldDef(fieldDef) && isBinning(fieldDef.bin)) {\n                    return 'bin-ordinal';\n                }\n                return 'linear';\n            }\n            else if (rangeType(channel) === 'discrete') {\n                log.warn(log.message.discreteChannelCannotEncode(channel, 'quantitative'));\n                // TODO: consider using quantize (equivalent to binning) once we have it\n                return 'ordinal';\n            }\n            return 'linear';\n        case 'geojson':\n            return undefined;\n    }\n    /* istanbul ignore next: should never reach this */\n    throw new Error(log.message.invalidFieldType(fieldDef.type));\n}\n//# sourceMappingURL=type.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { selector as parseSelector } from 'vega-event-selector';\nimport { identity, isArray, stringValue } from 'vega-util';\nimport { forEachSelection, MODIFY, STORE, unitName, VL_SELECTION_RESOLVE, TUPLE } from '.';\nimport { dateTimeToExpr, isDateTime, dateTimeToTimestamp } from '../../datetime';\nimport { keys, varName } from '../../util';\nimport { isUnitModel } from '../model';\nimport { forEachTransform } from './transforms/transforms';\nimport { parseSelectionBinExtent } from './parse';\nexport function assembleInit(init, isExpr = true, wrap = identity) {\n    if (isArray(init)) {\n        const assembled = init.map(v => assembleInit(v, isExpr, wrap));\n        return isExpr ? `[${assembled.join(', ')}]` : assembled;\n    }\n    else if (isDateTime(init)) {\n        if (isExpr) {\n            return wrap(dateTimeToExpr(init));\n        }\n        else {\n            return wrap(dateTimeToTimestamp(init));\n        }\n    }\n    return isExpr ? wrap(JSON.stringify(init)) : init;\n}\nexport function assembleUnitSelectionSignals(model, signals) {\n    forEachSelection(model, (selCmpt, selCompiler) => {\n        const name = selCmpt.name;\n        let modifyExpr = selCompiler.modifyExpr(model, selCmpt);\n        signals.push(...selCompiler.signals(model, selCmpt));\n        forEachTransform(selCmpt, txCompiler => {\n            if (txCompiler.signals) {\n                signals = txCompiler.signals(model, selCmpt, signals);\n            }\n            if (txCompiler.modifyExpr) {\n                modifyExpr = txCompiler.modifyExpr(model, selCmpt, modifyExpr);\n            }\n        });\n        signals.push({\n            name: name + MODIFY,\n            on: [\n                {\n                    events: { signal: selCmpt.name + TUPLE },\n                    update: `modify(${stringValue(selCmpt.name + STORE)}, ${modifyExpr})`\n                }\n            ]\n        });\n    });\n    return cleanupEmptyOnArray(signals);\n}\nexport function assembleFacetSignals(model, signals) {\n    if (model.component.selection && keys(model.component.selection).length) {\n        const name = stringValue(model.getName('cell'));\n        signals.unshift({\n            name: 'facet',\n            value: {},\n            on: [\n                {\n                    events: parseSelector('mousemove', 'scope'),\n                    update: `isTuple(facet) ? facet : group(${name}).datum`\n                }\n            ]\n        });\n    }\n    return cleanupEmptyOnArray(signals);\n}\nexport function assembleTopLevelSignals(model, signals) {\n    let hasSelections = false;\n    forEachSelection(model, (selCmpt, selCompiler) => {\n        const name = selCmpt.name;\n        const store = stringValue(name + STORE);\n        const hasSg = signals.filter(s => s.name === name);\n        if (hasSg.length === 0) {\n            const resolve = selCmpt.resolve === 'global' ? 'union' : selCmpt.resolve;\n            const isMulti = selCmpt.type === 'multi' ? ', true)' : ')';\n            signals.push({\n                name: selCmpt.name,\n                update: `${VL_SELECTION_RESOLVE}(${store}, ${stringValue(resolve)}${isMulti}`\n            });\n        }\n        hasSelections = true;\n        if (selCompiler.topLevelSignals) {\n            signals = selCompiler.topLevelSignals(model, selCmpt, signals);\n        }\n        forEachTransform(selCmpt, txCompiler => {\n            if (txCompiler.topLevelSignals) {\n                signals = txCompiler.topLevelSignals(model, selCmpt, signals);\n            }\n        });\n    });\n    if (hasSelections) {\n        const hasUnit = signals.filter(s => s.name === 'unit');\n        if (hasUnit.length === 0) {\n            signals.unshift({\n                name: 'unit',\n                value: {},\n                on: [{ events: 'mousemove', update: 'isTuple(group()) ? group() : unit' }]\n            });\n        }\n    }\n    return cleanupEmptyOnArray(signals);\n}\nexport function assembleUnitSelectionData(model, data) {\n    const dataCopy = [...data];\n    forEachSelection(model, selCmpt => {\n        const init = { name: selCmpt.name + STORE };\n        if (selCmpt.init) {\n            const fields = selCmpt.project.items.map(proj => {\n                const { signals } = proj, rest = __rest(proj, [\"signals\"]);\n                return rest;\n            });\n            const insert = selCmpt.init.map(i => assembleInit(i, false));\n            init.values =\n                selCmpt.type === 'interval'\n                    ? [{ unit: unitName(model, { escape: false }), fields, values: insert }]\n                    : insert.map(i => ({ unit: unitName(model, { escape: false }), fields, values: i }));\n        }\n        const contains = dataCopy.filter(d => d.name === selCmpt.name + STORE);\n        if (!contains.length) {\n            dataCopy.push(init);\n        }\n    });\n    return dataCopy;\n}\nexport function assembleUnitSelectionMarks(model, marks) {\n    forEachSelection(model, (selCmpt, selCompiler) => {\n        marks = selCompiler.marks ? selCompiler.marks(model, selCmpt, marks) : marks;\n        forEachTransform(selCmpt, txCompiler => {\n            if (txCompiler.marks) {\n                marks = txCompiler.marks(model, selCmpt, marks);\n            }\n        });\n    });\n    return marks;\n}\nexport function assembleLayerSelectionMarks(model, marks) {\n    for (const child of model.children) {\n        if (isUnitModel(child)) {\n            marks = assembleUnitSelectionMarks(child, marks);\n        }\n    }\n    return marks;\n}\nexport function assembleSelectionScaleDomain(model, extent) {\n    const name = extent.selection;\n    const selCmpt = model.getSelectionComponent(name, varName(name));\n    return { signal: parseSelectionBinExtent(selCmpt, extent) };\n}\nfunction cleanupEmptyOnArray(signals) {\n    return signals.map(s => {\n        if (s.on && !s.on.length)\n            delete s.on;\n        return s;\n    });\n}\n//# sourceMappingURL=assemble.js.map","import { stringValue } from 'vega-util';\nimport { FACET_CHANNELS } from '../../channel';\nimport { SELECTION_ID } from '../../selection';\nimport { vals } from '../../util';\nimport { isFacetModel } from '../model';\nimport interval from './interval';\nimport multi from './multi';\nimport single from './single';\nexport const STORE = '_store';\nexport const TUPLE = '_tuple';\nexport const MODIFY = '_modify';\nexport const SELECTION_DOMAIN = '_selection_domain_';\nexport const VL_SELECTION_RESOLVE = 'vlSelectionResolve';\nconst compilers = { single, multi, interval };\nexport function forEachSelection(model, cb) {\n    const selections = model.component.selection;\n    if (selections) {\n        for (const sel of vals(selections)) {\n            const success = cb(sel, compilers[sel.type]);\n            if (success === true)\n                break;\n        }\n    }\n}\nfunction getFacetModel(model) {\n    let parent = model.parent;\n    while (parent) {\n        if (isFacetModel(parent)) {\n            break;\n        }\n        parent = parent.parent;\n    }\n    return parent;\n}\nexport function unitName(model, { escape } = { escape: true }) {\n    let name = escape ? stringValue(model.name) : model.name;\n    const facetModel = getFacetModel(model);\n    if (facetModel) {\n        const { facet } = facetModel;\n        for (const channel of FACET_CHANNELS) {\n            if (facet[channel]) {\n                name += ` + '__facet_${channel}_' + (facet[${stringValue(facetModel.vgField(channel))}])`;\n            }\n        }\n    }\n    return name;\n}\nexport function requiresSelectionId(model) {\n    let identifier = false;\n    forEachSelection(model, selCmpt => {\n        identifier = identifier || selCmpt.project.items.some(proj => proj.field === SELECTION_ID);\n    });\n    return identifier;\n}\n//# sourceMappingURL=index.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { array, stringValue } from 'vega-util';\nimport { STORE, TUPLE, unitName } from '.';\nimport { X, Y } from '../../channel';\nimport { warn } from '../../log';\nimport { hasContinuousDomain } from '../../scale';\nimport { keys } from '../../util';\nimport { assembleInit } from './assemble';\nimport { TUPLE_FIELDS } from './transforms/project';\nimport scales from './transforms/scales';\nexport const BRUSH = '_brush';\nexport const SCALE_TRIGGER = '_scale_trigger';\nconst interval = {\n    signals: (model, selCmpt) => {\n        const name = selCmpt.name;\n        const fieldsSg = name + TUPLE_FIELDS;\n        const hasScales = scales.has(selCmpt);\n        const signals = [];\n        const dataSignals = [];\n        const scaleTriggers = [];\n        if (selCmpt.translate && !hasScales) {\n            const filterExpr = `!event.item || event.item.mark.name !== ${stringValue(name + BRUSH)}`;\n            events(selCmpt, (on, evt) => {\n                var _a;\n                const filters = array((_a = evt.between[0].filter) !== null && _a !== void 0 ? _a : (evt.between[0].filter = []));\n                if (filters.indexOf(filterExpr) < 0) {\n                    filters.push(filterExpr);\n                }\n                return on;\n            });\n        }\n        selCmpt.project.items.forEach((proj, i) => {\n            const channel = proj.channel;\n            if (channel !== X && channel !== Y) {\n                warn('Interval selections only support x and y encoding channels.');\n                return;\n            }\n            const init = selCmpt.init ? selCmpt.init[i] : null;\n            const cs = channelSignals(model, selCmpt, proj, init);\n            const dname = proj.signals.data;\n            const vname = proj.signals.visual;\n            const scaleName = stringValue(model.scaleName(channel));\n            const scaleType = model.getScaleComponent(channel).get('type');\n            const toNum = hasContinuousDomain(scaleType) ? '+' : '';\n            signals.push(...cs);\n            dataSignals.push(dname);\n            scaleTriggers.push({\n                scaleName: model.scaleName(channel),\n                expr: `(!isArray(${dname}) || ` +\n                    `(${toNum}invert(${scaleName}, ${vname})[0] === ${toNum}${dname}[0] && ` +\n                    `${toNum}invert(${scaleName}, ${vname})[1] === ${toNum}${dname}[1]))`\n            });\n        });\n        // Proxy scale reactions to ensure that an infinite loop doesn't occur\n        // when an interval selection filter touches the scale.\n        if (!hasScales) {\n            signals.push({\n                name: name + SCALE_TRIGGER,\n                value: {},\n                on: [\n                    {\n                        events: scaleTriggers.map(t => ({ scale: t.scaleName })),\n                        update: scaleTriggers.map(t => t.expr).join(' && ') + ` ? ${name + SCALE_TRIGGER} : {}`\n                    }\n                ]\n            });\n        }\n        // Only add an interval to the store if it has valid data extents. Data extents\n        // are set to null if pixel extents are equal to account for intervals over\n        // ordinal/nominal domains which, when inverted, will still produce a valid datum.\n        const init = selCmpt.init;\n        const update = `unit: ${unitName(model)}, fields: ${fieldsSg}, values`;\n        return signals.concat(Object.assign(Object.assign({ name: name + TUPLE }, (init ? { init: `{${update}: ${assembleInit(init)}}` } : {})), { on: [\n                {\n                    events: [{ signal: dataSignals.join(' || ') }],\n                    update: dataSignals.join(' && ') + ` ? {${update}: [${dataSignals}]} : null`\n                }\n            ] }));\n    },\n    modifyExpr: (model, selCmpt) => {\n        const tpl = selCmpt.name + TUPLE;\n        return tpl + ', ' + (selCmpt.resolve === 'global' ? 'true' : `{unit: ${unitName(model)}}`);\n    },\n    marks: (model, selCmpt, marks) => {\n        const name = selCmpt.name;\n        const { x, y } = selCmpt.project.hasChannel;\n        const xvname = x && x.signals.visual;\n        const yvname = y && y.signals.visual;\n        const store = `data(${stringValue(selCmpt.name + STORE)})`;\n        // Do not add a brush if we're binding to scales.\n        if (scales.has(selCmpt)) {\n            return marks;\n        }\n        const update = {\n            x: x !== undefined ? { signal: `${xvname}[0]` } : { value: 0 },\n            y: y !== undefined ? { signal: `${yvname}[0]` } : { value: 0 },\n            x2: x !== undefined ? { signal: `${xvname}[1]` } : { field: { group: 'width' } },\n            y2: y !== undefined ? { signal: `${yvname}[1]` } : { field: { group: 'height' } }\n        };\n        // If the selection is resolved to global, only a single interval is in\n        // the store. Wrap brush mark's encodings with a production rule to test\n        // this based on the `unit` property. Hide the brush mark if it corresponds\n        // to a unit different from the one in the store.\n        if (selCmpt.resolve === 'global') {\n            for (const key of keys(update)) {\n                update[key] = [\n                    Object.assign({ test: `${store}.length && ${store}[0].unit === ${unitName(model)}` }, update[key]),\n                    { value: 0 }\n                ];\n            }\n        }\n        // Two brush marks ensure that fill colors and other aesthetic choices do\n        // not interefere with the core marks, but that the brushed region can still\n        // be interacted with (e.g., dragging it around).\n        const _a = selCmpt.mark, { fill, fillOpacity, cursor } = _a, stroke = __rest(_a, [\"fill\", \"fillOpacity\", \"cursor\"]);\n        const vgStroke = keys(stroke).reduce((def, k) => {\n            def[k] = [\n                {\n                    test: [x !== undefined && `${xvname}[0] !== ${xvname}[1]`, y !== undefined && `${yvname}[0] !== ${yvname}[1]`]\n                        .filter(t => t)\n                        .join(' && '),\n                    value: stroke[k]\n                },\n                { value: null }\n            ];\n            return def;\n        }, {});\n        return [\n            {\n                name: name + BRUSH + '_bg',\n                type: 'rect',\n                clip: true,\n                encode: {\n                    enter: {\n                        fill: { value: fill },\n                        fillOpacity: { value: fillOpacity }\n                    },\n                    update: update\n                }\n            },\n            ...marks,\n            {\n                name: name + BRUSH,\n                type: 'rect',\n                clip: true,\n                encode: {\n                    enter: Object.assign(Object.assign({}, (cursor ? { cursor: { value: cursor } } : {})), { fill: { value: 'transparent' } }),\n                    update: Object.assign(Object.assign({}, update), vgStroke)\n                }\n            }\n        ];\n    }\n};\nexport default interval;\n/**\n * Returns the visual and data signals for an interval selection.\n */\nfunction channelSignals(model, selCmpt, proj, init) {\n    const channel = proj.channel;\n    const vname = proj.signals.visual;\n    const dname = proj.signals.data;\n    const hasScales = scales.has(selCmpt);\n    const scaleName = stringValue(model.scaleName(channel));\n    const scale = model.getScaleComponent(channel);\n    const scaleType = scale ? scale.get('type') : undefined;\n    const scaled = (str) => `scale(${scaleName}, ${str})`;\n    const size = model.getSizeSignalRef(channel === X ? 'width' : 'height').signal;\n    const coord = `${channel}(unit)`;\n    const on = events(selCmpt, (def, evt) => {\n        return [\n            ...def,\n            { events: evt.between[0], update: `[${coord}, ${coord}]` },\n            { events: evt, update: `[${vname}[0], clamp(${coord}, 0, ${size})]` } // Brush End\n        ];\n    });\n    // React to pan/zooms of continuous scales. Non-continuous scales\n    // (band, point) cannot be pan/zoomed and any other changes\n    // to their domains (e.g., filtering) should clear the brushes.\n    on.push({\n        events: { signal: selCmpt.name + SCALE_TRIGGER },\n        update: hasContinuousDomain(scaleType) ? `[${scaled(`${dname}[0]`)}, ${scaled(`${dname}[1]`)}]` : `[0, 0]`\n    });\n    return hasScales\n        ? [{ name: dname, on: [] }]\n        : [\n            Object.assign(Object.assign({ name: vname }, (init ? { init: assembleInit(init, true, scaled) } : { value: [] })), { on: on }),\n            Object.assign(Object.assign({ name: dname }, (init ? { init: assembleInit(init) } : {})), { on: [\n                    {\n                        events: { signal: vname },\n                        update: `${vname}[0] === ${vname}[1] ? null : invert(${scaleName}, ${vname})`\n                    }\n                ] })\n        ];\n}\nfunction events(selCmpt, cb) {\n    return selCmpt.events.reduce((on, evt) => {\n        if (!evt.between) {\n            warn(`${evt} is not an ordered event stream for interval selections.`);\n            return on;\n        }\n        return cb(on, evt);\n    }, []);\n}\n//# sourceMappingURL=interval.js.map","import { stringValue } from 'vega-util';\nimport { TUPLE, unitName } from '.';\nimport { TUPLE_FIELDS } from './transforms/project';\nexport function singleOrMultiSignals(model, selCmpt) {\n    const name = selCmpt.name;\n    const fieldsSg = name + TUPLE_FIELDS;\n    const project = selCmpt.project;\n    const datum = '(item().isVoronoi ? datum.datum : datum)';\n    const values = project.items\n        .map(p => {\n        const fieldDef = model.fieldDef(p.channel);\n        // Binned fields should capture extents, for a range test against the raw field.\n        return fieldDef && fieldDef.bin\n            ? `[${datum}[${stringValue(model.vgField(p.channel, {}))}], ` +\n                `${datum}[${stringValue(model.vgField(p.channel, { binSuffix: 'end' }))}]]`\n            : `${datum}[${stringValue(p.field)}]`;\n    })\n        .join(', ');\n    // Only add a discrete selection to the store if a datum is present _and_\n    // the interaction isn't occurring on a group mark. This guards against\n    // polluting interactive state with invalid values in faceted displays\n    // as the group marks are also data-driven. We force the update to account\n    // for constant null states but varying toggles (e.g., shift-click in\n    // whitespace followed by a click in whitespace; the store should only\n    // be cleared on the second click).\n    const update = `unit: ${unitName(model)}, fields: ${fieldsSg}, values`;\n    const events = selCmpt.events;\n    return [\n        {\n            name: name + TUPLE,\n            on: events\n                ? [\n                    {\n                        events,\n                        update: `datum && item().mark.marktype !== 'group' ? {${update}: [${values}]} : null`,\n                        force: true\n                    }\n                ]\n                : []\n        }\n    ];\n}\nconst multi = {\n    signals: singleOrMultiSignals,\n    modifyExpr: (model, selCmpt) => {\n        const tpl = selCmpt.name + TUPLE;\n        return tpl + ', ' + (selCmpt.resolve === 'global' ? 'null' : `{unit: ${unitName(model)}}`);\n    }\n};\nexport default multi;\n//# sourceMappingURL=multi.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { selector as parseSelector } from 'vega-event-selector';\nimport { isString, stringValue } from 'vega-util';\nimport { forEachSelection, STORE } from '.';\nimport { warn } from '../../log';\nimport { duplicate, keys, logicalExpr, varName } from '../../util';\nimport { OutputNode } from '../data/dataflow';\nimport { FilterNode } from '../data/filter';\nimport { forEachTransform } from './transforms/transforms';\nimport { DataSourceType } from '../../data';\nexport function parseUnitSelection(model, selDefs) {\n    var _a;\n    const selCmpts = {};\n    const selectionConfig = model.config.selection;\n    for (const name of keys(selDefs !== null && selDefs !== void 0 ? selDefs : {})) {\n        const selDef = duplicate(selDefs[name]);\n        const _b = selectionConfig[selDef.type], { fields, encodings } = _b, cfg = __rest(_b, [\"fields\", \"encodings\"]); // Project transform applies its defaults.\n        // Set default values from config if a property hasn't been specified,\n        // or if it is true. E.g., \"translate\": true should use the default\n        // event handlers for translate. However, true may be a valid value for\n        // a property (e.g., \"nearest\": true).\n        for (const key in cfg) {\n            // A selection should contain either `encodings` or `fields`, only use\n            // default values for these two values if neither of them is specified.\n            if ((key === 'encodings' && selDef.fields) || (key === 'fields' && selDef.encodings)) {\n                continue;\n            }\n            if (key === 'mark') {\n                selDef[key] = Object.assign(Object.assign({}, cfg[key]), selDef[key]);\n            }\n            if (selDef[key] === undefined || selDef[key] === true) {\n                selDef[key] = (_a = cfg[key]) !== null && _a !== void 0 ? _a : selDef[key];\n            }\n        }\n        const safeName = varName(name);\n        const selCmpt = (selCmpts[safeName] = Object.assign(Object.assign({}, selDef), { name: safeName, events: isString(selDef.on) ? parseSelector(selDef.on, 'scope') : duplicate(selDef.on) }));\n        forEachTransform(selCmpt, txCompiler => {\n            if (txCompiler.has(selCmpt) && txCompiler.parse) {\n                txCompiler.parse(model, selCmpt, selDef, selDefs[name]);\n            }\n        });\n    }\n    return selCmpts;\n}\nexport function parseSelectionPredicate(model, selections, dfnode, datum = 'datum') {\n    const stores = [];\n    function expr(name) {\n        const vname = varName(name);\n        const selCmpt = model.getSelectionComponent(vname, name);\n        const store = stringValue(vname + STORE);\n        if (selCmpt.project.timeUnit) {\n            const child = dfnode !== null && dfnode !== void 0 ? dfnode : model.component.data.raw;\n            const tunode = selCmpt.project.timeUnit.clone();\n            if (child.parent) {\n                tunode.insertAsParentOf(child);\n            }\n            else {\n                child.parent = tunode;\n            }\n        }\n        if (selCmpt.empty !== 'none') {\n            stores.push(store);\n        }\n        return (`vlSelectionTest(${store}, ${datum}` + (selCmpt.resolve === 'global' ? ')' : `, ${stringValue(selCmpt.resolve)})`));\n    }\n    const predicateStr = logicalExpr(selections, expr);\n    return ((stores.length ? '!(' + stores.map(s => `length(data(${s}))`).join(' || ') + ') || ' : '') + `(${predicateStr})`);\n}\nexport function parseSelectionBinExtent(selCmpt, extent) {\n    const encoding = extent['encoding'];\n    let field = extent['field'];\n    if (!encoding && !field) {\n        field = selCmpt.project.items[0].field;\n        if (selCmpt.project.items.length > 1) {\n            warn('A \"field\" or \"encoding\" must be specified when using a selection as a scale domain. ' +\n                `Using \"field\": ${stringValue(field)}.`);\n        }\n    }\n    else if (encoding && !field) {\n        const encodings = selCmpt.project.items.filter(p => p.channel === encoding);\n        if (!encodings.length || encodings.length > 1) {\n            field = selCmpt.project.items[0].field;\n            warn((!encodings.length ? 'No ' : 'Multiple ') +\n                `matching ${stringValue(encoding)} encoding found for selection ${stringValue(extent.selection)}. ` +\n                `Using \"field\": ${stringValue(field)}.`);\n        }\n        else {\n            field = encodings[0].field;\n        }\n    }\n    return `${selCmpt.name}[${stringValue(field)}]`;\n}\nexport function materializeSelections(model, main) {\n    forEachSelection(model, selCmpt => {\n        const selection = selCmpt.name;\n        const lookupName = model.getName(`lookup_${selection}`);\n        model.component.data.outputNodes[lookupName] = selCmpt.materialized = new OutputNode(new FilterNode(main, model, { selection }), lookupName, DataSourceType.Lookup, model.component.data.outputNodeRefCounts);\n    });\n}\n//# sourceMappingURL=parse.js.map","import { TUPLE, unitName } from '.';\nimport { singleOrMultiSignals } from './multi';\nconst single = {\n    signals: singleOrMultiSignals,\n    modifyExpr: (model, selCmpt) => {\n        const tpl = selCmpt.name + TUPLE;\n        return tpl + ', ' + (selCmpt.resolve === 'global' ? 'true' : `{unit: ${unitName(model)}}`);\n    }\n};\nexport default single;\n//# sourceMappingURL=single.js.map","import { selector as parseSelector } from 'vega-event-selector';\nimport { isString } from 'vega-util';\nimport { TUPLE } from '..';\nimport { varName } from '../../../util';\nimport inputBindings from './inputs';\nimport toggle, { TOGGLE } from './toggle';\nconst clear = {\n    has: selCmpt => {\n        return selCmpt.clear !== undefined && selCmpt.clear !== false;\n    },\n    parse: (model, selCmpt, selDef) => {\n        if (selDef.clear) {\n            selCmpt.clear = isString(selDef.clear) ? parseSelector(selDef.clear, 'scope') : selDef.clear;\n        }\n    },\n    topLevelSignals: (model, selCmpt, signals) => {\n        if (inputBindings.has(selCmpt)) {\n            for (const proj of selCmpt.project.items) {\n                const idx = signals.findIndex(n => n.name === varName(`${selCmpt.name}_${proj.field}`));\n                if (idx !== -1) {\n                    signals[idx].on.push({ events: selCmpt.clear, update: 'null' });\n                }\n            }\n        }\n        return signals;\n    },\n    signals: (model, selCmpt, signals) => {\n        function addClear(idx, update) {\n            if (idx !== -1 && signals[idx].on) {\n                signals[idx].on.push({ events: selCmpt.clear, update });\n            }\n        }\n        // Be as minimalist as possible when adding clear triggers to minimize dataflow execution.\n        if (selCmpt.type === 'interval') {\n            for (const proj of selCmpt.project.items) {\n                const vIdx = signals.findIndex(n => n.name === proj.signals.visual);\n                addClear(vIdx, '[0, 0]');\n                if (vIdx === -1) {\n                    const dIdx = signals.findIndex(n => n.name === proj.signals.data);\n                    addClear(dIdx, 'null');\n                }\n            }\n        }\n        else {\n            let tIdx = signals.findIndex(n => n.name === selCmpt.name + TUPLE);\n            addClear(tIdx, 'null');\n            if (toggle.has(selCmpt)) {\n                tIdx = signals.findIndex(n => n.name === selCmpt.name + TOGGLE);\n                addClear(tIdx, 'false');\n            }\n        }\n        return signals;\n    }\n};\nexport default clear;\n//# sourceMappingURL=clear.js.map","import { stringValue } from 'vega-util';\nimport { TUPLE } from '..';\nimport { varName } from '../../../util';\nimport { assembleInit } from '../assemble';\nimport nearest from './nearest';\nimport { TUPLE_FIELDS } from './project';\nimport { isLegendBinding } from '../../../selection';\nconst inputBindings = {\n    has: selCmpt => {\n        return (selCmpt.type === 'single' &&\n            selCmpt.resolve === 'global' &&\n            selCmpt.bind &&\n            selCmpt.bind !== 'scales' &&\n            !isLegendBinding(selCmpt.bind));\n    },\n    parse: (model, selCmpt, selDef, origDef) => {\n        // Binding a selection to input widgets disables default direct manipulation interaction.\n        // A user can choose to re-enable it by explicitly specifying triggering input events.\n        if (!origDef.on)\n            delete selCmpt.events;\n        if (!origDef.clear)\n            delete selCmpt.clear;\n    },\n    topLevelSignals: (model, selCmpt, signals) => {\n        const name = selCmpt.name;\n        const proj = selCmpt.project;\n        const bind = selCmpt.bind;\n        const init = selCmpt.init && selCmpt.init[0]; // Can only exist on single selections (one initial value).\n        const datum = nearest.has(selCmpt) ? '(item().isVoronoi ? datum.datum : datum)' : 'datum';\n        proj.items.forEach((p, i) => {\n            var _a, _b;\n            const sgname = varName(`${name}_${p.field}`);\n            const hasSignal = signals.filter(s => s.name === sgname);\n            if (!hasSignal.length) {\n                signals.unshift(Object.assign(Object.assign({ name: sgname }, (init ? { init: assembleInit(init[i]) } : { value: null })), { on: selCmpt.events\n                        ? [\n                            {\n                                events: selCmpt.events,\n                                update: `datum && item().mark.marktype !== 'group' ? ${datum}[${stringValue(p.field)}] : null`\n                            }\n                        ]\n                        : [], bind: (_b = (_a = bind[p.field]) !== null && _a !== void 0 ? _a : bind[p.channel]) !== null && _b !== void 0 ? _b : bind }));\n            }\n        });\n        return signals;\n    },\n    signals: (model, selCmpt, signals) => {\n        const name = selCmpt.name;\n        const proj = selCmpt.project;\n        const signal = signals.filter(s => s.name === name + TUPLE)[0];\n        const fields = name + TUPLE_FIELDS;\n        const values = proj.items.map(p => varName(`${name}_${p.field}`));\n        const valid = values.map(v => `${v} !== null`).join(' && ');\n        if (values.length) {\n            signal.update = `${valid} ? {fields: ${fields}, values: [${values.join(', ')}]} : null`;\n        }\n        delete signal.value;\n        delete signal.on;\n        return signals;\n    }\n};\nexport default inputBindings;\n//# sourceMappingURL=inputs.js.map","import { selector as parseSelector } from 'vega-event-selector';\nimport { array, isString } from 'vega-util';\nimport { forEachSelection, TUPLE } from '..';\nimport * as log from '../../../log';\nimport { isLegendBinding, isLegendStreamBinding, SELECTION_ID } from '../../../selection';\nimport { duplicate, varName } from '../../../util';\nimport { TUPLE_FIELDS } from './project';\nimport { TOGGLE } from './toggle';\nconst legendBindings = {\n    has: (selCmpt) => {\n        const spec = selCmpt.resolve === 'global' && selCmpt.bind && isLegendBinding(selCmpt.bind);\n        const projLen = selCmpt.project.items.length === 1 && selCmpt.project.items[0].field !== SELECTION_ID;\n        if (spec && !projLen) {\n            log.warn(log.message.LEGEND_BINDINGS_MUST_HAVE_PROJECTION);\n        }\n        return spec && projLen;\n    },\n    parse: (model, selCmpt, selDef, origDef) => {\n        var _a;\n        // Binding a selection to a legend disables default direct manipulation interaction.\n        // A user can choose to re-enable it by explicitly specifying triggering input events.\n        if (!origDef.on)\n            delete selCmpt.events;\n        if (!origDef.clear)\n            delete selCmpt.clear;\n        if (origDef.on || origDef.clear) {\n            const legendFilter = 'event.item && indexof(event.item.mark.role, \"legend\") < 0';\n            for (const evt of selCmpt.events) {\n                evt.filter = array((_a = evt.filter) !== null && _a !== void 0 ? _a : []);\n                if (evt.filter.indexOf(legendFilter) < 0) {\n                    evt.filter.push(legendFilter);\n                }\n            }\n        }\n        const evt = isLegendStreamBinding(selCmpt.bind) ? selCmpt.bind.legend : 'click';\n        const stream = isString(evt) ? parseSelector(evt, 'view') : array(evt);\n        selCmpt.bind = { legend: { merge: stream } };\n    },\n    topLevelSignals: (model, selCmpt, signals) => {\n        const selName = selCmpt.name;\n        const stream = isLegendStreamBinding(selCmpt.bind) && selCmpt.bind.legend;\n        const markName = (name) => (s) => {\n            const ds = duplicate(s);\n            ds.markname = name;\n            return ds;\n        };\n        for (const proj of selCmpt.project.items) {\n            if (!proj.hasLegend)\n                continue;\n            const prefix = `${varName(proj.field)}_legend`;\n            const sgName = `${selName}_${prefix}`;\n            const hasSignal = signals.filter(s => s.name === sgName);\n            if (hasSignal.length === 0) {\n                const events = stream.merge\n                    .map(markName(`${prefix}_symbols`))\n                    .concat(stream.merge.map(markName(`${prefix}_labels`)))\n                    .concat(stream.merge.map(markName(`${prefix}_entries`)));\n                signals.unshift(Object.assign(Object.assign({ name: sgName }, (!selCmpt.init ? { value: null } : {})), { on: [\n                        // Legend entries do not store values, so we need to walk the scenegraph to the symbol datum.\n                        { events, update: 'datum.value || item().items[0].items[0].datum.value', force: true },\n                        { events: stream.merge, update: `!event.item || !datum ? null : ${sgName}`, force: true }\n                    ] }));\n            }\n        }\n        return signals;\n    },\n    signals: (model, selCmpt, signals) => {\n        const name = selCmpt.name;\n        const proj = selCmpt.project;\n        const tuple = signals.find(s => s.name === name + TUPLE);\n        const fields = name + TUPLE_FIELDS;\n        const values = proj.items.filter(p => p.hasLegend).map(p => varName(`${name}_${varName(p.field)}_legend`));\n        const valid = values.map(v => `${v} !== null`).join(' && ');\n        const update = `${valid} ? {fields: ${fields}, values: [${values.join(', ')}]} : null`;\n        if (selCmpt.events && values.length > 0) {\n            tuple.on.push({\n                events: values.map(signal => ({ signal })),\n                update\n            });\n        }\n        else if (values.length > 0) {\n            tuple.update = update;\n            delete tuple.value;\n            delete tuple.on;\n        }\n        const toggle = signals.find(s => s.name === name + TOGGLE);\n        const events = isLegendStreamBinding(selCmpt.bind) && selCmpt.bind.legend;\n        if (toggle) {\n            if (!selCmpt.events)\n                toggle.on[0].events = events;\n            else\n                toggle.on.push(Object.assign(Object.assign({}, toggle.on[0]), { events }));\n        }\n        return signals;\n    }\n};\nexport default legendBindings;\nexport function parseInteractiveLegend(model, channel, legendCmpt) {\n    var _a;\n    const field = (_a = model.fieldDef(channel)) === null || _a === void 0 ? void 0 : _a.field;\n    forEachSelection(model, selCmpt => {\n        var _a, _b;\n        const proj = (_a = selCmpt.project.hasField[field]) !== null && _a !== void 0 ? _a : selCmpt.project.hasChannel[channel];\n        if (proj && legendBindings.has(selCmpt)) {\n            const legendSelections = (_b = legendCmpt.get('selections')) !== null && _b !== void 0 ? _b : [];\n            legendSelections.push(selCmpt.name);\n            legendCmpt.set('selections', legendSelections, false);\n            proj.hasLegend = true;\n        }\n    });\n}\n//# sourceMappingURL=legends.js.map","import * as log from '../../../log';\nimport { isPathMark } from '../../../mark';\nimport { tooltip } from '../../mark/encode';\nconst VORONOI = 'voronoi';\nconst nearest = {\n    has: selCmpt => {\n        return selCmpt.type !== 'interval' && selCmpt.nearest;\n    },\n    parse: (model, selCmpt) => {\n        // Scope selection events to the voronoi mark to prevent capturing\n        // events that occur on the group mark (https://github.com/vega/vega/issues/2112).\n        if (selCmpt.events) {\n            for (const s of selCmpt.events) {\n                s.markname = model.getName(VORONOI);\n            }\n        }\n    },\n    marks: (model, selCmpt, marks) => {\n        const { x, y } = selCmpt.project.hasChannel;\n        const markType = model.mark;\n        if (isPathMark(markType)) {\n            log.warn(log.message.nearestNotSupportForContinuous(markType));\n            return marks;\n        }\n        const cellDef = {\n            name: model.getName(VORONOI),\n            type: 'path',\n            interactive: true,\n            from: { data: model.getName('marks') },\n            encode: {\n                update: Object.assign({ fill: { value: 'transparent' }, strokeWidth: { value: 0.35 }, stroke: { value: 'transparent' }, isVoronoi: { value: true } }, tooltip(model, { reactiveGeom: true }))\n            },\n            transform: [\n                {\n                    type: 'voronoi',\n                    x: { expr: x || !y ? 'datum.datum.x || 0' : '0' },\n                    y: { expr: y || !x ? 'datum.datum.y || 0' : '0' },\n                    size: [model.getSizeSignalRef('width'), model.getSizeSignalRef('height')]\n                }\n            ]\n        };\n        let index = 0;\n        let exists = false;\n        marks.forEach((mark, i) => {\n            var _a;\n            const name = (_a = mark.name) !== null && _a !== void 0 ? _a : '';\n            if (name === model.component.mark[0].name) {\n                index = i;\n            }\n            else if (name.indexOf(VORONOI) >= 0) {\n                exists = true;\n            }\n        });\n        if (!exists) {\n            marks.splice(index + 1, 0, cellDef);\n        }\n        return marks;\n    }\n};\nexport default nearest;\n//# sourceMappingURL=nearest.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { array } from 'vega-util';\nimport { isSingleDefUnitChannel } from '../../../channel';\nimport * as log from '../../../log';\nimport { hasContinuousDomain } from '../../../scale';\nimport { hash, keys, replacePathInField, varName, isEmpty } from '../../../util';\nimport { TimeUnitNode } from '../../data/timeunit';\nexport const TUPLE_FIELDS = '_tuple_fields';\nexport class SelectionProjectionComponent {\n    constructor(...items) {\n        this.items = items;\n        this.hasChannel = {};\n        this.hasField = {};\n    }\n}\nconst project = {\n    has: () => {\n        return true; // This transform handles its own defaults, so always run parse.\n    },\n    parse: (model, selCmpt, selDef) => {\n        var _a, _b, _c;\n        const name = selCmpt.name;\n        const proj = (_a = selCmpt.project) !== null && _a !== void 0 ? _a : (selCmpt.project = new SelectionProjectionComponent());\n        const parsed = {};\n        const timeUnits = {};\n        const signals = new Set();\n        const signalName = (p, range) => {\n            const suffix = range === 'visual' ? p.channel : p.field;\n            let sg = varName(`${name}_${suffix}`);\n            for (let counter = 1; signals.has(sg); counter++) {\n                sg = varName(`${name}_${suffix}_${counter}`);\n            }\n            signals.add(sg);\n            return { [range]: sg };\n        };\n        // If no explicit projection (either fields or encodings) is specified, set some defaults.\n        // If an initial value is set, try to infer projections.\n        // Otherwise, use the default configuration.\n        if (!selDef.fields && !selDef.encodings) {\n            const cfg = model.config.selection[selDef.type];\n            if (selDef.init) {\n                for (const init of array(selDef.init)) {\n                    for (const key of keys(init)) {\n                        if (isSingleDefUnitChannel(key)) {\n                            (selDef.encodings || (selDef.encodings = [])).push(key);\n                        }\n                        else {\n                            if (selDef.type === 'interval') {\n                                log.warn(log.message.INTERVAL_INITIALIZED_WITH_X_Y);\n                                selDef.encodings = cfg.encodings;\n                            }\n                            else {\n                                (selDef.fields || (selDef.fields = [])).push(key);\n                            }\n                        }\n                    }\n                }\n            }\n            else {\n                selDef.encodings = cfg.encodings;\n                selDef.fields = cfg.fields;\n            }\n        }\n        // TODO: find a possible channel mapping for these fields.\n        for (const field of (_b = selDef.fields) !== null && _b !== void 0 ? _b : []) {\n            const p = { type: 'E', field };\n            p.signals = Object.assign({}, signalName(p, 'data'));\n            proj.items.push(p);\n            proj.hasField[field] = p;\n        }\n        for (const channel of (_c = selDef.encodings) !== null && _c !== void 0 ? _c : []) {\n            const fieldDef = model.fieldDef(channel);\n            if (fieldDef) {\n                let field = fieldDef.field;\n                if (fieldDef.aggregate) {\n                    log.warn(log.message.cannotProjectAggregate(channel, fieldDef.aggregate));\n                    continue;\n                }\n                else if (!field) {\n                    log.warn(log.message.cannotProjectOnChannelWithoutField(channel));\n                    continue;\n                }\n                if (fieldDef.timeUnit) {\n                    field = model.vgField(channel);\n                    // Construct TimeUnitComponents which will be combined into a\n                    // TimeUnitNode. This node may need to be inserted into the\n                    // dataflow if the selection is used across views that do not\n                    // have these time units defined.\n                    const component = {\n                        timeUnit: fieldDef.timeUnit,\n                        as: field,\n                        field: fieldDef.field\n                    };\n                    timeUnits[hash(component)] = component;\n                }\n                // Prevent duplicate projections on the same field.\n                // TODO: what if the same field is bound to multiple channels (e.g., SPLOM diag).\n                if (!parsed[field]) {\n                    // Determine whether the tuple will store enumerated or ranged values.\n                    // Interval selections store ranges for continuous scales, and enumerations otherwise.\n                    // Single/multi selections store ranges for binned fields, and enumerations otherwise.\n                    let type = 'E';\n                    if (selCmpt.type === 'interval') {\n                        const scaleType = model.getScaleComponent(channel).get('type');\n                        if (hasContinuousDomain(scaleType)) {\n                            type = 'R';\n                        }\n                    }\n                    else if (fieldDef.bin) {\n                        type = 'R-RE';\n                    }\n                    const p = { field, channel, type };\n                    p.signals = Object.assign(Object.assign({}, signalName(p, 'data')), signalName(p, 'visual'));\n                    proj.items.push((parsed[field] = p));\n                    proj.hasField[field] = proj.hasChannel[channel] = parsed[field];\n                }\n            }\n            else {\n                log.warn(log.message.cannotProjectOnChannelWithoutField(channel));\n            }\n        }\n        if (selDef.init) {\n            const parseInit = (i) => {\n                return proj.items.map(p => (i[p.channel] !== undefined ? i[p.channel] : i[p.field]));\n            };\n            if (selDef.type === 'interval') {\n                selCmpt.init = parseInit(selDef.init);\n            }\n            else {\n                const init = array(selDef.init);\n                selCmpt.init = init.map(parseInit);\n            }\n        }\n        if (!isEmpty(timeUnits)) {\n            proj.timeUnit = new TimeUnitNode(null, timeUnits);\n        }\n    },\n    signals: (model, selCmpt, allSignals) => {\n        const name = selCmpt.name + TUPLE_FIELDS;\n        const hasSignal = allSignals.filter(s => s.name === name);\n        return hasSignal.length > 0\n            ? allSignals\n            : allSignals.concat({\n                name,\n                value: selCmpt.project.items.map(proj => {\n                    const { signals, hasLegend } = proj, rest = __rest(proj, [\"signals\", \"hasLegend\"]);\n                    rest.field = replacePathInField(rest.field);\n                    return rest;\n                })\n            });\n    }\n};\nexport default project;\n//# sourceMappingURL=project.js.map","import { stringValue } from 'vega-util';\nimport { VL_SELECTION_RESOLVE } from '..';\nimport { isScaleChannel } from '../../../channel';\nimport * as log from '../../../log';\nimport { hasContinuousDomain } from '../../../scale';\nimport { isLayerModel } from '../../model';\nconst scaleBindings = {\n    has: selCmpt => {\n        return selCmpt.type === 'interval' && selCmpt.resolve === 'global' && selCmpt.bind && selCmpt.bind === 'scales';\n    },\n    parse: (model, selCmpt) => {\n        const bound = (selCmpt.scales = []);\n        for (const proj of selCmpt.project.items) {\n            const channel = proj.channel;\n            if (!isScaleChannel(channel)) {\n                continue;\n            }\n            const scale = model.getScaleComponent(channel);\n            const scaleType = scale ? scale.get('type') : undefined;\n            if (!scale || !hasContinuousDomain(scaleType)) {\n                log.warn(log.message.SCALE_BINDINGS_CONTINUOUS);\n                continue;\n            }\n            const extent = { selection: selCmpt.name, field: proj.field };\n            scale.set('selectionExtent', extent, true);\n            bound.push(proj);\n        }\n    },\n    topLevelSignals: (model, selCmpt, signals) => {\n        const bound = selCmpt.scales.filter(proj => signals.filter(s => s.name === proj.signals.data).length === 0);\n        // Top-level signals are only needed for multiview displays and if this\n        // view's top-level signals haven't already been generated.\n        if (!model.parent || isTopLevelLayer(model) || bound.length === 0) {\n            return signals;\n        }\n        // vlSelectionResolve does not account for the behavior of bound scales in\n        // multiview displays. Each unit view adds a tuple to the store, but the\n        // state of the selection is the unit selection most recently updated. This\n        // state is captured by the top-level signals that we insert and \"push\n        // outer\" to from within the units. We need to reassemble this state into\n        // the top-level named signal, except no single selCmpt has a global view.\n        const namedSg = signals.filter(s => s.name === selCmpt.name)[0];\n        let update = namedSg.update;\n        if (update.indexOf(VL_SELECTION_RESOLVE) >= 0) {\n            namedSg.update = `{${bound.map(proj => `${stringValue(proj.field)}: ${proj.signals.data}`).join(', ')}}`;\n        }\n        else {\n            for (const proj of bound) {\n                const mapping = `${stringValue(proj.field)}: ${proj.signals.data}`;\n                if (update.indexOf(mapping) < 0) {\n                    update = `${update.substring(0, update.length - 1)}, ${mapping}}`;\n                }\n            }\n            namedSg.update = update;\n        }\n        return signals.concat(bound.map(proj => ({ name: proj.signals.data })));\n    },\n    signals: (model, selCmpt, signals) => {\n        // Nested signals need only push to top-level signals with multiview displays.\n        if (model.parent && !isTopLevelLayer(model)) {\n            for (const proj of selCmpt.scales) {\n                const signal = signals.filter(s => s.name === proj.signals.data)[0];\n                signal.push = 'outer';\n                delete signal.value;\n                delete signal.update;\n            }\n        }\n        return signals;\n    }\n};\nexport default scaleBindings;\nexport function domain(model, channel) {\n    const scale = stringValue(model.scaleName(channel));\n    return `domain(${scale})`;\n}\nfunction isTopLevelLayer(model) {\n    var _a;\n    return model.parent && isLayerModel(model.parent) && ((_a = !model.parent.parent) !== null && _a !== void 0 ? _a : isTopLevelLayer(model.parent.parent));\n}\n//# sourceMappingURL=scales.js.map","import { TUPLE, unitName } from '..';\nexport const TOGGLE = '_toggle';\nconst toggle = {\n    has: selCmpt => {\n        return selCmpt.type === 'multi' && !!selCmpt.toggle;\n    },\n    signals: (model, selCmpt, signals) => {\n        return signals.concat({\n            name: selCmpt.name + TOGGLE,\n            value: false,\n            on: [{ events: selCmpt.events, update: selCmpt.toggle }]\n        });\n    },\n    modifyExpr: (model, selCmpt) => {\n        const tpl = selCmpt.name + TUPLE;\n        const signal = selCmpt.name + TOGGLE;\n        return (`${signal} ? null : ${tpl}, ` +\n            (selCmpt.resolve === 'global' ? `${signal} ? null : true, ` : `${signal} ? null : {unit: ${unitName(model)}}, `) +\n            `${signal} ? ${tpl} : null`);\n    }\n};\nexport default toggle;\n//# sourceMappingURL=toggle.js.map","import clear from './clear';\nimport inputs from './inputs';\nimport nearest from './nearest';\nimport project from './project';\nimport scales from './scales';\nimport legends from './legends';\nimport toggle from './toggle';\nimport translate from './translate';\nimport zoom from './zoom';\nconst compilers = [project, toggle, scales, legends, translate, zoom, inputs, nearest, clear];\nexport function forEachTransform(selCmpt, cb) {\n    for (const t of compilers) {\n        if (t.has(selCmpt)) {\n            cb(t);\n        }\n    }\n}\n//# sourceMappingURL=transforms.js.map","import { selector as parseSelector } from 'vega-event-selector';\nimport { X, Y } from '../../../channel';\nimport { BRUSH as INTERVAL_BRUSH } from '../interval';\nimport scalesCompiler, { domain } from './scales';\nconst ANCHOR = '_translate_anchor';\nconst DELTA = '_translate_delta';\nconst translate = {\n    has: selCmpt => {\n        return selCmpt.type === 'interval' && selCmpt.translate;\n    },\n    signals: (model, selCmpt, signals) => {\n        const name = selCmpt.name;\n        const hasScales = scalesCompiler.has(selCmpt);\n        const anchor = name + ANCHOR;\n        const { x, y } = selCmpt.project.hasChannel;\n        let events = parseSelector(selCmpt.translate, 'scope');\n        if (!hasScales) {\n            events = events.map(e => ((e.between[0].markname = name + INTERVAL_BRUSH), e));\n        }\n        signals.push({\n            name: anchor,\n            value: {},\n            on: [\n                {\n                    events: events.map(e => e.between[0]),\n                    update: '{x: x(unit), y: y(unit)' +\n                        (x !== undefined ? ', extent_x: ' + (hasScales ? domain(model, X) : `slice(${x.signals.visual})`) : '') +\n                        (y !== undefined ? ', extent_y: ' + (hasScales ? domain(model, Y) : `slice(${y.signals.visual})`) : '') +\n                        '}'\n                }\n            ]\n        }, {\n            name: name + DELTA,\n            value: {},\n            on: [\n                {\n                    events: events,\n                    update: `{x: ${anchor}.x - x(unit), y: ${anchor}.y - y(unit)}`\n                }\n            ]\n        });\n        if (x !== undefined) {\n            onDelta(model, selCmpt, x, 'width', signals);\n        }\n        if (y !== undefined) {\n            onDelta(model, selCmpt, y, 'height', signals);\n        }\n        return signals;\n    }\n};\nexport default translate;\nfunction onDelta(model, selCmpt, proj, size, signals) {\n    var _a;\n    const name = selCmpt.name;\n    const anchor = name + ANCHOR;\n    const delta = name + DELTA;\n    const channel = proj.channel;\n    const hasScales = scalesCompiler.has(selCmpt);\n    const signal = signals.filter(s => s.name === proj.signals[hasScales ? 'data' : 'visual'])[0];\n    const sizeSg = model.getSizeSignalRef(size).signal;\n    const scaleCmpt = model.getScaleComponent(channel);\n    const scaleType = scaleCmpt.get('type');\n    const sign = hasScales && channel === X ? '-' : ''; // Invert delta when panning x-scales.\n    const extent = `${anchor}.extent_${channel}`;\n    const offset = `${sign}${delta}.${channel} / ` + (hasScales ? `${sizeSg}` : `span(${extent})`);\n    const panFn = !hasScales\n        ? 'panLinear'\n        : scaleType === 'log'\n            ? 'panLog'\n            : scaleType === 'pow'\n                ? 'panPow'\n                : 'panLinear';\n    const update = `${panFn}(${extent}, ${offset}` +\n        (hasScales && scaleType === 'pow' ? `, ${(_a = scaleCmpt.get('exponent')) !== null && _a !== void 0 ? _a : 1}` : '') +\n        ')';\n    signal.on.push({\n        events: { signal: delta },\n        update: hasScales ? update : `clampRange(${update}, 0, ${sizeSg})`\n    });\n}\n//# sourceMappingURL=translate.js.map","import { selector as parseSelector } from 'vega-event-selector';\nimport { stringValue } from 'vega-util';\nimport { X, Y } from '../../../channel';\nimport { BRUSH as INTERVAL_BRUSH } from '../interval';\nimport { default as scalesCompiler, domain } from './scales';\nconst ANCHOR = '_zoom_anchor';\nconst DELTA = '_zoom_delta';\nconst zoom = {\n    has: selCmpt => {\n        return selCmpt.type === 'interval' && selCmpt.zoom;\n    },\n    signals: (model, selCmpt, signals) => {\n        const name = selCmpt.name;\n        const hasScales = scalesCompiler.has(selCmpt);\n        const delta = name + DELTA;\n        const { x, y } = selCmpt.project.hasChannel;\n        const sx = stringValue(model.scaleName(X));\n        const sy = stringValue(model.scaleName(Y));\n        let events = parseSelector(selCmpt.zoom, 'scope');\n        if (!hasScales) {\n            events = events.map(e => ((e.markname = name + INTERVAL_BRUSH), e));\n        }\n        signals.push({\n            name: name + ANCHOR,\n            on: [\n                {\n                    events: events,\n                    update: !hasScales\n                        ? `{x: x(unit), y: y(unit)}`\n                        : '{' +\n                            [sx ? `x: invert(${sx}, x(unit))` : '', sy ? `y: invert(${sy}, y(unit))` : '']\n                                .filter(expr => !!expr)\n                                .join(', ') +\n                            '}'\n                }\n            ]\n        }, {\n            name: delta,\n            on: [\n                {\n                    events: events,\n                    force: true,\n                    update: 'pow(1.001, event.deltaY * pow(16, event.deltaMode))'\n                }\n            ]\n        });\n        if (x !== undefined) {\n            onDelta(model, selCmpt, x, 'width', signals);\n        }\n        if (y !== undefined) {\n            onDelta(model, selCmpt, y, 'height', signals);\n        }\n        return signals;\n    }\n};\nexport default zoom;\nfunction onDelta(model, selCmpt, proj, size, signals) {\n    var _a;\n    const name = selCmpt.name;\n    const channel = proj.channel;\n    const hasScales = scalesCompiler.has(selCmpt);\n    const signal = signals.filter(s => s.name === proj.signals[hasScales ? 'data' : 'visual'])[0];\n    const sizeSg = model.getSizeSignalRef(size).signal;\n    const scaleCmpt = model.getScaleComponent(channel);\n    const scaleType = scaleCmpt.get('type');\n    const base = hasScales ? domain(model, channel) : signal.name;\n    const delta = name + DELTA;\n    const anchor = `${name}${ANCHOR}.${channel}`;\n    const zoomFn = !hasScales\n        ? 'zoomLinear'\n        : scaleType === 'log'\n            ? 'zoomLog'\n            : scaleType === 'pow'\n                ? 'zoomPow'\n                : 'zoomLinear';\n    const update = `${zoomFn}(${base}, ${anchor}, ${delta}` +\n        (hasScales && scaleType === 'pow' ? `, ${(_a = scaleCmpt.get('exponent')) !== null && _a !== void 0 ? _a : 1}` : '') +\n        ')';\n    signal.on.push({\n        events: { signal: delta },\n        update: hasScales ? update : `clampRange(${update}, 0, ${sizeSg})`\n    });\n}\n//# sourceMappingURL=zoom.js.map","/**\n * A class that behaves like a SignalRef but lazily generates the signal.\n * The provided generator function should use `Model.getSignalName` to use the correct signal name.\n */\nexport class SignalRefWrapper {\n    constructor(exprGenerator) {\n        Object.defineProperty(this, 'signal', {\n            enumerable: true,\n            get: exprGenerator\n        });\n    }\n    static fromName(rename, signalName) {\n        return new SignalRefWrapper(() => rename(signalName));\n    }\n}\n//# sourceMappingURL=signal.js.map","import * as log from '../log';\nimport { deepEqual, duplicate, getFirstDefined, keys } from '../util';\n/**\n * Generic class for storing properties that are explicitly specified\n * and implicitly determined by the compiler.\n * This is important for scale/axis/legend merging as\n * we want to prioritize properties that users explicitly specified.\n */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport class Split {\n    constructor(explicit = {}, implicit = {}) {\n        this.explicit = explicit;\n        this.implicit = implicit;\n    }\n    clone() {\n        return new Split(duplicate(this.explicit), duplicate(this.implicit));\n    }\n    combine() {\n        // FIXME remove \"as any\".\n        // Add \"as any\" to avoid an error \"Spread types may only be created from object types\".\n        return Object.assign(Object.assign({}, this.explicit), this.implicit);\n    }\n    get(key) {\n        // Explicit has higher precedence\n        return getFirstDefined(this.explicit[key], this.implicit[key]);\n    }\n    getWithExplicit(key) {\n        // Explicit has higher precedence\n        if (this.explicit[key] !== undefined) {\n            return { explicit: true, value: this.explicit[key] };\n        }\n        else if (this.implicit[key] !== undefined) {\n            return { explicit: false, value: this.implicit[key] };\n        }\n        return { explicit: false, value: undefined };\n    }\n    setWithExplicit(key, value) {\n        if (value.value !== undefined) {\n            this.set(key, value.value, value.explicit);\n        }\n    }\n    set(key, value, explicit) {\n        delete this[explicit ? 'implicit' : 'explicit'][key];\n        this[explicit ? 'explicit' : 'implicit'][key] = value;\n        return this;\n    }\n    copyKeyFromSplit(key, s) {\n        // Explicit has higher precedence\n        if (s.explicit[key] !== undefined) {\n            this.set(key, s.explicit[key], true);\n        }\n        else if (s.implicit[key] !== undefined) {\n            this.set(key, s.implicit[key], false);\n        }\n    }\n    copyKeyFromObject(key, s) {\n        // Explicit has higher precedence\n        if (s[key] !== undefined) {\n            this.set(key, s[key], true);\n        }\n    }\n    /**\n     * Merge split object into this split object. Properties from the other split\n     * overwrite properties from this split.\n     */\n    copyAll(other) {\n        for (const key of keys(other.combine())) {\n            const val = other.getWithExplicit(key);\n            this.setWithExplicit(key, val);\n        }\n    }\n}\nexport function makeExplicit(value) {\n    return {\n        explicit: true,\n        value\n    };\n}\nexport function makeImplicit(value) {\n    return {\n        explicit: false,\n        value\n    };\n}\nexport function tieBreakByComparing(compare) {\n    return (v1, v2, property, propertyOf) => {\n        const diff = compare(v1.value, v2.value);\n        if (diff > 0) {\n            return v1;\n        }\n        else if (diff < 0) {\n            return v2;\n        }\n        return defaultTieBreaker(v1, v2, property, propertyOf);\n    };\n}\nexport function defaultTieBreaker(v1, v2, property, propertyOf) {\n    if (v1.explicit && v2.explicit) {\n        log.warn(log.message.mergeConflictingProperty(property, propertyOf, v1.value, v2.value));\n    }\n    // If equal score, prefer v1.\n    return v1;\n}\nexport function mergeValuesWithExplicit(v1, v2, property, propertyOf, tieBreaker = defaultTieBreaker) {\n    if (v1 === undefined || v1.value === undefined) {\n        // For first run\n        return v2;\n    }\n    if (v1.explicit && !v2.explicit) {\n        return v1;\n    }\n    else if (v2.explicit && !v1.explicit) {\n        return v2;\n    }\n    else if (deepEqual(v1.value, v2.value)) {\n        return v1;\n    }\n    else {\n        return tieBreaker(v1, v2, property, propertyOf);\n    }\n}\n//# sourceMappingURL=split.js.map","import { isArray } from 'vega-util';\nimport { isConditionalAxisValue } from '../axis';\nimport { GEOPOSITION_CHANNELS, NONPOSITION_SCALE_CHANNELS, POSITION_SCALE_CHANNELS, SCALE_CHANNELS, supportLegend, X, Y } from '../channel';\nimport { getFieldDef, getFieldOrDatumDef, isFieldOrDatumDef, isTypedFieldDef } from '../channeldef';\nimport { isGraticuleGenerator } from '../data';\nimport * as vlEncoding from '../encoding';\nimport { initEncoding } from '../encoding';\nimport { replaceExprRefInIndex } from '../expr';\nimport { GEOSHAPE, isMarkDef } from '../mark';\nimport { isFrameMixins } from '../spec/base';\nimport { stack } from '../stack';\nimport { keys } from '../util';\nimport { assembleAxisSignals } from './axis/assemble';\nimport { parseUnitAxes } from './axis/parse';\nimport { signalOrValueRefWithCondition, signalRefOrValue } from './common';\nimport { parseData } from './data/parse';\nimport { assembleLayoutSignals } from './layoutsize/assemble';\nimport { initLayoutSize } from './layoutsize/init';\nimport { parseUnitLayoutSize } from './layoutsize/parse';\nimport { defaultFilled, initMarkdef } from './mark/init';\nimport { parseMarkGroups } from './mark/mark';\nimport { isLayerModel, ModelWithField } from './model';\nimport { assembleTopLevelSignals, assembleUnitSelectionData, assembleUnitSelectionMarks, assembleUnitSelectionSignals } from './selection/assemble';\nimport { parseUnitSelection } from './selection/parse';\n/**\n * Internal model of Vega-Lite specification for the compiler.\n */\nexport class UnitModel extends ModelWithField {\n    constructor(spec, parent, parentGivenName, parentGivenSize = {}, config) {\n        super(spec, 'unit', parent, parentGivenName, config, undefined, isFrameMixins(spec) ? spec.view : undefined);\n        this.specifiedScales = {};\n        this.specifiedAxes = {};\n        this.specifiedLegends = {};\n        this.specifiedProjection = {};\n        this.selection = {};\n        this.children = [];\n        const markDef = isMarkDef(spec.mark) ? Object.assign({}, spec.mark) : { type: spec.mark };\n        const mark = markDef.type;\n        // Need to init filled before other mark properties because encoding depends on filled but other mark properties depend on types inside encoding\n        if (markDef.filled === undefined) {\n            markDef.filled = defaultFilled(markDef, config, {\n                graticule: spec.data && isGraticuleGenerator(spec.data)\n            });\n        }\n        const encoding = (this.encoding = initEncoding(spec.encoding || {}, mark, markDef.filled, config));\n        this.markDef = initMarkdef(markDef, encoding, config);\n        this.size = initLayoutSize({\n            encoding: encoding,\n            size: isFrameMixins(spec)\n                ? Object.assign(Object.assign(Object.assign({}, parentGivenSize), (spec.width ? { width: spec.width } : {})), (spec.height ? { height: spec.height } : {})) : parentGivenSize\n        });\n        // calculate stack properties\n        this.stack = stack(mark, encoding);\n        this.specifiedScales = this.initScales(mark, encoding);\n        this.specifiedAxes = this.initAxes(encoding);\n        this.specifiedLegends = this.initLegends(encoding);\n        this.specifiedProjection = spec.projection;\n        // Selections will be initialized upon parse.\n        this.selection = spec.selection;\n    }\n    get hasProjection() {\n        const { encoding } = this;\n        const isGeoShapeMark = this.mark === GEOSHAPE;\n        const hasGeoPosition = encoding && GEOPOSITION_CHANNELS.some(channel => isFieldOrDatumDef(encoding[channel]));\n        return isGeoShapeMark || hasGeoPosition;\n    }\n    /**\n     * Return specified Vega-Lite scale domain for a particular channel\n     * @param channel\n     */\n    scaleDomain(channel) {\n        const scale = this.specifiedScales[channel];\n        return scale ? scale.domain : undefined;\n    }\n    axis(channel) {\n        return this.specifiedAxes[channel];\n    }\n    legend(channel) {\n        return this.specifiedLegends[channel];\n    }\n    initScales(mark, encoding) {\n        return SCALE_CHANNELS.reduce((scales, channel) => {\n            var _a;\n            const fieldOrDatumDef = getFieldOrDatumDef(encoding[channel]);\n            if (fieldOrDatumDef) {\n                scales[channel] = this.initScale((_a = fieldOrDatumDef.scale) !== null && _a !== void 0 ? _a : {});\n            }\n            return scales;\n        }, {});\n    }\n    initScale(scale) {\n        const { domain, range } = scale;\n        const scaleInternal = replaceExprRefInIndex(scale);\n        if (isArray(domain)) {\n            scaleInternal.domain = domain.map(signalRefOrValue);\n        }\n        if (isArray(range)) {\n            scaleInternal.range = range.map(signalRefOrValue);\n        }\n        return scaleInternal;\n    }\n    initAxes(encoding) {\n        return POSITION_SCALE_CHANNELS.reduce((_axis, channel) => {\n            // Position Axis\n            // TODO: handle ConditionFieldDef\n            const channelDef = encoding[channel];\n            if (isFieldOrDatumDef(channelDef) ||\n                (channel === X && isFieldOrDatumDef(encoding.x2)) ||\n                (channel === Y && isFieldOrDatumDef(encoding.y2))) {\n                const axisSpec = isFieldOrDatumDef(channelDef) ? channelDef.axis : undefined;\n                _axis[channel] = axisSpec\n                    ? this.initAxis(Object.assign({}, axisSpec)) // convert truthy value to object\n                    : axisSpec;\n            }\n            return _axis;\n        }, {});\n    }\n    initAxis(axis) {\n        const props = keys(axis);\n        const axisInternal = {};\n        for (const prop of props) {\n            const val = axis[prop];\n            axisInternal[prop] = isConditionalAxisValue(val)\n                ? signalOrValueRefWithCondition(val)\n                : signalRefOrValue(val);\n        }\n        return axisInternal;\n    }\n    initLegends(encoding) {\n        return NONPOSITION_SCALE_CHANNELS.reduce((_legend, channel) => {\n            const fieldOrDatumDef = getFieldOrDatumDef(encoding[channel]);\n            if (fieldOrDatumDef && supportLegend(channel)) {\n                const legend = fieldOrDatumDef.legend;\n                _legend[channel] = legend\n                    ? replaceExprRefInIndex(legend) // convert truthy value to object\n                    : legend;\n            }\n            return _legend;\n        }, {});\n    }\n    parseData() {\n        this.component.data = parseData(this);\n    }\n    parseLayoutSize() {\n        parseUnitLayoutSize(this);\n    }\n    parseSelections() {\n        this.component.selection = parseUnitSelection(this, this.selection);\n    }\n    parseMarkGroup() {\n        this.component.mark = parseMarkGroups(this);\n    }\n    parseAxesAndHeaders() {\n        this.component.axes = parseUnitAxes(this);\n    }\n    assembleSelectionTopLevelSignals(signals) {\n        return assembleTopLevelSignals(this, signals);\n    }\n    assembleSignals() {\n        return [...assembleAxisSignals(this), ...assembleUnitSelectionSignals(this, [])];\n    }\n    assembleSelectionData(data) {\n        return assembleUnitSelectionData(this, data);\n    }\n    assembleLayout() {\n        return null;\n    }\n    assembleLayoutSignals() {\n        return assembleLayoutSignals(this);\n    }\n    assembleMarks() {\n        var _a;\n        let marks = (_a = this.component.mark) !== null && _a !== void 0 ? _a : [];\n        // If this unit is part of a layer, selections should augment\n        // all in concert rather than each unit individually. This\n        // ensures correct interleaving of clipping and brushed marks.\n        if (!this.parent || !isLayerModel(this.parent)) {\n            marks = assembleUnitSelectionMarks(this, marks);\n        }\n        return marks.map(this.correctDataNames);\n    }\n    getMapping() {\n        return this.encoding;\n    }\n    get mark() {\n        return this.markDef.type;\n    }\n    channelHasField(channel) {\n        return vlEncoding.channelHasField(this.encoding, channel);\n    }\n    fieldDef(channel) {\n        const channelDef = this.encoding[channel];\n        return getFieldDef(channelDef);\n    }\n    typedFieldDef(channel) {\n        const fieldDef = this.fieldDef(channel);\n        if (isTypedFieldDef(fieldDef)) {\n            return fieldDef;\n        }\n        return null;\n    }\n}\n//# sourceMappingURL=unit.js.map","import { getMarkType } from '../mark';\nimport { isUnitSpec } from '../spec/unit';\nexport class CompositeMarkNormalizer {\n    constructor(name, run) {\n        this.name = name;\n        this.run = run;\n    }\n    hasMatchingType(spec) {\n        if (isUnitSpec(spec)) {\n            return getMarkType(spec.mark) === this.name;\n        }\n        return false;\n    }\n}\n//# sourceMappingURL=base.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isNumber, isObject } from 'vega-util';\nimport { getMarkPropOrConfig } from '../compile/common';\nimport { extractTransformsFromEncoding, normalizeEncoding } from '../encoding';\nimport * as log from '../log';\nimport { isMarkDef } from '../mark';\nimport { isEmpty, omit } from '../util';\nimport { CompositeMarkNormalizer } from './base';\nimport { compositeMarkContinuousAxis, compositeMarkOrient, filterTooltipWithAggregatedField, getCompositeMarkTooltip, getTitle, makeCompositeAggregatePartFactory, partLayerMixins } from './common';\nexport const BOXPLOT = 'boxplot';\nexport const BOXPLOT_PARTS = ['box', 'median', 'outliers', 'rule', 'ticks'];\nexport const boxPlotNormalizer = new CompositeMarkNormalizer(BOXPLOT, normalizeBoxPlot);\nexport function getBoxPlotType(extent) {\n    if (isNumber(extent)) {\n        return 'tukey';\n    }\n    // Ham: If we ever want to, we could add another extent syntax `{kIQR: number}` for the original [Q1-k*IQR, Q3+k*IQR] whisker and call this boxPlotType = `kIQR`. However, I'm not exposing this for now.\n    return extent;\n}\nexport function normalizeBoxPlot(spec, { config }) {\n    var _a, _b;\n    // Need to initEncoding first so we can infer type\n    spec = Object.assign(Object.assign({}, spec), { encoding: normalizeEncoding(spec.encoding, config) });\n    const { mark, encoding: _encoding, selection, projection: _p } = spec, outerSpec = __rest(spec, [\"mark\", \"encoding\", \"selection\", \"projection\"]);\n    const markDef = isMarkDef(mark) ? mark : { type: mark };\n    // TODO(https://github.com/vega/vega-lite/issues/3702): add selection support\n    if (selection) {\n        log.warn(log.message.selectionNotSupported('boxplot'));\n    }\n    const extent = (_a = markDef.extent) !== null && _a !== void 0 ? _a : config.boxplot.extent;\n    const sizeValue = getMarkPropOrConfig('size', markDef, // TODO: https://github.com/vega/vega-lite/issues/6245\n    config);\n    const boxPlotType = getBoxPlotType(extent);\n    const { bins, timeUnits, transform, continuousAxisChannelDef, continuousAxis, groupby, aggregate, encodingWithoutContinuousAxis, ticksOrient, boxOrient, customTooltipWithoutAggregatedField } = boxParams(spec, extent, config);\n    const { color, size } = encodingWithoutContinuousAxis, encodingWithoutSizeColorAndContinuousAxis = __rest(encodingWithoutContinuousAxis, [\"color\", \"size\"]);\n    const makeBoxPlotPart = (sharedEncoding) => {\n        return makeCompositeAggregatePartFactory(markDef, continuousAxis, continuousAxisChannelDef, sharedEncoding, config.boxplot);\n    };\n    const makeBoxPlotExtent = makeBoxPlotPart(encodingWithoutSizeColorAndContinuousAxis);\n    const makeBoxPlotBox = makeBoxPlotPart(encodingWithoutContinuousAxis);\n    const makeBoxPlotMidTick = makeBoxPlotPart(Object.assign(Object.assign({}, encodingWithoutSizeColorAndContinuousAxis), (size ? { size } : {})));\n    const fiveSummaryTooltipEncoding = getCompositeMarkTooltip([\n        { fieldPrefix: boxPlotType === 'min-max' ? 'upper_whisker_' : 'max_', titlePrefix: 'Max' },\n        { fieldPrefix: 'upper_box_', titlePrefix: 'Q3' },\n        { fieldPrefix: 'mid_box_', titlePrefix: 'Median' },\n        { fieldPrefix: 'lower_box_', titlePrefix: 'Q1' },\n        { fieldPrefix: boxPlotType === 'min-max' ? 'lower_whisker_' : 'min_', titlePrefix: 'Min' }\n    ], continuousAxisChannelDef, encodingWithoutContinuousAxis);\n    // ## Whisker Layers\n    const endTick = { type: 'tick', color: 'black', opacity: 1, orient: ticksOrient, invalid: null, aria: false };\n    const whiskerTooltipEncoding = boxPlotType === 'min-max'\n        ? fiveSummaryTooltipEncoding // for min-max, show five-summary tooltip for whisker\n        : // for tukey / k-IQR, just show upper/lower-whisker\n            getCompositeMarkTooltip([\n                { fieldPrefix: 'upper_whisker_', titlePrefix: 'Upper Whisker' },\n                { fieldPrefix: 'lower_whisker_', titlePrefix: 'Lower Whisker' }\n            ], continuousAxisChannelDef, encodingWithoutContinuousAxis);\n    const whiskerLayers = [\n        ...makeBoxPlotExtent({\n            partName: 'rule',\n            mark: { type: 'rule', invalid: null, aria: false },\n            positionPrefix: 'lower_whisker',\n            endPositionPrefix: 'lower_box',\n            extraEncoding: whiskerTooltipEncoding\n        }),\n        ...makeBoxPlotExtent({\n            partName: 'rule',\n            mark: { type: 'rule', invalid: null, aria: false },\n            positionPrefix: 'upper_box',\n            endPositionPrefix: 'upper_whisker',\n            extraEncoding: whiskerTooltipEncoding\n        }),\n        ...makeBoxPlotExtent({\n            partName: 'ticks',\n            mark: endTick,\n            positionPrefix: 'lower_whisker',\n            extraEncoding: whiskerTooltipEncoding\n        }),\n        ...makeBoxPlotExtent({\n            partName: 'ticks',\n            mark: endTick,\n            positionPrefix: 'upper_whisker',\n            extraEncoding: whiskerTooltipEncoding\n        })\n    ];\n    // ## Box Layers\n    // TODO: support hiding certain mark parts\n    const boxLayers = [\n        ...(boxPlotType !== 'tukey' ? whiskerLayers : []),\n        ...makeBoxPlotBox({\n            partName: 'box',\n            mark: Object.assign(Object.assign({ type: 'bar' }, (sizeValue ? { size: sizeValue } : {})), { orient: boxOrient, invalid: null, ariaRoleDescription: 'box' }),\n            positionPrefix: 'lower_box',\n            endPositionPrefix: 'upper_box',\n            extraEncoding: fiveSummaryTooltipEncoding\n        }),\n        ...makeBoxPlotMidTick({\n            partName: 'median',\n            mark: Object.assign(Object.assign(Object.assign({ type: 'tick', invalid: null }, (isObject(config.boxplot.median) && config.boxplot.median.color ? { color: config.boxplot.median.color } : {})), (sizeValue ? { size: sizeValue } : {})), { orient: ticksOrient, aria: false }),\n            positionPrefix: 'mid_box',\n            extraEncoding: fiveSummaryTooltipEncoding\n        })\n    ];\n    if (boxPlotType === 'min-max') {\n        return Object.assign(Object.assign({}, outerSpec), { transform: ((_b = outerSpec.transform) !== null && _b !== void 0 ? _b : []).concat(transform), layer: boxLayers });\n    }\n    // Tukey Box Plot\n    const lowerBoxExpr = `datum[\"lower_box_${continuousAxisChannelDef.field}\"]`;\n    const upperBoxExpr = `datum[\"upper_box_${continuousAxisChannelDef.field}\"]`;\n    const iqrExpr = `(${upperBoxExpr} - ${lowerBoxExpr})`;\n    const lowerWhiskerExpr = `${lowerBoxExpr} - ${extent} * ${iqrExpr}`;\n    const upperWhiskerExpr = `${upperBoxExpr} + ${extent} * ${iqrExpr}`;\n    const fieldExpr = `datum[\"${continuousAxisChannelDef.field}\"]`;\n    const joinaggregateTransform = {\n        joinaggregate: boxParamsQuartiles(continuousAxisChannelDef.field),\n        groupby\n    };\n    const filteredWhiskerSpec = {\n        transform: [\n            {\n                filter: `(${lowerWhiskerExpr} <= ${fieldExpr}) && (${fieldExpr} <= ${upperWhiskerExpr})`\n            },\n            {\n                aggregate: [\n                    {\n                        op: 'min',\n                        field: continuousAxisChannelDef.field,\n                        as: 'lower_whisker_' + continuousAxisChannelDef.field\n                    },\n                    {\n                        op: 'max',\n                        field: continuousAxisChannelDef.field,\n                        as: 'upper_whisker_' + continuousAxisChannelDef.field\n                    },\n                    // preserve lower_box / upper_box\n                    {\n                        op: 'min',\n                        field: 'lower_box_' + continuousAxisChannelDef.field,\n                        as: 'lower_box_' + continuousAxisChannelDef.field\n                    },\n                    {\n                        op: 'max',\n                        field: 'upper_box_' + continuousAxisChannelDef.field,\n                        as: 'upper_box_' + continuousAxisChannelDef.field\n                    },\n                    ...aggregate\n                ],\n                groupby\n            }\n        ],\n        layer: whiskerLayers\n    };\n    const { tooltip } = encodingWithoutSizeColorAndContinuousAxis, encodingWithoutSizeColorContinuousAxisAndTooltip = __rest(encodingWithoutSizeColorAndContinuousAxis, [\"tooltip\"]);\n    const { scale, axis } = continuousAxisChannelDef;\n    const title = getTitle(continuousAxisChannelDef);\n    const axisWithoutTitle = omit(axis, ['title']);\n    const outlierLayersMixins = partLayerMixins(markDef, 'outliers', config.boxplot, {\n        transform: [{ filter: `(${fieldExpr} < ${lowerWhiskerExpr}) || (${fieldExpr} > ${upperWhiskerExpr})` }],\n        mark: 'point',\n        encoding: Object.assign(Object.assign(Object.assign({ [continuousAxis]: Object.assign(Object.assign(Object.assign({ field: continuousAxisChannelDef.field, type: continuousAxisChannelDef.type }, (title !== undefined ? { title } : {})), (scale !== undefined ? { scale } : {})), (isEmpty(axisWithoutTitle) ? {} : { axis: axisWithoutTitle })) }, encodingWithoutSizeColorContinuousAxisAndTooltip), (color ? { color } : {})), (customTooltipWithoutAggregatedField ? { tooltip: customTooltipWithoutAggregatedField } : {}))\n    })[0];\n    let filteredLayersMixins;\n    const filteredLayersMixinsTransforms = [...bins, ...timeUnits, joinaggregateTransform];\n    if (outlierLayersMixins) {\n        filteredLayersMixins = {\n            transform: filteredLayersMixinsTransforms,\n            layer: [outlierLayersMixins, filteredWhiskerSpec]\n        };\n    }\n    else {\n        filteredLayersMixins = filteredWhiskerSpec;\n        filteredLayersMixins.transform.unshift(...filteredLayersMixinsTransforms);\n    }\n    return Object.assign(Object.assign({}, outerSpec), { layer: [\n            filteredLayersMixins,\n            {\n                // boxplot\n                transform,\n                layer: boxLayers\n            }\n        ] });\n}\nfunction boxParamsQuartiles(continousAxisField) {\n    return [\n        {\n            op: 'q1',\n            field: continousAxisField,\n            as: 'lower_box_' + continousAxisField\n        },\n        {\n            op: 'q3',\n            field: continousAxisField,\n            as: 'upper_box_' + continousAxisField\n        }\n    ];\n}\nfunction boxParams(spec, extent, config) {\n    const orient = compositeMarkOrient(spec, BOXPLOT);\n    const { continuousAxisChannelDef, continuousAxis } = compositeMarkContinuousAxis(spec, orient, BOXPLOT);\n    const continuousFieldName = continuousAxisChannelDef.field;\n    const boxPlotType = getBoxPlotType(extent);\n    const boxplotSpecificAggregate = [\n        ...boxParamsQuartiles(continuousFieldName),\n        {\n            op: 'median',\n            field: continuousFieldName,\n            as: 'mid_box_' + continuousFieldName\n        },\n        {\n            op: 'min',\n            field: continuousFieldName,\n            as: (boxPlotType === 'min-max' ? 'lower_whisker_' : 'min_') + continuousFieldName\n        },\n        {\n            op: 'max',\n            field: continuousFieldName,\n            as: (boxPlotType === 'min-max' ? 'upper_whisker_' : 'max_') + continuousFieldName\n        }\n    ];\n    const postAggregateCalculates = boxPlotType === 'min-max' || boxPlotType === 'tukey'\n        ? []\n        : [\n            // This is for the  original k-IQR, which we do not expose\n            {\n                calculate: `datum[\"upper_box_${continuousFieldName}\"] - datum[\"lower_box_${continuousFieldName}\"]`,\n                as: 'iqr_' + continuousFieldName\n            },\n            {\n                calculate: `min(datum[\"upper_box_${continuousFieldName}\"] + datum[\"iqr_${continuousFieldName}\"] * ${extent}, datum[\"max_${continuousFieldName}\"])`,\n                as: 'upper_whisker_' + continuousFieldName\n            },\n            {\n                calculate: `max(datum[\"lower_box_${continuousFieldName}\"] - datum[\"iqr_${continuousFieldName}\"] * ${extent}, datum[\"min_${continuousFieldName}\"])`,\n                as: 'lower_whisker_' + continuousFieldName\n            }\n        ];\n    const _a = spec.encoding, _b = continuousAxis, oldContinuousAxisChannelDef = _a[_b], oldEncodingWithoutContinuousAxis = __rest(_a, [typeof _b === \"symbol\" ? _b : _b + \"\"]);\n    const { customTooltipWithoutAggregatedField, filteredEncoding } = filterTooltipWithAggregatedField(oldEncodingWithoutContinuousAxis);\n    const { bins, timeUnits, aggregate, groupby, encoding: encodingWithoutContinuousAxis } = extractTransformsFromEncoding(filteredEncoding, config);\n    const ticksOrient = orient === 'vertical' ? 'horizontal' : 'vertical';\n    const boxOrient = orient;\n    const transform = [\n        ...bins,\n        ...timeUnits,\n        {\n            aggregate: [...aggregate, ...boxplotSpecificAggregate],\n            groupby\n        },\n        ...postAggregateCalculates\n    ];\n    return {\n        bins,\n        timeUnits,\n        transform,\n        groupby,\n        aggregate,\n        continuousAxisChannelDef,\n        continuousAxis,\n        encodingWithoutContinuousAxis,\n        ticksOrient,\n        boxOrient,\n        customTooltipWithoutAggregatedField\n    };\n}\n//# sourceMappingURL=boxplot.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isArray, isBoolean, isString } from 'vega-util';\nimport { isContinuousFieldOrDatumDef, isFieldDef, isFieldOrDatumDefForTimeFormat } from '../channeldef';\nimport { fieldDefs } from '../encoding';\nimport * as log from '../log';\nimport { isMarkDef } from '../mark';\nimport { getFirstDefined, hash, unique } from '../util';\nimport { isSignalRef } from '../vega.schema';\nimport { toStringFieldDef } from './../channeldef';\nexport function filterTooltipWithAggregatedField(oldEncoding) {\n    const { tooltip } = oldEncoding, filteredEncoding = __rest(oldEncoding, [\"tooltip\"]);\n    if (!tooltip) {\n        return { filteredEncoding };\n    }\n    let customTooltipWithAggregatedField;\n    let customTooltipWithoutAggregatedField;\n    if (isArray(tooltip)) {\n        for (const t of tooltip) {\n            if (t.aggregate) {\n                if (!customTooltipWithAggregatedField) {\n                    customTooltipWithAggregatedField = [];\n                }\n                customTooltipWithAggregatedField.push(t);\n            }\n            else {\n                if (!customTooltipWithoutAggregatedField) {\n                    customTooltipWithoutAggregatedField = [];\n                }\n                customTooltipWithoutAggregatedField.push(t);\n            }\n        }\n        if (customTooltipWithAggregatedField) {\n            filteredEncoding.tooltip = customTooltipWithAggregatedField;\n        }\n    }\n    else {\n        if (tooltip['aggregate']) {\n            filteredEncoding.tooltip = tooltip;\n        }\n        else {\n            customTooltipWithoutAggregatedField = tooltip;\n        }\n    }\n    if (isArray(customTooltipWithoutAggregatedField) && customTooltipWithoutAggregatedField.length === 1) {\n        customTooltipWithoutAggregatedField = customTooltipWithoutAggregatedField[0];\n    }\n    return { customTooltipWithoutAggregatedField, filteredEncoding };\n}\nexport function getCompositeMarkTooltip(tooltipSummary, continuousAxisChannelDef, encodingWithoutContinuousAxis, withFieldName = true) {\n    if ('tooltip' in encodingWithoutContinuousAxis) {\n        return { tooltip: encodingWithoutContinuousAxis.tooltip };\n    }\n    const fiveSummaryTooltip = tooltipSummary.map(({ fieldPrefix, titlePrefix }) => {\n        const mainTitle = withFieldName ? ` of ${getTitle(continuousAxisChannelDef)}` : '';\n        return {\n            field: fieldPrefix + continuousAxisChannelDef.field,\n            type: continuousAxisChannelDef.type,\n            title: isSignalRef(titlePrefix) ? { signal: titlePrefix + `\"${escape(mainTitle)}\"` } : titlePrefix + mainTitle\n        };\n    });\n    const tooltipFieldDefs = fieldDefs(encodingWithoutContinuousAxis).map(toStringFieldDef);\n    return {\n        tooltip: [\n            ...fiveSummaryTooltip,\n            // need to cast because TextFieldDef supports fewer types of bin\n            ...unique(tooltipFieldDefs, hash)\n        ]\n    };\n}\nexport function getTitle(continuousAxisChannelDef) {\n    const { title, field } = continuousAxisChannelDef;\n    return getFirstDefined(title, field);\n}\nexport function makeCompositeAggregatePartFactory(compositeMarkDef, continuousAxis, continuousAxisChannelDef, sharedEncoding, compositeMarkConfig) {\n    const { scale, axis } = continuousAxisChannelDef;\n    return ({ partName, mark, positionPrefix, endPositionPrefix = undefined, extraEncoding = {} }) => {\n        const title = getTitle(continuousAxisChannelDef);\n        return partLayerMixins(compositeMarkDef, partName, compositeMarkConfig, {\n            mark,\n            encoding: Object.assign(Object.assign(Object.assign({ [continuousAxis]: Object.assign(Object.assign(Object.assign({ field: positionPrefix + '_' + continuousAxisChannelDef.field, type: continuousAxisChannelDef.type }, (title !== undefined ? { title } : {})), (scale !== undefined ? { scale } : {})), (axis !== undefined ? { axis } : {})) }, (isString(endPositionPrefix)\n                ? {\n                    [continuousAxis + '2']: {\n                        field: endPositionPrefix + '_' + continuousAxisChannelDef.field\n                    }\n                }\n                : {})), sharedEncoding), extraEncoding)\n        });\n    };\n}\nexport function partLayerMixins(markDef, part, compositeMarkConfig, partBaseSpec) {\n    const { clip, color, opacity } = markDef;\n    const mark = markDef.type;\n    if (markDef[part] || (markDef[part] === undefined && compositeMarkConfig[part])) {\n        return [\n            Object.assign(Object.assign({}, partBaseSpec), { mark: Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, compositeMarkConfig[part]), (clip ? { clip } : {})), (color ? { color } : {})), (opacity ? { opacity } : {})), (isMarkDef(partBaseSpec.mark) ? partBaseSpec.mark : { type: partBaseSpec.mark })), { style: `${mark}-${part}` }), (isBoolean(markDef[part]) ? {} : markDef[part])) })\n        ];\n    }\n    return [];\n}\nexport function compositeMarkContinuousAxis(spec, orient, compositeMark) {\n    const { encoding } = spec;\n    const continuousAxis = orient === 'vertical' ? 'y' : 'x';\n    const continuousAxisChannelDef = encoding[continuousAxis]; // Safe to cast because if x is not continuous fielddef, the orient would not be horizontal.\n    const continuousAxisChannelDef2 = encoding[continuousAxis + '2'];\n    const continuousAxisChannelDefError = encoding[continuousAxis + 'Error'];\n    const continuousAxisChannelDefError2 = encoding[continuousAxis + 'Error2'];\n    return {\n        continuousAxisChannelDef: filterAggregateFromChannelDef(continuousAxisChannelDef, compositeMark),\n        continuousAxisChannelDef2: filterAggregateFromChannelDef(continuousAxisChannelDef2, compositeMark),\n        continuousAxisChannelDefError: filterAggregateFromChannelDef(continuousAxisChannelDefError, compositeMark),\n        continuousAxisChannelDefError2: filterAggregateFromChannelDef(continuousAxisChannelDefError2, compositeMark),\n        continuousAxis\n    };\n}\nfunction filterAggregateFromChannelDef(continuousAxisChannelDef, compositeMark) {\n    if (continuousAxisChannelDef && continuousAxisChannelDef.aggregate) {\n        const { aggregate } = continuousAxisChannelDef, continuousAxisWithoutAggregate = __rest(continuousAxisChannelDef, [\"aggregate\"]);\n        if (aggregate !== compositeMark) {\n            log.warn(log.message.errorBarContinuousAxisHasCustomizedAggregate(aggregate, compositeMark));\n        }\n        return continuousAxisWithoutAggregate;\n    }\n    else {\n        return continuousAxisChannelDef;\n    }\n}\nexport function compositeMarkOrient(spec, compositeMark) {\n    const { mark, encoding } = spec;\n    const { x, y } = encoding;\n    if (isMarkDef(mark) && mark.orient) {\n        return mark.orient;\n    }\n    if (isContinuousFieldOrDatumDef(x)) {\n        // x is continuous\n        if (isContinuousFieldOrDatumDef(y)) {\n            // both x and y are continuous\n            const xAggregate = isFieldDef(x) && x.aggregate;\n            const yAggregate = isFieldDef(y) && y.aggregate;\n            if (!xAggregate && yAggregate === compositeMark) {\n                return 'vertical';\n            }\n            else if (!yAggregate && xAggregate === compositeMark) {\n                return 'horizontal';\n            }\n            else if (xAggregate === compositeMark && yAggregate === compositeMark) {\n                throw new Error('Both x and y cannot have aggregate');\n            }\n            else {\n                if (isFieldOrDatumDefForTimeFormat(y) && !isFieldOrDatumDefForTimeFormat(x)) {\n                    // y is temporal but x is not\n                    return 'horizontal';\n                }\n                // default orientation for two continuous\n                return 'vertical';\n            }\n        }\n        return 'horizontal';\n    }\n    else if (isContinuousFieldOrDatumDef(y)) {\n        // y is continuous but x is not\n        return 'vertical';\n    }\n    else {\n        // Neither x nor y is continuous.\n        throw new Error(`Need a valid continuous axis for ${compositeMark}s`);\n    }\n}\n//# sourceMappingURL=common.js.map","import { normalizeEncoding } from '../encoding';\nimport * as log from '../log';\nimport { CompositeMarkNormalizer } from './base';\nimport { makeCompositeAggregatePartFactory } from './common';\nimport { errorBarParams } from './errorbar';\nexport const ERRORBAND = 'errorband';\nexport const ERRORBAND_PARTS = ['band', 'borders'];\nexport const errorBandNormalizer = new CompositeMarkNormalizer(ERRORBAND, normalizeErrorBand);\nexport function normalizeErrorBand(spec, { config }) {\n    // Need to initEncoding first so we can infer type\n    spec = Object.assign(Object.assign({}, spec), { encoding: normalizeEncoding(spec.encoding, config) });\n    const { transform, continuousAxisChannelDef, continuousAxis, encodingWithoutContinuousAxis, markDef, outerSpec, tooltipEncoding } = errorBarParams(spec, ERRORBAND, config);\n    const errorBandDef = markDef;\n    const makeErrorBandPart = makeCompositeAggregatePartFactory(errorBandDef, continuousAxis, continuousAxisChannelDef, encodingWithoutContinuousAxis, config.errorband);\n    const is2D = spec.encoding.x !== undefined && spec.encoding.y !== undefined;\n    let bandMark = { type: is2D ? 'area' : 'rect' };\n    let bordersMark = { type: is2D ? 'line' : 'rule' };\n    const interpolate = Object.assign(Object.assign({}, (errorBandDef.interpolate ? { interpolate: errorBandDef.interpolate } : {})), (errorBandDef.tension && errorBandDef.interpolate ? { tension: errorBandDef.tension } : {}));\n    if (is2D) {\n        bandMark = Object.assign(Object.assign(Object.assign({}, bandMark), interpolate), { ariaRoleDescription: 'errorband' });\n        bordersMark = Object.assign(Object.assign(Object.assign({}, bordersMark), interpolate), { aria: false });\n    }\n    else if (errorBandDef.interpolate) {\n        log.warn(log.message.errorBand1DNotSupport('interpolate'));\n    }\n    else if (errorBandDef.tension) {\n        log.warn(log.message.errorBand1DNotSupport('tension'));\n    }\n    return Object.assign(Object.assign({}, outerSpec), { transform, layer: [\n            ...makeErrorBandPart({\n                partName: 'band',\n                mark: bandMark,\n                positionPrefix: 'lower',\n                endPositionPrefix: 'upper',\n                extraEncoding: tooltipEncoding\n            }),\n            ...makeErrorBandPart({\n                partName: 'borders',\n                mark: bordersMark,\n                positionPrefix: 'lower',\n                extraEncoding: tooltipEncoding\n            }),\n            ...makeErrorBandPart({\n                partName: 'borders',\n                mark: bordersMark,\n                positionPrefix: 'upper',\n                extraEncoding: tooltipEncoding\n            })\n        ] });\n}\n//# sourceMappingURL=errorband.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isContinuousFieldOrDatumDef, isFieldOrDatumDef, title } from '../channeldef';\nimport { extractTransformsFromEncoding, normalizeEncoding } from '../encoding';\nimport * as log from '../log';\nimport { isMarkDef } from '../mark';\nimport { replaceAll, titleCase } from '../util';\nimport { CompositeMarkNormalizer } from './base';\nimport { compositeMarkContinuousAxis, compositeMarkOrient, getCompositeMarkTooltip, makeCompositeAggregatePartFactory } from './common';\nexport const ERRORBAR = 'errorbar';\nexport const ERRORBAR_PARTS = ['ticks', 'rule'];\nexport const errorBarNormalizer = new CompositeMarkNormalizer(ERRORBAR, normalizeErrorBar);\nexport function normalizeErrorBar(spec, { config }) {\n    // Need to initEncoding first so we can infer type\n    spec = Object.assign(Object.assign({}, spec), { encoding: normalizeEncoding(spec.encoding, config) });\n    const { transform, continuousAxisChannelDef, continuousAxis, encodingWithoutContinuousAxis, ticksOrient, markDef, outerSpec, tooltipEncoding } = errorBarParams(spec, ERRORBAR, config);\n    delete encodingWithoutContinuousAxis['size'];\n    const makeErrorBarPart = makeCompositeAggregatePartFactory(markDef, continuousAxis, continuousAxisChannelDef, encodingWithoutContinuousAxis, config.errorbar);\n    const thickness = markDef.thickness;\n    const size = markDef.size;\n    const tick = Object.assign(Object.assign({ type: 'tick', orient: ticksOrient, aria: false }, (thickness !== undefined ? { thickness } : {})), (size !== undefined ? { size } : {}));\n    const layer = [\n        ...makeErrorBarPart({\n            partName: 'ticks',\n            mark: tick,\n            positionPrefix: 'lower',\n            extraEncoding: tooltipEncoding\n        }),\n        ...makeErrorBarPart({\n            partName: 'ticks',\n            mark: tick,\n            positionPrefix: 'upper',\n            extraEncoding: tooltipEncoding\n        }),\n        ...makeErrorBarPart({\n            partName: 'rule',\n            mark: Object.assign({ type: 'rule', ariaRoleDescription: 'errorbar' }, (thickness !== undefined ? { size: thickness } : {})),\n            positionPrefix: 'lower',\n            endPositionPrefix: 'upper',\n            extraEncoding: tooltipEncoding\n        })\n    ];\n    return Object.assign(Object.assign(Object.assign({}, outerSpec), { transform }), (layer.length > 1 ? { layer } : Object.assign({}, layer[0])));\n}\nfunction errorBarOrientAndInputType(spec, compositeMark) {\n    const { encoding } = spec;\n    if (errorBarIsInputTypeRaw(encoding)) {\n        return {\n            orient: compositeMarkOrient(spec, compositeMark),\n            inputType: 'raw'\n        };\n    }\n    const isTypeAggregatedUpperLower = errorBarIsInputTypeAggregatedUpperLower(encoding);\n    const isTypeAggregatedError = errorBarIsInputTypeAggregatedError(encoding);\n    const x = encoding.x;\n    const y = encoding.y;\n    if (isTypeAggregatedUpperLower) {\n        // type is aggregated-upper-lower\n        if (isTypeAggregatedError) {\n            throw new Error(`${compositeMark} cannot be both type aggregated-upper-lower and aggregated-error`);\n        }\n        const x2 = encoding.x2;\n        const y2 = encoding.y2;\n        if (isFieldOrDatumDef(x2) && isFieldOrDatumDef(y2)) {\n            // having both x, x2 and y, y2\n            throw new Error(`${compositeMark} cannot have both x2 and y2`);\n        }\n        else if (isFieldOrDatumDef(x2)) {\n            if (isContinuousFieldOrDatumDef(x)) {\n                // having x, x2 quantitative and field y, y2 are not specified\n                return { orient: 'horizontal', inputType: 'aggregated-upper-lower' };\n            }\n            else {\n                // having x, x2 that are not both quantitative\n                throw new Error(`Both x and x2 have to be quantitative in ${compositeMark}`);\n            }\n        }\n        else if (isFieldOrDatumDef(y2)) {\n            // y2 is a FieldDef\n            if (isContinuousFieldOrDatumDef(y)) {\n                // having y, y2 quantitative and field x, x2 are not specified\n                return { orient: 'vertical', inputType: 'aggregated-upper-lower' };\n            }\n            else {\n                // having y, y2 that are not both quantitative\n                throw new Error(`Both y and y2 have to be quantitative in ${compositeMark}`);\n            }\n        }\n        throw new Error('No ranged axis');\n    }\n    else {\n        // type is aggregated-error\n        const xError = encoding.xError;\n        const xError2 = encoding.xError2;\n        const yError = encoding.yError;\n        const yError2 = encoding.yError2;\n        if (isFieldOrDatumDef(xError2) && !isFieldOrDatumDef(xError)) {\n            // having xError2 without xError\n            throw new Error(`${compositeMark} cannot have xError2 without xError`);\n        }\n        if (isFieldOrDatumDef(yError2) && !isFieldOrDatumDef(yError)) {\n            // having yError2 without yError\n            throw new Error(`${compositeMark} cannot have yError2 without yError`);\n        }\n        if (isFieldOrDatumDef(xError) && isFieldOrDatumDef(yError)) {\n            // having both xError and yError\n            throw new Error(`${compositeMark} cannot have both xError and yError with both are quantiative`);\n        }\n        else if (isFieldOrDatumDef(xError)) {\n            if (isContinuousFieldOrDatumDef(x)) {\n                // having x and xError that are all quantitative\n                return { orient: 'horizontal', inputType: 'aggregated-error' };\n            }\n            else {\n                // having x, xError, and xError2 that are not all quantitative\n                throw new Error('All x, xError, and xError2 (if exist) have to be quantitative');\n            }\n        }\n        else if (isFieldOrDatumDef(yError)) {\n            if (isContinuousFieldOrDatumDef(y)) {\n                // having y and yError that are all quantitative\n                return { orient: 'vertical', inputType: 'aggregated-error' };\n            }\n            else {\n                // having y, yError, and yError2 that are not all quantitative\n                throw new Error('All y, yError, and yError2 (if exist) have to be quantitative');\n            }\n        }\n        throw new Error('No ranged axis');\n    }\n}\nfunction errorBarIsInputTypeRaw(encoding) {\n    return ((isFieldOrDatumDef(encoding.x) || isFieldOrDatumDef(encoding.y)) &&\n        !isFieldOrDatumDef(encoding.x2) &&\n        !isFieldOrDatumDef(encoding.y2) &&\n        !isFieldOrDatumDef(encoding.xError) &&\n        !isFieldOrDatumDef(encoding.xError2) &&\n        !isFieldOrDatumDef(encoding.yError) &&\n        !isFieldOrDatumDef(encoding.yError2));\n}\nfunction errorBarIsInputTypeAggregatedUpperLower(encoding) {\n    return isFieldOrDatumDef(encoding.x2) || isFieldOrDatumDef(encoding.y2);\n}\nfunction errorBarIsInputTypeAggregatedError(encoding) {\n    return (isFieldOrDatumDef(encoding.xError) ||\n        isFieldOrDatumDef(encoding.xError2) ||\n        isFieldOrDatumDef(encoding.yError) ||\n        isFieldOrDatumDef(encoding.yError2));\n}\nexport function errorBarParams(spec, compositeMark, config) {\n    var _a;\n    // TODO: use selection\n    const { mark, encoding, selection, projection: _p } = spec, outerSpec = __rest(spec, [\"mark\", \"encoding\", \"selection\", \"projection\"]);\n    const markDef = isMarkDef(mark) ? mark : { type: mark };\n    // TODO(https://github.com/vega/vega-lite/issues/3702): add selection support\n    if (selection) {\n        log.warn(log.message.selectionNotSupported(compositeMark));\n    }\n    const { orient, inputType } = errorBarOrientAndInputType(spec, compositeMark);\n    const { continuousAxisChannelDef, continuousAxisChannelDef2, continuousAxisChannelDefError, continuousAxisChannelDefError2, continuousAxis } = compositeMarkContinuousAxis(spec, orient, compositeMark);\n    const { errorBarSpecificAggregate, postAggregateCalculates, tooltipSummary, tooltipTitleWithFieldName } = errorBarAggregationAndCalculation(markDef, continuousAxisChannelDef, continuousAxisChannelDef2, continuousAxisChannelDefError, continuousAxisChannelDefError2, inputType, compositeMark, config);\n    const _b = encoding, _c = continuousAxis, oldContinuousAxisChannelDef = _b[_c], _d = continuousAxis === 'x' ? 'x2' : 'y2', oldContinuousAxisChannelDef2 = _b[_d], _e = continuousAxis === 'x' ? 'xError' : 'yError', oldContinuousAxisChannelDefError = _b[_e], _f = continuousAxis === 'x' ? 'xError2' : 'yError2', oldContinuousAxisChannelDefError2 = _b[_f], oldEncodingWithoutContinuousAxis = __rest(_b, [typeof _c === \"symbol\" ? _c : _c + \"\", typeof _d === \"symbol\" ? _d : _d + \"\", typeof _e === \"symbol\" ? _e : _e + \"\", typeof _f === \"symbol\" ? _f : _f + \"\"]);\n    const { bins, timeUnits, aggregate: oldAggregate, groupby: oldGroupBy, encoding: encodingWithoutContinuousAxis } = extractTransformsFromEncoding(oldEncodingWithoutContinuousAxis, config);\n    const aggregate = [...oldAggregate, ...errorBarSpecificAggregate];\n    const groupby = inputType !== 'raw' ? [] : oldGroupBy;\n    const tooltipEncoding = getCompositeMarkTooltip(tooltipSummary, continuousAxisChannelDef, encodingWithoutContinuousAxis, tooltipTitleWithFieldName);\n    return {\n        transform: [\n            ...((_a = outerSpec.transform) !== null && _a !== void 0 ? _a : []),\n            ...bins,\n            ...timeUnits,\n            ...(aggregate.length === 0 ? [] : [{ aggregate, groupby }]),\n            ...postAggregateCalculates\n        ],\n        groupby,\n        continuousAxisChannelDef,\n        continuousAxis,\n        encodingWithoutContinuousAxis,\n        ticksOrient: orient === 'vertical' ? 'horizontal' : 'vertical',\n        markDef,\n        outerSpec,\n        tooltipEncoding\n    };\n}\nfunction errorBarAggregationAndCalculation(markDef, continuousAxisChannelDef, continuousAxisChannelDef2, continuousAxisChannelDefError, continuousAxisChannelDefError2, inputType, compositeMark, config) {\n    let errorBarSpecificAggregate = [];\n    let postAggregateCalculates = [];\n    const continuousFieldName = continuousAxisChannelDef.field;\n    let tooltipSummary;\n    let tooltipTitleWithFieldName = false;\n    if (inputType === 'raw') {\n        const center = markDef.center\n            ? markDef.center\n            : markDef.extent\n                ? markDef.extent === 'iqr'\n                    ? 'median'\n                    : 'mean'\n                : config.errorbar.center;\n        const extent = markDef.extent ? markDef.extent : center === 'mean' ? 'stderr' : 'iqr';\n        if ((center === 'median') !== (extent === 'iqr')) {\n            log.warn(log.message.errorBarCenterIsUsedWithWrongExtent(center, extent, compositeMark));\n        }\n        if (extent === 'stderr' || extent === 'stdev') {\n            errorBarSpecificAggregate = [\n                { op: extent, field: continuousFieldName, as: 'extent_' + continuousFieldName },\n                { op: center, field: continuousFieldName, as: 'center_' + continuousFieldName }\n            ];\n            postAggregateCalculates = [\n                {\n                    calculate: `datum[\"center_${continuousFieldName}\"] + datum[\"extent_${continuousFieldName}\"]`,\n                    as: 'upper_' + continuousFieldName\n                },\n                {\n                    calculate: `datum[\"center_${continuousFieldName}\"] - datum[\"extent_${continuousFieldName}\"]`,\n                    as: 'lower_' + continuousFieldName\n                }\n            ];\n            tooltipSummary = [\n                { fieldPrefix: 'center_', titlePrefix: titleCase(center) },\n                { fieldPrefix: 'upper_', titlePrefix: getTitlePrefix(center, extent, '+') },\n                { fieldPrefix: 'lower_', titlePrefix: getTitlePrefix(center, extent, '-') }\n            ];\n            tooltipTitleWithFieldName = true;\n        }\n        else {\n            let centerOp;\n            let lowerExtentOp;\n            let upperExtentOp;\n            if (extent === 'ci') {\n                centerOp = 'mean';\n                lowerExtentOp = 'ci0';\n                upperExtentOp = 'ci1';\n            }\n            else {\n                centerOp = 'median';\n                lowerExtentOp = 'q1';\n                upperExtentOp = 'q3';\n            }\n            errorBarSpecificAggregate = [\n                { op: lowerExtentOp, field: continuousFieldName, as: 'lower_' + continuousFieldName },\n                { op: upperExtentOp, field: continuousFieldName, as: 'upper_' + continuousFieldName },\n                { op: centerOp, field: continuousFieldName, as: 'center_' + continuousFieldName }\n            ];\n            tooltipSummary = [\n                {\n                    fieldPrefix: 'upper_',\n                    titlePrefix: title({ field: continuousFieldName, aggregate: upperExtentOp, type: 'quantitative' }, config, {\n                        allowDisabling: false\n                    })\n                },\n                {\n                    fieldPrefix: 'lower_',\n                    titlePrefix: title({ field: continuousFieldName, aggregate: lowerExtentOp, type: 'quantitative' }, config, {\n                        allowDisabling: false\n                    })\n                },\n                {\n                    fieldPrefix: 'center_',\n                    titlePrefix: title({ field: continuousFieldName, aggregate: centerOp, type: 'quantitative' }, config, {\n                        allowDisabling: false\n                    })\n                }\n            ];\n        }\n    }\n    else {\n        if (markDef.center || markDef.extent) {\n            log.warn(log.message.errorBarCenterAndExtentAreNotNeeded(markDef.center, markDef.extent));\n        }\n        if (inputType === 'aggregated-upper-lower') {\n            tooltipSummary = [];\n            postAggregateCalculates = [\n                { calculate: `datum[\"${continuousAxisChannelDef2.field}\"]`, as: 'upper_' + continuousFieldName },\n                { calculate: `datum[\"${continuousFieldName}\"]`, as: 'lower_' + continuousFieldName }\n            ];\n        }\n        else if (inputType === 'aggregated-error') {\n            tooltipSummary = [{ fieldPrefix: '', titlePrefix: continuousFieldName }];\n            postAggregateCalculates = [\n                {\n                    calculate: `datum[\"${continuousFieldName}\"] + datum[\"${continuousAxisChannelDefError.field}\"]`,\n                    as: 'upper_' + continuousFieldName\n                }\n            ];\n            if (continuousAxisChannelDefError2) {\n                postAggregateCalculates.push({\n                    calculate: `datum[\"${continuousFieldName}\"] + datum[\"${continuousAxisChannelDefError2.field}\"]`,\n                    as: 'lower_' + continuousFieldName\n                });\n            }\n            else {\n                postAggregateCalculates.push({\n                    calculate: `datum[\"${continuousFieldName}\"] - datum[\"${continuousAxisChannelDefError.field}\"]`,\n                    as: 'lower_' + continuousFieldName\n                });\n            }\n        }\n        for (const postAggregateCalculate of postAggregateCalculates) {\n            tooltipSummary.push({\n                fieldPrefix: postAggregateCalculate.as.substring(0, 6),\n                titlePrefix: replaceAll(replaceAll(postAggregateCalculate.calculate, 'datum[\"', ''), '\"]', '')\n            });\n        }\n    }\n    return { postAggregateCalculates, errorBarSpecificAggregate, tooltipSummary, tooltipTitleWithFieldName };\n}\nfunction getTitlePrefix(center, extent, operation) {\n    return titleCase(center) + ' ' + operation + ' ' + extent;\n}\n//# sourceMappingURL=errorbar.js.map","import { keys } from '../util';\nimport { CompositeMarkNormalizer } from './base';\nimport { BOXPLOT, BOXPLOT_PARTS, normalizeBoxPlot } from './boxplot';\nimport { ERRORBAND, ERRORBAND_PARTS, normalizeErrorBand } from './errorband';\nimport { ERRORBAR, ERRORBAR_PARTS, normalizeErrorBar } from './errorbar';\n/**\n * Registry index for all composite mark's normalizer\n */\nconst compositeMarkRegistry = {};\nexport function add(mark, run, parts) {\n    const normalizer = new CompositeMarkNormalizer(mark, run);\n    compositeMarkRegistry[mark] = { normalizer, parts };\n}\nexport function remove(mark) {\n    delete compositeMarkRegistry[mark];\n}\nexport function getAllCompositeMarks() {\n    return keys(compositeMarkRegistry);\n}\nadd(BOXPLOT, normalizeBoxPlot, BOXPLOT_PARTS);\nadd(ERRORBAR, normalizeErrorBar, ERRORBAR_PARTS);\nadd(ERRORBAND, normalizeErrorBand, ERRORBAND_PARTS);\n//# sourceMappingURL=index.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isObject, mergeConfig } from 'vega-util';\nimport { AXIS_CONFIGS, isConditionalAxisValue } from './axis';\nimport { signalOrValueRefWithCondition, signalRefOrValue } from './compile/common';\nimport { getAllCompositeMarks } from './compositemark';\nimport { replaceExprRefInIndex } from './expr';\nimport { VL_ONLY_LEGEND_CONFIG } from './guide';\nimport { HEADER_CONFIGS } from './header';\nimport { defaultLegendConfig } from './legend';\nimport * as mark from './mark';\nimport { MARK_CONFIGS, PRIMITIVE_MARKS, VL_ONLY_MARK_CONFIG_PROPERTIES, VL_ONLY_MARK_SPECIFIC_CONFIG_PROPERTY_INDEX } from './mark';\nimport { assembleParameterSignals } from './parameter';\nimport { defaultScaleConfig } from './scale';\nimport { defaultConfig as defaultSelectionConfig } from './selection';\nimport { DEFAULT_SPACING, isStep } from './spec/base';\nimport { extractTitleConfig } from './title';\nimport { duplicate, getFirstDefined, isEmpty, keys, omit } from './util';\nexport function getViewConfigContinuousSize(viewConfig, channel) {\n    var _a;\n    return (_a = viewConfig[channel]) !== null && _a !== void 0 ? _a : viewConfig[channel === 'width' ? 'continuousWidth' : 'continuousHeight']; // get width/height for backwards compatibility\n}\nexport function getViewConfigDiscreteStep(viewConfig, channel) {\n    const size = getViewConfigDiscreteSize(viewConfig, channel);\n    return isStep(size) ? size.step : DEFAULT_STEP;\n}\nexport function getViewConfigDiscreteSize(viewConfig, channel) {\n    var _a;\n    const size = (_a = viewConfig[channel]) !== null && _a !== void 0 ? _a : viewConfig[channel === 'width' ? 'discreteWidth' : 'discreteHeight']; // get width/height for backwards compatibility\n    return getFirstDefined(size, { step: viewConfig.step });\n}\nexport const DEFAULT_STEP = 20;\nexport const defaultViewConfig = {\n    continuousWidth: 200,\n    continuousHeight: 200,\n    step: DEFAULT_STEP\n};\nexport function isVgScheme(rangeScheme) {\n    return rangeScheme && !!rangeScheme['scheme'];\n}\nexport const defaultConfig = {\n    background: 'white',\n    padding: 5,\n    timeFormat: '%b %d, %Y',\n    countTitle: 'Count of Records',\n    view: defaultViewConfig,\n    mark: mark.defaultMarkConfig,\n    arc: {},\n    area: {},\n    bar: mark.defaultBarConfig,\n    circle: {},\n    geoshape: {},\n    image: {},\n    line: {},\n    point: {},\n    rect: mark.defaultRectConfig,\n    rule: { color: 'black' },\n    square: {},\n    text: { color: 'black' },\n    tick: mark.defaultTickConfig,\n    trail: {},\n    boxplot: {\n        size: 14,\n        extent: 1.5,\n        box: {},\n        median: { color: 'white' },\n        outliers: {},\n        rule: {},\n        ticks: null\n    },\n    errorbar: {\n        center: 'mean',\n        rule: true,\n        ticks: false\n    },\n    errorband: {\n        band: {\n            opacity: 0.3\n        },\n        borders: false\n    },\n    scale: defaultScaleConfig,\n    projection: {},\n    legend: defaultLegendConfig,\n    header: { titlePadding: 10, labelPadding: 10 },\n    headerColumn: {},\n    headerRow: {},\n    headerFacet: {},\n    selection: defaultSelectionConfig,\n    style: {},\n    title: {},\n    facet: { spacing: DEFAULT_SPACING },\n    concat: { spacing: DEFAULT_SPACING }\n};\n// Tableau10 color palette, copied from `vegaScale.scheme('tableau10')`\nconst tab10 = [\n    '#4c78a8',\n    '#f58518',\n    '#e45756',\n    '#72b7b2',\n    '#54a24b',\n    '#eeca3b',\n    '#b279a2',\n    '#ff9da6',\n    '#9d755d',\n    '#bab0ac'\n];\nexport const DEFAULT_FONT_SIZE = {\n    text: 11,\n    guideLabel: 10,\n    guideTitle: 11,\n    groupTitle: 13,\n    groupSubtitle: 12\n};\nexport const DEFAULT_COLOR = {\n    blue: tab10[0],\n    orange: tab10[1],\n    red: tab10[2],\n    teal: tab10[3],\n    green: tab10[4],\n    yellow: tab10[5],\n    purple: tab10[6],\n    pink: tab10[7],\n    brown: tab10[8],\n    gray0: '#000',\n    gray1: '#111',\n    gray2: '#222',\n    gray3: '#333',\n    gray4: '#444',\n    gray5: '#555',\n    gray6: '#666',\n    gray7: '#777',\n    gray8: '#888',\n    gray9: '#999',\n    gray10: '#aaa',\n    gray11: '#bbb',\n    gray12: '#ccc',\n    gray13: '#ddd',\n    gray14: '#eee',\n    gray15: '#fff'\n};\nexport function colorSignalConfig(color = {}) {\n    return {\n        signals: [\n            {\n                name: 'color',\n                value: isObject(color) ? Object.assign(Object.assign({}, DEFAULT_COLOR), color) : DEFAULT_COLOR\n            }\n        ],\n        mark: { color: { signal: 'color.blue' } },\n        rule: { color: { signal: 'color.gray0' } },\n        text: {\n            color: { signal: 'color.gray0' }\n        },\n        style: {\n            'guide-label': {\n                fill: { signal: 'color.gray0' }\n            },\n            'guide-title': {\n                fill: { signal: 'color.gray0' }\n            },\n            'group-title': {\n                fill: { signal: 'color.gray0' }\n            },\n            'group-subtitle': {\n                fill: { signal: 'color.gray0' }\n            },\n            cell: {\n                stroke: { signal: 'color.gray8' }\n            }\n        },\n        axis: {\n            domainColor: { signal: 'color.gray13' },\n            gridColor: { signal: 'color.gray8' },\n            tickColor: { signal: 'color.gray13' }\n        },\n        range: {\n            category: [\n                { signal: 'color.blue' },\n                { signal: 'color.orange' },\n                { signal: 'color.red' },\n                { signal: 'color.teal' },\n                { signal: 'color.green' },\n                { signal: 'color.yellow' },\n                { signal: 'color.purple' },\n                { signal: 'color.pink' },\n                { signal: 'color.brown' },\n                { signal: 'color.grey8' }\n            ]\n        }\n    };\n}\nexport function fontSizeSignalConfig(fontSize) {\n    return {\n        signals: [\n            {\n                name: 'fontSize',\n                value: isObject(fontSize) ? Object.assign(Object.assign({}, DEFAULT_FONT_SIZE), fontSize) : DEFAULT_FONT_SIZE\n            }\n        ],\n        text: {\n            fontSize: { signal: 'fontSize.text' }\n        },\n        style: {\n            'guide-label': {\n                fontSize: { signal: 'fontSize.guideLabel' }\n            },\n            'guide-title': {\n                fontSize: { signal: 'fontSize.guideTitle' }\n            },\n            'group-title': {\n                fontSize: { signal: 'fontSize.groupTitle' }\n            },\n            'group-subtitle': {\n                fontSize: { signal: 'fontSize.groupSubtitle' }\n            }\n        }\n    };\n}\nexport function fontConfig(font) {\n    return {\n        text: { font },\n        style: {\n            'guide-label': { font },\n            'guide-title': { font },\n            'group-title': { font },\n            'group-subtitle': { font }\n        }\n    };\n}\nfunction getAxisConfigInternal(axisConfig) {\n    const props = keys(axisConfig || {});\n    const axisConfigInternal = {};\n    for (const prop of props) {\n        const val = axisConfig[prop];\n        axisConfigInternal[prop] = isConditionalAxisValue(val)\n            ? signalOrValueRefWithCondition(val)\n            : signalRefOrValue(val);\n    }\n    return axisConfigInternal;\n}\nfunction getStyleConfigInternal(styleConfig) {\n    const props = keys(styleConfig);\n    const styleConfigInternal = {};\n    for (const prop of props) {\n        // We need to cast to cheat a bit here since styleConfig can be either mark config or axis config\n        styleConfigInternal[prop] = getAxisConfigInternal(styleConfig[prop]);\n    }\n    return styleConfigInternal;\n}\nconst configPropsWithExpr = [\n    ...MARK_CONFIGS,\n    ...AXIS_CONFIGS,\n    ...HEADER_CONFIGS,\n    'background',\n    'padding',\n    'legend',\n    'lineBreak',\n    'scale',\n    'style',\n    'title',\n    'view'\n];\n/**\n * Merge specified config with default config and config for the `color` flag,\n * then replace all expressions with signals\n */\nexport function initConfig(specifiedConfig = {}) {\n    const { color, font, fontSize } = specifiedConfig, restConfig = __rest(specifiedConfig, [\"color\", \"font\", \"fontSize\"]);\n    const mergedConfig = mergeConfig({}, defaultConfig, font ? fontConfig(font) : {}, color ? colorSignalConfig(color) : {}, fontSize ? fontSizeSignalConfig(fontSize) : {}, restConfig || {});\n    const outputConfig = omit(mergedConfig, configPropsWithExpr);\n    for (const prop of ['background', 'lineBreak', 'padding']) {\n        if (mergedConfig[prop]) {\n            outputConfig[prop] = signalRefOrValue(mergedConfig[prop]);\n        }\n    }\n    for (const markConfigType of mark.MARK_CONFIGS) {\n        if (mergedConfig[markConfigType]) {\n            outputConfig[markConfigType] = replaceExprRefInIndex(mergedConfig[markConfigType]);\n        }\n    }\n    for (const axisConfigType of AXIS_CONFIGS) {\n        if (mergedConfig[axisConfigType]) {\n            outputConfig[axisConfigType] = getAxisConfigInternal(mergedConfig[axisConfigType]);\n        }\n    }\n    for (const headerConfigType of HEADER_CONFIGS) {\n        if (mergedConfig[headerConfigType]) {\n            outputConfig[headerConfigType] = replaceExprRefInIndex(mergedConfig[headerConfigType]);\n        }\n    }\n    if (mergedConfig.legend) {\n        outputConfig.legend = replaceExprRefInIndex(mergedConfig.legend);\n    }\n    if (mergedConfig.scale) {\n        outputConfig.scale = replaceExprRefInIndex(mergedConfig.scale);\n    }\n    if (mergedConfig.style) {\n        outputConfig.style = getStyleConfigInternal(mergedConfig.style);\n    }\n    if (mergedConfig.title) {\n        outputConfig.title = replaceExprRefInIndex(mergedConfig.title);\n    }\n    if (mergedConfig.view) {\n        outputConfig.view = replaceExprRefInIndex(mergedConfig.view);\n    }\n    return outputConfig;\n}\nconst MARK_STYLES = ['view', ...PRIMITIVE_MARKS];\nconst VL_ONLY_CONFIG_PROPERTIES = [\n    'color',\n    'fontSize',\n    'background',\n    'padding',\n    'facet',\n    'concat',\n    'numberFormat',\n    'timeFormat',\n    'countTitle',\n    'header',\n    'axisQuantitative',\n    'axisTemporal',\n    'axisDiscrete',\n    'axisPoint',\n    'axisXBand',\n    'axisXPoint',\n    'axisXDiscrete',\n    'axisXQuantitative',\n    'axisXTemporal',\n    'axisYBand',\n    'axisYPoint',\n    'axisYDiscrete',\n    'axisYQuantitative',\n    'axisYTemporal',\n    'scale',\n    'selection',\n    'overlay' // FIXME: Redesign and unhide this\n];\nconst VL_ONLY_ALL_MARK_SPECIFIC_CONFIG_PROPERTY_INDEX = Object.assign({ view: ['continuousWidth', 'continuousHeight', 'discreteWidth', 'discreteHeight', 'step'] }, VL_ONLY_MARK_SPECIFIC_CONFIG_PROPERTY_INDEX);\nexport function stripAndRedirectConfig(config) {\n    config = duplicate(config);\n    for (const prop of VL_ONLY_CONFIG_PROPERTIES) {\n        delete config[prop];\n    }\n    if (config.axis) {\n        // delete condition axis config\n        for (const prop in config.axis) {\n            if (isConditionalAxisValue(config.axis[prop])) {\n                delete config.axis[prop];\n            }\n        }\n    }\n    if (config.legend) {\n        for (const prop of VL_ONLY_LEGEND_CONFIG) {\n            delete config.legend[prop];\n        }\n    }\n    // Remove Vega-Lite only generic mark config\n    if (config.mark) {\n        for (const prop of VL_ONLY_MARK_CONFIG_PROPERTIES) {\n            delete config.mark[prop];\n        }\n        if (config.mark.tooltip && isObject(config.mark.tooltip)) {\n            delete config.mark.tooltip;\n        }\n    }\n    if (config.params) {\n        config.signals = (config.signals || []).concat(assembleParameterSignals(config.params));\n        delete config.params;\n    }\n    for (const markType of MARK_STYLES) {\n        // Remove Vega-Lite-only mark config\n        for (const prop of VL_ONLY_MARK_CONFIG_PROPERTIES) {\n            delete config[markType][prop];\n        }\n        // Remove Vega-Lite only mark-specific config\n        const vlOnlyMarkSpecificConfigs = VL_ONLY_ALL_MARK_SPECIFIC_CONFIG_PROPERTY_INDEX[markType];\n        if (vlOnlyMarkSpecificConfigs) {\n            for (const prop of vlOnlyMarkSpecificConfigs) {\n                delete config[markType][prop];\n            }\n        }\n        // Redirect mark config to config.style so that mark config only affect its own mark type\n        // without affecting other marks that share the same underlying Vega marks.\n        // For example, config.rect should not affect bar marks.\n        redirectConfigToStyleConfig(config, markType);\n    }\n    for (const m of getAllCompositeMarks()) {\n        // Clean up the composite mark config as we don't need them in the output specs anymore\n        delete config[m];\n    }\n    redirectTitleConfig(config);\n    // Remove empty config objects.\n    for (const prop in config) {\n        if (isObject(config[prop]) && isEmpty(config[prop])) {\n            delete config[prop];\n        }\n    }\n    return isEmpty(config) ? undefined : config;\n}\n/**\n *\n * Redirect config.title -- so that title config do not affect header labels,\n * which also uses `title` directive to implement.\n *\n * For subtitle configs in config.title, keep them in config.title as header titles never have subtitles.\n */\nfunction redirectTitleConfig(config) {\n    const { titleMarkConfig, subtitleMarkConfig, subtitle } = extractTitleConfig(config.title);\n    // set config.style if title/subtitleMarkConfig is not an empty object\n    if (!isEmpty(titleMarkConfig)) {\n        config.style['group-title'] = Object.assign(Object.assign({}, config.style['group-title']), titleMarkConfig // config.title has higher precedence than config.style.group-title in Vega\n        );\n    }\n    if (!isEmpty(subtitleMarkConfig)) {\n        config.style['group-subtitle'] = Object.assign(Object.assign({}, config.style['group-subtitle']), subtitleMarkConfig);\n    }\n    // subtitle part can stay in config.title since header titles do not use subtitle\n    if (!isEmpty(subtitle)) {\n        config.title = subtitle;\n    }\n    else {\n        delete config.title;\n    }\n}\nfunction redirectConfigToStyleConfig(config, prop, // string = composite mark\ntoProp, compositeMarkPart) {\n    const propConfig = compositeMarkPart ? config[prop][compositeMarkPart] : config[prop];\n    if (prop === 'view') {\n        toProp = 'cell'; // View's default style is \"cell\"\n    }\n    const style = Object.assign(Object.assign({}, propConfig), config.style[toProp !== null && toProp !== void 0 ? toProp : prop]);\n    // set config.style if it is not an empty object\n    if (!isEmpty(style)) {\n        config.style[toProp !== null && toProp !== void 0 ? toProp : prop] = style;\n    }\n    if (!compositeMarkPart) {\n        // For composite mark, so don't delete the whole config yet as we have to do multiple redirections.\n        delete config[prop];\n    }\n}\n//# sourceMappingURL=config.js.map","export function isUrlData(data) {\n    return 'url' in data;\n}\nexport function isInlineData(data) {\n    return 'values' in data;\n}\nexport function isNamedData(data) {\n    return 'name' in data && !isUrlData(data) && !isInlineData(data) && !isGenerator(data);\n}\nexport function isGenerator(data) {\n    return data && (isSequenceGenerator(data) || isSphereGenerator(data) || isGraticuleGenerator(data));\n}\nexport function isSequenceGenerator(data) {\n    return 'sequence' in data;\n}\nexport function isSphereGenerator(data) {\n    return 'sphere' in data;\n}\nexport function isGraticuleGenerator(data) {\n    return 'graticule' in data;\n}\nexport var DataSourceType;\n(function (DataSourceType) {\n    DataSourceType[DataSourceType[\"Raw\"] = 0] = \"Raw\";\n    DataSourceType[DataSourceType[\"Main\"] = 1] = \"Main\";\n    DataSourceType[DataSourceType[\"Row\"] = 2] = \"Row\";\n    DataSourceType[DataSourceType[\"Column\"] = 3] = \"Column\";\n    DataSourceType[DataSourceType[\"Lookup\"] = 4] = \"Lookup\";\n})(DataSourceType || (DataSourceType = {}));\n//# sourceMappingURL=data.js.map","// DateTime definition object\nimport { isNumber, isObject } from 'vega-util';\nimport * as log from './log';\nimport { TIMEUNIT_PARTS } from './timeunit';\nimport { duplicate, isNumeric, keys } from './util';\nexport function isDateTime(o) {\n    if (o && isObject(o)) {\n        for (const part of TIMEUNIT_PARTS) {\n            if (part in o) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\nexport const MONTHS = [\n    'january',\n    'february',\n    'march',\n    'april',\n    'may',\n    'june',\n    'july',\n    'august',\n    'september',\n    'october',\n    'november',\n    'december'\n];\nexport const SHORT_MONTHS = MONTHS.map(m => m.substr(0, 3));\nexport const DAYS = ['sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday'];\nexport const SHORT_DAYS = DAYS.map(d => d.substr(0, 3));\nfunction normalizeQuarter(q) {\n    if (isNumeric(q)) {\n        q = +q;\n    }\n    if (isNumber(q)) {\n        if (q > 4) {\n            log.warn(log.message.invalidTimeUnit('quarter', q));\n        }\n        // We accept 1-based quarter, so need to readjust to 0-based quarter\n        return q - 1;\n    }\n    else {\n        // Invalid quarter\n        throw new Error(log.message.invalidTimeUnit('quarter', q));\n    }\n}\nfunction normalizeMonth(m) {\n    if (isNumeric(m)) {\n        m = +m;\n    }\n    if (isNumber(m)) {\n        // We accept 1-based month, so need to readjust to 0-based month\n        return m - 1;\n    }\n    else {\n        const lowerM = m.toLowerCase();\n        const monthIndex = MONTHS.indexOf(lowerM);\n        if (monthIndex !== -1) {\n            return monthIndex; // 0 for january, ...\n        }\n        const shortM = lowerM.substr(0, 3);\n        const shortMonthIndex = SHORT_MONTHS.indexOf(shortM);\n        if (shortMonthIndex !== -1) {\n            return shortMonthIndex;\n        }\n        // Invalid month\n        throw new Error(log.message.invalidTimeUnit('month', m));\n    }\n}\nfunction normalizeDay(d) {\n    if (isNumeric(d)) {\n        d = +d;\n    }\n    if (isNumber(d)) {\n        // mod so that this can be both 0-based where 0 = sunday\n        // and 1-based where 7=sunday\n        return d % 7;\n    }\n    else {\n        const lowerD = d.toLowerCase();\n        const dayIndex = DAYS.indexOf(lowerD);\n        if (dayIndex !== -1) {\n            return dayIndex; // 0 for january, ...\n        }\n        const shortD = lowerD.substr(0, 3);\n        const shortDayIndex = SHORT_DAYS.indexOf(shortD);\n        if (shortDayIndex !== -1) {\n            return shortDayIndex;\n        }\n        // Invalid day\n        throw new Error(log.message.invalidTimeUnit('day', d));\n    }\n}\n/**\n * @param d the date.\n * @param normalize whether to normalize quarter, month, day. This should probably be true if d is a DateTime.\n * @returns array of date time parts [year, month, day, hours, minutes, seconds, milliseconds]\n */\nfunction dateTimeParts(d, normalize) {\n    const parts = [];\n    if (normalize && d.day !== undefined) {\n        if (keys(d).length > 1) {\n            log.warn(log.message.droppedDay(d));\n            d = duplicate(d);\n            delete d.day;\n        }\n    }\n    if (d.year !== undefined) {\n        parts.push(d.year);\n    }\n    else {\n        // Just like Vega's timeunit transform, set default year to 2012, so domain conversion will be compatible with Vega\n        // Note: 2012 is a leap year (and so the date February 29 is respected) that begins on a Sunday (and so days of the week will order properly at the beginning of the year).\n        parts.push(2012);\n    }\n    if (d.month !== undefined) {\n        const month = normalize ? normalizeMonth(d.month) : d.month;\n        parts.push(month);\n    }\n    else if (d.quarter !== undefined) {\n        const quarter = normalize ? normalizeQuarter(d.quarter) : d.quarter;\n        parts.push(isNumber(quarter) ? quarter * 3 : quarter + '*3');\n    }\n    else {\n        parts.push(0); // months start at zero in JS\n    }\n    if (d.date !== undefined) {\n        parts.push(d.date);\n    }\n    else if (d.day !== undefined) {\n        // HACK: Day only works as a standalone unit\n        // This is only correct because we always set year to 2006 for day\n        const day = normalize ? normalizeDay(d.day) : d.day;\n        parts.push(isNumber(day) ? day + 1 : day + '+1');\n    }\n    else {\n        parts.push(1); // Date starts at 1 in JS\n    }\n    // Note: can't use TimeUnit enum here as importing it will create\n    // circular dependency problem!\n    for (const timeUnit of ['hours', 'minutes', 'seconds', 'milliseconds']) {\n        const unit = d[timeUnit];\n        parts.push(typeof unit === 'undefined' ? 0 : unit);\n    }\n    return parts;\n}\n/**\n * Return Vega expression for a date time.\n *\n * @param d the date time.\n * @returns the Vega expression.\n */\nexport function dateTimeToExpr(d) {\n    const parts = dateTimeParts(d, true);\n    const string = parts.join(', ');\n    if (d.utc) {\n        return `utc(${string})`;\n    }\n    else {\n        return `datetime(${string})`;\n    }\n}\n/**\n * Return Vega expression for a date time expression.\n *\n * @param d the internal date time object with expression.\n * @returns the Vega expression.\n */\nexport function dateTimeExprToExpr(d) {\n    const parts = dateTimeParts(d, false);\n    const string = parts.join(', ');\n    if (d.utc) {\n        return `utc(${string})`;\n    }\n    else {\n        return `datetime(${string})`;\n    }\n}\n/**\n * @param d the date time.\n * @returns the timestamp.\n */\nexport function dateTimeToTimestamp(d) {\n    const parts = dateTimeParts(d, true);\n    if (d.utc) {\n        return +new Date(Date.UTC(...parts));\n    }\n    else {\n        return +new Date(...parts);\n    }\n}\n//# sourceMappingURL=datetime.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { array, isArray } from 'vega-util';\nimport { isArgmaxDef, isArgminDef } from './aggregate';\nimport { isBinned, isBinning } from './bin';\nimport { ANGLE, CHANNELS, COLOR, DESCRIPTION, DETAIL, FILL, FILLOPACITY, HREF, isChannel, isNonPositionScaleChannel, isSecondaryRangeChannel, isXorY, KEY, LATITUDE, LATITUDE2, LONGITUDE, LONGITUDE2, OPACITY, ORDER, RADIUS, RADIUS2, SHAPE, SIZE, STROKE, STROKEDASH, STROKEOPACITY, STROKEWIDTH, supportMark, TEXT, THETA, THETA2, TOOLTIP, URL, X, X2, Y, Y2 } from './channel';\nimport { binRequiresRange, getFieldDef, getGuide, hasConditionalFieldDef, initChannelDef, initFieldDef, isConditionalDef, isDatumDef, isFieldDef, isTypedFieldDef, isValueDef, title, vgField } from './channeldef';\nimport * as log from './log';\nimport { QUANTITATIVE, TEMPORAL } from './type';\nimport { keys, some } from './util';\nimport { isSignalRef } from './vega.schema';\nexport function channelHasField(encoding, channel) {\n    const channelDef = encoding && encoding[channel];\n    if (channelDef) {\n        if (isArray(channelDef)) {\n            return some(channelDef, fieldDef => !!fieldDef.field);\n        }\n        else {\n            return isFieldDef(channelDef) || hasConditionalFieldDef(channelDef);\n        }\n    }\n    return false;\n}\nexport function isAggregate(encoding) {\n    return some(CHANNELS, channel => {\n        if (channelHasField(encoding, channel)) {\n            const channelDef = encoding[channel];\n            if (isArray(channelDef)) {\n                return some(channelDef, fieldDef => !!fieldDef.aggregate);\n            }\n            else {\n                const fieldDef = getFieldDef(channelDef);\n                return fieldDef && !!fieldDef.aggregate;\n            }\n        }\n        return false;\n    });\n}\nexport function extractTransformsFromEncoding(oldEncoding, config) {\n    const groupby = [];\n    const bins = [];\n    const timeUnits = [];\n    const aggregate = [];\n    const encoding = {};\n    forEach(oldEncoding, (channelDef, channel) => {\n        // Extract potential embedded transformations along with remaining properties\n        if (isFieldDef(channelDef)) {\n            const { field, aggregate: aggOp, bin, timeUnit } = channelDef, remaining = __rest(channelDef, [\"field\", \"aggregate\", \"bin\", \"timeUnit\"]);\n            if (aggOp || timeUnit || bin) {\n                const guide = getGuide(channelDef);\n                const isTitleDefined = guide && guide.title;\n                let newField = vgField(channelDef, { forAs: true });\n                const newFieldDef = Object.assign(Object.assign(Object.assign({}, (isTitleDefined ? [] : { title: title(channelDef, config, { allowDisabling: true }) })), remaining), { \n                    // Always overwrite field\n                    field: newField });\n                if (aggOp) {\n                    let op;\n                    if (isArgmaxDef(aggOp)) {\n                        op = 'argmax';\n                        newField = vgField({ op: 'argmax', field: aggOp.argmax }, { forAs: true });\n                        newFieldDef.field = `${newField}.${field}`;\n                    }\n                    else if (isArgminDef(aggOp)) {\n                        op = 'argmin';\n                        newField = vgField({ op: 'argmin', field: aggOp.argmin }, { forAs: true });\n                        newFieldDef.field = `${newField}.${field}`;\n                    }\n                    else if (aggOp !== 'boxplot' && aggOp !== 'errorbar' && aggOp !== 'errorband') {\n                        op = aggOp;\n                    }\n                    if (op) {\n                        const aggregateEntry = {\n                            op,\n                            as: newField\n                        };\n                        if (field) {\n                            aggregateEntry.field = field;\n                        }\n                        aggregate.push(aggregateEntry);\n                    }\n                }\n                else {\n                    groupby.push(newField);\n                    if (isTypedFieldDef(channelDef) && isBinning(bin)) {\n                        bins.push({ bin, field, as: newField });\n                        // Add additional groupbys for range and end of bins\n                        groupby.push(vgField(channelDef, { binSuffix: 'end' }));\n                        if (binRequiresRange(channelDef, channel)) {\n                            groupby.push(vgField(channelDef, { binSuffix: 'range' }));\n                        }\n                        // Create accompanying 'x2' or 'y2' field if channel is 'x' or 'y' respectively\n                        if (isXorY(channel)) {\n                            const secondaryChannel = {\n                                field: newField + '_end'\n                            };\n                            encoding[channel + '2'] = secondaryChannel;\n                        }\n                        newFieldDef.bin = 'binned';\n                        if (!isSecondaryRangeChannel(channel)) {\n                            newFieldDef['type'] = QUANTITATIVE;\n                        }\n                    }\n                    else if (timeUnit) {\n                        timeUnits.push({\n                            timeUnit,\n                            field,\n                            as: newField\n                        });\n                        // define the format type for later compilation\n                        const formatType = isTypedFieldDef(channelDef) && channelDef.type !== TEMPORAL && 'time';\n                        if (formatType) {\n                            if (channel === TEXT || channel === TOOLTIP) {\n                                newFieldDef['formatType'] = formatType;\n                            }\n                            else if (isNonPositionScaleChannel(channel)) {\n                                newFieldDef['legend'] = Object.assign({ formatType }, newFieldDef['legend']);\n                            }\n                            else if (isXorY(channel)) {\n                                newFieldDef['axis'] = Object.assign({ formatType }, newFieldDef['axis']);\n                            }\n                        }\n                    }\n                }\n                // now the field should refer to post-transformed field instead\n                encoding[channel] = newFieldDef;\n            }\n            else {\n                groupby.push(field);\n                encoding[channel] = oldEncoding[channel];\n            }\n        }\n        else {\n            // For value def / signal ref / datum def, just copy\n            encoding[channel] = oldEncoding[channel];\n        }\n    });\n    return {\n        bins,\n        timeUnits,\n        aggregate,\n        groupby,\n        encoding\n    };\n}\nexport function markChannelCompatible(encoding, channel, mark) {\n    const markSupported = supportMark(channel, mark);\n    if (!markSupported) {\n        return false;\n    }\n    else if (markSupported === 'binned') {\n        const primaryFieldDef = encoding[channel === X2 ? X : Y];\n        // circle, point, square and tick only support x2/y2 when their corresponding x/y fieldDef\n        // has \"binned\" data and thus need x2/y2 to specify the bin-end field.\n        if (isFieldDef(primaryFieldDef) && isFieldDef(encoding[channel]) && isBinned(primaryFieldDef.bin)) {\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    return true;\n}\nexport function initEncoding(encoding, mark, filled, config) {\n    return keys(encoding).reduce((normalizedEncoding, channel) => {\n        if (!isChannel(channel)) {\n            // Drop invalid channel\n            log.warn(log.message.invalidEncodingChannel(channel));\n            return normalizedEncoding;\n        }\n        const channelDef = encoding[channel];\n        if (channel === 'angle' && mark === 'arc' && !encoding.theta) {\n            log.warn(log.message.REPLACE_ANGLE_WITH_THETA);\n            channel = THETA;\n        }\n        if (!markChannelCompatible(encoding, channel, mark)) {\n            // Drop unsupported channel\n            log.warn(log.message.incompatibleChannel(channel, mark));\n            return normalizedEncoding;\n        }\n        // Drop line's size if the field is aggregated.\n        if (channel === SIZE && mark === 'line') {\n            const fieldDef = getFieldDef(encoding[channel]);\n            if (fieldDef === null || fieldDef === void 0 ? void 0 : fieldDef.aggregate) {\n                log.warn(log.message.LINE_WITH_VARYING_SIZE);\n                return normalizedEncoding;\n            }\n        }\n        // Drop color if either fill or stroke is specified\n        if (channel === COLOR && (filled ? 'fill' in encoding : 'stroke' in encoding)) {\n            log.warn(log.message.droppingColor('encoding', { fill: 'fill' in encoding, stroke: 'stroke' in encoding }));\n            return normalizedEncoding;\n        }\n        if (channel === DETAIL ||\n            (channel === ORDER && !isArray(channelDef) && !isValueDef(channelDef)) ||\n            (channel === TOOLTIP && isArray(channelDef))) {\n            if (channelDef) {\n                // Array of fieldDefs for detail channel (or production rule)\n                normalizedEncoding[channel] = array(channelDef).reduce((defs, fieldDef) => {\n                    if (!isFieldDef(fieldDef)) {\n                        log.warn(log.message.emptyFieldDef(fieldDef, channel));\n                    }\n                    else {\n                        defs.push(initFieldDef(fieldDef, channel));\n                    }\n                    return defs;\n                }, []);\n            }\n        }\n        else {\n            if (channel === TOOLTIP && channelDef === null) {\n                // Preserve null so we can use it to disable tooltip\n                normalizedEncoding[channel] = null;\n            }\n            else if (!isFieldDef(channelDef) &&\n                !isDatumDef(channelDef) &&\n                !isValueDef(channelDef) &&\n                !isConditionalDef(channelDef) &&\n                !isSignalRef(channelDef)) {\n                log.warn(log.message.emptyFieldDef(channelDef, channel));\n                return normalizedEncoding;\n            }\n            normalizedEncoding[channel] = initChannelDef(channelDef, channel, config);\n        }\n        return normalizedEncoding;\n    }, {});\n}\n/**\n * For composite marks, we have to call initChannelDef during init so we can infer types earlier.\n */\nexport function normalizeEncoding(encoding, config) {\n    const normalizedEncoding = {};\n    for (const channel of keys(encoding)) {\n        const newChannelDef = initChannelDef(encoding[channel], channel, config, { compositeMark: true });\n        normalizedEncoding[channel] = newChannelDef;\n    }\n    return normalizedEncoding;\n}\nexport function fieldDefs(encoding) {\n    const arr = [];\n    for (const channel of keys(encoding)) {\n        if (channelHasField(encoding, channel)) {\n            const channelDef = encoding[channel];\n            const channelDefArray = array(channelDef);\n            for (const def of channelDefArray) {\n                if (isFieldDef(def)) {\n                    arr.push(def);\n                }\n                else if (hasConditionalFieldDef(def)) {\n                    arr.push(def.condition);\n                }\n            }\n        }\n    }\n    return arr;\n}\nexport function forEach(mapping, f, thisArg) {\n    if (!mapping) {\n        return;\n    }\n    for (const channel of keys(mapping)) {\n        const el = mapping[channel];\n        if (isArray(el)) {\n            for (const channelDef of el) {\n                f.call(thisArg, channelDef, channel);\n            }\n        }\n        else {\n            f.call(thisArg, el, channel);\n        }\n    }\n}\nexport function reduce(mapping, f, init, thisArg) {\n    if (!mapping) {\n        return init;\n    }\n    return keys(mapping).reduce((r, channel) => {\n        const map = mapping[channel];\n        if (isArray(map)) {\n            return map.reduce((r1, channelDef) => {\n                return f.call(thisArg, r1, channelDef, channel);\n            }, r);\n        }\n        else {\n            return f.call(thisArg, r, map, channel);\n        }\n    }, init);\n}\n/**\n * Returns list of path grouping fields for the given encoding\n */\nexport function pathGroupingFields(mark, encoding) {\n    return keys(encoding).reduce((details, channel) => {\n        switch (channel) {\n            // x, y, x2, y2, lat, long, lat1, long2, order, tooltip, href, aria label, cursor should not cause lines to group\n            case X:\n            case Y:\n            case HREF:\n            case DESCRIPTION:\n            case URL:\n            case X2:\n            case Y2:\n            case THETA:\n            case THETA2:\n            case RADIUS:\n            case RADIUS2:\n            // falls through\n            case LATITUDE:\n            case LONGITUDE:\n            case LATITUDE2:\n            case LONGITUDE2:\n            // TODO: case 'cursor':\n            // text, shape, shouldn't be a part of line/trail/area [falls through]\n            case TEXT:\n            case SHAPE:\n            case ANGLE:\n            // falls through\n            // tooltip fields should not be added to group by [falls through]\n            case TOOLTIP:\n                return details;\n            case ORDER:\n                // order should not group line / trail\n                if (mark === 'line' || mark === 'trail') {\n                    return details;\n                }\n            // but order should group area for stacking (falls through)\n            case DETAIL:\n            case KEY: {\n                const channelDef = encoding[channel];\n                if (isArray(channelDef) || isFieldDef(channelDef)) {\n                    for (const fieldDef of array(channelDef)) {\n                        if (!fieldDef.aggregate) {\n                            details.push(vgField(fieldDef, {}));\n                        }\n                    }\n                }\n                return details;\n            }\n            case SIZE:\n                if (mark === 'trail') {\n                    // For trail, size should not group trail lines.\n                    return details;\n                }\n            // For line, size should group lines.\n            // falls through\n            case COLOR:\n            case FILL:\n            case STROKE:\n            case OPACITY:\n            case FILLOPACITY:\n            case STROKEOPACITY:\n            case STROKEDASH:\n            case STROKEWIDTH: {\n                // TODO strokeDashOffset:\n                // falls through\n                const fieldDef = getFieldDef(encoding[channel]);\n                if (fieldDef && !fieldDef.aggregate) {\n                    details.push(vgField(fieldDef, {}));\n                }\n                return details;\n            }\n        }\n    }, []);\n}\n//# sourceMappingURL=encoding.js.map","import { signalRefOrValue } from './compile/common';\nimport { keys } from './util';\nimport { isSignalRef } from './vega.schema';\nexport function isExprRef(o) {\n    return o && !!o['expr'];\n}\nexport function isExprOrSignalRef(o) {\n    return isExprRef(o) || isSignalRef(o);\n}\nexport function replaceExprRefInIndex(index) {\n    const props = keys(index || {});\n    const newIndex = {};\n    for (const prop of props) {\n        newIndex[prop] = signalRefOrValue(index[prop]);\n    }\n    return newIndex;\n}\n//# sourceMappingURL=expr.js.map","export const VL_ONLY_LEGEND_CONFIG = [\n    'gradientHorizontalMaxLength',\n    'gradientHorizontalMinLength',\n    'gradientVerticalMaxLength',\n    'gradientVerticalMinLength',\n    'unselectedOpacity'\n];\n//# sourceMappingURL=guide.js.map","import { keys } from './util';\nexport const HEADER_TITLE_PROPERTIES_MAP = {\n    titleAlign: 'align',\n    titleAnchor: 'anchor',\n    titleAngle: 'angle',\n    titleBaseline: 'baseline',\n    titleColor: 'color',\n    titleFont: 'font',\n    titleFontSize: 'fontSize',\n    titleFontStyle: 'fontStyle',\n    titleFontWeight: 'fontWeight',\n    titleLimit: 'limit',\n    titleLineHeight: 'lineHeight',\n    titleOrient: 'orient',\n    titlePadding: 'offset'\n};\nexport const HEADER_LABEL_PROPERTIES_MAP = {\n    labelAlign: 'align',\n    labelAnchor: 'anchor',\n    labelAngle: 'angle',\n    labelBaseline: 'baseline',\n    labelColor: 'color',\n    labelFont: 'font',\n    labelFontSize: 'fontSize',\n    labelFontStyle: 'fontStyle',\n    labelFontWeight: 'fontWeight',\n    labelLimit: 'limit',\n    labelLineHeight: 'lineHeight',\n    labelOrient: 'orient',\n    labelPadding: 'offset'\n};\nexport const HEADER_TITLE_PROPERTIES = keys(HEADER_TITLE_PROPERTIES_MAP);\nexport const HEADER_LABEL_PROPERTIES = keys(HEADER_LABEL_PROPERTIES_MAP);\nconst HEADER_CONFIGS_INDEX = {\n    header: 1,\n    headerRow: 1,\n    headerColumn: 1,\n    headerFacet: 1\n};\nexport const HEADER_CONFIGS = keys(HEADER_CONFIGS_INDEX);\n//# sourceMappingURL=header.js.map","import { version } from '../package.json';\nimport { normalize } from './normalize';\nexport { compile } from './compile/compile';\nexport * from './util';\nexport { normalize, version };\n//# sourceMappingURL=index.js.map","import { keys } from './util';\nexport const LEGEND_SCALE_CHANNELS = [\n    'size',\n    'shape',\n    'fill',\n    'stroke',\n    'strokeDash',\n    'strokeWidth',\n    'opacity'\n];\nexport const defaultLegendConfig = {\n    gradientHorizontalMaxLength: 200,\n    gradientHorizontalMinLength: 100,\n    gradientVerticalMaxLength: 200,\n    gradientVerticalMinLength: 64,\n    unselectedOpacity: 0.35\n};\nexport const COMMON_LEGEND_PROPERTY_INDEX = {\n    aria: 1,\n    clipHeight: 1,\n    columnPadding: 1,\n    columns: 1,\n    cornerRadius: 1,\n    description: 1,\n    direction: 1,\n    fillColor: 1,\n    format: 1,\n    formatType: 1,\n    gradientLength: 1,\n    gradientOpacity: 1,\n    gradientStrokeColor: 1,\n    gradientStrokeWidth: 1,\n    gradientThickness: 1,\n    gridAlign: 1,\n    labelAlign: 1,\n    labelBaseline: 1,\n    labelColor: 1,\n    labelFont: 1,\n    labelFontSize: 1,\n    labelFontStyle: 1,\n    labelFontWeight: 1,\n    labelLimit: 1,\n    labelOffset: 1,\n    labelOpacity: 1,\n    labelOverlap: 1,\n    labelPadding: 1,\n    labelSeparation: 1,\n    legendX: 1,\n    legendY: 1,\n    offset: 1,\n    orient: 1,\n    padding: 1,\n    rowPadding: 1,\n    strokeColor: 1,\n    symbolDash: 1,\n    symbolDashOffset: 1,\n    symbolFillColor: 1,\n    symbolLimit: 1,\n    symbolOffset: 1,\n    symbolOpacity: 1,\n    symbolSize: 1,\n    symbolStrokeColor: 1,\n    symbolStrokeWidth: 1,\n    symbolType: 1,\n    tickCount: 1,\n    tickMinStep: 1,\n    title: 1,\n    titleAlign: 1,\n    titleAnchor: 1,\n    titleBaseline: 1,\n    titleColor: 1,\n    titleFont: 1,\n    titleFontSize: 1,\n    titleFontStyle: 1,\n    titleFontWeight: 1,\n    titleLimit: 1,\n    titleLineHeight: 1,\n    titleOpacity: 1,\n    titleOrient: 1,\n    titlePadding: 1,\n    type: 1,\n    values: 1,\n    zindex: 1\n};\nexport const LEGEND_PROPERTIES = keys(COMMON_LEGEND_PROPERTY_INDEX);\n//# sourceMappingURL=legend.js.map","/**\n * Vega-Lite's singleton logger utility.\n */\nvar __classPrivateFieldSet = (this && this.__classPrivateFieldSet) || function (receiver, privateMap, value) {\n    if (!privateMap.has(receiver)) {\n        throw new TypeError(\"attempted to set private field on non-instance\");\n    }\n    privateMap.set(receiver, value);\n    return value;\n};\nvar __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, privateMap) {\n    if (!privateMap.has(receiver)) {\n        throw new TypeError(\"attempted to get private field on non-instance\");\n    }\n    return privateMap.get(receiver);\n};\nvar _level;\nimport { Debug, Error as ErrorLevel, Info, logger, Warn } from 'vega-util';\nimport * as message_1 from './message';\nexport { message_1 as message };\n/**\n * Main (default) Vega Logger instance for Vega-Lite.\n */\nconst main = logger(Warn);\nlet current = main;\n/**\n * Logger tool for checking if the code throws correct warning.\n */\nexport class LocalLogger {\n    constructor() {\n        this.warns = [];\n        this.infos = [];\n        this.debugs = [];\n        _level.set(this, Warn);\n    }\n    level(_) {\n        if (_) {\n            __classPrivateFieldSet(this, _level, _);\n            return this;\n        }\n        return __classPrivateFieldGet(this, _level);\n    }\n    warn(...args) {\n        if (__classPrivateFieldGet(this, _level) >= Warn)\n            this.warns.push(...args);\n        return this;\n    }\n    info(...args) {\n        if (__classPrivateFieldGet(this, _level) >= Info)\n            this.infos.push(...args);\n        return this;\n    }\n    debug(...args) {\n        if (__classPrivateFieldGet(this, _level) >= Debug)\n            this.debugs.push(...args);\n        return this;\n    }\n    error(...args) {\n        if (__classPrivateFieldGet(this, _level) >= ErrorLevel)\n            throw Error(...args);\n        return this;\n    }\n}\n_level = new WeakMap();\nexport function wrap(f) {\n    return () => {\n        current = new LocalLogger();\n        f(current);\n        reset();\n    };\n}\n/**\n * Set the singleton logger to be a custom logger.\n */\nexport function set(newLogger) {\n    current = newLogger;\n    return current;\n}\n/**\n * Reset the main logger to use the default Vega Logger.\n */\nexport function reset() {\n    current = main;\n    return current;\n}\nexport function error(...args) {\n    current.error(...args);\n}\nexport function warn(...args) {\n    current.warn(...args);\n}\nexport function info(...args) {\n    current.info(...args);\n}\nexport function debug(...args) {\n    current.debug(...args);\n}\n//# sourceMappingURL=index.js.map","import { getSizeChannel } from '../channel';\nimport { stringify } from '../util';\nexport function invalidSpec(spec) {\n    return `Invalid specification ${JSON.stringify(spec)}. Make sure the specification includes at least one of the following properties: \"mark\", \"layer\", \"facet\", \"hconcat\", \"vconcat\", \"concat\", or \"repeat\".`;\n}\n// FIT\nexport const FIT_NON_SINGLE = 'Autosize \"fit\" only works for single views and layered views.';\nexport function containerSizeNonSingle(name) {\n    const uName = name == 'width' ? 'Width' : 'Height';\n    return `${uName} \"container\" only works for single views and layered views.`;\n}\nexport function containerSizeNotCompatibleWithAutosize(name) {\n    const uName = name == 'width' ? 'Width' : 'Height';\n    const fitDirection = name == 'width' ? 'x' : 'y';\n    return `${uName} \"container\" only works well with autosize \"fit\" or \"fit-${fitDirection}\".`;\n}\nexport function droppingFit(channel) {\n    return channel\n        ? `Dropping \"fit-${channel}\" because spec has discrete ${getSizeChannel(channel)}.`\n        : `Dropping \"fit\" because spec has discrete size.`;\n}\n// VIEW SIZE\nexport function unknownField(channel) {\n    return `Unknown field for ${channel}. Cannot calculate view size.`;\n}\n// SELECTION\nexport function cannotProjectOnChannelWithoutField(channel) {\n    return `Cannot project a selection on encoding channel \"${channel}\", which has no field.`;\n}\nexport function cannotProjectAggregate(channel, aggregate) {\n    return `Cannot project a selection on encoding channel \"${channel}\" as it uses an aggregate function (\"${aggregate}\").`;\n}\nexport function nearestNotSupportForContinuous(mark) {\n    return `The \"nearest\" transform is not supported for ${mark} marks.`;\n}\nexport function selectionNotSupported(mark) {\n    return `Selection not supported for ${mark} yet.`;\n}\nexport function selectionNotFound(name) {\n    return `Cannot find a selection named \"${name}\".`;\n}\nexport const SCALE_BINDINGS_CONTINUOUS = 'Scale bindings are currently only supported for scales with unbinned, continuous domains.';\nexport const LEGEND_BINDINGS_MUST_HAVE_PROJECTION = 'Legend bindings are only supported for selections over an individual field or encoding channel.';\nexport function noSameUnitLookup(name) {\n    return (`Cannot define and lookup the \"${name}\" selection in the same view. ` +\n        `Try moving the lookup into a second, layered view?`);\n}\nexport const NEEDS_SAME_SELECTION = 'The same selection must be used to override scale domains in a layered view.';\nexport const INTERVAL_INITIALIZED_WITH_X_Y = 'Interval selections should be initialized using \"x\" and/or \"y\" keys.';\n// REPEAT\nexport function noSuchRepeatedValue(field) {\n    return `Unknown repeated value \"${field}\".`;\n}\nexport function columnsNotSupportByRowCol(type) {\n    return `The \"columns\" property cannot be used when \"${type}\" has nested row/column.`;\n}\n// CONCAT / REPEAT\nexport const CONCAT_CANNOT_SHARE_AXIS = 'Axes cannot be shared in concatenated or repeated views yet (https://github.com/vega/vega-lite/issues/2415).';\n// DATA\nexport function unrecognizedParse(p) {\n    return `Unrecognized parse \"${p}\".`;\n}\nexport function differentParse(field, local, ancestor) {\n    return `An ancestor parsed field \"${field}\" as ${ancestor} but a child wants to parse the field as ${local}.`;\n}\nexport const ADD_SAME_CHILD_TWICE = 'Attempt to add the same child twice.';\n// TRANSFORMS\nexport function invalidTransformIgnored(transform) {\n    return `Ignoring an invalid transform: ${stringify(transform)}.`;\n}\nexport const NO_FIELDS_NEEDS_AS = 'If \"from.fields\" is not specified, \"as\" has to be a string that specifies the key to be used for the data from the secondary source.';\n// ENCODING & FACET\nexport function customFormatTypeNotAllowed(channel) {\n    return `Config.customFormatTypes is not true, thus custom format type and format for channel ${channel} are dropped.`;\n}\nexport function projectionOverridden(opt) {\n    const { parentProjection, projection } = opt;\n    return `Layer's shared projection ${stringify(parentProjection)} is overridden by a child projection ${stringify(projection)}.`;\n}\nexport const REPLACE_ANGLE_WITH_THETA = 'Arc marks uses theta channel rather than angle, replacing angle with theta.';\nexport function primitiveChannelDef(channel, type, value) {\n    return `Channel ${channel} is a ${type}. Converted to {value: ${stringify(value)}}.`;\n}\nexport function invalidFieldType(type) {\n    return `Invalid field type \"${type}\".`;\n}\nexport function invalidFieldTypeForCountAggregate(type, aggregate) {\n    return `Invalid field type \"${type}\" for aggregate: \"${aggregate}\", using \"quantitative\" instead.`;\n}\nexport function invalidAggregate(aggregate) {\n    return `Invalid aggregation operator \"${aggregate}\".`;\n}\nexport function missingFieldType(channel, newType) {\n    return `Missing type for channel \"${channel}\", using \"${newType}\" instead.`;\n}\nexport function droppingColor(type, opt) {\n    const { fill, stroke } = opt;\n    return `Dropping color ${type} as the plot also has ${fill && stroke ? 'fill and stroke' : fill ? 'fill' : 'stroke'}.`;\n}\nexport function emptyFieldDef(fieldDef, channel) {\n    return `Dropping ${stringify(fieldDef)} from channel \"${channel}\" since it does not contain any data field, datum, value, or signal.`;\n}\nexport function latLongDeprecated(channel, type, newChannel) {\n    return `${channel}-encoding with type ${type} is deprecated. Replacing with ${newChannel}-encoding.`;\n}\nexport const LINE_WITH_VARYING_SIZE = 'Line marks cannot encode size with a non-groupby field. You may want to use trail marks instead.';\nexport function incompatibleChannel(channel, markOrFacet, when) {\n    return `${channel} dropped as it is incompatible with \"${markOrFacet}\"${when ? ` when ${when}` : ''}.`;\n}\nexport function invalidEncodingChannel(channel) {\n    return `${channel}-encoding is dropped as ${channel} is not a valid encoding channel.`;\n}\nexport function facetChannelShouldBeDiscrete(channel) {\n    return `${channel} encoding should be discrete (ordinal / nominal / binned).`;\n}\nexport function facetChannelDropped(channels) {\n    return `Facet encoding dropped as ${channels.join(' and ')} ${channels.length > 1 ? 'are' : 'is'} also specified.`;\n}\nexport function discreteChannelCannotEncode(channel, type) {\n    return `Using discrete channel \"${channel}\" to encode \"${type}\" field can be misleading as it does not encode ${type === 'ordinal' ? 'order' : 'magnitude'}.`;\n}\n// MARK\nexport function rangeMarkAlignmentCannotBeExpression(align) {\n    return `The ${align} for range marks cannot be an expression`;\n}\nexport function lineWithRange(hasX2, hasY2) {\n    const channels = hasX2 && hasY2 ? 'x2 and y2' : hasX2 ? 'x2' : 'y2';\n    return `Line mark is for continuous lines and thus cannot be used with ${channels}. We will use the rule mark (line segments) instead.`;\n}\nexport function orientOverridden(original, actual) {\n    return `Specified orient \"${original}\" overridden with \"${actual}\".`;\n}\n// SCALE\nexport const CANNOT_UNION_CUSTOM_DOMAIN_WITH_FIELD_DOMAIN = 'Custom domain scale cannot be unioned with default field-based domain.';\nexport const RANGE_STEP_DEPRECATED = `Scale's \"rangeStep\" is deprecated and will be removed in Vega-Lite 5.0. Please use \"width\"/\"height\": {\"step\": ...} instead. See https://vega.github.io/vega-lite/docs/size.html.`;\nexport function cannotUseScalePropertyWithNonColor(prop) {\n    return `Cannot use the scale property \"${prop}\" with non-color channel.`;\n}\nexport function unaggregateDomainHasNoEffectForRawField(fieldDef) {\n    return `Using unaggregated domain with raw field has no effect (${stringify(fieldDef)}).`;\n}\nexport function unaggregateDomainWithNonSharedDomainOp(aggregate) {\n    return `Unaggregated domain not applicable for \"${aggregate}\" since it produces values outside the origin domain of the source data.`;\n}\nexport function unaggregatedDomainWithLogScale(fieldDef) {\n    return `Unaggregated domain is currently unsupported for log scale (${stringify(fieldDef)}).`;\n}\nexport function cannotApplySizeToNonOrientedMark(mark) {\n    return `Cannot apply size to non-oriented mark \"${mark}\".`;\n}\nexport function scaleTypeNotWorkWithChannel(channel, scaleType, defaultScaleType) {\n    return `Channel \"${channel}\" does not work with \"${scaleType}\" scale. We are using \"${defaultScaleType}\" scale instead.`;\n}\nexport function scaleTypeNotWorkWithFieldDef(scaleType, defaultScaleType) {\n    return `FieldDef does not work with \"${scaleType}\" scale. We are using \"${defaultScaleType}\" scale instead.`;\n}\nexport function scalePropertyNotWorkWithScaleType(scaleType, propName, channel) {\n    return `${channel}-scale's \"${propName}\" is dropped as it does not work with ${scaleType} scale.`;\n}\nexport function scaleTypeNotWorkWithMark(mark, scaleType) {\n    return `Scale type \"${scaleType}\" does not work with mark \"${mark}\".`;\n}\nexport function stepDropped(channel) {\n    return `The step for \"${channel}\" is dropped because the ${channel === 'width' ? 'x' : 'y'} is continuous.`;\n}\nexport function mergeConflictingProperty(property, propertyOf, v1, v2) {\n    return `Conflicting ${propertyOf.toString()} property \"${property.toString()}\" (${stringify(v1)} and ${stringify(v2)}). Using ${stringify(v1)}.`;\n}\nexport function mergeConflictingDomainProperty(property, propertyOf, v1, v2) {\n    return `Conflicting ${propertyOf.toString()} property \"${property.toString()}\" (${stringify(v1)} and ${stringify(v2)}). Using the union of the two domains.`;\n}\nexport function independentScaleMeansIndependentGuide(channel) {\n    return `Setting the scale to be independent for \"${channel}\" means we also have to set the guide (axis or legend) to be independent.`;\n}\nexport function domainSortDropped(sort) {\n    return `Dropping sort property ${stringify(sort)} as unioned domains only support boolean or op \"count\", \"min\", and \"max\".`;\n}\nexport const MORE_THAN_ONE_SORT = 'Domains that should be unioned has conflicting sort properties. Sort will be set to true.';\nexport const FACETED_INDEPENDENT_DIFFERENT_SOURCES = 'Detected faceted independent scales that union domain of multiple fields from different data sources. We will use the first field. The result view size may be incorrect.';\nexport const FACETED_INDEPENDENT_SAME_FIELDS_DIFFERENT_SOURCES = 'Detected faceted independent scales that union domain of the same fields from different source. We will assume that this is the same field from a different fork of the same data source. However, if this is not the case, the result view size may be incorrect.';\nexport const FACETED_INDEPENDENT_SAME_SOURCE = 'Detected faceted independent scales that union domain of multiple fields from the same data source. We will use the first field. The result view size may be incorrect.';\n// AXIS\nexport const INVALID_CHANNEL_FOR_AXIS = 'Invalid channel for axis.';\n// STACK\nexport function cannotStackRangedMark(channel) {\n    return `Cannot stack \"${channel}\" if there is already \"${channel}2\".`;\n}\nexport function cannotStackNonLinearScale(scaleType) {\n    return `Cannot stack non-linear scale (${scaleType}).`;\n}\nexport function stackNonSummativeAggregate(aggregate) {\n    return `Stacking is applied even though the aggregate function is non-summative (\"${aggregate}\").`;\n}\n// TIMEUNIT\nexport function invalidTimeUnit(unitName, value) {\n    return `Invalid ${unitName}: ${stringify(value)}.`;\n}\nexport function droppedDay(d) {\n    return `Dropping day from datetime ${stringify(d)} as day cannot be combined with other units.`;\n}\nexport function errorBarCenterAndExtentAreNotNeeded(center, extent) {\n    return `${extent ? 'extent ' : ''}${extent && center ? 'and ' : ''}${center ? 'center ' : ''}${extent && center ? 'are ' : 'is '}not needed when data are aggregated.`;\n}\nexport function errorBarCenterIsUsedWithWrongExtent(center, extent, mark) {\n    return `${center} is not usually used with ${extent} for ${mark}.`;\n}\nexport function errorBarContinuousAxisHasCustomizedAggregate(aggregate, compositeMark) {\n    return `Continuous axis should not have customized aggregation function ${aggregate}; ${compositeMark} already agregates the axis.`;\n}\nexport function errorBand1DNotSupport(property) {\n    return `1D error band does not support ${property}.`;\n}\n// CHANNEL\nexport function channelRequiredForBinned(channel) {\n    return `Channel ${channel} is required for \"binned\" bin.`;\n}\nexport function channelShouldNotBeUsedForBinned(channel) {\n    return `Channel ${channel} should not be used with \"binned\" bin.`;\n}\nexport function domainRequiredForThresholdScale(channel) {\n    return `Domain for ${channel} is required for threshold scale.`;\n}\n//# sourceMappingURL=message.js.map","export function isLogicalOr(op) {\n    return !!op.or;\n}\nexport function isLogicalAnd(op) {\n    return !!op.and;\n}\nexport function isLogicalNot(op) {\n    return !!op.not;\n}\nexport function forEachLeaf(op, fn) {\n    if (isLogicalNot(op)) {\n        forEachLeaf(op.not, fn);\n    }\n    else if (isLogicalAnd(op)) {\n        for (const subop of op.and) {\n            forEachLeaf(subop, fn);\n        }\n    }\n    else if (isLogicalOr(op)) {\n        for (const subop of op.or) {\n            forEachLeaf(subop, fn);\n        }\n    }\n    else {\n        fn(op);\n    }\n}\nexport function normalizeLogicalComposition(op, normalizer) {\n    if (isLogicalNot(op)) {\n        return { not: normalizeLogicalComposition(op.not, normalizer) };\n    }\n    else if (isLogicalAnd(op)) {\n        return { and: op.and.map(o => normalizeLogicalComposition(o, normalizer)) };\n    }\n    else if (isLogicalOr(op)) {\n        return { or: op.or.map(o => normalizeLogicalComposition(o, normalizer)) };\n    }\n    else {\n        return normalizer(op);\n    }\n}\n//# sourceMappingURL=logical.js.map","import { toSet } from 'vega-util';\nimport { contains, keys } from './util';\n/**\n * All types of primitive marks.\n */\nexport const Mark = {\n    arc: 'arc',\n    area: 'area',\n    bar: 'bar',\n    image: 'image',\n    line: 'line',\n    point: 'point',\n    rect: 'rect',\n    rule: 'rule',\n    text: 'text',\n    tick: 'tick',\n    trail: 'trail',\n    circle: 'circle',\n    square: 'square',\n    geoshape: 'geoshape'\n};\nexport const ARC = Mark.arc;\nexport const AREA = Mark.area;\nexport const BAR = Mark.bar;\nexport const IMAGE = Mark.image;\nexport const LINE = Mark.line;\nexport const POINT = Mark.point;\nexport const RECT = Mark.rect;\nexport const RULE = Mark.rule;\nexport const TEXT = Mark.text;\nexport const TICK = Mark.tick;\nexport const TRAIL = Mark.trail;\nexport const CIRCLE = Mark.circle;\nexport const SQUARE = Mark.square;\nexport const GEOSHAPE = Mark.geoshape;\nexport function isMark(m) {\n    return m in Mark;\n}\nexport function isPathMark(m) {\n    return contains(['line', 'area', 'trail'], m);\n}\nexport function isRectBasedMark(m) {\n    return contains(['rect', 'bar', 'image', 'arc' /* arc is rect/interval in polar coordinate */], m);\n}\nexport const PRIMITIVE_MARKS = keys(Mark);\nexport function isMarkDef(mark) {\n    return mark['type'];\n}\nconst PRIMITIVE_MARK_INDEX = toSet(PRIMITIVE_MARKS);\nexport function isPrimitiveMark(mark) {\n    const markType = isMarkDef(mark) ? mark.type : mark;\n    return markType in PRIMITIVE_MARK_INDEX;\n}\nexport const STROKE_CONFIG = [\n    'stroke',\n    'strokeWidth',\n    'strokeDash',\n    'strokeDashOffset',\n    'strokeOpacity',\n    'strokeJoin',\n    'strokeMiterLimit'\n];\nexport const FILL_CONFIG = ['fill', 'fillOpacity'];\nexport const FILL_STROKE_CONFIG = [...STROKE_CONFIG, ...FILL_CONFIG];\nconst VL_ONLY_MARK_CONFIG_INDEX = {\n    color: 1,\n    filled: 1,\n    invalid: 1,\n    order: 1,\n    radius2: 1,\n    theta2: 1,\n    timeUnitBand: 1,\n    timeUnitBandPosition: 1\n};\nexport const VL_ONLY_MARK_CONFIG_PROPERTIES = keys(VL_ONLY_MARK_CONFIG_INDEX);\nexport const VL_ONLY_MARK_SPECIFIC_CONFIG_PROPERTY_INDEX = {\n    area: ['line', 'point'],\n    bar: ['binSpacing', 'continuousBandSize', 'discreteBandSize'],\n    rect: ['binSpacing', 'continuousBandSize', 'discreteBandSize'],\n    line: ['point'],\n    tick: ['bandSize', 'thickness']\n};\nexport const defaultMarkConfig = {\n    color: '#4c78a8',\n    invalid: 'filter',\n    timeUnitBand: 1\n};\nconst MARK_CONFIG_INDEX = {\n    mark: 1,\n    arc: 1,\n    area: 1,\n    bar: 1,\n    circle: 1,\n    image: 1,\n    line: 1,\n    point: 1,\n    rect: 1,\n    rule: 1,\n    square: 1,\n    text: 1,\n    tick: 1,\n    trail: 1,\n    geoshape: 1\n};\nexport const MARK_CONFIGS = keys(MARK_CONFIG_INDEX);\nexport const BAR_CORNER_RADIUS_INDEX = {\n    horizontal: ['cornerRadiusTopRight', 'cornerRadiusBottomRight'],\n    vertical: ['cornerRadiusTopLeft', 'cornerRadiusTopRight']\n};\nconst DEFAULT_RECT_BAND_SIZE = 5;\nexport const defaultBarConfig = {\n    binSpacing: 1,\n    continuousBandSize: DEFAULT_RECT_BAND_SIZE,\n    timeUnitBandPosition: 0.5\n};\nexport const defaultRectConfig = {\n    binSpacing: 0,\n    continuousBandSize: DEFAULT_RECT_BAND_SIZE,\n    timeUnitBandPosition: 0.5\n};\nexport const defaultTickConfig = {\n    thickness: 1\n};\nexport function getMarkType(m) {\n    return isMarkDef(m) ? m.type : m;\n}\n//# sourceMappingURL=mark.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isArray } from 'vega-util';\nimport { COLUMN, FACET, ROW } from '../channel';\nimport { hasConditionalFieldOrDatumDef, isFieldOrDatumDef, isValueDef } from '../channeldef';\nimport { boxPlotNormalizer } from '../compositemark/boxplot';\nimport { errorBandNormalizer } from '../compositemark/errorband';\nimport { errorBarNormalizer } from '../compositemark/errorbar';\nimport { channelHasField } from '../encoding';\nimport * as log from '../log';\nimport { isFacetMapping } from '../spec/facet';\nimport { SpecMapper } from '../spec/map';\nimport { isLayerRepeatSpec } from '../spec/repeat';\nimport { isUnitSpec } from '../spec/unit';\nimport { isEmpty, keys, omit, varName } from '../util';\nimport { isSignalRef } from '../vega.schema';\nimport { PathOverlayNormalizer } from './pathoverlay';\nimport { RangeStepNormalizer } from './rangestep';\nimport { replaceRepeaterInEncoding, replaceRepeaterInFacet } from './repeater';\nimport { RuleForRangedLineNormalizer } from './ruleforrangedline';\nexport class CoreNormalizer extends SpecMapper {\n    constructor() {\n        super(...arguments);\n        this.nonFacetUnitNormalizers = [\n            boxPlotNormalizer,\n            errorBarNormalizer,\n            errorBandNormalizer,\n            new PathOverlayNormalizer(),\n            new RuleForRangedLineNormalizer(),\n            new RangeStepNormalizer()\n        ];\n    }\n    map(spec, params) {\n        // Special handling for a faceted unit spec as it can return a facet spec, not just a layer or unit spec like a normal unit spec.\n        if (isUnitSpec(spec)) {\n            const hasRow = channelHasField(spec.encoding, ROW);\n            const hasColumn = channelHasField(spec.encoding, COLUMN);\n            const hasFacet = channelHasField(spec.encoding, FACET);\n            if (hasRow || hasColumn || hasFacet) {\n                return this.mapFacetedUnit(spec, params);\n            }\n        }\n        return super.map(spec, params);\n    }\n    // This is for normalizing non-facet unit\n    mapUnit(spec, params) {\n        const { parentEncoding, parentProjection } = params;\n        const encoding = replaceRepeaterInEncoding(spec.encoding, params.repeater);\n        const specWithReplacedEncoding = Object.assign(Object.assign({}, spec), (encoding ? { encoding } : {}));\n        if (parentEncoding || parentProjection) {\n            return this.mapUnitWithParentEncodingOrProjection(specWithReplacedEncoding, params);\n        }\n        const normalizeLayerOrUnit = this.mapLayerOrUnit.bind(this);\n        for (const unitNormalizer of this.nonFacetUnitNormalizers) {\n            if (unitNormalizer.hasMatchingType(specWithReplacedEncoding, params.config)) {\n                return unitNormalizer.run(specWithReplacedEncoding, params, normalizeLayerOrUnit);\n            }\n        }\n        return specWithReplacedEncoding;\n    }\n    mapRepeat(spec, params) {\n        if (isLayerRepeatSpec(spec)) {\n            return this.mapLayerRepeat(spec, params);\n        }\n        else {\n            return this.mapNonLayerRepeat(spec, params);\n        }\n    }\n    mapLayerRepeat(spec, params) {\n        const { repeat, spec: childSpec } = spec, rest = __rest(spec, [\"repeat\", \"spec\"]);\n        const { row, column, layer } = repeat;\n        const { repeater = {}, repeaterPrefix = '' } = params;\n        if (row || column) {\n            return this.mapRepeat(Object.assign(Object.assign({}, spec), { repeat: Object.assign(Object.assign({}, (row ? { row } : {})), (column ? { column } : {})), spec: {\n                    repeat: { layer },\n                    spec: childSpec\n                } }), params);\n        }\n        else {\n            return Object.assign(Object.assign({}, rest), { layer: layer.map(layerValue => {\n                    const childRepeater = Object.assign(Object.assign({}, repeater), { layer: layerValue });\n                    const childName = (childSpec.name || '') + repeaterPrefix + `child__layer_${varName(layerValue)}`;\n                    const child = this.mapLayerOrUnit(childSpec, Object.assign(Object.assign({}, params), { repeater: childRepeater, repeaterPrefix: childName }));\n                    child.name = childName;\n                    return child;\n                }) });\n        }\n    }\n    mapNonLayerRepeat(spec, params) {\n        var _a;\n        const { repeat, spec: childSpec, data } = spec, remainingProperties = __rest(spec, [\"repeat\", \"spec\", \"data\"]);\n        if (!isArray(repeat) && spec.columns) {\n            // is repeat with row/column\n            spec = omit(spec, ['columns']);\n            log.warn(log.message.columnsNotSupportByRowCol('repeat'));\n        }\n        const concat = [];\n        const { repeater = {}, repeaterPrefix = '' } = params;\n        const row = (!isArray(repeat) && repeat.row) || [repeater ? repeater.row : null];\n        const column = (!isArray(repeat) && repeat.column) || [repeater ? repeater.column : null];\n        const repeatValues = (isArray(repeat) && repeat) || [repeater ? repeater.repeat : null];\n        // cross product\n        for (const repeatValue of repeatValues) {\n            for (const rowValue of row) {\n                for (const columnValue of column) {\n                    const childRepeater = {\n                        repeat: repeatValue,\n                        row: rowValue,\n                        column: columnValue,\n                        layer: repeater.layer\n                    };\n                    const childName = (childSpec.name || '') +\n                        repeaterPrefix +\n                        'child__' +\n                        (isArray(repeat)\n                            ? `${varName(repeatValue)}`\n                            : (repeat.row ? `row_${varName(rowValue)}` : '') +\n                                (repeat.column ? `column_${varName(columnValue)}` : ''));\n                    const child = this.map(childSpec, Object.assign(Object.assign({}, params), { repeater: childRepeater, repeaterPrefix: childName }));\n                    child.name = childName;\n                    // we move data up\n                    concat.push(omit(child, ['data']));\n                }\n            }\n        }\n        const columns = isArray(repeat) ? spec.columns : repeat.column ? repeat.column.length : 1;\n        return Object.assign(Object.assign({ data: (_a = childSpec.data) !== null && _a !== void 0 ? _a : data, align: 'all' }, remainingProperties), { columns,\n            concat });\n    }\n    mapFacet(spec, params) {\n        const { facet } = spec;\n        if (isFacetMapping(facet) && spec.columns) {\n            // is facet with row/column\n            spec = omit(spec, ['columns']);\n            log.warn(log.message.columnsNotSupportByRowCol('facet'));\n        }\n        return super.mapFacet(spec, params);\n    }\n    mapUnitWithParentEncodingOrProjection(spec, params) {\n        const { encoding, projection } = spec;\n        const { parentEncoding, parentProjection, config } = params;\n        const mergedProjection = mergeProjection({ parentProjection, projection });\n        const mergedEncoding = mergeEncoding({\n            parentEncoding,\n            encoding: replaceRepeaterInEncoding(encoding, params.repeater)\n        });\n        return this.mapUnit(Object.assign(Object.assign(Object.assign({}, spec), (mergedProjection ? { projection: mergedProjection } : {})), (mergedEncoding ? { encoding: mergedEncoding } : {})), { config });\n    }\n    mapFacetedUnit(spec, params) {\n        // New encoding in the inside spec should not contain row / column\n        // as row/column should be moved to facet\n        const _a = spec.encoding, { row, column, facet } = _a, encoding = __rest(_a, [\"row\", \"column\", \"facet\"]);\n        // Mark and encoding should be moved into the inner spec\n        const { mark, width, projection, height, view, selection, encoding: _ } = spec, outerSpec = __rest(spec, [\"mark\", \"width\", \"projection\", \"height\", \"view\", \"selection\", \"encoding\"]);\n        const { facetMapping, layout } = this.getFacetMappingAndLayout({ row, column, facet }, params);\n        const newEncoding = replaceRepeaterInEncoding(encoding, params.repeater);\n        return this.mapFacet(Object.assign(Object.assign(Object.assign({}, outerSpec), layout), { \n            // row / column has higher precedence than facet\n            facet: facetMapping, spec: Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, (width ? { width } : {})), (height ? { height } : {})), (view ? { view } : {})), (projection ? { projection } : {})), { mark, encoding: newEncoding }), (selection ? { selection } : {})) }), params);\n    }\n    getFacetMappingAndLayout(facets, params) {\n        var _a;\n        const { row, column, facet } = facets;\n        if (row || column) {\n            if (facet) {\n                log.warn(log.message.facetChannelDropped([...(row ? [ROW] : []), ...(column ? [COLUMN] : [])]));\n            }\n            const facetMapping = {};\n            const layout = {};\n            for (const channel of [ROW, COLUMN]) {\n                const def = facets[channel];\n                if (def) {\n                    const { align, center, spacing, columns } = def, defWithoutLayout = __rest(def, [\"align\", \"center\", \"spacing\", \"columns\"]);\n                    facetMapping[channel] = defWithoutLayout;\n                    for (const prop of ['align', 'center', 'spacing']) {\n                        if (def[prop] !== undefined) {\n                            layout[prop] = (_a = layout[prop]) !== null && _a !== void 0 ? _a : {};\n                            layout[prop][channel] = def[prop];\n                        }\n                    }\n                }\n            }\n            return { facetMapping, layout };\n        }\n        else {\n            const { align, center, spacing, columns } = facet, facetMapping = __rest(facet, [\"align\", \"center\", \"spacing\", \"columns\"]);\n            return {\n                facetMapping: replaceRepeaterInFacet(facetMapping, params.repeater),\n                layout: Object.assign(Object.assign(Object.assign(Object.assign({}, (align ? { align } : {})), (center ? { center } : {})), (spacing ? { spacing } : {})), (columns ? { columns } : {}))\n            };\n        }\n    }\n    mapLayer(spec, _a) {\n        // Special handling for extended layer spec\n        var { parentEncoding, parentProjection } = _a, otherParams = __rest(_a, [\"parentEncoding\", \"parentProjection\"]);\n        const { encoding, projection } = spec, rest = __rest(spec, [\"encoding\", \"projection\"]);\n        const params = Object.assign(Object.assign({}, otherParams), { parentEncoding: mergeEncoding({ parentEncoding, encoding, layer: true }), parentProjection: mergeProjection({ parentProjection, projection }) });\n        return super.mapLayer(rest, params);\n    }\n}\nfunction mergeEncoding({ parentEncoding, encoding = {}, layer }) {\n    let merged = {};\n    if (parentEncoding) {\n        const channels = new Set([...keys(parentEncoding), ...keys(encoding)]);\n        for (const channel of channels) {\n            const channelDef = encoding[channel];\n            const parentChannelDef = parentEncoding[channel];\n            if (isFieldOrDatumDef(channelDef)) {\n                // Field/Datum Def can inherit properties from its parent\n                // Note that parentChannelDef doesn't have to be a field/datum def if the channelDef is already one.\n                const mergedChannelDef = Object.assign(Object.assign({}, parentChannelDef), channelDef);\n                merged[channel] = mergedChannelDef;\n            }\n            else if (hasConditionalFieldOrDatumDef(channelDef)) {\n                merged[channel] = Object.assign(Object.assign({}, channelDef), { condition: Object.assign(Object.assign({}, parentChannelDef), channelDef.condition) });\n            }\n            else if (channelDef || channelDef === null) {\n                merged[channel] = channelDef;\n            }\n            else if (layer ||\n                isValueDef(parentChannelDef) ||\n                isSignalRef(parentChannelDef) ||\n                isFieldOrDatumDef(parentChannelDef) ||\n                isArray(parentChannelDef)) {\n                merged[channel] = parentChannelDef;\n            }\n        }\n    }\n    else {\n        merged = encoding;\n    }\n    return !merged || isEmpty(merged) ? undefined : merged;\n}\nfunction mergeProjection(opt) {\n    const { parentProjection, projection } = opt;\n    if (parentProjection && projection) {\n        log.warn(log.message.projectionOverridden({ parentProjection, projection }));\n    }\n    return projection !== null && projection !== void 0 ? projection : parentProjection;\n}\n//# sourceMappingURL=core.js.map","import { isString } from 'vega-util';\nimport { initConfig } from '../config';\nimport * as log from '../log';\nimport { isLayerSpec, isUnitSpec } from '../spec';\nimport { deepEqual } from '../util';\nimport { CoreNormalizer } from './core';\nexport function normalize(spec, config) {\n    if (config === undefined) {\n        config = initConfig(spec.config);\n    }\n    const normalizedSpec = normalizeGenericSpec(spec, config);\n    const { width, height } = spec;\n    const autosize = normalizeAutoSize(normalizedSpec, { width, height, autosize: spec.autosize }, config);\n    return Object.assign(Object.assign({}, normalizedSpec), (autosize ? { autosize } : {}));\n}\nconst normalizer = new CoreNormalizer();\n/**\n * Decompose extended unit specs into composition of pure unit specs.\n */\nfunction normalizeGenericSpec(spec, config = {}) {\n    return normalizer.map(spec, { config });\n}\nfunction _normalizeAutoSize(autosize) {\n    return isString(autosize) ? { type: autosize } : autosize !== null && autosize !== void 0 ? autosize : {};\n}\n/**\n * Normalize autosize and deal with width or height == \"container\".\n */\nexport function normalizeAutoSize(spec, sizeInfo, config) {\n    let { width, height } = sizeInfo;\n    const isFitCompatible = isUnitSpec(spec) || isLayerSpec(spec);\n    const autosizeDefault = {};\n    if (!isFitCompatible) {\n        // If spec is not compatible with autosize == \"fit\", discard width/height == container\n        if (width == 'container') {\n            log.warn(log.message.containerSizeNonSingle('width'));\n            width = undefined;\n        }\n        if (height == 'container') {\n            log.warn(log.message.containerSizeNonSingle('height'));\n            height = undefined;\n        }\n    }\n    else {\n        // Default autosize parameters to fit when width/height is \"container\"\n        if (width == 'container' && height == 'container') {\n            autosizeDefault.type = 'fit';\n            autosizeDefault.contains = 'padding';\n        }\n        else if (width == 'container') {\n            autosizeDefault.type = 'fit-x';\n            autosizeDefault.contains = 'padding';\n        }\n        else if (height == 'container') {\n            autosizeDefault.type = 'fit-y';\n            autosizeDefault.contains = 'padding';\n        }\n    }\n    const autosize = Object.assign(Object.assign(Object.assign({ type: 'pad' }, autosizeDefault), (config ? _normalizeAutoSize(config.autosize) : {})), _normalizeAutoSize(spec.autosize));\n    if (autosize.type === 'fit' && !isFitCompatible) {\n        log.warn(log.message.FIT_NON_SINGLE);\n        autosize.type = 'pad';\n    }\n    if (width == 'container' && !(autosize.type == 'fit' || autosize.type == 'fit-x')) {\n        log.warn(log.message.containerSizeNotCompatibleWithAutosize('width'));\n    }\n    if (height == 'container' && !(autosize.type == 'fit' || autosize.type == 'fit-y')) {\n        log.warn(log.message.containerSizeNotCompatibleWithAutosize('height'));\n    }\n    // Delete autosize property if it's Vega's default\n    if (deepEqual(autosize, { type: 'pad' })) {\n        return undefined;\n    }\n    return autosize;\n}\n//# sourceMappingURL=index.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isObject } from 'vega-util';\nimport { normalizeEncoding } from '../encoding';\nimport { isMarkDef } from '../mark';\nimport { isUnitSpec } from '../spec/unit';\nimport { stack } from '../stack';\nimport { keys, omit, pick } from '../util';\nfunction dropLineAndPoint(markDef) {\n    const { point: _point, line: _line } = markDef, mark = __rest(markDef, [\"point\", \"line\"]);\n    return keys(mark).length > 1 ? mark : mark.type;\n}\nfunction dropLineAndPointFromConfig(config) {\n    for (const mark of ['line', 'area', 'rule', 'trail']) {\n        if (config[mark]) {\n            config = Object.assign(Object.assign({}, config), { \n                // TODO: remove as any\n                [mark]: omit(config[mark], ['point', 'line']) });\n        }\n    }\n    return config;\n}\nfunction getPointOverlay(markDef, markConfig = {}, encoding) {\n    if (markDef.point === 'transparent') {\n        return { opacity: 0 };\n    }\n    else if (markDef.point) {\n        // truthy : true or object\n        return isObject(markDef.point) ? markDef.point : {};\n    }\n    else if (markDef.point !== undefined) {\n        // false or null\n        return null;\n    }\n    else {\n        // undefined (not disabled)\n        if (markConfig.point || encoding.shape) {\n            // enable point overlay if config[mark].point is truthy or if encoding.shape is provided\n            return isObject(markConfig.point) ? markConfig.point : {};\n        }\n        // markDef.point is defined as falsy\n        return undefined;\n    }\n}\nfunction getLineOverlay(markDef, markConfig = {}) {\n    if (markDef.line) {\n        // true or object\n        return markDef.line === true ? {} : markDef.line;\n    }\n    else if (markDef.line !== undefined) {\n        // false or null\n        return null;\n    }\n    else {\n        // undefined (not disabled)\n        if (markConfig.line) {\n            // enable line overlay if config[mark].line is truthy\n            return markConfig.line === true ? {} : markConfig.line;\n        }\n        // markDef.point is defined as falsy\n        return undefined;\n    }\n}\nexport class PathOverlayNormalizer {\n    constructor() {\n        this.name = 'path-overlay';\n    }\n    hasMatchingType(spec, config) {\n        if (isUnitSpec(spec)) {\n            const { mark, encoding } = spec;\n            const markDef = isMarkDef(mark) ? mark : { type: mark };\n            switch (markDef.type) {\n                case 'line':\n                case 'rule':\n                case 'trail':\n                    return !!getPointOverlay(markDef, config[markDef.type], encoding);\n                case 'area':\n                    return (\n                    // false / null are also included as we want to remove the properties\n                    !!getPointOverlay(markDef, config[markDef.type], encoding) ||\n                        !!getLineOverlay(markDef, config[markDef.type]));\n            }\n        }\n        return false;\n    }\n    run(spec, params, normalize) {\n        const { config } = params;\n        const { selection, projection, mark, encoding: e } = spec, outerSpec = __rest(spec, [\"selection\", \"projection\", \"mark\", \"encoding\"]);\n        // Need to call normalizeEncoding because we need the inferred types to correctly determine stack\n        const encoding = normalizeEncoding(e, config);\n        const markDef = isMarkDef(mark) ? mark : { type: mark };\n        const pointOverlay = getPointOverlay(markDef, config[markDef.type], encoding);\n        const lineOverlay = markDef.type === 'area' && getLineOverlay(markDef, config[markDef.type]);\n        const layer = [\n            Object.assign(Object.assign({}, (selection ? { selection } : {})), { mark: dropLineAndPoint(Object.assign(Object.assign({}, (markDef.type === 'area' && markDef.opacity === undefined && markDef.fillOpacity === undefined\n                    ? { opacity: 0.7 }\n                    : {})), markDef)), \n                // drop shape from encoding as this might be used to trigger point overlay\n                encoding: omit(encoding, ['shape']) })\n        ];\n        // FIXME: determine rules for applying selections.\n        // Need to copy stack config to overlayed layer\n        const stackProps = stack(markDef, encoding);\n        let overlayEncoding = encoding;\n        if (stackProps) {\n            const { fieldChannel: stackFieldChannel, offset } = stackProps;\n            overlayEncoding = Object.assign(Object.assign({}, encoding), { [stackFieldChannel]: Object.assign(Object.assign({}, encoding[stackFieldChannel]), (offset ? { stack: offset } : {})) });\n        }\n        if (lineOverlay) {\n            layer.push(Object.assign(Object.assign({}, (projection ? { projection } : {})), { mark: Object.assign(Object.assign({ type: 'line' }, pick(markDef, ['clip', 'interpolate', 'tension', 'tooltip'])), lineOverlay), encoding: overlayEncoding }));\n        }\n        if (pointOverlay) {\n            layer.push(Object.assign(Object.assign({}, (projection ? { projection } : {})), { mark: Object.assign(Object.assign({ type: 'point', opacity: 1, filled: true }, pick(markDef, ['clip', 'tooltip'])), pointOverlay), encoding: overlayEncoding }));\n        }\n        return normalize(Object.assign(Object.assign({}, outerSpec), { layer }), Object.assign(Object.assign({}, params), { config: dropLineAndPointFromConfig(config) }));\n    }\n}\n//# sourceMappingURL=pathoverlay.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { getSizeChannel, POSITION_SCALE_CHANNELS } from '../channel';\nimport { isFieldOrDatumDef } from '../channeldef';\nimport * as log from '../log';\nimport { isUnitSpec } from '../spec/unit';\nimport { isEmpty } from '../util';\nexport class RangeStepNormalizer {\n    constructor() {\n        this.name = 'RangeStep';\n    }\n    hasMatchingType(spec) {\n        var _a;\n        if (isUnitSpec(spec) && spec.encoding) {\n            for (const channel of POSITION_SCALE_CHANNELS) {\n                const def = spec.encoding[channel];\n                if (def && isFieldOrDatumDef(def)) {\n                    if ((_a = def === null || def === void 0 ? void 0 : def.scale) === null || _a === void 0 ? void 0 : _a['rangeStep']) {\n                        return true;\n                    }\n                }\n            }\n        }\n        return false;\n    }\n    run(spec) {\n        var _a;\n        const sizeMixins = {};\n        let encoding = Object.assign({}, spec.encoding);\n        for (const channel of POSITION_SCALE_CHANNELS) {\n            const sizeType = getSizeChannel(channel);\n            const def = encoding[channel];\n            if (def && isFieldOrDatumDef(def)) {\n                if ((_a = def === null || def === void 0 ? void 0 : def.scale) === null || _a === void 0 ? void 0 : _a['rangeStep']) {\n                    const { scale } = def, defWithoutScale = __rest(def, [\"scale\"]);\n                    const _b = scale, { rangeStep } = _b, scaleWithoutRangeStep = __rest(_b, [\"rangeStep\"]);\n                    sizeMixins[sizeType] = { step: scale['rangeStep'] };\n                    log.warn(log.message.RANGE_STEP_DEPRECATED);\n                    encoding = Object.assign(Object.assign({}, encoding), { [channel]: Object.assign(Object.assign({}, defWithoutScale), (isEmpty(scaleWithoutRangeStep) ? {} : { scale: scaleWithoutRangeStep })) });\n                }\n            }\n        }\n        return Object.assign(Object.assign(Object.assign({}, sizeMixins), spec), { encoding });\n    }\n}\n//# sourceMappingURL=rangestep.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { hasOwnProperty, isArray } from 'vega-util';\nimport { hasConditionalFieldOrDatumDef, isConditionalDef, isFieldDef, isFieldOrDatumDef, isRepeatRef, isSortableFieldDef } from '../channeldef';\nimport * as log from '../log';\nimport { isSortField } from '../sort';\nimport { isFacetMapping } from '../spec/facet';\nexport function replaceRepeaterInFacet(facet, repeater) {\n    if (!repeater) {\n        return facet;\n    }\n    if (isFacetMapping(facet)) {\n        return replaceRepeaterInMapping(facet, repeater);\n    }\n    return replaceRepeaterInFieldDef(facet, repeater);\n}\nexport function replaceRepeaterInEncoding(encoding, repeater) {\n    if (!repeater) {\n        return encoding;\n    }\n    return replaceRepeaterInMapping(encoding, repeater);\n}\n/**\n * Replaces repeated value and returns if the repeated value is valid.\n */\nfunction replaceRepeatInProp(prop, o, repeater) {\n    const val = o[prop];\n    if (isRepeatRef(val)) {\n        if (val.repeat in repeater) {\n            return Object.assign(Object.assign({}, o), { [prop]: repeater[val.repeat] });\n        }\n        else {\n            log.warn(log.message.noSuchRepeatedValue(val.repeat));\n            return undefined;\n        }\n    }\n    return o;\n}\n/**\n * Replace repeater values in a field def with the concrete field name.\n */\nfunction replaceRepeaterInFieldDef(fieldDef, repeater) {\n    fieldDef = replaceRepeatInProp('field', fieldDef, repeater);\n    if (fieldDef === undefined) {\n        // the field def should be ignored\n        return undefined;\n    }\n    else if (fieldDef === null) {\n        return null;\n    }\n    if (isSortableFieldDef(fieldDef) && isSortField(fieldDef.sort)) {\n        const sort = replaceRepeatInProp('field', fieldDef.sort, repeater);\n        fieldDef = Object.assign(Object.assign({}, fieldDef), (sort ? { sort } : {}));\n    }\n    return fieldDef;\n}\nfunction replaceRepeaterInFieldOrDatumDef(def, repeater) {\n    if (isFieldDef(def)) {\n        return replaceRepeaterInFieldDef(def, repeater);\n    }\n    else {\n        const datumDef = replaceRepeatInProp('datum', def, repeater);\n        if (datumDef !== def && !datumDef.type) {\n            datumDef.type = 'nominal';\n        }\n        return datumDef;\n    }\n}\nfunction replaceRepeaterInChannelDef(channelDef, repeater) {\n    if (isFieldOrDatumDef(channelDef)) {\n        const fd = replaceRepeaterInFieldOrDatumDef(channelDef, repeater);\n        if (fd) {\n            return fd;\n        }\n        else if (isConditionalDef(channelDef)) {\n            return { condition: channelDef.condition };\n        }\n    }\n    else {\n        if (hasConditionalFieldOrDatumDef(channelDef)) {\n            const fd = replaceRepeaterInFieldOrDatumDef(channelDef.condition, repeater);\n            if (fd) {\n                return Object.assign(Object.assign({}, channelDef), { condition: fd });\n            }\n            else {\n                const { condition } = channelDef, channelDefWithoutCondition = __rest(channelDef, [\"condition\"]);\n                return channelDefWithoutCondition;\n            }\n        }\n        return channelDef;\n    }\n    return undefined;\n}\nfunction replaceRepeaterInMapping(mapping, repeater) {\n    const out = {};\n    for (const channel in mapping) {\n        if (hasOwnProperty(mapping, channel)) {\n            const channelDef = mapping[channel];\n            if (isArray(channelDef)) {\n                // array cannot have condition\n                out[channel] = channelDef // somehow we need to cast it here\n                    .map(cd => replaceRepeaterInChannelDef(cd, repeater))\n                    .filter(cd => cd);\n            }\n            else {\n                const cd = replaceRepeaterInChannelDef(channelDef, repeater);\n                if (cd !== undefined) {\n                    out[channel] = cd;\n                }\n            }\n        }\n    }\n    return out;\n}\n//# sourceMappingURL=repeater.js.map","import { isBinned } from '../bin';\nimport { getMainRangeChannel, SECONDARY_RANGE_CHANNEL } from '../channel';\nimport { isDatumDef, isFieldDef } from '../channeldef';\nimport * as log from '../log';\nimport { isUnitSpec } from '../spec/unit';\nexport class RuleForRangedLineNormalizer {\n    constructor() {\n        this.name = 'RuleForRangedLine';\n    }\n    hasMatchingType(spec) {\n        if (isUnitSpec(spec)) {\n            const { encoding, mark } = spec;\n            if (mark === 'line') {\n                for (const channel of SECONDARY_RANGE_CHANNEL) {\n                    const mainChannel = getMainRangeChannel(channel);\n                    const mainChannelDef = encoding[mainChannel];\n                    if (encoding[channel]) {\n                        if ((isFieldDef(mainChannelDef) && !isBinned(mainChannelDef.bin)) || isDatumDef(mainChannelDef)) {\n                            return true;\n                        }\n                    }\n                }\n            }\n        }\n        return false;\n    }\n    run(spec, params, normalize) {\n        const { encoding } = spec;\n        log.warn(log.message.lineWithRange(!!encoding.x2, !!encoding.y2));\n        return normalize(Object.assign(Object.assign({}, spec), { mark: 'rule' }), params);\n    }\n}\n//# sourceMappingURL=ruleforrangedline.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nexport function assembleParameterSignals(params) {\n    const signals = [];\n    for (const param of params || []) {\n        const { expr, bind } = param, rest = __rest(param, [\"expr\", \"bind\"]);\n        if (bind && expr) {\n            // Vega's InitSignal -- apply expr to \"init\"\n            const signal = Object.assign(Object.assign({}, rest), { bind, init: expr });\n            signals.push(signal);\n        }\n        else {\n            const signal = Object.assign(Object.assign(Object.assign({}, rest), (expr ? { update: expr } : {})), (bind ? { bind } : {}));\n            signals.push(signal);\n        }\n    }\n    return signals;\n}\n//# sourceMappingURL=parameter.js.map","import { isArray } from 'vega-util';\nimport { valueExpr, vgField } from './channeldef';\nimport { fieldExpr as timeUnitFieldExpr, normalizeTimeUnit } from './timeunit';\nimport { isSignalRef } from './vega.schema';\nexport function isSelectionPredicate(predicate) {\n    return predicate === null || predicate === void 0 ? void 0 : predicate['selection'];\n}\nexport function isFieldEqualPredicate(predicate) {\n    return predicate && !!predicate.field && predicate.equal !== undefined;\n}\nexport function isFieldLTPredicate(predicate) {\n    return predicate && !!predicate.field && predicate.lt !== undefined;\n}\nexport function isFieldLTEPredicate(predicate) {\n    return predicate && !!predicate.field && predicate.lte !== undefined;\n}\nexport function isFieldGTPredicate(predicate) {\n    return predicate && !!predicate.field && predicate.gt !== undefined;\n}\nexport function isFieldGTEPredicate(predicate) {\n    return predicate && !!predicate.field && predicate.gte !== undefined;\n}\nexport function isFieldRangePredicate(predicate) {\n    if (predicate && predicate.field) {\n        if (isArray(predicate.range) && predicate.range.length === 2) {\n            return true;\n        }\n        else if (isSignalRef(predicate.range)) {\n            return true;\n        }\n    }\n    return false;\n}\nexport function isFieldOneOfPredicate(predicate) {\n    return (predicate && !!predicate.field && (isArray(predicate.oneOf) || isArray(predicate.in)) // backward compatibility\n    );\n}\nexport function isFieldValidPredicate(predicate) {\n    return predicate && !!predicate.field && predicate.valid !== undefined;\n}\nexport function isFieldPredicate(predicate) {\n    return (isFieldOneOfPredicate(predicate) ||\n        isFieldEqualPredicate(predicate) ||\n        isFieldRangePredicate(predicate) ||\n        isFieldLTPredicate(predicate) ||\n        isFieldGTPredicate(predicate) ||\n        isFieldLTEPredicate(predicate) ||\n        isFieldGTEPredicate(predicate));\n}\nfunction predicateValueExpr(v, timeUnit) {\n    return valueExpr(v, { timeUnit, wrapTime: true });\n}\nfunction predicateValuesExpr(vals, timeUnit) {\n    return vals.map(v => predicateValueExpr(v, timeUnit));\n}\n// This method is used by Voyager. Do not change its behavior without changing Voyager.\nexport function fieldFilterExpression(predicate, useInRange = true) {\n    var _a;\n    const { field } = predicate;\n    const timeUnit = (_a = normalizeTimeUnit(predicate.timeUnit)) === null || _a === void 0 ? void 0 : _a.unit;\n    const fieldExpr = timeUnit\n        ? // For timeUnit, cast into integer with time() so we can use ===, inrange, indexOf to compare values directly.\n            // TODO: We calculate timeUnit on the fly here. Consider if we would like to consolidate this with timeUnit pipeline\n            // TODO: support utc\n            'time(' + timeUnitFieldExpr(timeUnit, field) + ')'\n        : vgField(predicate, { expr: 'datum' });\n    if (isFieldEqualPredicate(predicate)) {\n        return fieldExpr + '===' + predicateValueExpr(predicate.equal, timeUnit);\n    }\n    else if (isFieldLTPredicate(predicate)) {\n        const upper = predicate.lt;\n        return `${fieldExpr}<${predicateValueExpr(upper, timeUnit)}`;\n    }\n    else if (isFieldGTPredicate(predicate)) {\n        const lower = predicate.gt;\n        return `${fieldExpr}>${predicateValueExpr(lower, timeUnit)}`;\n    }\n    else if (isFieldLTEPredicate(predicate)) {\n        const upper = predicate.lte;\n        return `${fieldExpr}<=${predicateValueExpr(upper, timeUnit)}`;\n    }\n    else if (isFieldGTEPredicate(predicate)) {\n        const lower = predicate.gte;\n        return `${fieldExpr}>=${predicateValueExpr(lower, timeUnit)}`;\n    }\n    else if (isFieldOneOfPredicate(predicate)) {\n        return `indexof([${predicateValuesExpr(predicate.oneOf, timeUnit).join(',')}], ${fieldExpr}) !== -1`;\n    }\n    else if (isFieldValidPredicate(predicate)) {\n        return fieldValidPredicate(fieldExpr, predicate.valid);\n    }\n    else if (isFieldRangePredicate(predicate)) {\n        const { range } = predicate;\n        const lower = isSignalRef(range) ? { signal: `${range.signal}[0]` } : range[0];\n        const upper = isSignalRef(range) ? { signal: `${range.signal}[1]` } : range[1];\n        if (lower !== null && upper !== null && useInRange) {\n            return ('inrange(' +\n                fieldExpr +\n                ', [' +\n                predicateValueExpr(lower, timeUnit) +\n                ', ' +\n                predicateValueExpr(upper, timeUnit) +\n                '])');\n        }\n        const exprs = [];\n        if (lower !== null) {\n            exprs.push(`${fieldExpr} >= ${predicateValueExpr(lower, timeUnit)}`);\n        }\n        if (upper !== null) {\n            exprs.push(`${fieldExpr} <= ${predicateValueExpr(upper, timeUnit)}`);\n        }\n        return exprs.length > 0 ? exprs.join(' && ') : 'true';\n    }\n    /* istanbul ignore next: it should never reach here */\n    throw new Error(`Invalid field predicate: ${JSON.stringify(predicate)}`);\n}\nexport function fieldValidPredicate(fieldExpr, valid = true) {\n    if (valid) {\n        return `isValid(${fieldExpr}) && isFinite(+${fieldExpr})`;\n    }\n    else {\n        return `!isValid(${fieldExpr}) || !isFinite(+${fieldExpr})`;\n    }\n}\nexport function normalizePredicate(f) {\n    var _a;\n    if (isFieldPredicate(f) && f.timeUnit) {\n        return Object.assign(Object.assign({}, f), { timeUnit: (_a = normalizeTimeUnit(f.timeUnit)) === null || _a === void 0 ? void 0 : _a.unit });\n    }\n    return f;\n}\n//# sourceMappingURL=predicate.js.map","export const PROJECTION_PROPERTIES = [\n    'type',\n    'clipAngle',\n    'clipExtent',\n    'center',\n    'rotate',\n    'precision',\n    'reflectX',\n    'reflectY',\n    'coefficient',\n    'distance',\n    'fraction',\n    'lobes',\n    'parallel',\n    'radius',\n    'ratio',\n    'spacing',\n    'tilt'\n];\n//# sourceMappingURL=projection.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isString, toSet } from 'vega-util';\nimport * as CHANNEL from './channel';\nimport { isColorChannel } from './channel';\nimport * as log from './log';\nimport { NOMINAL, ORDINAL, QUANTITATIVE, TEMPORAL } from './type';\nimport { contains, keys } from './util';\nexport const ScaleType = {\n    // Continuous - Quantitative\n    LINEAR: 'linear',\n    LOG: 'log',\n    POW: 'pow',\n    SQRT: 'sqrt',\n    SYMLOG: 'symlog',\n    IDENTITY: 'identity',\n    SEQUENTIAL: 'sequential',\n    // Continuous - Time\n    TIME: 'time',\n    UTC: 'utc',\n    // Discretizing scales\n    QUANTILE: 'quantile',\n    QUANTIZE: 'quantize',\n    THRESHOLD: 'threshold',\n    BIN_ORDINAL: 'bin-ordinal',\n    // Discrete scales\n    ORDINAL: 'ordinal',\n    POINT: 'point',\n    BAND: 'band'\n};\n/**\n * Index for scale categories -- only scale of the same categories can be merged together.\n * Current implementation is trying to be conservative and avoid merging scale type that might not work together\n */\nexport const SCALE_CATEGORY_INDEX = {\n    linear: 'numeric',\n    log: 'numeric',\n    pow: 'numeric',\n    sqrt: 'numeric',\n    symlog: 'numeric',\n    identity: 'numeric',\n    sequential: 'numeric',\n    time: 'time',\n    utc: 'time',\n    ordinal: 'ordinal',\n    'bin-ordinal': 'bin-ordinal',\n    point: 'ordinal-position',\n    band: 'ordinal-position',\n    quantile: 'discretizing',\n    quantize: 'discretizing',\n    threshold: 'discretizing'\n};\nexport const SCALE_TYPES = keys(SCALE_CATEGORY_INDEX);\n/**\n * Whether the two given scale types can be merged together.\n */\nexport function scaleCompatible(scaleType1, scaleType2) {\n    const scaleCategory1 = SCALE_CATEGORY_INDEX[scaleType1];\n    const scaleCategory2 = SCALE_CATEGORY_INDEX[scaleType2];\n    return (scaleCategory1 === scaleCategory2 ||\n        (scaleCategory1 === 'ordinal-position' && scaleCategory2 === 'time') ||\n        (scaleCategory2 === 'ordinal-position' && scaleCategory1 === 'time'));\n}\n/**\n * Index for scale precedence -- high score = higher priority for merging.\n */\nconst SCALE_PRECEDENCE_INDEX = {\n    // numeric\n    linear: 0,\n    log: 1,\n    pow: 1,\n    sqrt: 1,\n    symlog: 1,\n    identity: 1,\n    sequential: 1,\n    // time\n    time: 0,\n    utc: 0,\n    // ordinal-position -- these have higher precedence than continuous scales as they support more types of data\n    point: 10,\n    band: 11,\n    // non grouped types\n    ordinal: 0,\n    'bin-ordinal': 0,\n    quantile: 0,\n    quantize: 0,\n    threshold: 0\n};\n/**\n * Return scale categories -- only scale of the same categories can be merged together.\n */\nexport function scaleTypePrecedence(scaleType) {\n    return SCALE_PRECEDENCE_INDEX[scaleType];\n}\nexport const CONTINUOUS_TO_CONTINUOUS_SCALES = ['linear', 'log', 'pow', 'sqrt', 'symlog', 'time', 'utc'];\nconst CONTINUOUS_TO_CONTINUOUS_INDEX = toSet(CONTINUOUS_TO_CONTINUOUS_SCALES);\nexport const QUANTITATIVE_SCALES = ['linear', 'log', 'pow', 'sqrt', 'symlog'];\nconst QUANTITATIVE_SCALES_INDEX = toSet(QUANTITATIVE_SCALES);\nexport function isQuantitative(type) {\n    return type in QUANTITATIVE_SCALES_INDEX;\n}\nexport const CONTINUOUS_TO_DISCRETE_SCALES = ['quantile', 'quantize', 'threshold'];\nconst CONTINUOUS_TO_DISCRETE_INDEX = toSet(CONTINUOUS_TO_DISCRETE_SCALES);\nexport const CONTINUOUS_DOMAIN_SCALES = CONTINUOUS_TO_CONTINUOUS_SCALES.concat([\n    'quantile',\n    'quantize',\n    'threshold',\n    'sequential',\n    'identity'\n]);\nconst CONTINUOUS_DOMAIN_INDEX = toSet(CONTINUOUS_DOMAIN_SCALES);\nexport const DISCRETE_DOMAIN_SCALES = ['ordinal', 'bin-ordinal', 'point', 'band'];\nconst DISCRETE_DOMAIN_INDEX = toSet(DISCRETE_DOMAIN_SCALES);\nexport const TIME_SCALE_TYPES = ['time', 'utc'];\nexport function hasDiscreteDomain(type) {\n    return type in DISCRETE_DOMAIN_INDEX;\n}\nexport function hasContinuousDomain(type) {\n    return type in CONTINUOUS_DOMAIN_INDEX;\n}\nexport function isContinuousToContinuous(type) {\n    return type in CONTINUOUS_TO_CONTINUOUS_INDEX;\n}\nexport function isContinuousToDiscrete(type) {\n    return type in CONTINUOUS_TO_DISCRETE_INDEX;\n}\nexport const defaultScaleConfig = {\n    pointPadding: 0.5,\n    barBandPaddingInner: 0.1,\n    rectBandPaddingInner: 0,\n    minBandSize: 2,\n    minFontSize: 8,\n    maxFontSize: 40,\n    minOpacity: 0.3,\n    maxOpacity: 0.8,\n    // FIXME: revise if these *can* become ratios of width/height step\n    minSize: 9,\n    minStrokeWidth: 1,\n    maxStrokeWidth: 4,\n    quantileCount: 4,\n    quantizeCount: 4\n};\nexport function isExtendedScheme(scheme) {\n    return !isString(scheme) && !!scheme['name'];\n}\nexport function isSelectionDomain(domain) {\n    return domain === null || domain === void 0 ? void 0 : domain['selection'];\n}\nexport function isDomainUnionWith(domain) {\n    return domain && domain['unionWith'];\n}\nconst SCALE_PROPERTY_INDEX = {\n    type: 1,\n    domain: 1,\n    domainMax: 1,\n    domainMin: 1,\n    domainMid: 1,\n    align: 1,\n    range: 1,\n    rangeMax: 1,\n    rangeMin: 1,\n    scheme: 1,\n    bins: 1,\n    // Other properties\n    reverse: 1,\n    round: 1,\n    // quantitative / time\n    clamp: 1,\n    nice: 1,\n    // quantitative\n    base: 1,\n    exponent: 1,\n    constant: 1,\n    interpolate: 1,\n    zero: 1,\n    // band/point\n    padding: 1,\n    paddingInner: 1,\n    paddingOuter: 1\n};\nexport const SCALE_PROPERTIES = keys(SCALE_PROPERTY_INDEX);\nconst { type, domain, range, rangeMax, rangeMin, scheme } = SCALE_PROPERTY_INDEX, NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTY_INDEX = __rest(SCALE_PROPERTY_INDEX, [\"type\", \"domain\", \"range\", \"rangeMax\", \"rangeMin\", \"scheme\"]);\nexport const NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTIES = keys(NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTY_INDEX);\nexport function scaleTypeSupportProperty(scaleType, propName) {\n    switch (propName) {\n        case 'type':\n        case 'domain':\n        case 'reverse':\n        case 'range':\n            return true;\n        case 'scheme':\n        case 'interpolate':\n            return !contains(['point', 'band', 'identity'], scaleType);\n        case 'bins':\n            return !contains(['point', 'band', 'identity', 'ordinal'], scaleType);\n        case 'round':\n            return isContinuousToContinuous(scaleType) || scaleType === 'band' || scaleType === 'point';\n        case 'padding':\n        case 'rangeMin':\n        case 'rangeMax':\n            return isContinuousToContinuous(scaleType) || contains(['point', 'band'], scaleType);\n        case 'paddingOuter':\n        case 'align':\n            return contains(['point', 'band'], scaleType);\n        case 'paddingInner':\n            return scaleType === 'band';\n        case 'domainMax':\n        case 'domainMid':\n        case 'domainMin':\n        case 'clamp':\n            return isContinuousToContinuous(scaleType);\n        case 'nice':\n            return isContinuousToContinuous(scaleType) || scaleType === 'quantize' || scaleType === 'threshold';\n        case 'exponent':\n            return scaleType === 'pow';\n        case 'base':\n            return scaleType === 'log';\n        case 'constant':\n            return scaleType === 'symlog';\n        case 'zero':\n            return (hasContinuousDomain(scaleType) &&\n                !contains([\n                    'log',\n                    'time',\n                    'utc',\n                    'threshold',\n                    'quantile' // quantile depends on distribution so zero does not matter\n                ], scaleType));\n    }\n}\n/**\n * Returns undefined if the input channel supports the input scale property name\n */\nexport function channelScalePropertyIncompatability(channel, propName) {\n    switch (propName) {\n        case 'interpolate':\n        case 'scheme':\n        case 'domainMid':\n            if (!isColorChannel(channel)) {\n                return log.message.cannotUseScalePropertyWithNonColor(channel);\n            }\n            return undefined;\n        case 'align':\n        case 'type':\n        case 'bins':\n        case 'domain':\n        case 'domainMax':\n        case 'domainMin':\n        case 'range':\n        case 'base':\n        case 'exponent':\n        case 'constant':\n        case 'nice':\n        case 'padding':\n        case 'paddingInner':\n        case 'paddingOuter':\n        case 'rangeMax':\n        case 'rangeMin':\n        case 'reverse':\n        case 'round':\n        case 'clamp':\n        case 'zero':\n            return undefined; // GOOD!\n    }\n}\nexport function scaleTypeSupportDataType(specifiedType, fieldDefType) {\n    if (contains([ORDINAL, NOMINAL], fieldDefType)) {\n        return specifiedType === undefined || hasDiscreteDomain(specifiedType);\n    }\n    else if (fieldDefType === TEMPORAL) {\n        return contains([ScaleType.TIME, ScaleType.UTC, undefined], specifiedType);\n    }\n    else if (fieldDefType === QUANTITATIVE) {\n        return contains([\n            ScaleType.LOG,\n            ScaleType.POW,\n            ScaleType.SQRT,\n            ScaleType.SYMLOG,\n            ScaleType.QUANTILE,\n            ScaleType.QUANTIZE,\n            ScaleType.THRESHOLD,\n            ScaleType.LINEAR,\n            undefined\n        ], specifiedType);\n    }\n    return true;\n}\nexport function channelSupportScaleType(channel, scaleType) {\n    if (!CHANNEL.isScaleChannel(channel)) {\n        return false;\n    }\n    switch (channel) {\n        case CHANNEL.X:\n        case CHANNEL.Y:\n        case CHANNEL.THETA:\n        case CHANNEL.RADIUS:\n            return isContinuousToContinuous(scaleType) || contains(['band', 'point'], scaleType);\n        case CHANNEL.SIZE: // TODO: size and opacity can support ordinal with more modification\n        case CHANNEL.STROKEWIDTH:\n        case CHANNEL.OPACITY:\n        case CHANNEL.FILLOPACITY:\n        case CHANNEL.STROKEOPACITY:\n        case CHANNEL.ANGLE:\n            // Although it generally doesn't make sense to use band with size and opacity,\n            // it can also work since we use band: 0.5 to get midpoint.\n            return (isContinuousToContinuous(scaleType) ||\n                isContinuousToDiscrete(scaleType) ||\n                contains(['band', 'point', 'ordinal'], scaleType));\n        case CHANNEL.COLOR:\n        case CHANNEL.FILL:\n        case CHANNEL.STROKE:\n            return scaleType !== 'band'; // band does not make sense with color\n        case CHANNEL.STROKEDASH:\n            return scaleType === 'ordinal' || isContinuousToDiscrete(scaleType);\n        case CHANNEL.SHAPE:\n            return scaleType === 'ordinal'; // shape = lookup only\n    }\n}\n//# sourceMappingURL=scale.js.map","import { isObject } from 'vega-util';\nexport const SELECTION_ID = '_vgsid_';\nexport const defaultConfig = {\n    single: {\n        on: 'click',\n        fields: [SELECTION_ID],\n        resolve: 'global',\n        empty: 'all',\n        clear: 'dblclick'\n    },\n    multi: {\n        on: 'click',\n        fields: [SELECTION_ID],\n        toggle: 'event.shiftKey',\n        resolve: 'global',\n        empty: 'all',\n        clear: 'dblclick'\n    },\n    interval: {\n        on: '[mousedown, window:mouseup] > window:mousemove!',\n        encodings: ['x', 'y'],\n        translate: '[mousedown, window:mouseup] > window:mousemove!',\n        zoom: 'wheel!',\n        mark: { fill: '#333', fillOpacity: 0.125, stroke: 'white' },\n        resolve: 'global',\n        clear: 'dblclick'\n    }\n};\nexport function isLegendBinding(bind) {\n    return !!bind && (bind === 'legend' || !!bind.legend);\n}\nexport function isLegendStreamBinding(bind) {\n    return isLegendBinding(bind) && isObject(bind);\n}\n//# sourceMappingURL=selection.js.map","import { isArray } from 'vega-util';\nexport const DEFAULT_SORT_OP = 'min';\nconst SORT_BY_CHANNEL_INDEX = {\n    x: 1,\n    y: 1,\n    color: 1,\n    fill: 1,\n    stroke: 1,\n    strokeWidth: 1,\n    size: 1,\n    shape: 1,\n    fillOpacity: 1,\n    strokeOpacity: 1,\n    opacity: 1,\n    text: 1\n};\nexport function isSortByChannel(c) {\n    return c in SORT_BY_CHANNEL_INDEX;\n}\nexport function isSortByEncoding(sort) {\n    return !!sort && !!sort['encoding'];\n}\nexport function isSortField(sort) {\n    return !!sort && (sort['op'] === 'count' || !!sort['field']);\n}\nexport function isSortArray(sort) {\n    return !!sort && isArray(sort);\n}\n//# sourceMappingURL=sort.js.map","import { isNumber, isObject } from 'vega-util';\nimport { keys } from '../util';\nimport { isConcatSpec, isVConcatSpec } from './concat';\nimport { isFacetMapping, isFacetSpec } from './facet';\nexport function isStep(size) {\n    return isObject(size) && size['step'] !== undefined;\n}\nexport function isFrameMixins(o) {\n    return o['view'] || o['width'] || o['height'];\n}\nexport const DEFAULT_SPACING = 20;\nconst COMPOSITION_LAYOUT_INDEX = {\n    align: 1,\n    bounds: 1,\n    center: 1,\n    columns: 1,\n    spacing: 1\n};\nconst COMPOSITION_LAYOUT_PROPERTIES = keys(COMPOSITION_LAYOUT_INDEX);\nexport function extractCompositionLayout(spec, specType, config) {\n    var _a, _b;\n    const compositionConfig = config[specType];\n    const layout = {};\n    // Apply config first\n    const { spacing: spacingConfig, columns } = compositionConfig;\n    if (spacingConfig !== undefined) {\n        layout.spacing = spacingConfig;\n    }\n    if (columns !== undefined) {\n        if ((isFacetSpec(spec) && !isFacetMapping(spec.facet)) || isConcatSpec(spec)) {\n            layout.columns = columns;\n        }\n    }\n    if (isVConcatSpec(spec)) {\n        layout.columns = 1;\n    }\n    // Then copy properties from the spec\n    for (const prop of COMPOSITION_LAYOUT_PROPERTIES) {\n        if (spec[prop] !== undefined) {\n            if (prop === 'spacing') {\n                const spacing = spec[prop];\n                layout[prop] = isNumber(spacing)\n                    ? spacing\n                    : {\n                        row: (_a = spacing.row) !== null && _a !== void 0 ? _a : spacingConfig,\n                        column: (_b = spacing.column) !== null && _b !== void 0 ? _b : spacingConfig\n                    };\n            }\n            else {\n                layout[prop] = spec[prop];\n            }\n        }\n    }\n    return layout;\n}\n//# sourceMappingURL=base.js.map","export function isAnyConcatSpec(spec) {\n    return isVConcatSpec(spec) || isHConcatSpec(spec) || isConcatSpec(spec);\n}\nexport function isConcatSpec(spec) {\n    return 'concat' in spec;\n}\nexport function isVConcatSpec(spec) {\n    return 'vconcat' in spec;\n}\nexport function isHConcatSpec(spec) {\n    return 'hconcat' in spec;\n}\n//# sourceMappingURL=concat.js.map","export function isFacetMapping(f) {\n    return 'row' in f || 'column' in f;\n}\nexport function isFacetFieldDef(channelDef) {\n    return !!channelDef && 'header' in channelDef;\n}\nexport function isFacetSpec(spec) {\n    return 'facet' in spec;\n}\n//# sourceMappingURL=facet.js.map","export { isAnyConcatSpec, isHConcatSpec, isVConcatSpec } from './concat';\nexport { isFacetSpec } from './facet';\nexport { isLayerSpec } from './layer';\nexport { isRepeatSpec } from './repeat';\nexport { isUnitSpec } from './unit';\n//# sourceMappingURL=index.js.map","export function isLayerSpec(spec) {\n    return 'layer' in spec;\n}\n//# sourceMappingURL=layer.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport * as log from '../log';\nimport { isConcatSpec, isHConcatSpec, isVConcatSpec } from './concat';\nimport { isFacetSpec } from './facet';\nimport { isLayerSpec } from './layer';\nimport { isRepeatSpec } from './repeat';\nimport { isUnitSpec } from './unit';\nexport class SpecMapper {\n    map(spec, params) {\n        if (isFacetSpec(spec)) {\n            return this.mapFacet(spec, params);\n        }\n        else if (isRepeatSpec(spec)) {\n            return this.mapRepeat(spec, params);\n        }\n        else if (isHConcatSpec(spec)) {\n            return this.mapHConcat(spec, params);\n        }\n        else if (isVConcatSpec(spec)) {\n            return this.mapVConcat(spec, params);\n        }\n        else if (isConcatSpec(spec)) {\n            return this.mapConcat(spec, params);\n        }\n        else {\n            return this.mapLayerOrUnit(spec, params);\n        }\n    }\n    mapLayerOrUnit(spec, params) {\n        if (isLayerSpec(spec)) {\n            return this.mapLayer(spec, params);\n        }\n        else if (isUnitSpec(spec)) {\n            return this.mapUnit(spec, params);\n        }\n        throw new Error(log.message.invalidSpec(spec));\n    }\n    mapLayer(spec, params) {\n        return Object.assign(Object.assign({}, spec), { layer: spec.layer.map(subspec => this.mapLayerOrUnit(subspec, params)) });\n    }\n    mapHConcat(spec, params) {\n        return Object.assign(Object.assign({}, spec), { hconcat: spec.hconcat.map(subspec => this.map(subspec, params)) });\n    }\n    mapVConcat(spec, params) {\n        return Object.assign(Object.assign({}, spec), { vconcat: spec.vconcat.map(subspec => this.map(subspec, params)) });\n    }\n    mapConcat(spec, params) {\n        const { concat } = spec, rest = __rest(spec, [\"concat\"]);\n        return Object.assign(Object.assign({}, rest), { concat: concat.map(subspec => this.map(subspec, params)) });\n    }\n    mapFacet(spec, params) {\n        return Object.assign(Object.assign({}, spec), { \n            // TODO: remove \"any\" once we support all facet listed in https://github.com/vega/vega-lite/issues/2760\n            spec: this.map(spec.spec, params) });\n    }\n    mapRepeat(spec, params) {\n        return Object.assign(Object.assign({}, spec), { \n            // as any is required here since TS cannot infer that the output type satisfies the input type\n            spec: this.map(spec.spec, params) });\n    }\n}\n//# sourceMappingURL=map.js.map","import { isArray } from 'vega-util';\nexport function isRepeatSpec(spec) {\n    return 'repeat' in spec;\n}\nexport function isLayerRepeatSpec(spec) {\n    return !isArray(spec.repeat) && spec.repeat['layer'];\n}\n//# sourceMappingURL=repeat.js.map","import { getPositionScaleChannel } from '../channel';\nimport { signalRefOrValue } from '../compile/common';\nexport function isFitType(autoSizeType) {\n    return autoSizeType === 'fit' || autoSizeType === 'fit-x' || autoSizeType === 'fit-y';\n}\nexport function getFitType(sizeType) {\n    return sizeType ? `fit-${getPositionScaleChannel(sizeType)}` : 'fit';\n}\nconst TOP_LEVEL_PROPERTIES = [\n    'background',\n    'padding'\n    // We do not include \"autosize\" here as it is supported by only unit and layer specs and thus need to be normalized\n];\nexport function extractTopLevelProperties(t, includeParams) {\n    const o = {};\n    for (const p of TOP_LEVEL_PROPERTIES) {\n        if (t && t[p] !== undefined) {\n            o[p] = signalRefOrValue(t[p]);\n        }\n    }\n    if (includeParams) {\n        o.params = t.params;\n    }\n    return o;\n}\n//# sourceMappingURL=toplevel.js.map","export function isUnitSpec(spec) {\n    return 'mark' in spec;\n}\n//# sourceMappingURL=unit.js.map","import { array, isBoolean } from 'vega-util';\nimport { SUM_OPS } from './aggregate';\nimport { getSecondaryRangeChannel, NONPOSITION_CHANNELS } from './channel';\nimport { channelDefType, getFieldDef, isFieldDef, isFieldOrDatumDef, vgField } from './channeldef';\nimport { channelHasField, isAggregate } from './encoding';\nimport * as log from './log';\nimport { ARC, AREA, BAR, CIRCLE, isMarkDef, isPathMark, LINE, POINT, RULE, SQUARE, TEXT, TICK } from './mark';\nimport { ScaleType } from './scale';\nimport { contains } from './util';\nconst STACK_OFFSET_INDEX = {\n    zero: 1,\n    center: 1,\n    normalize: 1\n};\nexport function isStackOffset(s) {\n    return s in STACK_OFFSET_INDEX;\n}\nexport const STACKABLE_MARKS = new Set([ARC, BAR, AREA, RULE, POINT, CIRCLE, SQUARE, LINE, TEXT, TICK]);\nexport const STACK_BY_DEFAULT_MARKS = new Set([BAR, AREA, ARC]);\nfunction potentialStackedChannel(encoding, x) {\n    var _a, _b;\n    const y = x === 'x' ? 'y' : 'radius';\n    const xDef = encoding[x];\n    const yDef = encoding[y];\n    if (isFieldDef(xDef) && isFieldDef(yDef)) {\n        if (channelDefType(xDef) === 'quantitative' && channelDefType(yDef) === 'quantitative') {\n            if (xDef.stack) {\n                return x;\n            }\n            else if (yDef.stack) {\n                return y;\n            }\n            const xAggregate = isFieldDef(xDef) && !!xDef.aggregate;\n            const yAggregate = isFieldDef(yDef) && !!yDef.aggregate;\n            // if there is no explicit stacking, only apply stack if there is only one aggregate for x or y\n            if (xAggregate !== yAggregate) {\n                return xAggregate ? x : y;\n            }\n            else {\n                const xScale = (_a = xDef.scale) === null || _a === void 0 ? void 0 : _a.type;\n                const yScale = (_b = yDef.scale) === null || _b === void 0 ? void 0 : _b.type;\n                if (xScale && xScale !== 'linear') {\n                    return y;\n                }\n                else if (yScale && yScale !== 'linear') {\n                    return x;\n                }\n            }\n        }\n        else if (channelDefType(xDef) === 'quantitative') {\n            return x;\n        }\n        else if (channelDefType(yDef) === 'quantitative') {\n            return y;\n        }\n    }\n    else if (channelDefType(xDef) === 'quantitative') {\n        return x;\n    }\n    else if (channelDefType(yDef) === 'quantitative') {\n        return y;\n    }\n    return undefined;\n}\nfunction getDimensionChannel(channel) {\n    switch (channel) {\n        case 'x':\n            return 'y';\n        case 'y':\n            return 'x';\n        case 'theta':\n            return 'radius';\n        case 'radius':\n            return 'theta';\n    }\n}\n// Note: CompassQL uses this method and only pass in required properties of each argument object.\n// If required properties change, make sure to update CompassQL.\nexport function stack(m, encoding, opt = {}) {\n    const mark = isMarkDef(m) ? m.type : m;\n    // Should have stackable mark\n    if (!STACKABLE_MARKS.has(mark)) {\n        return null;\n    }\n    // Run potential stacked twice, one for Cartesian and another for Polar,\n    // so text marks can be stacked in any of the coordinates.\n    // Note: The logic here is not perfectly correct.  If we want to support stacked dot plots where each dot is a pie chart with label, we have to change the stack logic here to separate Cartesian stacking for polar stacking.\n    // However, since we probably never want to do that, let's just note the limitation here.\n    const fieldChannel = potentialStackedChannel(encoding, 'x') || potentialStackedChannel(encoding, 'theta');\n    if (!fieldChannel) {\n        return null;\n    }\n    const stackedFieldDef = encoding[fieldChannel];\n    const stackedField = isFieldDef(stackedFieldDef) ? vgField(stackedFieldDef, {}) : undefined;\n    let dimensionChannel = getDimensionChannel(fieldChannel);\n    let dimensionDef = encoding[dimensionChannel];\n    let dimensionField = isFieldDef(dimensionDef) ? vgField(dimensionDef, {}) : undefined;\n    // avoid grouping by the stacked field\n    if (dimensionField === stackedField) {\n        dimensionField = undefined;\n        dimensionDef = undefined;\n        dimensionChannel = undefined;\n    }\n    // Should have grouping level of detail that is different from the dimension field\n    const stackBy = NONPOSITION_CHANNELS.reduce((sc, channel) => {\n        // Ignore tooltip in stackBy (https://github.com/vega/vega-lite/issues/4001)\n        if (channel !== 'tooltip' && channelHasField(encoding, channel)) {\n            const channelDef = encoding[channel];\n            for (const cDef of array(channelDef)) {\n                const fieldDef = getFieldDef(cDef);\n                if (fieldDef.aggregate) {\n                    continue;\n                }\n                // Check whether the channel's field is identical to x/y's field or if the channel is a repeat\n                const f = vgField(fieldDef, {});\n                if (\n                // if fielddef is a repeat, just include it in the stack by\n                !f ||\n                    // otherwise, the field must be different from x and y fields.\n                    f !== dimensionField) {\n                    sc.push({ channel, fieldDef });\n                }\n            }\n        }\n        return sc;\n    }, []);\n    // Automatically determine offset\n    let offset;\n    if (stackedFieldDef.stack !== undefined) {\n        if (isBoolean(stackedFieldDef.stack)) {\n            offset = stackedFieldDef.stack ? 'zero' : null;\n        }\n        else {\n            offset = stackedFieldDef.stack;\n        }\n    }\n    else if (stackBy.length > 0 && STACK_BY_DEFAULT_MARKS.has(mark)) {\n        // Bar and Area with sum ops are automatically stacked by default\n        offset = 'zero';\n    }\n    if (!offset || !isStackOffset(offset)) {\n        return null;\n    }\n    if (isAggregate(encoding) && stackBy.length === 0) {\n        return null;\n    }\n    // warn when stacking non-linear\n    if (stackedFieldDef.scale && stackedFieldDef.scale.type && stackedFieldDef.scale.type !== ScaleType.LINEAR) {\n        if (opt.disallowNonLinearStack) {\n            return null;\n        }\n        else {\n            log.warn(log.message.cannotStackNonLinearScale(stackedFieldDef.scale.type));\n        }\n    }\n    // Check if it is a ranged mark\n    if (isFieldOrDatumDef(encoding[getSecondaryRangeChannel(fieldChannel)])) {\n        if (stackedFieldDef.stack !== undefined) {\n            log.warn(log.message.cannotStackRangedMark(fieldChannel));\n        }\n        return null;\n    }\n    // Warn if stacking non-summative aggregate\n    if (isFieldDef(stackedFieldDef) && stackedFieldDef.aggregate && !contains(SUM_OPS, stackedFieldDef.aggregate)) {\n        log.warn(log.message.stackNonSummativeAggregate(stackedFieldDef.aggregate));\n    }\n    return {\n        groupbyChannel: dimensionDef ? dimensionChannel : undefined,\n        groupbyField: dimensionField,\n        fieldChannel,\n        impute: stackedFieldDef.impute === null ? false : isPathMark(mark),\n        stackBy,\n        offset\n    };\n}\n//# sourceMappingURL=stack.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport stringify from 'fast-json-stable-stringify';\nimport { isObject, isString } from 'vega-util';\nimport { dateTimeExprToExpr } from './datetime';\nimport { accessPathWithDatum, keys, varName } from './util';\n/** Time Unit that only corresponds to only one part of Date objects. */\nexport const LOCAL_SINGLE_TIMEUNIT_INDEX = {\n    year: 1,\n    quarter: 1,\n    month: 1,\n    week: 1,\n    day: 1,\n    dayofyear: 1,\n    date: 1,\n    hours: 1,\n    minutes: 1,\n    seconds: 1,\n    milliseconds: 1\n};\nexport const TIMEUNIT_PARTS = keys(LOCAL_SINGLE_TIMEUNIT_INDEX);\nexport function isLocalSingleTimeUnit(timeUnit) {\n    return !!LOCAL_SINGLE_TIMEUNIT_INDEX[timeUnit];\n}\nexport const UTC_SINGLE_TIMEUNIT_INDEX = {\n    utcyear: 1,\n    utcquarter: 1,\n    utcmonth: 1,\n    utcweek: 1,\n    utcday: 1,\n    utcdayofyear: 1,\n    utcdate: 1,\n    utchours: 1,\n    utcminutes: 1,\n    utcseconds: 1,\n    utcmilliseconds: 1\n};\nexport const LOCAL_MULTI_TIMEUNIT_INDEX = {\n    yearquarter: 1,\n    yearquartermonth: 1,\n    yearmonth: 1,\n    yearmonthdate: 1,\n    yearmonthdatehours: 1,\n    yearmonthdatehoursminutes: 1,\n    yearmonthdatehoursminutesseconds: 1,\n    yearweek: 1,\n    yearweekday: 1,\n    yearweekdayhours: 1,\n    yearweekdayhoursminutes: 1,\n    yearweekdayhoursminutesseconds: 1,\n    yeardayofyear: 1,\n    quartermonth: 1,\n    monthdate: 1,\n    monthdatehours: 1,\n    monthdatehoursminutes: 1,\n    monthdatehoursminutesseconds: 1,\n    weekday: 1,\n    weeksdayhours: 1,\n    weekdayhoursminutes: 1,\n    weekdayhoursminutesseconds: 1,\n    dayhours: 1,\n    dayhoursminutes: 1,\n    dayhoursminutesseconds: 1,\n    hoursminutes: 1,\n    hoursminutesseconds: 1,\n    minutesseconds: 1,\n    secondsmilliseconds: 1\n};\nexport const UTC_MULTI_TIMEUNIT_INDEX = {\n    utcyearquarter: 1,\n    utcyearquartermonth: 1,\n    utcyearmonth: 1,\n    utcyearmonthdate: 1,\n    utcyearmonthdatehours: 1,\n    utcyearmonthdatehoursminutes: 1,\n    utcyearmonthdatehoursminutesseconds: 1,\n    utcyearweek: 1,\n    utcyearweekday: 1,\n    utcyearweekdayhours: 1,\n    utcyearweekdayhoursminutes: 1,\n    utcyearweekdayhoursminutesseconds: 1,\n    utcyeardayofyear: 1,\n    utcquartermonth: 1,\n    utcmonthdate: 1,\n    utcmonthdatehours: 1,\n    utcmonthdatehoursminutes: 1,\n    utcmonthdatehoursminutesseconds: 1,\n    utcweekday: 1,\n    utcweeksdayhours: 1,\n    utcweekdayhoursminutes: 1,\n    utcweekdayhoursminutesseconds: 1,\n    utcdayhours: 1,\n    utcdayhoursminutes: 1,\n    utcdayhoursminutesseconds: 1,\n    utchoursminutes: 1,\n    utchoursminutesseconds: 1,\n    utcminutesseconds: 1,\n    utcsecondsmilliseconds: 1\n};\nexport function isUTCTimeUnit(t) {\n    return t.startsWith('utc');\n}\nexport function getLocalTimeUnit(t) {\n    return t.substr(3);\n}\n// In order of increasing specificity\nexport const VEGALITE_TIMEFORMAT = {\n    'year-month': '%b %Y ',\n    'year-month-date': '%b %d, %Y '\n};\nexport function getTimeUnitParts(timeUnit) {\n    const parts = [];\n    for (const part of TIMEUNIT_PARTS) {\n        if (containsTimeUnit(timeUnit, part)) {\n            parts.push(part);\n        }\n    }\n    return parts;\n}\n/** Returns true if fullTimeUnit contains the timeUnit, false otherwise. */\nexport function containsTimeUnit(fullTimeUnit, timeUnit) {\n    const index = fullTimeUnit.indexOf(timeUnit);\n    if (index < 0) {\n        return false;\n    }\n    // exclude milliseconds\n    if (index > 0 && timeUnit === 'seconds' && fullTimeUnit.charAt(index - 1) === 'i') {\n        return false;\n    }\n    // exclude dayofyear\n    if (fullTimeUnit.length > index + 3 && timeUnit === 'day' && fullTimeUnit.charAt(index + 3) === 'o') {\n        return false;\n    }\n    if (index > 0 && timeUnit === 'year' && fullTimeUnit.charAt(index - 1) === 'f') {\n        return false;\n    }\n    return true;\n}\n/**\n * Returns Vega expression for a given timeUnit and fieldRef\n */\nexport function fieldExpr(fullTimeUnit, field, { end } = { end: false }) {\n    const fieldRef = accessPathWithDatum(field);\n    const utc = isUTCTimeUnit(fullTimeUnit) ? 'utc' : '';\n    function func(timeUnit) {\n        if (timeUnit === 'quarter') {\n            // quarter starting at 0 (0,3,6,9).\n            return `(${utc}quarter(${fieldRef})-1)`;\n        }\n        else {\n            return `${utc}${timeUnit}(${fieldRef})`;\n        }\n    }\n    let lastTimeUnit;\n    const dateExpr = {};\n    for (const part of TIMEUNIT_PARTS) {\n        if (containsTimeUnit(fullTimeUnit, part)) {\n            dateExpr[part] = func(part);\n            lastTimeUnit = part;\n        }\n    }\n    if (end) {\n        dateExpr[lastTimeUnit] += '+1';\n    }\n    return dateTimeExprToExpr(dateExpr);\n}\nexport function timeUnitSpecifierExpression(timeUnit) {\n    if (!timeUnit) {\n        return undefined;\n    }\n    const timeUnitParts = getTimeUnitParts(timeUnit);\n    return `timeUnitSpecifier(${stringify(timeUnitParts)}, ${stringify(VEGALITE_TIMEFORMAT)})`;\n}\n/**\n * Returns the signal expression used for axis labels for a time unit.\n */\nexport function formatExpression(timeUnit, field, isUTCScale) {\n    if (!timeUnit) {\n        return undefined;\n    }\n    const expr = timeUnitSpecifierExpression(timeUnit);\n    // We only use utcFormat for utc scale\n    // For utc time units, the data is already converted as a part of timeUnit transform.\n    // Thus, utc time units should use timeFormat to avoid shifting the time twice.\n    const utc = isUTCScale || isUTCTimeUnit(timeUnit);\n    return `${utc ? 'utc' : 'time'}Format(${field}, ${expr})`;\n}\nexport function normalizeTimeUnit(timeUnit) {\n    if (!timeUnit) {\n        return undefined;\n    }\n    let params;\n    if (isString(timeUnit)) {\n        params = {\n            unit: timeUnit\n        };\n    }\n    else if (isObject(timeUnit)) {\n        params = Object.assign(Object.assign({}, timeUnit), (timeUnit.unit ? { unit: timeUnit.unit } : {}));\n    }\n    if (isUTCTimeUnit(params.unit)) {\n        params.utc = true;\n        params.unit = getLocalTimeUnit(params.unit);\n    }\n    return params;\n}\nexport function timeUnitToString(tu) {\n    const _a = normalizeTimeUnit(tu), { utc } = _a, rest = __rest(_a, [\"utc\"]);\n    if (rest.unit) {\n        return ((utc ? 'utc' : '') +\n            keys(rest)\n                .map(p => varName(`${p === 'unit' ? '' : `_${p}_`}${rest[p]}`))\n                .join(''));\n    }\n    else {\n        // when maxbins is specified instead of units\n        return ((utc ? 'utc' : '') +\n            'timeunit' +\n            keys(rest)\n                .map(p => varName(`_${p}_${rest[p]}`))\n                .join(''));\n    }\n}\n//# sourceMappingURL=timeunit.js.map","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { isArray, isString } from 'vega-util';\nimport { pick } from './util';\nexport function extractTitleConfig(titleConfig) {\n    const { \n    // These are non-mark title config that need to be hardcoded\n    anchor, frame, offset, orient, \n    // color needs to be redirect to fill\n    color, \n    // subtitle properties\n    subtitleColor, subtitleFont, subtitleFontSize, subtitleFontStyle, subtitleFontWeight, subtitleLineHeight, subtitlePadding } = titleConfig, \n    // The rest are mark config.\n    rest = __rest(titleConfig, [\"anchor\", \"frame\", \"offset\", \"orient\", \"color\", \"subtitleColor\", \"subtitleFont\", \"subtitleFontSize\", \"subtitleFontStyle\", \"subtitleFontWeight\", \"subtitleLineHeight\", \"subtitlePadding\"]);\n    const titleMarkConfig = Object.assign(Object.assign({}, rest), (color ? { fill: color } : {}));\n    // These are non-mark title config that need to be hardcoded\n    const nonMark = Object.assign(Object.assign(Object.assign(Object.assign({}, (anchor ? { anchor } : {})), (frame ? { frame } : {})), (offset ? { offset } : {})), (orient ? { orient } : {}));\n    // subtitle part can stay in config.title since header titles do not use subtitle\n    const subtitle = Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, (subtitleColor ? { subtitleColor } : {})), (subtitleFont ? { subtitleFont } : {})), (subtitleFontSize ? { subtitleFontSize } : {})), (subtitleFontStyle ? { subtitleFontStyle } : {})), (subtitleFontWeight ? { subtitleFontWeight } : {})), (subtitleLineHeight ? { subtitleLineHeight } : {})), (subtitlePadding ? { subtitlePadding } : {}));\n    const subtitleMarkConfig = pick(titleMarkConfig, ['align', 'baseline', 'dx', 'dy', 'limit']);\n    return { titleMarkConfig, subtitleMarkConfig, nonMark, subtitle };\n}\nexport function isText(v) {\n    return isString(v) || (isArray(v) && isString(v[0]));\n}\n//# sourceMappingURL=title.js.map","import { normalizeLogicalComposition } from './logical';\nimport { normalizePredicate } from './predicate';\nexport function isFilter(t) {\n    return 'filter' in t;\n}\nexport function isImputeSequence(t) {\n    return (t === null || t === void 0 ? void 0 : t['stop']) !== undefined;\n}\nexport function isLookup(t) {\n    return 'lookup' in t;\n}\nexport function isLookupData(from) {\n    return 'data' in from;\n}\nexport function isLookupSelection(from) {\n    return 'selection' in from;\n}\nexport function isPivot(t) {\n    return 'pivot' in t;\n}\nexport function isDensity(t) {\n    return 'density' in t;\n}\nexport function isQuantile(t) {\n    return 'quantile' in t;\n}\nexport function isRegression(t) {\n    return 'regression' in t;\n}\nexport function isLoess(t) {\n    return 'loess' in t;\n}\nexport function isSample(t) {\n    return 'sample' in t;\n}\nexport function isWindow(t) {\n    return 'window' in t;\n}\nexport function isJoinAggregate(t) {\n    return 'joinaggregate' in t;\n}\nexport function isFlatten(t) {\n    return 'flatten' in t;\n}\nexport function isCalculate(t) {\n    return 'calculate' in t;\n}\nexport function isBin(t) {\n    return 'bin' in t;\n}\nexport function isImpute(t) {\n    return 'impute' in t;\n}\nexport function isTimeUnit(t) {\n    return 'timeUnit' in t;\n}\nexport function isAggregate(t) {\n    return 'aggregate' in t;\n}\nexport function isStack(t) {\n    return 'stack' in t;\n}\nexport function isFold(t) {\n    return 'fold' in t;\n}\nexport function normalizeTransform(transform) {\n    return transform.map(t => {\n        if (isFilter(t)) {\n            return {\n                filter: normalizeLogicalComposition(t.filter, normalizePredicate)\n            };\n        }\n        return t;\n    });\n}\n//# sourceMappingURL=transform.js.map","import { keys } from './util';\n/**\n * Data type based on level of measurement\n */\nexport const Type = {\n    quantitative: 'quantitative',\n    ordinal: 'ordinal',\n    temporal: 'temporal',\n    nominal: 'nominal',\n    geojson: 'geojson'\n};\nexport function isType(t) {\n    return t in Type;\n}\nexport const QUANTITATIVE = Type.quantitative;\nexport const ORDINAL = Type.ordinal;\nexport const TEMPORAL = Type.temporal;\nexport const NOMINAL = Type.nominal;\nexport const GEOJSON = Type.geojson;\nexport const TYPES = keys(Type);\n/**\n * Get full, lowercase type name for a given type.\n * @param  type\n * @return Full type name.\n */\nexport function getFullName(type) {\n    if (type) {\n        type = type.toLowerCase();\n        switch (type) {\n            case 'q':\n            case QUANTITATIVE:\n                return 'quantitative';\n            case 't':\n            case TEMPORAL:\n                return 'temporal';\n            case 'o':\n            case ORDINAL:\n                return 'ordinal';\n            case 'n':\n            case NOMINAL:\n                return 'nominal';\n            case GEOJSON:\n                return 'geojson';\n        }\n    }\n    // If we get invalid input, return undefined type.\n    return undefined;\n}\n//# sourceMappingURL=type.js.map","import 'array-flat-polyfill';\nimport { default as clone_ } from 'clone';\nimport deepEqual_ from 'fast-deep-equal';\nimport stableStringify from 'fast-json-stable-stringify';\nimport { hasOwnProperty, isNumber, isString, splitAccessPath, stringValue, writeConfig } from 'vega-util';\nimport { isLogicalAnd, isLogicalNot, isLogicalOr } from './logical';\nexport const deepEqual = deepEqual_;\nexport const duplicate = clone_;\n/**\n * Creates an object composed of the picked object properties.\n *\n * var object = {'a': 1, 'b': '2', 'c': 3};\n * pick(object, ['a', 'c']);\n * // → {'a': 1, 'c': 3}\n */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function pick(obj, props) {\n    const copy = {};\n    for (const prop of props) {\n        if (hasOwnProperty(obj, prop)) {\n            copy[prop] = obj[prop];\n        }\n    }\n    return copy;\n}\n/**\n * The opposite of _.pick; this method creates an object composed of the own\n * and inherited enumerable string keyed properties of object that are not omitted.\n */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function omit(obj, props) {\n    const copy = Object.assign({}, obj);\n    for (const prop of props) {\n        delete copy[prop];\n    }\n    return copy;\n}\n/**\n * Monkey patch Set so that `stringify` produces a string representation of sets.\n */\nSet.prototype['toJSON'] = function () {\n    return `Set(${[...this].map(x => stableStringify(x)).join(',')})`;\n};\n/**\n * Converts any object to a string representation that can be consumed by humans.\n */\nexport const stringify = stableStringify;\n/**\n * Converts any object to a string of limited size, or a number.\n */\nexport function hash(a) {\n    if (isNumber(a)) {\n        return a;\n    }\n    const str = isString(a) ? a : stableStringify(a);\n    // short strings can be used as hash directly, longer strings are hashed to reduce memory usage\n    if (str.length < 250) {\n        return str;\n    }\n    // from http://werxltd.com/wp/2010/05/13/javascript-implementation-of-javas-string-hashcode-method/\n    let h = 0;\n    for (let i = 0; i < str.length; i++) {\n        const char = str.charCodeAt(i);\n        h = (h << 5) - h + char;\n        h = h & h; // Convert to 32bit integer\n    }\n    return h;\n}\nexport function isNullOrFalse(x) {\n    return x === false || x === null;\n}\nexport function contains(array, item) {\n    return array.indexOf(item) > -1;\n}\n/**\n * Returns true if any item returns true.\n */\nexport function some(arr, f) {\n    let i = 0;\n    for (const [k, a] of arr.entries()) {\n        if (f(a, k, i++)) {\n            return true;\n        }\n    }\n    return false;\n}\n/**\n * Returns true if all items return true.\n */\nexport function every(arr, f) {\n    let i = 0;\n    for (const [k, a] of arr.entries()) {\n        if (!f(a, k, i++)) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * recursively merges src into dest\n */\nexport function mergeDeep(dest, ...src) {\n    for (const s of src) {\n        deepMerge_(dest, s !== null && s !== void 0 ? s : {});\n    }\n    return dest;\n}\nfunction deepMerge_(dest, src) {\n    for (const property of keys(src)) {\n        writeConfig(dest, property, src[property], true);\n    }\n}\nexport function unique(values, f) {\n    const results = [];\n    const u = {};\n    let v;\n    for (const val of values) {\n        v = f(val);\n        if (v in u) {\n            continue;\n        }\n        u[v] = 1;\n        results.push(val);\n    }\n    return results;\n}\n/**\n * Returns true if the two dictionaries disagree. Applies only to defined values.\n */\nexport function isEqual(dict, other) {\n    const dictKeys = keys(dict);\n    const otherKeys = keys(other);\n    if (dictKeys.length !== otherKeys.length) {\n        return false;\n    }\n    for (const key of dictKeys) {\n        if (dict[key] !== other[key]) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function setEqual(a, b) {\n    if (a.size !== b.size) {\n        return false;\n    }\n    for (const e of a) {\n        if (!b.has(e)) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function hasIntersection(a, b) {\n    for (const key of a) {\n        if (b.has(key)) {\n            return true;\n        }\n    }\n    return false;\n}\nexport function prefixGenerator(a) {\n    const prefixes = new Set();\n    for (const x of a) {\n        const splitField = splitAccessPath(x);\n        // Wrap every element other than the first in `[]`\n        const wrappedWithAccessors = splitField.map((y, i) => (i === 0 ? y : `[${y}]`));\n        const computedPrefixes = wrappedWithAccessors.map((_, i) => wrappedWithAccessors.slice(0, i + 1).join(''));\n        for (const y of computedPrefixes) {\n            prefixes.add(y);\n        }\n    }\n    return prefixes;\n}\n/**\n * Returns true if a and b have an intersection. Also return true if a or b are undefined\n * since this means we don't know what fields a node produces or depends on.\n */\nexport function fieldIntersection(a, b) {\n    if (a === undefined || b === undefined) {\n        return true;\n    }\n    return hasIntersection(prefixGenerator(a), prefixGenerator(b));\n}\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function isEmpty(obj) {\n    return keys(obj).length === 0;\n}\n// This is a stricter version of Object.keys but with better types. See https://github.com/Microsoft/TypeScript/pull/12253#issuecomment-263132208\nexport const keys = Object.keys;\nexport const vals = Object.values;\nexport const entries = Object.entries;\nexport function isBoolean(b) {\n    return b === true || b === false;\n}\n/**\n * Convert a string into a valid variable name\n */\nexport function varName(s) {\n    // Replace non-alphanumeric characters (anything besides a-zA-Z0-9_) with _\n    const alphanumericS = s.replace(/\\W/g, '_');\n    // Add _ if the string has leading numbers.\n    return (s.match(/^\\d+/) ? '_' : '') + alphanumericS;\n}\nexport function logicalExpr(op, cb) {\n    if (isLogicalNot(op)) {\n        return '!(' + logicalExpr(op.not, cb) + ')';\n    }\n    else if (isLogicalAnd(op)) {\n        return '(' + op.and.map((and) => logicalExpr(and, cb)).join(') && (') + ')';\n    }\n    else if (isLogicalOr(op)) {\n        return '(' + op.or.map((or) => logicalExpr(or, cb)).join(') || (') + ')';\n    }\n    else {\n        return cb(op);\n    }\n}\n/**\n * Delete nested property of an object, and delete the ancestors of the property if they become empty.\n */\nexport function deleteNestedProperty(obj, orderedProps) {\n    if (orderedProps.length === 0) {\n        return true;\n    }\n    const prop = orderedProps.shift(); // eslint-disable-line @typescript-eslint/no-non-null-assertion\n    if (prop in obj && deleteNestedProperty(obj[prop], orderedProps)) {\n        delete obj[prop];\n    }\n    return isEmpty(obj);\n}\nexport function titleCase(s) {\n    return s.charAt(0).toUpperCase() + s.substr(1);\n}\n/**\n * Converts a path to an access path with datum.\n * @param path The field name.\n * @param datum The string to use for `datum`.\n */\nexport function accessPathWithDatum(path, datum = 'datum') {\n    const pieces = splitAccessPath(path);\n    const prefixes = [];\n    for (let i = 1; i <= pieces.length; i++) {\n        const prefix = `[${pieces.slice(0, i).map(stringValue).join('][')}]`;\n        prefixes.push(`${datum}${prefix}`);\n    }\n    return prefixes.join(' && ');\n}\n/**\n * Return access with datum to the flattened field.\n *\n * @param path The field name.\n * @param datum The string to use for `datum`.\n */\nexport function flatAccessWithDatum(path, datum = 'datum') {\n    return `${datum}[${stringValue(splitAccessPath(path).join('.'))}]`;\n}\nfunction escapePathAccess(string) {\n    return string.replace(/(\\[|\\]|\\.|'|\")/g, '\\\\$1');\n}\n/**\n * Replaces path accesses with access to non-nested field.\n * For example, `foo[\"bar\"].baz` becomes `foo\\\\.bar\\\\.baz`.\n */\nexport function replacePathInField(path) {\n    return `${splitAccessPath(path).map(escapePathAccess).join('\\\\.')}`;\n}\n/**\n * Replace all occurrences of a string with another string.\n *\n * @param string the string to replace in\n * @param find the string to replace\n * @param replacement the replacement\n */\nexport function replaceAll(string, find, replacement) {\n    return string.replace(new RegExp(find.replace(/[-/\\\\^$*+?.()|[\\]{}]/g, '\\\\$&'), 'g'), replacement);\n}\n/**\n * Remove path accesses with access from field.\n * For example, `foo[\"bar\"].baz` becomes `foo.bar.baz`.\n */\nexport function removePathFromField(path) {\n    return `${splitAccessPath(path).join('.')}`;\n}\n/**\n * Count the depth of the path. Returns 1 for fields that are not nested.\n */\nexport function accessPathDepth(path) {\n    if (!path) {\n        return 0;\n    }\n    return splitAccessPath(path).length;\n}\n/**\n * This is a replacement for chained || for numeric properties or properties that respect null so that 0 will be included.\n */\nexport function getFirstDefined(...args) {\n    for (const arg of args) {\n        if (arg !== undefined) {\n            return arg;\n        }\n    }\n    return undefined;\n}\n// variable used to generate id\nlet idCounter = 42;\n/**\n * Returns a new random id every time it gets called.\n *\n * Has side effect!\n */\nexport function uniqueId(prefix) {\n    const id = ++idCounter;\n    return prefix ? String(prefix) + id : id;\n}\n/**\n * Resets the id counter used in uniqueId. This can be useful for testing.\n */\nexport function resetIdCounter() {\n    idCounter = 42;\n}\nexport function internalField(name) {\n    return isInternalField(name) ? name : `__${name}`;\n}\nexport function isInternalField(name) {\n    return name.indexOf('__') === 0;\n}\n/**\n * Normalize angle to be within [0,360).\n */\nexport function normalizeAngle(angle) {\n    if (angle === undefined) {\n        return undefined;\n    }\n    return ((angle % 360) + 360) % 360;\n}\n/**\n * Returns whether the passed in value is a valid number.\n */\nexport function isNumeric(value) {\n    if (isNumber(value)) {\n        return true;\n    }\n    return !isNaN(value) && !isNaN(parseFloat(value));\n}\n//# sourceMappingURL=util.js.map","import { isArray } from 'vega-util';\nimport { keys } from './util';\nexport function isSignalRef(o) {\n    return o && !!o['signal'];\n}\nexport function isVgRangeStep(range) {\n    return !!range['step'];\n}\nexport function isDataRefUnionedDomain(domain) {\n    if (!isArray(domain)) {\n        return 'fields' in domain && !('data' in domain);\n    }\n    return false;\n}\nexport function isFieldRefUnionDomain(domain) {\n    if (!isArray(domain)) {\n        return 'fields' in domain && 'data' in domain;\n    }\n    return false;\n}\nexport function isDataRefDomain(domain) {\n    if (!isArray(domain)) {\n        return 'field' in domain && 'data' in domain;\n    }\n    return false;\n}\nconst VG_MARK_CONFIG_INDEX = {\n    aria: 1,\n    description: 1,\n    ariaRole: 1,\n    ariaRoleDescription: 1,\n    blend: 1,\n    opacity: 1,\n    fill: 1,\n    fillOpacity: 1,\n    stroke: 1,\n    strokeCap: 1,\n    strokeWidth: 1,\n    strokeOpacity: 1,\n    strokeDash: 1,\n    strokeDashOffset: 1,\n    strokeJoin: 1,\n    strokeOffset: 1,\n    strokeMiterLimit: 1,\n    startAngle: 1,\n    endAngle: 1,\n    padAngle: 1,\n    innerRadius: 1,\n    outerRadius: 1,\n    size: 1,\n    shape: 1,\n    interpolate: 1,\n    tension: 1,\n    orient: 1,\n    align: 1,\n    baseline: 1,\n    text: 1,\n    dir: 1,\n    dx: 1,\n    dy: 1,\n    ellipsis: 1,\n    limit: 1,\n    radius: 1,\n    theta: 1,\n    angle: 1,\n    font: 1,\n    fontSize: 1,\n    fontWeight: 1,\n    fontStyle: 1,\n    lineBreak: 1,\n    lineHeight: 1,\n    cursor: 1,\n    href: 1,\n    tooltip: 1,\n    cornerRadius: 1,\n    cornerRadiusTopLeft: 1,\n    cornerRadiusTopRight: 1,\n    cornerRadiusBottomLeft: 1,\n    cornerRadiusBottomRight: 1,\n    aspect: 1,\n    width: 1,\n    height: 1,\n    url: 1,\n    smooth: 1\n    // commented below are vg channel that do not have mark config.\n    // x: 1,\n    // y: 1,\n    // x2: 1,\n    // y2: 1,\n    // xc'|'yc'\n    // clip: 1,\n    // path: 1,\n    // url: 1,\n};\nexport const VG_MARK_CONFIGS = keys(VG_MARK_CONFIG_INDEX);\nexport const VG_MARK_INDEX = {\n    arc: 1,\n    area: 1,\n    group: 1,\n    image: 1,\n    line: 1,\n    path: 1,\n    rect: 1,\n    rule: 1,\n    shape: 1,\n    symbol: 1,\n    text: 1,\n    trail: 1\n};\n// Vega's cornerRadius channels.\nexport const VG_CORNERRADIUS_CHANNELS = [\n    'cornerRadius',\n    'cornerRadiusTopLeft',\n    'cornerRadiusTopRight',\n    'cornerRadiusBottomLeft',\n    'cornerRadiusBottomRight'\n];\n//# sourceMappingURL=vega.schema.js.map","import { error, toSet, isFunction, isString, hasOwnProperty } from 'vega-util';\n\nconst RawCode = 'RawCode';\nconst Literal = 'Literal';\nconst Property = 'Property';\nconst Identifier = 'Identifier';\nconst ArrayExpression = 'ArrayExpression';\nconst BinaryExpression = 'BinaryExpression';\nconst CallExpression = 'CallExpression';\nconst ConditionalExpression = 'ConditionalExpression';\nconst LogicalExpression = 'LogicalExpression';\nconst MemberExpression = 'MemberExpression';\nconst ObjectExpression = 'ObjectExpression';\nconst UnaryExpression = 'UnaryExpression';\nfunction ASTNode(type) {\n  this.type = type;\n}\n\nASTNode.prototype.visit = function (visitor) {\n  let c, i, n;\n  if (visitor(this)) return 1;\n\n  for (c = children(this), i = 0, n = c.length; i < n; ++i) {\n    if (c[i].visit(visitor)) return 1;\n  }\n};\n\nfunction children(node) {\n  switch (node.type) {\n    case ArrayExpression:\n      return node.elements;\n\n    case BinaryExpression:\n    case LogicalExpression:\n      return [node.left, node.right];\n\n    case CallExpression:\n      return [node.callee].concat(node.arguments);\n\n    case ConditionalExpression:\n      return [node.test, node.consequent, node.alternate];\n\n    case MemberExpression:\n      return [node.object, node.property];\n\n    case ObjectExpression:\n      return node.properties;\n\n    case Property:\n      return [node.key, node.value];\n\n    case UnaryExpression:\n      return [node.argument];\n\n    case Identifier:\n    case Literal:\n    case RawCode:\n    default:\n      return [];\n  }\n}\n\n/*\n  The following expression parser is based on Esprima (http://esprima.org/).\n  Original header comment and license for Esprima is included here:\n\n  Copyright (C) 2013 Ariya Hidayat <ariya.hidayat@gmail.com>\n  Copyright (C) 2013 Thaddee Tyl <thaddee.tyl@gmail.com>\n  Copyright (C) 2013 Mathias Bynens <mathias@qiwi.be>\n  Copyright (C) 2012 Ariya Hidayat <ariya.hidayat@gmail.com>\n  Copyright (C) 2012 Mathias Bynens <mathias@qiwi.be>\n  Copyright (C) 2012 Joost-Wim Boekesteijn <joost-wim@boekesteijn.nl>\n  Copyright (C) 2012 Kris Kowal <kris.kowal@cixar.com>\n  Copyright (C) 2012 Yusuke Suzuki <utatane.tea@gmail.com>\n  Copyright (C) 2012 Arpad Borsos <arpad.borsos@googlemail.com>\n  Copyright (C) 2011 Ariya Hidayat <ariya.hidayat@gmail.com>\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n  ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\n  DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n  LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\n  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n*/\nvar TokenName, source, index, length, lookahead;\nvar TokenBooleanLiteral = 1,\n    TokenEOF = 2,\n    TokenIdentifier = 3,\n    TokenKeyword = 4,\n    TokenNullLiteral = 5,\n    TokenNumericLiteral = 6,\n    TokenPunctuator = 7,\n    TokenStringLiteral = 8,\n    TokenRegularExpression = 9;\nTokenName = {};\nTokenName[TokenBooleanLiteral] = 'Boolean';\nTokenName[TokenEOF] = '<end>';\nTokenName[TokenIdentifier] = 'Identifier';\nTokenName[TokenKeyword] = 'Keyword';\nTokenName[TokenNullLiteral] = 'Null';\nTokenName[TokenNumericLiteral] = 'Numeric';\nTokenName[TokenPunctuator] = 'Punctuator';\nTokenName[TokenStringLiteral] = 'String';\nTokenName[TokenRegularExpression] = 'RegularExpression';\nvar SyntaxArrayExpression = 'ArrayExpression',\n    SyntaxBinaryExpression = 'BinaryExpression',\n    SyntaxCallExpression = 'CallExpression',\n    SyntaxConditionalExpression = 'ConditionalExpression',\n    SyntaxIdentifier = 'Identifier',\n    SyntaxLiteral = 'Literal',\n    SyntaxLogicalExpression = 'LogicalExpression',\n    SyntaxMemberExpression = 'MemberExpression',\n    SyntaxObjectExpression = 'ObjectExpression',\n    SyntaxProperty = 'Property',\n    SyntaxUnaryExpression = 'UnaryExpression'; // Error messages should be identical to V8.\n\nvar MessageUnexpectedToken = 'Unexpected token %0',\n    MessageUnexpectedNumber = 'Unexpected number',\n    MessageUnexpectedString = 'Unexpected string',\n    MessageUnexpectedIdentifier = 'Unexpected identifier',\n    MessageUnexpectedReserved = 'Unexpected reserved word',\n    MessageUnexpectedEOS = 'Unexpected end of input',\n    MessageInvalidRegExp = 'Invalid regular expression',\n    MessageUnterminatedRegExp = 'Invalid regular expression: missing /',\n    MessageStrictOctalLiteral = 'Octal literals are not allowed in strict mode.',\n    MessageStrictDuplicateProperty = 'Duplicate data property in object literal not allowed in strict mode';\nvar ILLEGAL = 'ILLEGAL',\n    DISABLED = 'Disabled.'; // See also tools/generate-unicode-regex.py.\n\nvar RegexNonAsciiIdentifierStart = new RegExp('[\\\\xAA\\\\xB5\\\\xBA\\\\xC0-\\\\xD6\\\\xD8-\\\\xF6\\\\xF8-\\\\u02C1\\\\u02C6-\\\\u02D1\\\\u02E0-\\\\u02E4\\\\u02EC\\\\u02EE\\\\u0370-\\\\u0374\\\\u0376\\\\u0377\\\\u037A-\\\\u037D\\\\u037F\\\\u0386\\\\u0388-\\\\u038A\\\\u038C\\\\u038E-\\\\u03A1\\\\u03A3-\\\\u03F5\\\\u03F7-\\\\u0481\\\\u048A-\\\\u052F\\\\u0531-\\\\u0556\\\\u0559\\\\u0561-\\\\u0587\\\\u05D0-\\\\u05EA\\\\u05F0-\\\\u05F2\\\\u0620-\\\\u064A\\\\u066E\\\\u066F\\\\u0671-\\\\u06D3\\\\u06D5\\\\u06E5\\\\u06E6\\\\u06EE\\\\u06EF\\\\u06FA-\\\\u06FC\\\\u06FF\\\\u0710\\\\u0712-\\\\u072F\\\\u074D-\\\\u07A5\\\\u07B1\\\\u07CA-\\\\u07EA\\\\u07F4\\\\u07F5\\\\u07FA\\\\u0800-\\\\u0815\\\\u081A\\\\u0824\\\\u0828\\\\u0840-\\\\u0858\\\\u08A0-\\\\u08B2\\\\u0904-\\\\u0939\\\\u093D\\\\u0950\\\\u0958-\\\\u0961\\\\u0971-\\\\u0980\\\\u0985-\\\\u098C\\\\u098F\\\\u0990\\\\u0993-\\\\u09A8\\\\u09AA-\\\\u09B0\\\\u09B2\\\\u09B6-\\\\u09B9\\\\u09BD\\\\u09CE\\\\u09DC\\\\u09DD\\\\u09DF-\\\\u09E1\\\\u09F0\\\\u09F1\\\\u0A05-\\\\u0A0A\\\\u0A0F\\\\u0A10\\\\u0A13-\\\\u0A28\\\\u0A2A-\\\\u0A30\\\\u0A32\\\\u0A33\\\\u0A35\\\\u0A36\\\\u0A38\\\\u0A39\\\\u0A59-\\\\u0A5C\\\\u0A5E\\\\u0A72-\\\\u0A74\\\\u0A85-\\\\u0A8D\\\\u0A8F-\\\\u0A91\\\\u0A93-\\\\u0AA8\\\\u0AAA-\\\\u0AB0\\\\u0AB2\\\\u0AB3\\\\u0AB5-\\\\u0AB9\\\\u0ABD\\\\u0AD0\\\\u0AE0\\\\u0AE1\\\\u0B05-\\\\u0B0C\\\\u0B0F\\\\u0B10\\\\u0B13-\\\\u0B28\\\\u0B2A-\\\\u0B30\\\\u0B32\\\\u0B33\\\\u0B35-\\\\u0B39\\\\u0B3D\\\\u0B5C\\\\u0B5D\\\\u0B5F-\\\\u0B61\\\\u0B71\\\\u0B83\\\\u0B85-\\\\u0B8A\\\\u0B8E-\\\\u0B90\\\\u0B92-\\\\u0B95\\\\u0B99\\\\u0B9A\\\\u0B9C\\\\u0B9E\\\\u0B9F\\\\u0BA3\\\\u0BA4\\\\u0BA8-\\\\u0BAA\\\\u0BAE-\\\\u0BB9\\\\u0BD0\\\\u0C05-\\\\u0C0C\\\\u0C0E-\\\\u0C10\\\\u0C12-\\\\u0C28\\\\u0C2A-\\\\u0C39\\\\u0C3D\\\\u0C58\\\\u0C59\\\\u0C60\\\\u0C61\\\\u0C85-\\\\u0C8C\\\\u0C8E-\\\\u0C90\\\\u0C92-\\\\u0CA8\\\\u0CAA-\\\\u0CB3\\\\u0CB5-\\\\u0CB9\\\\u0CBD\\\\u0CDE\\\\u0CE0\\\\u0CE1\\\\u0CF1\\\\u0CF2\\\\u0D05-\\\\u0D0C\\\\u0D0E-\\\\u0D10\\\\u0D12-\\\\u0D3A\\\\u0D3D\\\\u0D4E\\\\u0D60\\\\u0D61\\\\u0D7A-\\\\u0D7F\\\\u0D85-\\\\u0D96\\\\u0D9A-\\\\u0DB1\\\\u0DB3-\\\\u0DBB\\\\u0DBD\\\\u0DC0-\\\\u0DC6\\\\u0E01-\\\\u0E30\\\\u0E32\\\\u0E33\\\\u0E40-\\\\u0E46\\\\u0E81\\\\u0E82\\\\u0E84\\\\u0E87\\\\u0E88\\\\u0E8A\\\\u0E8D\\\\u0E94-\\\\u0E97\\\\u0E99-\\\\u0E9F\\\\u0EA1-\\\\u0EA3\\\\u0EA5\\\\u0EA7\\\\u0EAA\\\\u0EAB\\\\u0EAD-\\\\u0EB0\\\\u0EB2\\\\u0EB3\\\\u0EBD\\\\u0EC0-\\\\u0EC4\\\\u0EC6\\\\u0EDC-\\\\u0EDF\\\\u0F00\\\\u0F40-\\\\u0F47\\\\u0F49-\\\\u0F6C\\\\u0F88-\\\\u0F8C\\\\u1000-\\\\u102A\\\\u103F\\\\u1050-\\\\u1055\\\\u105A-\\\\u105D\\\\u1061\\\\u1065\\\\u1066\\\\u106E-\\\\u1070\\\\u1075-\\\\u1081\\\\u108E\\\\u10A0-\\\\u10C5\\\\u10C7\\\\u10CD\\\\u10D0-\\\\u10FA\\\\u10FC-\\\\u1248\\\\u124A-\\\\u124D\\\\u1250-\\\\u1256\\\\u1258\\\\u125A-\\\\u125D\\\\u1260-\\\\u1288\\\\u128A-\\\\u128D\\\\u1290-\\\\u12B0\\\\u12B2-\\\\u12B5\\\\u12B8-\\\\u12BE\\\\u12C0\\\\u12C2-\\\\u12C5\\\\u12C8-\\\\u12D6\\\\u12D8-\\\\u1310\\\\u1312-\\\\u1315\\\\u1318-\\\\u135A\\\\u1380-\\\\u138F\\\\u13A0-\\\\u13F4\\\\u1401-\\\\u166C\\\\u166F-\\\\u167F\\\\u1681-\\\\u169A\\\\u16A0-\\\\u16EA\\\\u16EE-\\\\u16F8\\\\u1700-\\\\u170C\\\\u170E-\\\\u1711\\\\u1720-\\\\u1731\\\\u1740-\\\\u1751\\\\u1760-\\\\u176C\\\\u176E-\\\\u1770\\\\u1780-\\\\u17B3\\\\u17D7\\\\u17DC\\\\u1820-\\\\u1877\\\\u1880-\\\\u18A8\\\\u18AA\\\\u18B0-\\\\u18F5\\\\u1900-\\\\u191E\\\\u1950-\\\\u196D\\\\u1970-\\\\u1974\\\\u1980-\\\\u19AB\\\\u19C1-\\\\u19C7\\\\u1A00-\\\\u1A16\\\\u1A20-\\\\u1A54\\\\u1AA7\\\\u1B05-\\\\u1B33\\\\u1B45-\\\\u1B4B\\\\u1B83-\\\\u1BA0\\\\u1BAE\\\\u1BAF\\\\u1BBA-\\\\u1BE5\\\\u1C00-\\\\u1C23\\\\u1C4D-\\\\u1C4F\\\\u1C5A-\\\\u1C7D\\\\u1CE9-\\\\u1CEC\\\\u1CEE-\\\\u1CF1\\\\u1CF5\\\\u1CF6\\\\u1D00-\\\\u1DBF\\\\u1E00-\\\\u1F15\\\\u1F18-\\\\u1F1D\\\\u1F20-\\\\u1F45\\\\u1F48-\\\\u1F4D\\\\u1F50-\\\\u1F57\\\\u1F59\\\\u1F5B\\\\u1F5D\\\\u1F5F-\\\\u1F7D\\\\u1F80-\\\\u1FB4\\\\u1FB6-\\\\u1FBC\\\\u1FBE\\\\u1FC2-\\\\u1FC4\\\\u1FC6-\\\\u1FCC\\\\u1FD0-\\\\u1FD3\\\\u1FD6-\\\\u1FDB\\\\u1FE0-\\\\u1FEC\\\\u1FF2-\\\\u1FF4\\\\u1FF6-\\\\u1FFC\\\\u2071\\\\u207F\\\\u2090-\\\\u209C\\\\u2102\\\\u2107\\\\u210A-\\\\u2113\\\\u2115\\\\u2119-\\\\u211D\\\\u2124\\\\u2126\\\\u2128\\\\u212A-\\\\u212D\\\\u212F-\\\\u2139\\\\u213C-\\\\u213F\\\\u2145-\\\\u2149\\\\u214E\\\\u2160-\\\\u2188\\\\u2C00-\\\\u2C2E\\\\u2C30-\\\\u2C5E\\\\u2C60-\\\\u2CE4\\\\u2CEB-\\\\u2CEE\\\\u2CF2\\\\u2CF3\\\\u2D00-\\\\u2D25\\\\u2D27\\\\u2D2D\\\\u2D30-\\\\u2D67\\\\u2D6F\\\\u2D80-\\\\u2D96\\\\u2DA0-\\\\u2DA6\\\\u2DA8-\\\\u2DAE\\\\u2DB0-\\\\u2DB6\\\\u2DB8-\\\\u2DBE\\\\u2DC0-\\\\u2DC6\\\\u2DC8-\\\\u2DCE\\\\u2DD0-\\\\u2DD6\\\\u2DD8-\\\\u2DDE\\\\u2E2F\\\\u3005-\\\\u3007\\\\u3021-\\\\u3029\\\\u3031-\\\\u3035\\\\u3038-\\\\u303C\\\\u3041-\\\\u3096\\\\u309D-\\\\u309F\\\\u30A1-\\\\u30FA\\\\u30FC-\\\\u30FF\\\\u3105-\\\\u312D\\\\u3131-\\\\u318E\\\\u31A0-\\\\u31BA\\\\u31F0-\\\\u31FF\\\\u3400-\\\\u4DB5\\\\u4E00-\\\\u9FCC\\\\uA000-\\\\uA48C\\\\uA4D0-\\\\uA4FD\\\\uA500-\\\\uA60C\\\\uA610-\\\\uA61F\\\\uA62A\\\\uA62B\\\\uA640-\\\\uA66E\\\\uA67F-\\\\uA69D\\\\uA6A0-\\\\uA6EF\\\\uA717-\\\\uA71F\\\\uA722-\\\\uA788\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7AD\\\\uA7B0\\\\uA7B1\\\\uA7F7-\\\\uA801\\\\uA803-\\\\uA805\\\\uA807-\\\\uA80A\\\\uA80C-\\\\uA822\\\\uA840-\\\\uA873\\\\uA882-\\\\uA8B3\\\\uA8F2-\\\\uA8F7\\\\uA8FB\\\\uA90A-\\\\uA925\\\\uA930-\\\\uA946\\\\uA960-\\\\uA97C\\\\uA984-\\\\uA9B2\\\\uA9CF\\\\uA9E0-\\\\uA9E4\\\\uA9E6-\\\\uA9EF\\\\uA9FA-\\\\uA9FE\\\\uAA00-\\\\uAA28\\\\uAA40-\\\\uAA42\\\\uAA44-\\\\uAA4B\\\\uAA60-\\\\uAA76\\\\uAA7A\\\\uAA7E-\\\\uAAAF\\\\uAAB1\\\\uAAB5\\\\uAAB6\\\\uAAB9-\\\\uAABD\\\\uAAC0\\\\uAAC2\\\\uAADB-\\\\uAADD\\\\uAAE0-\\\\uAAEA\\\\uAAF2-\\\\uAAF4\\\\uAB01-\\\\uAB06\\\\uAB09-\\\\uAB0E\\\\uAB11-\\\\uAB16\\\\uAB20-\\\\uAB26\\\\uAB28-\\\\uAB2E\\\\uAB30-\\\\uAB5A\\\\uAB5C-\\\\uAB5F\\\\uAB64\\\\uAB65\\\\uABC0-\\\\uABE2\\\\uAC00-\\\\uD7A3\\\\uD7B0-\\\\uD7C6\\\\uD7CB-\\\\uD7FB\\\\uF900-\\\\uFA6D\\\\uFA70-\\\\uFAD9\\\\uFB00-\\\\uFB06\\\\uFB13-\\\\uFB17\\\\uFB1D\\\\uFB1F-\\\\uFB28\\\\uFB2A-\\\\uFB36\\\\uFB38-\\\\uFB3C\\\\uFB3E\\\\uFB40\\\\uFB41\\\\uFB43\\\\uFB44\\\\uFB46-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFD8F\\\\uFD92-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFE74\\\\uFE76-\\\\uFEFC\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\uFF66-\\\\uFFBE\\\\uFFC2-\\\\uFFC7\\\\uFFCA-\\\\uFFCF\\\\uFFD2-\\\\uFFD7\\\\uFFDA-\\\\uFFDC]'),\n    // eslint-disable-next-line no-misleading-character-class\nRegexNonAsciiIdentifierPart = new RegExp('[\\\\xAA\\\\xB5\\\\xBA\\\\xC0-\\\\xD6\\\\xD8-\\\\xF6\\\\xF8-\\\\u02C1\\\\u02C6-\\\\u02D1\\\\u02E0-\\\\u02E4\\\\u02EC\\\\u02EE\\\\u0300-\\\\u0374\\\\u0376\\\\u0377\\\\u037A-\\\\u037D\\\\u037F\\\\u0386\\\\u0388-\\\\u038A\\\\u038C\\\\u038E-\\\\u03A1\\\\u03A3-\\\\u03F5\\\\u03F7-\\\\u0481\\\\u0483-\\\\u0487\\\\u048A-\\\\u052F\\\\u0531-\\\\u0556\\\\u0559\\\\u0561-\\\\u0587\\\\u0591-\\\\u05BD\\\\u05BF\\\\u05C1\\\\u05C2\\\\u05C4\\\\u05C5\\\\u05C7\\\\u05D0-\\\\u05EA\\\\u05F0-\\\\u05F2\\\\u0610-\\\\u061A\\\\u0620-\\\\u0669\\\\u066E-\\\\u06D3\\\\u06D5-\\\\u06DC\\\\u06DF-\\\\u06E8\\\\u06EA-\\\\u06FC\\\\u06FF\\\\u0710-\\\\u074A\\\\u074D-\\\\u07B1\\\\u07C0-\\\\u07F5\\\\u07FA\\\\u0800-\\\\u082D\\\\u0840-\\\\u085B\\\\u08A0-\\\\u08B2\\\\u08E4-\\\\u0963\\\\u0966-\\\\u096F\\\\u0971-\\\\u0983\\\\u0985-\\\\u098C\\\\u098F\\\\u0990\\\\u0993-\\\\u09A8\\\\u09AA-\\\\u09B0\\\\u09B2\\\\u09B6-\\\\u09B9\\\\u09BC-\\\\u09C4\\\\u09C7\\\\u09C8\\\\u09CB-\\\\u09CE\\\\u09D7\\\\u09DC\\\\u09DD\\\\u09DF-\\\\u09E3\\\\u09E6-\\\\u09F1\\\\u0A01-\\\\u0A03\\\\u0A05-\\\\u0A0A\\\\u0A0F\\\\u0A10\\\\u0A13-\\\\u0A28\\\\u0A2A-\\\\u0A30\\\\u0A32\\\\u0A33\\\\u0A35\\\\u0A36\\\\u0A38\\\\u0A39\\\\u0A3C\\\\u0A3E-\\\\u0A42\\\\u0A47\\\\u0A48\\\\u0A4B-\\\\u0A4D\\\\u0A51\\\\u0A59-\\\\u0A5C\\\\u0A5E\\\\u0A66-\\\\u0A75\\\\u0A81-\\\\u0A83\\\\u0A85-\\\\u0A8D\\\\u0A8F-\\\\u0A91\\\\u0A93-\\\\u0AA8\\\\u0AAA-\\\\u0AB0\\\\u0AB2\\\\u0AB3\\\\u0AB5-\\\\u0AB9\\\\u0ABC-\\\\u0AC5\\\\u0AC7-\\\\u0AC9\\\\u0ACB-\\\\u0ACD\\\\u0AD0\\\\u0AE0-\\\\u0AE3\\\\u0AE6-\\\\u0AEF\\\\u0B01-\\\\u0B03\\\\u0B05-\\\\u0B0C\\\\u0B0F\\\\u0B10\\\\u0B13-\\\\u0B28\\\\u0B2A-\\\\u0B30\\\\u0B32\\\\u0B33\\\\u0B35-\\\\u0B39\\\\u0B3C-\\\\u0B44\\\\u0B47\\\\u0B48\\\\u0B4B-\\\\u0B4D\\\\u0B56\\\\u0B57\\\\u0B5C\\\\u0B5D\\\\u0B5F-\\\\u0B63\\\\u0B66-\\\\u0B6F\\\\u0B71\\\\u0B82\\\\u0B83\\\\u0B85-\\\\u0B8A\\\\u0B8E-\\\\u0B90\\\\u0B92-\\\\u0B95\\\\u0B99\\\\u0B9A\\\\u0B9C\\\\u0B9E\\\\u0B9F\\\\u0BA3\\\\u0BA4\\\\u0BA8-\\\\u0BAA\\\\u0BAE-\\\\u0BB9\\\\u0BBE-\\\\u0BC2\\\\u0BC6-\\\\u0BC8\\\\u0BCA-\\\\u0BCD\\\\u0BD0\\\\u0BD7\\\\u0BE6-\\\\u0BEF\\\\u0C00-\\\\u0C03\\\\u0C05-\\\\u0C0C\\\\u0C0E-\\\\u0C10\\\\u0C12-\\\\u0C28\\\\u0C2A-\\\\u0C39\\\\u0C3D-\\\\u0C44\\\\u0C46-\\\\u0C48\\\\u0C4A-\\\\u0C4D\\\\u0C55\\\\u0C56\\\\u0C58\\\\u0C59\\\\u0C60-\\\\u0C63\\\\u0C66-\\\\u0C6F\\\\u0C81-\\\\u0C83\\\\u0C85-\\\\u0C8C\\\\u0C8E-\\\\u0C90\\\\u0C92-\\\\u0CA8\\\\u0CAA-\\\\u0CB3\\\\u0CB5-\\\\u0CB9\\\\u0CBC-\\\\u0CC4\\\\u0CC6-\\\\u0CC8\\\\u0CCA-\\\\u0CCD\\\\u0CD5\\\\u0CD6\\\\u0CDE\\\\u0CE0-\\\\u0CE3\\\\u0CE6-\\\\u0CEF\\\\u0CF1\\\\u0CF2\\\\u0D01-\\\\u0D03\\\\u0D05-\\\\u0D0C\\\\u0D0E-\\\\u0D10\\\\u0D12-\\\\u0D3A\\\\u0D3D-\\\\u0D44\\\\u0D46-\\\\u0D48\\\\u0D4A-\\\\u0D4E\\\\u0D57\\\\u0D60-\\\\u0D63\\\\u0D66-\\\\u0D6F\\\\u0D7A-\\\\u0D7F\\\\u0D82\\\\u0D83\\\\u0D85-\\\\u0D96\\\\u0D9A-\\\\u0DB1\\\\u0DB3-\\\\u0DBB\\\\u0DBD\\\\u0DC0-\\\\u0DC6\\\\u0DCA\\\\u0DCF-\\\\u0DD4\\\\u0DD6\\\\u0DD8-\\\\u0DDF\\\\u0DE6-\\\\u0DEF\\\\u0DF2\\\\u0DF3\\\\u0E01-\\\\u0E3A\\\\u0E40-\\\\u0E4E\\\\u0E50-\\\\u0E59\\\\u0E81\\\\u0E82\\\\u0E84\\\\u0E87\\\\u0E88\\\\u0E8A\\\\u0E8D\\\\u0E94-\\\\u0E97\\\\u0E99-\\\\u0E9F\\\\u0EA1-\\\\u0EA3\\\\u0EA5\\\\u0EA7\\\\u0EAA\\\\u0EAB\\\\u0EAD-\\\\u0EB9\\\\u0EBB-\\\\u0EBD\\\\u0EC0-\\\\u0EC4\\\\u0EC6\\\\u0EC8-\\\\u0ECD\\\\u0ED0-\\\\u0ED9\\\\u0EDC-\\\\u0EDF\\\\u0F00\\\\u0F18\\\\u0F19\\\\u0F20-\\\\u0F29\\\\u0F35\\\\u0F37\\\\u0F39\\\\u0F3E-\\\\u0F47\\\\u0F49-\\\\u0F6C\\\\u0F71-\\\\u0F84\\\\u0F86-\\\\u0F97\\\\u0F99-\\\\u0FBC\\\\u0FC6\\\\u1000-\\\\u1049\\\\u1050-\\\\u109D\\\\u10A0-\\\\u10C5\\\\u10C7\\\\u10CD\\\\u10D0-\\\\u10FA\\\\u10FC-\\\\u1248\\\\u124A-\\\\u124D\\\\u1250-\\\\u1256\\\\u1258\\\\u125A-\\\\u125D\\\\u1260-\\\\u1288\\\\u128A-\\\\u128D\\\\u1290-\\\\u12B0\\\\u12B2-\\\\u12B5\\\\u12B8-\\\\u12BE\\\\u12C0\\\\u12C2-\\\\u12C5\\\\u12C8-\\\\u12D6\\\\u12D8-\\\\u1310\\\\u1312-\\\\u1315\\\\u1318-\\\\u135A\\\\u135D-\\\\u135F\\\\u1380-\\\\u138F\\\\u13A0-\\\\u13F4\\\\u1401-\\\\u166C\\\\u166F-\\\\u167F\\\\u1681-\\\\u169A\\\\u16A0-\\\\u16EA\\\\u16EE-\\\\u16F8\\\\u1700-\\\\u170C\\\\u170E-\\\\u1714\\\\u1720-\\\\u1734\\\\u1740-\\\\u1753\\\\u1760-\\\\u176C\\\\u176E-\\\\u1770\\\\u1772\\\\u1773\\\\u1780-\\\\u17D3\\\\u17D7\\\\u17DC\\\\u17DD\\\\u17E0-\\\\u17E9\\\\u180B-\\\\u180D\\\\u1810-\\\\u1819\\\\u1820-\\\\u1877\\\\u1880-\\\\u18AA\\\\u18B0-\\\\u18F5\\\\u1900-\\\\u191E\\\\u1920-\\\\u192B\\\\u1930-\\\\u193B\\\\u1946-\\\\u196D\\\\u1970-\\\\u1974\\\\u1980-\\\\u19AB\\\\u19B0-\\\\u19C9\\\\u19D0-\\\\u19D9\\\\u1A00-\\\\u1A1B\\\\u1A20-\\\\u1A5E\\\\u1A60-\\\\u1A7C\\\\u1A7F-\\\\u1A89\\\\u1A90-\\\\u1A99\\\\u1AA7\\\\u1AB0-\\\\u1ABD\\\\u1B00-\\\\u1B4B\\\\u1B50-\\\\u1B59\\\\u1B6B-\\\\u1B73\\\\u1B80-\\\\u1BF3\\\\u1C00-\\\\u1C37\\\\u1C40-\\\\u1C49\\\\u1C4D-\\\\u1C7D\\\\u1CD0-\\\\u1CD2\\\\u1CD4-\\\\u1CF6\\\\u1CF8\\\\u1CF9\\\\u1D00-\\\\u1DF5\\\\u1DFC-\\\\u1F15\\\\u1F18-\\\\u1F1D\\\\u1F20-\\\\u1F45\\\\u1F48-\\\\u1F4D\\\\u1F50-\\\\u1F57\\\\u1F59\\\\u1F5B\\\\u1F5D\\\\u1F5F-\\\\u1F7D\\\\u1F80-\\\\u1FB4\\\\u1FB6-\\\\u1FBC\\\\u1FBE\\\\u1FC2-\\\\u1FC4\\\\u1FC6-\\\\u1FCC\\\\u1FD0-\\\\u1FD3\\\\u1FD6-\\\\u1FDB\\\\u1FE0-\\\\u1FEC\\\\u1FF2-\\\\u1FF4\\\\u1FF6-\\\\u1FFC\\\\u200C\\\\u200D\\\\u203F\\\\u2040\\\\u2054\\\\u2071\\\\u207F\\\\u2090-\\\\u209C\\\\u20D0-\\\\u20DC\\\\u20E1\\\\u20E5-\\\\u20F0\\\\u2102\\\\u2107\\\\u210A-\\\\u2113\\\\u2115\\\\u2119-\\\\u211D\\\\u2124\\\\u2126\\\\u2128\\\\u212A-\\\\u212D\\\\u212F-\\\\u2139\\\\u213C-\\\\u213F\\\\u2145-\\\\u2149\\\\u214E\\\\u2160-\\\\u2188\\\\u2C00-\\\\u2C2E\\\\u2C30-\\\\u2C5E\\\\u2C60-\\\\u2CE4\\\\u2CEB-\\\\u2CF3\\\\u2D00-\\\\u2D25\\\\u2D27\\\\u2D2D\\\\u2D30-\\\\u2D67\\\\u2D6F\\\\u2D7F-\\\\u2D96\\\\u2DA0-\\\\u2DA6\\\\u2DA8-\\\\u2DAE\\\\u2DB0-\\\\u2DB6\\\\u2DB8-\\\\u2DBE\\\\u2DC0-\\\\u2DC6\\\\u2DC8-\\\\u2DCE\\\\u2DD0-\\\\u2DD6\\\\u2DD8-\\\\u2DDE\\\\u2DE0-\\\\u2DFF\\\\u2E2F\\\\u3005-\\\\u3007\\\\u3021-\\\\u302F\\\\u3031-\\\\u3035\\\\u3038-\\\\u303C\\\\u3041-\\\\u3096\\\\u3099\\\\u309A\\\\u309D-\\\\u309F\\\\u30A1-\\\\u30FA\\\\u30FC-\\\\u30FF\\\\u3105-\\\\u312D\\\\u3131-\\\\u318E\\\\u31A0-\\\\u31BA\\\\u31F0-\\\\u31FF\\\\u3400-\\\\u4DB5\\\\u4E00-\\\\u9FCC\\\\uA000-\\\\uA48C\\\\uA4D0-\\\\uA4FD\\\\uA500-\\\\uA60C\\\\uA610-\\\\uA62B\\\\uA640-\\\\uA66F\\\\uA674-\\\\uA67D\\\\uA67F-\\\\uA69D\\\\uA69F-\\\\uA6F1\\\\uA717-\\\\uA71F\\\\uA722-\\\\uA788\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7AD\\\\uA7B0\\\\uA7B1\\\\uA7F7-\\\\uA827\\\\uA840-\\\\uA873\\\\uA880-\\\\uA8C4\\\\uA8D0-\\\\uA8D9\\\\uA8E0-\\\\uA8F7\\\\uA8FB\\\\uA900-\\\\uA92D\\\\uA930-\\\\uA953\\\\uA960-\\\\uA97C\\\\uA980-\\\\uA9C0\\\\uA9CF-\\\\uA9D9\\\\uA9E0-\\\\uA9FE\\\\uAA00-\\\\uAA36\\\\uAA40-\\\\uAA4D\\\\uAA50-\\\\uAA59\\\\uAA60-\\\\uAA76\\\\uAA7A-\\\\uAAC2\\\\uAADB-\\\\uAADD\\\\uAAE0-\\\\uAAEF\\\\uAAF2-\\\\uAAF6\\\\uAB01-\\\\uAB06\\\\uAB09-\\\\uAB0E\\\\uAB11-\\\\uAB16\\\\uAB20-\\\\uAB26\\\\uAB28-\\\\uAB2E\\\\uAB30-\\\\uAB5A\\\\uAB5C-\\\\uAB5F\\\\uAB64\\\\uAB65\\\\uABC0-\\\\uABEA\\\\uABEC\\\\uABED\\\\uABF0-\\\\uABF9\\\\uAC00-\\\\uD7A3\\\\uD7B0-\\\\uD7C6\\\\uD7CB-\\\\uD7FB\\\\uF900-\\\\uFA6D\\\\uFA70-\\\\uFAD9\\\\uFB00-\\\\uFB06\\\\uFB13-\\\\uFB17\\\\uFB1D-\\\\uFB28\\\\uFB2A-\\\\uFB36\\\\uFB38-\\\\uFB3C\\\\uFB3E\\\\uFB40\\\\uFB41\\\\uFB43\\\\uFB44\\\\uFB46-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFD8F\\\\uFD92-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE00-\\\\uFE0F\\\\uFE20-\\\\uFE2D\\\\uFE33\\\\uFE34\\\\uFE4D-\\\\uFE4F\\\\uFE70-\\\\uFE74\\\\uFE76-\\\\uFEFC\\\\uFF10-\\\\uFF19\\\\uFF21-\\\\uFF3A\\\\uFF3F\\\\uFF41-\\\\uFF5A\\\\uFF66-\\\\uFFBE\\\\uFFC2-\\\\uFFC7\\\\uFFCA-\\\\uFFCF\\\\uFFD2-\\\\uFFD7\\\\uFFDA-\\\\uFFDC]'); // Ensure the condition is true, otherwise throw an error.\n// This is only to have a better contract semantic, i.e. another safety net\n// to catch a logic error. The condition shall be fulfilled in normal case.\n// Do NOT use this to enforce a certain condition on any user input.\n\nfunction assert(condition, message) {\n  /* istanbul ignore next */\n  if (!condition) {\n    throw new Error('ASSERT: ' + message);\n  }\n}\n\nfunction isDecimalDigit(ch) {\n  return ch >= 0x30 && ch <= 0x39; // 0..9\n}\n\nfunction isHexDigit(ch) {\n  return '0123456789abcdefABCDEF'.indexOf(ch) >= 0;\n}\n\nfunction isOctalDigit(ch) {\n  return '01234567'.indexOf(ch) >= 0;\n} // 7.2 White Space\n\n\nfunction isWhiteSpace(ch) {\n  return ch === 0x20 || ch === 0x09 || ch === 0x0B || ch === 0x0C || ch === 0xA0 || ch >= 0x1680 && [0x1680, 0x180E, 0x2000, 0x2001, 0x2002, 0x2003, 0x2004, 0x2005, 0x2006, 0x2007, 0x2008, 0x2009, 0x200A, 0x202F, 0x205F, 0x3000, 0xFEFF].indexOf(ch) >= 0;\n} // 7.3 Line Terminators\n\n\nfunction isLineTerminator(ch) {\n  return ch === 0x0A || ch === 0x0D || ch === 0x2028 || ch === 0x2029;\n} // 7.6 Identifier Names and Identifiers\n\n\nfunction isIdentifierStart(ch) {\n  return ch === 0x24 || ch === 0x5F || // $ (dollar) and _ (underscore)\n  ch >= 0x41 && ch <= 0x5A || // A..Z\n  ch >= 0x61 && ch <= 0x7A || // a..z\n  ch === 0x5C || // \\ (backslash)\n  ch >= 0x80 && RegexNonAsciiIdentifierStart.test(String.fromCharCode(ch));\n}\n\nfunction isIdentifierPart(ch) {\n  return ch === 0x24 || ch === 0x5F || // $ (dollar) and _ (underscore)\n  ch >= 0x41 && ch <= 0x5A || // A..Z\n  ch >= 0x61 && ch <= 0x7A || // a..z\n  ch >= 0x30 && ch <= 0x39 || // 0..9\n  ch === 0x5C || // \\ (backslash)\n  ch >= 0x80 && RegexNonAsciiIdentifierPart.test(String.fromCharCode(ch));\n} // 7.6.1.1 Keywords\n\n\nconst keywords = {\n  'if': 1,\n  'in': 1,\n  'do': 1,\n  'var': 1,\n  'for': 1,\n  'new': 1,\n  'try': 1,\n  'let': 1,\n  'this': 1,\n  'else': 1,\n  'case': 1,\n  'void': 1,\n  'with': 1,\n  'enum': 1,\n  'while': 1,\n  'break': 1,\n  'catch': 1,\n  'throw': 1,\n  'const': 1,\n  'yield': 1,\n  'class': 1,\n  'super': 1,\n  'return': 1,\n  'typeof': 1,\n  'delete': 1,\n  'switch': 1,\n  'export': 1,\n  'import': 1,\n  'public': 1,\n  'static': 1,\n  'default': 1,\n  'finally': 1,\n  'extends': 1,\n  'package': 1,\n  'private': 1,\n  'function': 1,\n  'continue': 1,\n  'debugger': 1,\n  'interface': 1,\n  'protected': 1,\n  'instanceof': 1,\n  'implements': 1\n};\n\nfunction skipComment() {\n  while (index < length) {\n    const ch = source.charCodeAt(index);\n\n    if (isWhiteSpace(ch) || isLineTerminator(ch)) {\n      ++index;\n    } else {\n      break;\n    }\n  }\n}\n\nfunction scanHexEscape(prefix) {\n  var i,\n      len,\n      ch,\n      code = 0;\n  len = prefix === 'u' ? 4 : 2;\n\n  for (i = 0; i < len; ++i) {\n    if (index < length && isHexDigit(source[index])) {\n      ch = source[index++];\n      code = code * 16 + '0123456789abcdef'.indexOf(ch.toLowerCase());\n    } else {\n      throwError({}, MessageUnexpectedToken, ILLEGAL);\n    }\n  }\n\n  return String.fromCharCode(code);\n}\n\nfunction scanUnicodeCodePointEscape() {\n  var ch, code, cu1, cu2;\n  ch = source[index];\n  code = 0; // At least, one hex digit is required.\n\n  if (ch === '}') {\n    throwError({}, MessageUnexpectedToken, ILLEGAL);\n  }\n\n  while (index < length) {\n    ch = source[index++];\n\n    if (!isHexDigit(ch)) {\n      break;\n    }\n\n    code = code * 16 + '0123456789abcdef'.indexOf(ch.toLowerCase());\n  }\n\n  if (code > 0x10FFFF || ch !== '}') {\n    throwError({}, MessageUnexpectedToken, ILLEGAL);\n  } // UTF-16 Encoding\n\n\n  if (code <= 0xFFFF) {\n    return String.fromCharCode(code);\n  }\n\n  cu1 = (code - 0x10000 >> 10) + 0xD800;\n  cu2 = (code - 0x10000 & 1023) + 0xDC00;\n  return String.fromCharCode(cu1, cu2);\n}\n\nfunction getEscapedIdentifier() {\n  var ch, id;\n  ch = source.charCodeAt(index++);\n  id = String.fromCharCode(ch); // '\\u' (U+005C, U+0075) denotes an escaped character.\n\n  if (ch === 0x5C) {\n    if (source.charCodeAt(index) !== 0x75) {\n      throwError({}, MessageUnexpectedToken, ILLEGAL);\n    }\n\n    ++index;\n    ch = scanHexEscape('u');\n\n    if (!ch || ch === '\\\\' || !isIdentifierStart(ch.charCodeAt(0))) {\n      throwError({}, MessageUnexpectedToken, ILLEGAL);\n    }\n\n    id = ch;\n  }\n\n  while (index < length) {\n    ch = source.charCodeAt(index);\n\n    if (!isIdentifierPart(ch)) {\n      break;\n    }\n\n    ++index;\n    id += String.fromCharCode(ch); // '\\u' (U+005C, U+0075) denotes an escaped character.\n\n    if (ch === 0x5C) {\n      id = id.substr(0, id.length - 1);\n\n      if (source.charCodeAt(index) !== 0x75) {\n        throwError({}, MessageUnexpectedToken, ILLEGAL);\n      }\n\n      ++index;\n      ch = scanHexEscape('u');\n\n      if (!ch || ch === '\\\\' || !isIdentifierPart(ch.charCodeAt(0))) {\n        throwError({}, MessageUnexpectedToken, ILLEGAL);\n      }\n\n      id += ch;\n    }\n  }\n\n  return id;\n}\n\nfunction getIdentifier() {\n  var start, ch;\n  start = index++;\n\n  while (index < length) {\n    ch = source.charCodeAt(index);\n\n    if (ch === 0x5C) {\n      // Blackslash (U+005C) marks Unicode escape sequence.\n      index = start;\n      return getEscapedIdentifier();\n    }\n\n    if (isIdentifierPart(ch)) {\n      ++index;\n    } else {\n      break;\n    }\n  }\n\n  return source.slice(start, index);\n}\n\nfunction scanIdentifier() {\n  var start, id, type;\n  start = index; // Backslash (U+005C) starts an escaped character.\n\n  id = source.charCodeAt(index) === 0x5C ? getEscapedIdentifier() : getIdentifier(); // There is no keyword or literal with only one character.\n  // Thus, it must be an identifier.\n\n  if (id.length === 1) {\n    type = TokenIdentifier;\n  } else if (keywords.hasOwnProperty(id)) {\n    // eslint-disable-line no-prototype-builtins\n    type = TokenKeyword;\n  } else if (id === 'null') {\n    type = TokenNullLiteral;\n  } else if (id === 'true' || id === 'false') {\n    type = TokenBooleanLiteral;\n  } else {\n    type = TokenIdentifier;\n  }\n\n  return {\n    type: type,\n    value: id,\n    start: start,\n    end: index\n  };\n} // 7.7 Punctuators\n\n\nfunction scanPunctuator() {\n  var start = index,\n      code = source.charCodeAt(index),\n      code2,\n      ch1 = source[index],\n      ch2,\n      ch3,\n      ch4;\n\n  switch (code) {\n    // Check for most common single-character punctuators.\n    case 0x2E: // . dot\n\n    case 0x28: // ( open bracket\n\n    case 0x29: // ) close bracket\n\n    case 0x3B: // ; semicolon\n\n    case 0x2C: // , comma\n\n    case 0x7B: // { open curly brace\n\n    case 0x7D: // } close curly brace\n\n    case 0x5B: // [\n\n    case 0x5D: // ]\n\n    case 0x3A: // :\n\n    case 0x3F: // ?\n\n    case 0x7E:\n      // ~\n      ++index;\n      return {\n        type: TokenPunctuator,\n        value: String.fromCharCode(code),\n        start: start,\n        end: index\n      };\n\n    default:\n      code2 = source.charCodeAt(index + 1); // '=' (U+003D) marks an assignment or comparison operator.\n\n      if (code2 === 0x3D) {\n        switch (code) {\n          case 0x2B: // +\n\n          case 0x2D: // -\n\n          case 0x2F: // /\n\n          case 0x3C: // <\n\n          case 0x3E: // >\n\n          case 0x5E: // ^\n\n          case 0x7C: // |\n\n          case 0x25: // %\n\n          case 0x26: // &\n\n          case 0x2A:\n            // *\n            index += 2;\n            return {\n              type: TokenPunctuator,\n              value: String.fromCharCode(code) + String.fromCharCode(code2),\n              start: start,\n              end: index\n            };\n\n          case 0x21: // !\n\n          case 0x3D:\n            // =\n            index += 2; // !== and ===\n\n            if (source.charCodeAt(index) === 0x3D) {\n              ++index;\n            }\n\n            return {\n              type: TokenPunctuator,\n              value: source.slice(start, index),\n              start: start,\n              end: index\n            };\n        }\n      }\n\n  } // 4-character punctuator: >>>=\n\n\n  ch4 = source.substr(index, 4);\n\n  if (ch4 === '>>>=') {\n    index += 4;\n    return {\n      type: TokenPunctuator,\n      value: ch4,\n      start: start,\n      end: index\n    };\n  } // 3-character punctuators: === !== >>> <<= >>=\n\n\n  ch3 = ch4.substr(0, 3);\n\n  if (ch3 === '>>>' || ch3 === '<<=' || ch3 === '>>=') {\n    index += 3;\n    return {\n      type: TokenPunctuator,\n      value: ch3,\n      start: start,\n      end: index\n    };\n  } // Other 2-character punctuators: ++ -- << >> && ||\n\n\n  ch2 = ch3.substr(0, 2);\n\n  if (ch1 === ch2[1] && '+-<>&|'.indexOf(ch1) >= 0 || ch2 === '=>') {\n    index += 2;\n    return {\n      type: TokenPunctuator,\n      value: ch2,\n      start: start,\n      end: index\n    };\n  }\n\n  if (ch2 === '//') {\n    throwError({}, MessageUnexpectedToken, ILLEGAL);\n  } // 1-character punctuators: < > = ! + - * % & | ^ /\n\n\n  if ('<>=!+-*%&|^/'.indexOf(ch1) >= 0) {\n    ++index;\n    return {\n      type: TokenPunctuator,\n      value: ch1,\n      start: start,\n      end: index\n    };\n  }\n\n  throwError({}, MessageUnexpectedToken, ILLEGAL);\n} // 7.8.3 Numeric Literals\n\n\nfunction scanHexLiteral(start) {\n  let number = '';\n\n  while (index < length) {\n    if (!isHexDigit(source[index])) {\n      break;\n    }\n\n    number += source[index++];\n  }\n\n  if (number.length === 0) {\n    throwError({}, MessageUnexpectedToken, ILLEGAL);\n  }\n\n  if (isIdentifierStart(source.charCodeAt(index))) {\n    throwError({}, MessageUnexpectedToken, ILLEGAL);\n  }\n\n  return {\n    type: TokenNumericLiteral,\n    value: parseInt('0x' + number, 16),\n    start: start,\n    end: index\n  };\n}\n\nfunction scanOctalLiteral(start) {\n  let number = '0' + source[index++];\n\n  while (index < length) {\n    if (!isOctalDigit(source[index])) {\n      break;\n    }\n\n    number += source[index++];\n  }\n\n  if (isIdentifierStart(source.charCodeAt(index)) || isDecimalDigit(source.charCodeAt(index))) {\n    throwError({}, MessageUnexpectedToken, ILLEGAL);\n  }\n\n  return {\n    type: TokenNumericLiteral,\n    value: parseInt(number, 8),\n    octal: true,\n    start: start,\n    end: index\n  };\n}\n\nfunction scanNumericLiteral() {\n  var number, start, ch;\n  ch = source[index];\n  assert(isDecimalDigit(ch.charCodeAt(0)) || ch === '.', 'Numeric literal must start with a decimal digit or a decimal point');\n  start = index;\n  number = '';\n\n  if (ch !== '.') {\n    number = source[index++];\n    ch = source[index]; // Hex number starts with '0x'.\n    // Octal number starts with '0'.\n\n    if (number === '0') {\n      if (ch === 'x' || ch === 'X') {\n        ++index;\n        return scanHexLiteral(start);\n      }\n\n      if (isOctalDigit(ch)) {\n        return scanOctalLiteral(start);\n      } // decimal number starts with '0' such as '09' is illegal.\n\n\n      if (ch && isDecimalDigit(ch.charCodeAt(0))) {\n        throwError({}, MessageUnexpectedToken, ILLEGAL);\n      }\n    }\n\n    while (isDecimalDigit(source.charCodeAt(index))) {\n      number += source[index++];\n    }\n\n    ch = source[index];\n  }\n\n  if (ch === '.') {\n    number += source[index++];\n\n    while (isDecimalDigit(source.charCodeAt(index))) {\n      number += source[index++];\n    }\n\n    ch = source[index];\n  }\n\n  if (ch === 'e' || ch === 'E') {\n    number += source[index++];\n    ch = source[index];\n\n    if (ch === '+' || ch === '-') {\n      number += source[index++];\n    }\n\n    if (isDecimalDigit(source.charCodeAt(index))) {\n      while (isDecimalDigit(source.charCodeAt(index))) {\n        number += source[index++];\n      }\n    } else {\n      throwError({}, MessageUnexpectedToken, ILLEGAL);\n    }\n  }\n\n  if (isIdentifierStart(source.charCodeAt(index))) {\n    throwError({}, MessageUnexpectedToken, ILLEGAL);\n  }\n\n  return {\n    type: TokenNumericLiteral,\n    value: parseFloat(number),\n    start: start,\n    end: index\n  };\n} // 7.8.4 String Literals\n\n\nfunction scanStringLiteral() {\n  var str = '',\n      quote,\n      start,\n      ch,\n      code,\n      octal = false;\n  quote = source[index];\n  assert(quote === '\\'' || quote === '\"', 'String literal must starts with a quote');\n  start = index;\n  ++index;\n\n  while (index < length) {\n    ch = source[index++];\n\n    if (ch === quote) {\n      quote = '';\n      break;\n    } else if (ch === '\\\\') {\n      ch = source[index++];\n\n      if (!ch || !isLineTerminator(ch.charCodeAt(0))) {\n        switch (ch) {\n          case 'u':\n          case 'x':\n            if (source[index] === '{') {\n              ++index;\n              str += scanUnicodeCodePointEscape();\n            } else {\n              str += scanHexEscape(ch);\n            }\n\n            break;\n\n          case 'n':\n            str += '\\n';\n            break;\n\n          case 'r':\n            str += '\\r';\n            break;\n\n          case 't':\n            str += '\\t';\n            break;\n\n          case 'b':\n            str += '\\b';\n            break;\n\n          case 'f':\n            str += '\\f';\n            break;\n\n          case 'v':\n            str += '\\x0B';\n            break;\n\n          default:\n            if (isOctalDigit(ch)) {\n              code = '01234567'.indexOf(ch); // \\0 is not octal escape sequence\n\n              if (code !== 0) {\n                octal = true;\n              }\n\n              if (index < length && isOctalDigit(source[index])) {\n                octal = true;\n                code = code * 8 + '01234567'.indexOf(source[index++]); // 3 digits are only allowed when string starts\n                // with 0, 1, 2, 3\n\n                if ('0123'.indexOf(ch) >= 0 && index < length && isOctalDigit(source[index])) {\n                  code = code * 8 + '01234567'.indexOf(source[index++]);\n                }\n              }\n\n              str += String.fromCharCode(code);\n            } else {\n              str += ch;\n            }\n\n            break;\n        }\n      } else {\n        if (ch === '\\r' && source[index] === '\\n') {\n          ++index;\n        }\n      }\n    } else if (isLineTerminator(ch.charCodeAt(0))) {\n      break;\n    } else {\n      str += ch;\n    }\n  }\n\n  if (quote !== '') {\n    throwError({}, MessageUnexpectedToken, ILLEGAL);\n  }\n\n  return {\n    type: TokenStringLiteral,\n    value: str,\n    octal: octal,\n    start: start,\n    end: index\n  };\n}\n\nfunction testRegExp(pattern, flags) {\n  let tmp = pattern;\n\n  if (flags.indexOf('u') >= 0) {\n    // Replace each astral symbol and every Unicode code point\n    // escape sequence with a single ASCII symbol to avoid throwing on\n    // regular expressions that are only valid in combination with the\n    // `/u` flag.\n    // Note: replacing with the ASCII symbol `x` might cause false\n    // negatives in unlikely scenarios. For example, `[\\u{61}-b]` is a\n    // perfectly valid pattern that is equivalent to `[a-b]`, but it\n    // would be replaced by `[x-b]` which throws an error.\n    tmp = tmp.replace(/\\\\u\\{([0-9a-fA-F]+)\\}/g, ($0, $1) => {\n      if (parseInt($1, 16) <= 0x10FFFF) {\n        return 'x';\n      }\n\n      throwError({}, MessageInvalidRegExp);\n    }).replace(/[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]/g, 'x');\n  } // First, detect invalid regular expressions.\n\n\n  try {\n    new RegExp(tmp);\n  } catch (e) {\n    throwError({}, MessageInvalidRegExp);\n  } // Return a regular expression object for this pattern-flag pair, or\n  // `null` in case the current environment doesn't support the flags it\n  // uses.\n\n\n  try {\n    return new RegExp(pattern, flags);\n  } catch (exception) {\n    return null;\n  }\n}\n\nfunction scanRegExpBody() {\n  var ch, str, classMarker, terminated, body;\n  ch = source[index];\n  assert(ch === '/', 'Regular expression literal must start with a slash');\n  str = source[index++];\n  classMarker = false;\n  terminated = false;\n\n  while (index < length) {\n    ch = source[index++];\n    str += ch;\n\n    if (ch === '\\\\') {\n      ch = source[index++]; // ECMA-262 7.8.5\n\n      if (isLineTerminator(ch.charCodeAt(0))) {\n        throwError({}, MessageUnterminatedRegExp);\n      }\n\n      str += ch;\n    } else if (isLineTerminator(ch.charCodeAt(0))) {\n      throwError({}, MessageUnterminatedRegExp);\n    } else if (classMarker) {\n      if (ch === ']') {\n        classMarker = false;\n      }\n    } else {\n      if (ch === '/') {\n        terminated = true;\n        break;\n      } else if (ch === '[') {\n        classMarker = true;\n      }\n    }\n  }\n\n  if (!terminated) {\n    throwError({}, MessageUnterminatedRegExp);\n  } // Exclude leading and trailing slash.\n\n\n  body = str.substr(1, str.length - 2);\n  return {\n    value: body,\n    literal: str\n  };\n}\n\nfunction scanRegExpFlags() {\n  var ch, str, flags;\n  str = '';\n  flags = '';\n\n  while (index < length) {\n    ch = source[index];\n\n    if (!isIdentifierPart(ch.charCodeAt(0))) {\n      break;\n    }\n\n    ++index;\n\n    if (ch === '\\\\' && index < length) {\n      throwError({}, MessageUnexpectedToken, ILLEGAL);\n    } else {\n      flags += ch;\n      str += ch;\n    }\n  }\n\n  if (flags.search(/[^gimuy]/g) >= 0) {\n    throwError({}, MessageInvalidRegExp, flags);\n  }\n\n  return {\n    value: flags,\n    literal: str\n  };\n}\n\nfunction scanRegExp() {\n  var start, body, flags, value;\n  lookahead = null;\n  skipComment();\n  start = index;\n  body = scanRegExpBody();\n  flags = scanRegExpFlags();\n  value = testRegExp(body.value, flags.value);\n  return {\n    literal: body.literal + flags.literal,\n    value: value,\n    regex: {\n      pattern: body.value,\n      flags: flags.value\n    },\n    start: start,\n    end: index\n  };\n}\n\nfunction isIdentifierName(token) {\n  return token.type === TokenIdentifier || token.type === TokenKeyword || token.type === TokenBooleanLiteral || token.type === TokenNullLiteral;\n}\n\nfunction advance() {\n  skipComment();\n\n  if (index >= length) {\n    return {\n      type: TokenEOF,\n      start: index,\n      end: index\n    };\n  }\n\n  const ch = source.charCodeAt(index);\n\n  if (isIdentifierStart(ch)) {\n    return scanIdentifier();\n  } // Very common: ( and ) and ;\n\n\n  if (ch === 0x28 || ch === 0x29 || ch === 0x3B) {\n    return scanPunctuator();\n  } // String literal starts with single quote (U+0027) or double quote (U+0022).\n\n\n  if (ch === 0x27 || ch === 0x22) {\n    return scanStringLiteral();\n  } // Dot (.) U+002E can also start a floating-point number, hence the need\n  // to check the next character.\n\n\n  if (ch === 0x2E) {\n    if (isDecimalDigit(source.charCodeAt(index + 1))) {\n      return scanNumericLiteral();\n    }\n\n    return scanPunctuator();\n  }\n\n  if (isDecimalDigit(ch)) {\n    return scanNumericLiteral();\n  }\n\n  return scanPunctuator();\n}\n\nfunction lex() {\n  const token = lookahead;\n  index = token.end;\n  lookahead = advance();\n  index = token.end;\n  return token;\n}\n\nfunction peek() {\n  const pos = index;\n  lookahead = advance();\n  index = pos;\n}\n\nfunction finishArrayExpression(elements) {\n  const node = new ASTNode(SyntaxArrayExpression);\n  node.elements = elements;\n  return node;\n}\n\nfunction finishBinaryExpression(operator, left, right) {\n  const node = new ASTNode(operator === '||' || operator === '&&' ? SyntaxLogicalExpression : SyntaxBinaryExpression);\n  node.operator = operator;\n  node.left = left;\n  node.right = right;\n  return node;\n}\n\nfunction finishCallExpression(callee, args) {\n  const node = new ASTNode(SyntaxCallExpression);\n  node.callee = callee;\n  node.arguments = args;\n  return node;\n}\n\nfunction finishConditionalExpression(test, consequent, alternate) {\n  const node = new ASTNode(SyntaxConditionalExpression);\n  node.test = test;\n  node.consequent = consequent;\n  node.alternate = alternate;\n  return node;\n}\n\nfunction finishIdentifier(name) {\n  const node = new ASTNode(SyntaxIdentifier);\n  node.name = name;\n  return node;\n}\n\nfunction finishLiteral(token) {\n  const node = new ASTNode(SyntaxLiteral);\n  node.value = token.value;\n  node.raw = source.slice(token.start, token.end);\n\n  if (token.regex) {\n    if (node.raw === '//') {\n      node.raw = '/(?:)/';\n    }\n\n    node.regex = token.regex;\n  }\n\n  return node;\n}\n\nfunction finishMemberExpression(accessor, object, property) {\n  const node = new ASTNode(SyntaxMemberExpression);\n  node.computed = accessor === '[';\n  node.object = object;\n  node.property = property;\n  if (!node.computed) property.member = true;\n  return node;\n}\n\nfunction finishObjectExpression(properties) {\n  const node = new ASTNode(SyntaxObjectExpression);\n  node.properties = properties;\n  return node;\n}\n\nfunction finishProperty(kind, key, value) {\n  const node = new ASTNode(SyntaxProperty);\n  node.key = key;\n  node.value = value;\n  node.kind = kind;\n  return node;\n}\n\nfunction finishUnaryExpression(operator, argument) {\n  const node = new ASTNode(SyntaxUnaryExpression);\n  node.operator = operator;\n  node.argument = argument;\n  node.prefix = true;\n  return node;\n} // Throw an exception\n\n\nfunction throwError(token, messageFormat) {\n  var error,\n      args = Array.prototype.slice.call(arguments, 2),\n      msg = messageFormat.replace(/%(\\d)/g, (whole, index) => {\n    assert(index < args.length, 'Message reference must be in range');\n    return args[index];\n  });\n  error = new Error(msg);\n  error.index = index;\n  error.description = msg;\n  throw error;\n} // Throw an exception because of the token.\n\n\nfunction throwUnexpected(token) {\n  if (token.type === TokenEOF) {\n    throwError(token, MessageUnexpectedEOS);\n  }\n\n  if (token.type === TokenNumericLiteral) {\n    throwError(token, MessageUnexpectedNumber);\n  }\n\n  if (token.type === TokenStringLiteral) {\n    throwError(token, MessageUnexpectedString);\n  }\n\n  if (token.type === TokenIdentifier) {\n    throwError(token, MessageUnexpectedIdentifier);\n  }\n\n  if (token.type === TokenKeyword) {\n    throwError(token, MessageUnexpectedReserved);\n  } // BooleanLiteral, NullLiteral, or Punctuator.\n\n\n  throwError(token, MessageUnexpectedToken, token.value);\n} // Expect the next token to match the specified punctuator.\n// If not, an exception will be thrown.\n\n\nfunction expect(value) {\n  const token = lex();\n\n  if (token.type !== TokenPunctuator || token.value !== value) {\n    throwUnexpected(token);\n  }\n} // Return true if the next token matches the specified punctuator.\n\n\nfunction match(value) {\n  return lookahead.type === TokenPunctuator && lookahead.value === value;\n} // Return true if the next token matches the specified keyword\n\n\nfunction matchKeyword(keyword) {\n  return lookahead.type === TokenKeyword && lookahead.value === keyword;\n} // 11.1.4 Array Initialiser\n\n\nfunction parseArrayInitialiser() {\n  const elements = [];\n  index = lookahead.start;\n  expect('[');\n\n  while (!match(']')) {\n    if (match(',')) {\n      lex();\n      elements.push(null);\n    } else {\n      elements.push(parseConditionalExpression());\n\n      if (!match(']')) {\n        expect(',');\n      }\n    }\n  }\n\n  lex();\n  return finishArrayExpression(elements);\n} // 11.1.5 Object Initialiser\n\n\nfunction parseObjectPropertyKey() {\n  index = lookahead.start;\n  const token = lex(); // Note: This function is called only from parseObjectProperty(), where\n  // EOF and Punctuator tokens are already filtered out.\n\n  if (token.type === TokenStringLiteral || token.type === TokenNumericLiteral) {\n    if (token.octal) {\n      throwError(token, MessageStrictOctalLiteral);\n    }\n\n    return finishLiteral(token);\n  }\n\n  return finishIdentifier(token.value);\n}\n\nfunction parseObjectProperty() {\n  var token, key, id, value;\n  index = lookahead.start;\n  token = lookahead;\n\n  if (token.type === TokenIdentifier) {\n    id = parseObjectPropertyKey();\n    expect(':');\n    value = parseConditionalExpression();\n    return finishProperty('init', id, value);\n  }\n\n  if (token.type === TokenEOF || token.type === TokenPunctuator) {\n    throwUnexpected(token);\n  } else {\n    key = parseObjectPropertyKey();\n    expect(':');\n    value = parseConditionalExpression();\n    return finishProperty('init', key, value);\n  }\n}\n\nfunction parseObjectInitialiser() {\n  var properties = [],\n      property,\n      name,\n      key,\n      map = {},\n      toString = String;\n  index = lookahead.start;\n  expect('{');\n\n  while (!match('}')) {\n    property = parseObjectProperty();\n\n    if (property.key.type === SyntaxIdentifier) {\n      name = property.key.name;\n    } else {\n      name = toString(property.key.value);\n    }\n\n    key = '$' + name;\n\n    if (Object.prototype.hasOwnProperty.call(map, key)) {\n      throwError({}, MessageStrictDuplicateProperty);\n    } else {\n      map[key] = true;\n    }\n\n    properties.push(property);\n\n    if (!match('}')) {\n      expect(',');\n    }\n  }\n\n  expect('}');\n  return finishObjectExpression(properties);\n} // 11.1.6 The Grouping Operator\n\n\nfunction parseGroupExpression() {\n  expect('(');\n  const expr = parseExpression();\n  expect(')');\n  return expr;\n} // 11.1 Primary Expressions\n\n\nconst legalKeywords = {\n  'if': 1\n};\n\nfunction parsePrimaryExpression() {\n  var type, token, expr;\n\n  if (match('(')) {\n    return parseGroupExpression();\n  }\n\n  if (match('[')) {\n    return parseArrayInitialiser();\n  }\n\n  if (match('{')) {\n    return parseObjectInitialiser();\n  }\n\n  type = lookahead.type;\n  index = lookahead.start;\n\n  if (type === TokenIdentifier || legalKeywords[lookahead.value]) {\n    expr = finishIdentifier(lex().value);\n  } else if (type === TokenStringLiteral || type === TokenNumericLiteral) {\n    if (lookahead.octal) {\n      throwError(lookahead, MessageStrictOctalLiteral);\n    }\n\n    expr = finishLiteral(lex());\n  } else if (type === TokenKeyword) {\n    throw new Error(DISABLED);\n  } else if (type === TokenBooleanLiteral) {\n    token = lex();\n    token.value = token.value === 'true';\n    expr = finishLiteral(token);\n  } else if (type === TokenNullLiteral) {\n    token = lex();\n    token.value = null;\n    expr = finishLiteral(token);\n  } else if (match('/') || match('/=')) {\n    expr = finishLiteral(scanRegExp());\n    peek();\n  } else {\n    throwUnexpected(lex());\n  }\n\n  return expr;\n} // 11.2 Left-Hand-Side Expressions\n\n\nfunction parseArguments() {\n  const args = [];\n  expect('(');\n\n  if (!match(')')) {\n    while (index < length) {\n      args.push(parseConditionalExpression());\n\n      if (match(')')) {\n        break;\n      }\n\n      expect(',');\n    }\n  }\n\n  expect(')');\n  return args;\n}\n\nfunction parseNonComputedProperty() {\n  index = lookahead.start;\n  const token = lex();\n\n  if (!isIdentifierName(token)) {\n    throwUnexpected(token);\n  }\n\n  return finishIdentifier(token.value);\n}\n\nfunction parseNonComputedMember() {\n  expect('.');\n  return parseNonComputedProperty();\n}\n\nfunction parseComputedMember() {\n  expect('[');\n  const expr = parseExpression();\n  expect(']');\n  return expr;\n}\n\nfunction parseLeftHandSideExpressionAllowCall() {\n  var expr, args, property;\n  expr = parsePrimaryExpression();\n\n  for (;;) {\n    if (match('.')) {\n      property = parseNonComputedMember();\n      expr = finishMemberExpression('.', expr, property);\n    } else if (match('(')) {\n      args = parseArguments();\n      expr = finishCallExpression(expr, args);\n    } else if (match('[')) {\n      property = parseComputedMember();\n      expr = finishMemberExpression('[', expr, property);\n    } else {\n      break;\n    }\n  }\n\n  return expr;\n} // 11.3 Postfix Expressions\n\n\nfunction parsePostfixExpression() {\n  const expr = parseLeftHandSideExpressionAllowCall();\n\n  if (lookahead.type === TokenPunctuator) {\n    if (match('++') || match('--')) {\n      throw new Error(DISABLED);\n    }\n  }\n\n  return expr;\n} // 11.4 Unary Operators\n\n\nfunction parseUnaryExpression() {\n  var token, expr;\n\n  if (lookahead.type !== TokenPunctuator && lookahead.type !== TokenKeyword) {\n    expr = parsePostfixExpression();\n  } else if (match('++') || match('--')) {\n    throw new Error(DISABLED);\n  } else if (match('+') || match('-') || match('~') || match('!')) {\n    token = lex();\n    expr = parseUnaryExpression();\n    expr = finishUnaryExpression(token.value, expr);\n  } else if (matchKeyword('delete') || matchKeyword('void') || matchKeyword('typeof')) {\n    throw new Error(DISABLED);\n  } else {\n    expr = parsePostfixExpression();\n  }\n\n  return expr;\n}\n\nfunction binaryPrecedence(token) {\n  let prec = 0;\n\n  if (token.type !== TokenPunctuator && token.type !== TokenKeyword) {\n    return 0;\n  }\n\n  switch (token.value) {\n    case '||':\n      prec = 1;\n      break;\n\n    case '&&':\n      prec = 2;\n      break;\n\n    case '|':\n      prec = 3;\n      break;\n\n    case '^':\n      prec = 4;\n      break;\n\n    case '&':\n      prec = 5;\n      break;\n\n    case '==':\n    case '!=':\n    case '===':\n    case '!==':\n      prec = 6;\n      break;\n\n    case '<':\n    case '>':\n    case '<=':\n    case '>=':\n    case 'instanceof':\n    case 'in':\n      prec = 7;\n      break;\n\n    case '<<':\n    case '>>':\n    case '>>>':\n      prec = 8;\n      break;\n\n    case '+':\n    case '-':\n      prec = 9;\n      break;\n\n    case '*':\n    case '/':\n    case '%':\n      prec = 11;\n      break;\n  }\n\n  return prec;\n} // 11.5 Multiplicative Operators\n// 11.6 Additive Operators\n// 11.7 Bitwise Shift Operators\n// 11.8 Relational Operators\n// 11.9 Equality Operators\n// 11.10 Binary Bitwise Operators\n// 11.11 Binary Logical Operators\n\n\nfunction parseBinaryExpression() {\n  var marker, markers, expr, token, prec, stack, right, operator, left, i;\n  marker = lookahead;\n  left = parseUnaryExpression();\n  token = lookahead;\n  prec = binaryPrecedence(token);\n\n  if (prec === 0) {\n    return left;\n  }\n\n  token.prec = prec;\n  lex();\n  markers = [marker, lookahead];\n  right = parseUnaryExpression();\n  stack = [left, token, right];\n\n  while ((prec = binaryPrecedence(lookahead)) > 0) {\n    // Reduce: make a binary expression from the three topmost entries.\n    while (stack.length > 2 && prec <= stack[stack.length - 2].prec) {\n      right = stack.pop();\n      operator = stack.pop().value;\n      left = stack.pop();\n      markers.pop();\n      expr = finishBinaryExpression(operator, left, right);\n      stack.push(expr);\n    } // Shift.\n\n\n    token = lex();\n    token.prec = prec;\n    stack.push(token);\n    markers.push(lookahead);\n    expr = parseUnaryExpression();\n    stack.push(expr);\n  } // Final reduce to clean-up the stack.\n\n\n  i = stack.length - 1;\n  expr = stack[i];\n  markers.pop();\n\n  while (i > 1) {\n    markers.pop();\n    expr = finishBinaryExpression(stack[i - 1].value, stack[i - 2], expr);\n    i -= 2;\n  }\n\n  return expr;\n} // 11.12 Conditional Operator\n\n\nfunction parseConditionalExpression() {\n  var expr, consequent, alternate;\n  expr = parseBinaryExpression();\n\n  if (match('?')) {\n    lex();\n    consequent = parseConditionalExpression();\n    expect(':');\n    alternate = parseConditionalExpression();\n    expr = finishConditionalExpression(expr, consequent, alternate);\n  }\n\n  return expr;\n} // 11.14 Comma Operator\n\n\nfunction parseExpression() {\n  const expr = parseConditionalExpression();\n\n  if (match(',')) {\n    throw new Error(DISABLED); // no sequence expressions\n  }\n\n  return expr;\n}\n\nfunction parser (code) {\n  source = code;\n  index = 0;\n  length = source.length;\n  lookahead = null;\n  peek();\n  const expr = parseExpression();\n\n  if (lookahead.type !== TokenEOF) {\n    throw new Error('Unexpect token after expression.');\n  }\n\n  return expr;\n}\n\nvar Constants = {\n  NaN: 'NaN',\n  E: 'Math.E',\n  LN2: 'Math.LN2',\n  LN10: 'Math.LN10',\n  LOG2E: 'Math.LOG2E',\n  LOG10E: 'Math.LOG10E',\n  PI: 'Math.PI',\n  SQRT1_2: 'Math.SQRT1_2',\n  SQRT2: 'Math.SQRT2',\n  MIN_VALUE: 'Number.MIN_VALUE',\n  MAX_VALUE: 'Number.MAX_VALUE'\n};\n\nfunction Functions (codegen) {\n  function fncall(name, args, cast, type) {\n    let obj = codegen(args[0]);\n\n    if (cast) {\n      obj = cast + '(' + obj + ')';\n      if (cast.lastIndexOf('new ', 0) === 0) obj = '(' + obj + ')';\n    }\n\n    return obj + '.' + name + (type < 0 ? '' : type === 0 ? '()' : '(' + args.slice(1).map(codegen).join(',') + ')');\n  }\n\n  function fn(name, cast, type) {\n    return args => fncall(name, args, cast, type);\n  }\n\n  const DATE = 'new Date',\n        STRING = 'String',\n        REGEXP = 'RegExp';\n  return {\n    // MATH functions\n    isNaN: 'Number.isNaN',\n    isFinite: 'Number.isFinite',\n    abs: 'Math.abs',\n    acos: 'Math.acos',\n    asin: 'Math.asin',\n    atan: 'Math.atan',\n    atan2: 'Math.atan2',\n    ceil: 'Math.ceil',\n    cos: 'Math.cos',\n    exp: 'Math.exp',\n    floor: 'Math.floor',\n    log: 'Math.log',\n    max: 'Math.max',\n    min: 'Math.min',\n    pow: 'Math.pow',\n    random: 'Math.random',\n    round: 'Math.round',\n    sin: 'Math.sin',\n    sqrt: 'Math.sqrt',\n    tan: 'Math.tan',\n    clamp: function (args) {\n      if (args.length < 3) error('Missing arguments to clamp function.');\n      if (args.length > 3) error('Too many arguments to clamp function.');\n      const a = args.map(codegen);\n      return 'Math.max(' + a[1] + ', Math.min(' + a[2] + ',' + a[0] + '))';\n    },\n    // DATE functions\n    now: 'Date.now',\n    utc: 'Date.UTC',\n    datetime: DATE,\n    date: fn('getDate', DATE, 0),\n    day: fn('getDay', DATE, 0),\n    year: fn('getFullYear', DATE, 0),\n    month: fn('getMonth', DATE, 0),\n    hours: fn('getHours', DATE, 0),\n    minutes: fn('getMinutes', DATE, 0),\n    seconds: fn('getSeconds', DATE, 0),\n    milliseconds: fn('getMilliseconds', DATE, 0),\n    time: fn('getTime', DATE, 0),\n    timezoneoffset: fn('getTimezoneOffset', DATE, 0),\n    utcdate: fn('getUTCDate', DATE, 0),\n    utcday: fn('getUTCDay', DATE, 0),\n    utcyear: fn('getUTCFullYear', DATE, 0),\n    utcmonth: fn('getUTCMonth', DATE, 0),\n    utchours: fn('getUTCHours', DATE, 0),\n    utcminutes: fn('getUTCMinutes', DATE, 0),\n    utcseconds: fn('getUTCSeconds', DATE, 0),\n    utcmilliseconds: fn('getUTCMilliseconds', DATE, 0),\n    // sequence functions\n    length: fn('length', null, -1),\n    join: fn('join', null),\n    indexof: fn('indexOf', null),\n    lastindexof: fn('lastIndexOf', null),\n    slice: fn('slice', null),\n    reverse: function (args) {\n      return '(' + codegen(args[0]) + ').slice().reverse()';\n    },\n    // STRING functions\n    parseFloat: 'parseFloat',\n    parseInt: 'parseInt',\n    upper: fn('toUpperCase', STRING, 0),\n    lower: fn('toLowerCase', STRING, 0),\n    substring: fn('substring', STRING),\n    split: fn('split', STRING),\n    replace: fn('replace', STRING),\n    trim: fn('trim', STRING, 0),\n    // REGEXP functions\n    regexp: REGEXP,\n    test: fn('test', REGEXP),\n    // Control Flow functions\n    if: function (args) {\n      if (args.length < 3) error('Missing arguments to if function.');\n      if (args.length > 3) error('Too many arguments to if function.');\n      const a = args.map(codegen);\n      return '(' + a[0] + '?' + a[1] + ':' + a[2] + ')';\n    }\n  };\n}\n\nfunction stripQuotes(s) {\n  const n = s && s.length - 1;\n  return n && (s[0] === '\"' && s[n] === '\"' || s[0] === '\\'' && s[n] === '\\'') ? s.slice(1, -1) : s;\n}\n\nfunction codegen (opt) {\n  opt = opt || {};\n  const allowed = opt.allowed ? toSet(opt.allowed) : {},\n        forbidden = opt.forbidden ? toSet(opt.forbidden) : {},\n        constants = opt.constants || Constants,\n        functions = (opt.functions || Functions)(visit),\n        globalvar = opt.globalvar,\n        fieldvar = opt.fieldvar,\n        outputGlobal = isFunction(globalvar) ? globalvar : id => \"\".concat(globalvar, \"[\\\"\").concat(id, \"\\\"]\");\n  let globals = {},\n      fields = {},\n      memberDepth = 0;\n\n  function visit(ast) {\n    if (isString(ast)) return ast;\n    const generator = Generators[ast.type];\n    if (generator == null) error('Unsupported type: ' + ast.type);\n    return generator(ast);\n  }\n\n  const Generators = {\n    Literal: n => n.raw,\n    Identifier: n => {\n      const id = n.name;\n\n      if (memberDepth > 0) {\n        return id;\n      } else if (hasOwnProperty(forbidden, id)) {\n        return error('Illegal identifier: ' + id);\n      } else if (hasOwnProperty(constants, id)) {\n        return constants[id];\n      } else if (hasOwnProperty(allowed, id)) {\n        return id;\n      } else {\n        globals[id] = 1;\n        return outputGlobal(id);\n      }\n    },\n    MemberExpression: n => {\n      const d = !n.computed,\n            o = visit(n.object);\n      if (d) memberDepth += 1;\n      const p = visit(n.property);\n\n      if (o === fieldvar) {\n        // strip quotes to sanitize field name (#1653)\n        fields[stripQuotes(p)] = 1;\n      }\n\n      if (d) memberDepth -= 1;\n      return o + (d ? '.' + p : '[' + p + ']');\n    },\n    CallExpression: n => {\n      if (n.callee.type !== 'Identifier') {\n        error('Illegal callee type: ' + n.callee.type);\n      }\n\n      const callee = n.callee.name,\n            args = n.arguments,\n            fn = hasOwnProperty(functions, callee) && functions[callee];\n      if (!fn) error('Unrecognized function: ' + callee);\n      return isFunction(fn) ? fn(args) : fn + '(' + args.map(visit).join(',') + ')';\n    },\n    ArrayExpression: n => '[' + n.elements.map(visit).join(',') + ']',\n    BinaryExpression: n => '(' + visit(n.left) + ' ' + n.operator + ' ' + visit(n.right) + ')',\n    UnaryExpression: n => '(' + n.operator + visit(n.argument) + ')',\n    ConditionalExpression: n => '(' + visit(n.test) + '?' + visit(n.consequent) + ':' + visit(n.alternate) + ')',\n    LogicalExpression: n => '(' + visit(n.left) + n.operator + visit(n.right) + ')',\n    ObjectExpression: n => '{' + n.properties.map(visit).join(',') + '}',\n    Property: n => {\n      memberDepth += 1;\n      const k = visit(n.key);\n      memberDepth -= 1;\n      return k + ':' + visit(n.value);\n    }\n  };\n\n  function codegen(ast) {\n    const result = {\n      code: visit(ast),\n      globals: Object.keys(globals),\n      fields: Object.keys(fields)\n    };\n    globals = {};\n    fields = {};\n    return result;\n  }\n\n  codegen.functions = functions;\n  codegen.constants = constants;\n  return codegen;\n}\n\nexport { ASTNode, ArrayExpression, BinaryExpression, CallExpression, ConditionalExpression, Identifier, Literal, LogicalExpression, MemberExpression, ObjectExpression, Property, RawCode, UnaryExpression, codegen, Constants as constants, Functions as functions, parser as parse };\n"],"sourceRoot":""}